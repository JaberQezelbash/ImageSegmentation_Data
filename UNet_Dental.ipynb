{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30fd6712-1e22-4294-9a8c-f5683b765da0",
   "metadata": {},
   "source": [
    "* UNet architecture\n",
    "* Latest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd2aa2c-790b-4da0-a507-bd0df903964c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 17:00:44\n",
      "Accuracy: 0.8921 - Precision: 0.0296 - Recall: 0.0980 - Specificity: 0.9135 - F1: 0.0455 - Loss: 0.1255\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 17:01:24\n",
      "Accuracy: 0.9314 - Precision: 0.0148 - Recall: 0.0490 - Specificity: 0.9568 - F1: 0.0227 - Loss: 0.1055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import backend as K\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Directory paths\n",
    "train_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\train\"\n",
    "train_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\train\\train_mask\"\n",
    "test_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\test\"\n",
    "test_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\test\\test_mask\"\n",
    "valid_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\valid\"\n",
    "valid_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\valid\\valid_mask\"\n",
    "\n",
    "# Image generator to load data in batches\n",
    "def image_generator(img_dir, mask_dir, batch_size, img_size=(256, 256)):\n",
    "    img_files = os.listdir(img_dir)\n",
    "    while True:\n",
    "        images = []\n",
    "        masks = []\n",
    "        for img_file in img_files:\n",
    "            img_path = os.path.join(img_dir, img_file)\n",
    "            mask_file = img_file + \"_mask.png\"\n",
    "            mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "            if os.path.exists(mask_path):\n",
    "                # Load image and mask\n",
    "                img = load_img(img_path, color_mode='rgb', target_size=img_size)\n",
    "                img = img_to_array(img) / 255.0\n",
    "                mask = load_img(mask_path, color_mode='grayscale', target_size=img_size)\n",
    "                mask = img_to_array(mask) / 255.0\n",
    "\n",
    "                images.append(img)\n",
    "                masks.append(mask)\n",
    "\n",
    "            if len(images) == batch_size:\n",
    "                yield np.array(images), np.array(masks)\n",
    "                images = []\n",
    "                masks = []\n",
    "\n",
    "# U-Net Model\n",
    "def unet_model(input_size=(256, 256, 3)):\n",
    "    inputs = tf.keras.layers.Input(input_size)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    c1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(c1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c1)\n",
    "\n",
    "    c2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(p1)\n",
    "    c2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(c2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c2)\n",
    "\n",
    "    c3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(p2)\n",
    "    c3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(c3)\n",
    "    p3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c3)\n",
    "\n",
    "    c4 = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same')(p3)\n",
    "    c4 = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same')(c4)\n",
    "    p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    b = tf.keras.layers.Conv2D(1024, 3, activation='relu', padding='same')(p4)\n",
    "    b = tf.keras.layers.Conv2D(1024, 3, activation='relu', padding='same')(b)\n",
    "\n",
    "    # Decoder\n",
    "    u1 = tf.keras.layers.Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(b)\n",
    "    u1 = tf.keras.layers.concatenate([u1, c4])\n",
    "    c5 = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same')(u1)\n",
    "    c5 = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same')(c5)\n",
    "\n",
    "    u2 = tf.keras.layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(c5)\n",
    "    u2 = tf.keras.layers.concatenate([u2, c3])\n",
    "    c6 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(u2)\n",
    "    c6 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same')(c6)\n",
    "\n",
    "    u3 = tf.keras.layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(c6)\n",
    "    u3 = tf.keras.layers.concatenate([u3, c2])\n",
    "    c7 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(u3)\n",
    "    c7 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(c7)\n",
    "\n",
    "    u4 = tf.keras.layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(c7)\n",
    "    u4 = tf.keras.layers.concatenate([u4, c1])\n",
    "    c8 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(u4)\n",
    "    c8 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(c8)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(c8)\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Define custom metrics\n",
    "def custom_precision(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_positives = K.sum(K.round(y_true * y_pred_bin))\n",
    "    predicted_positives = K.sum(y_pred_bin)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def custom_recall(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_positives = K.sum(K.round(y_true * y_pred_bin))\n",
    "    possible_positives = K.sum(y_true)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def custom_specificity(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_negatives = K.sum(K.round((1 - y_true) * (1 - y_pred_bin)))\n",
    "    possible_negatives = K.sum(1 - y_true)\n",
    "    specificity = true_negatives / (possible_negatives + K.epsilon())\n",
    "    return specificity\n",
    "\n",
    "def custom_f1(y_true, y_pred):\n",
    "    precision = custom_precision(y_true, y_pred)\n",
    "    recall = custom_recall(y_true, y_pred)\n",
    "    return 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "\n",
    "# Define Focal Loss\n",
    "def focal_loss_fixed(y_true, y_pred):\n",
    "    gamma = 2.0\n",
    "    alpha = 0.25\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    cross_entropy = -y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred)\n",
    "    weight = alpha * y_true * K.pow((1 - y_pred), gamma) + (1 - alpha) * (1 - y_true) * K.pow(y_pred, gamma)\n",
    "    loss = weight * cross_entropy\n",
    "    return K.mean(loss)\n",
    "\n",
    "# Compile the model\n",
    "model = unet_model()\n",
    "model.compile(optimizer='adam', loss=focal_loss_fixed, metrics=['accuracy', custom_precision, custom_recall, custom_specificity, custom_f1])\n",
    "\n",
    "# Batch size for training\n",
    "batch_size = 16\n",
    "\n",
    "# Create data generators\n",
    "train_gen = image_generator(train_img_dir, train_mask_dir, batch_size)\n",
    "valid_gen = image_generator(valid_img_dir, valid_mask_dir, batch_size)\n",
    "test_gen = image_generator(test_img_dir, test_mask_dir, batch_size)\n",
    "\n",
    "# Number of steps per epoch\n",
    "steps_per_epoch = len(os.listdir(train_img_dir)) // batch_size\n",
    "validation_steps = len(os.listdir(valid_img_dir)) // batch_size\n",
    "test_steps = len(os.listdir(test_img_dir)) // batch_size\n",
    "\n",
    "# Custom callback to print more metrics at each batch and epoch for training, validation, and test sets\n",
    "class MetricsCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, total_batches, X_valid, y_valid, X_test, y_test):\n",
    "        super().__init__()\n",
    "        self.batch_counter = 1\n",
    "        self.total_batches = total_batches\n",
    "        self.current_epoch = 1\n",
    "        self.X_valid = X_valid\n",
    "        self.y_valid = y_valid\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.current_epoch = epoch + 1\n",
    "        print(f\"\\nEpoch {self.current_epoch}/{self.params['epochs']}\")\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        accuracy = logs.get('accuracy', 0)\n",
    "        loss = logs.get('loss', 0)\n",
    "        precision = logs.get('custom_precision', 0)\n",
    "        recall = logs.get('custom_recall', 0)\n",
    "        f1 = logs.get('custom_f1', 0)\n",
    "        specificity = logs.get('custom_specificity', 0)\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print(f\"Batch {self.batch_counter}/{self.total_batches} ━━━━━━━━━━━━━━━━━━━━ {current_time}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f} - Precision: {precision:.4f} - Recall: {recall:.4f} - Specificity: {specificity:.4f} - F1: {f1:.4f} - Loss: {loss:.4f}\\n\")\n",
    "        self.batch_counter += 1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        accuracy = logs.get('accuracy', 0)\n",
    "        val_accuracy = logs.get('val_accuracy', 0)\n",
    "        loss = logs.get('loss', 0)\n",
    "        val_loss = logs.get('val_loss', 0)\n",
    "        precision = logs.get('custom_precision', 0)\n",
    "        val_precision = logs.get('val_custom_precision', 0)\n",
    "        recall = logs.get('custom_recall', 0)\n",
    "        val_recall = logs.get('val_custom_recall', 0)\n",
    "        f1 = logs.get('custom_f1', 0)\n",
    "        val_f1 = logs.get('val_custom_f1', 0)\n",
    "        specificity = logs.get('custom_specificity', 0)\n",
    "        val_specificity = logs.get('val_custom_specificity', 0)\n",
    "        print(f\"Epoch {epoch+1}/{self.params['epochs']}\")\n",
    "        print(f\"Train - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Specificity: {specificity:.4f}, F1: {f1:.4f}, Loss: {loss:.4f}\")\n",
    "        print(f\"Validation - Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, Specificity: {val_specificity:.4f}, F1: {val_f1:.4f}, Loss: {val_loss:.4f}\\n\")\n",
    "        test_loss, test_accuracy, test_precision, test_recall, test_specificity, test_f1 = self.model.evaluate(self.X_test, self.y_test, verbose=0)\n",
    "        print(f\"Test Set Results - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, Specificity: {test_specificity:.4f}, F1: {test_f1:.4f}, Loss: {test_loss:.4f}\\n\")\n",
    "        self.batch_counter = 1\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Initialize the custom callback with validation and test data\n",
    "metrics_callback = MetricsCallback(total_batches=steps_per_epoch, X_valid=valid_gen, y_valid=valid_gen, X_test=test_gen, y_test=test_gen)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=20,\n",
    "    validation_data=valid_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[metrics_callback, early_stopping],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('dental_xray_unet_model.h5')\n",
    "\n",
    "# Evaluate on the training set\n",
    "train_gen_full = image_generator(train_img_dir, train_mask_dir, batch_size)\n",
    "y_train_pred = model.predict(train_gen_full, steps=steps_per_epoch)\n",
    "y_train_pred_bin = (y_train_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "# Confusion Matrix for training\n",
    "conf_matrix_train = confusion_matrix(y_train_pred_bin.flatten(), y_train_pred_bin.flatten())\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_train, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix for Train\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix for validation set\n",
    "y_valid_pred = model.predict(valid_gen, steps=validation_steps)\n",
    "y_valid_pred_bin = (y_valid_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "conf_matrix_valid = confusion_matrix(y_valid_pred_bin.flatten(), y_valid_pred_bin.flatten())\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_valid, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix for Validation\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix for test set\n",
    "y_test_pred = model.predict(test_gen, steps=test_steps)\n",
    "y_test_pred_bin = (y_test_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "conf_matrix_test = confusion_matrix(y_test_pred_bin.flatten(), y_test_pred_bin.flatten())\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_test, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix for Test\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization: Show input image, true mask, and predicted mask for a few samples\n",
    "def visualize_predictions(images, true_masks, pred_masks, title):\n",
    "    for i in range(3):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(true_masks[i].squeeze(), cmap='gray')\n",
    "        plt.title('Ground Truth Mask')\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(pred_masks[i].squeeze(), cmap='gray')\n",
    "        plt.title('Predicted Mask')\n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "\n",
    "# Visualize predictions for training set\n",
    "visualize_predictions(X_train, y_train, y_train_pred_bin, \"Train Set Predictions\")\n",
    "\n",
    "# Visualize predictions for validation set\n",
    "visualize_predictions(X_valid, y_valid, y_valid_pred_bin, \"Validation Set Predictions\")\n",
    "\n",
    "# Visualize predictions for test set\n",
    "visualize_predictions(X_test, y_test, y_test_pred_bin, \"Test Set Predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7978ff-c9ef-4529-bebc-db8fbcc87c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
