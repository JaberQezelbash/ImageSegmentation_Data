{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e54f3a5-8dbb-4713-b8f2-a308f199c978",
   "metadata": {},
   "source": [
    "* VGG16 architecture\n",
    "* Latest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d21be30-7d32-45a5-8dd1-a781f7af43bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 17:27:31\n",
      "Accuracy: 0.3463 - Precision: 0.0261 - Recall: 0.6575 - Specificity: 0.3379 - F1: 0.0502 - Loss: 0.3124\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 17:27:40\n",
      "Accuracy: 0.6158 - Precision: 0.0299 - Recall: 0.3813 - Specificity: 0.6234 - F1: 0.0506 - Loss: 0.1795\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 17:27:48\n",
      "Accuracy: 0.7330 - Precision: 0.0199 - Recall: 0.2542 - Specificity: 0.7484 - F1: 0.0338 - Loss: 0.1301\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 17:27:56\n",
      "Accuracy: 0.7953 - Precision: 0.0150 - Recall: 0.1906 - Specificity: 0.8110 - F1: 0.0253 - Loss: 0.1020\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 17:28:05\n",
      "Accuracy: 0.8329 - Precision: 0.0120 - Recall: 0.1525 - Specificity: 0.8487 - F1: 0.0203 - Loss: 0.0850\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 17:28:14\n",
      "Accuracy: 0.8568 - Precision: 0.0100 - Recall: 0.1271 - Specificity: 0.8739 - F1: 0.0169 - Loss: 0.0749\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 17:28:25\n",
      "Accuracy: 0.8752 - Precision: 0.0085 - Recall: 0.1089 - Specificity: 0.8919 - F1: 0.0145 - Loss: 0.0660\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 17:28:35\n",
      "Accuracy: 0.8886 - Precision: 0.0075 - Recall: 0.0953 - Specificity: 0.9054 - F1: 0.0127 - Loss: 0.0595\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 17:28:44\n",
      "Accuracy: 0.8992 - Precision: 0.0066 - Recall: 0.0847 - Specificity: 0.9159 - F1: 0.0113 - Loss: 0.0542\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 17:28:52\n",
      "Accuracy: 0.9076 - Precision: 0.0060 - Recall: 0.0763 - Specificity: 0.9243 - F1: 0.0101 - Loss: 0.0499\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 17:29:01\n",
      "Accuracy: 0.9144 - Precision: 0.0054 - Recall: 0.0693 - Specificity: 0.9312 - F1: 0.0092 - Loss: 0.0463\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 17:29:09\n",
      "Accuracy: 0.9200 - Precision: 0.0050 - Recall: 0.0635 - Specificity: 0.9369 - F1: 0.0084 - Loss: 0.0433\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 17:29:18\n",
      "Accuracy: 0.9247 - Precision: 0.0046 - Recall: 0.0587 - Specificity: 0.9418 - F1: 0.0078 - Loss: 0.0407\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 17:29:26\n",
      "Accuracy: 0.9289 - Precision: 0.0043 - Recall: 0.0545 - Specificity: 0.9459 - F1: 0.0072 - Loss: 0.0385\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 17:29:34\n",
      "Accuracy: 0.9324 - Precision: 0.0040 - Recall: 0.0508 - Specificity: 0.9496 - F1: 0.0068 - Loss: 0.0366\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 17:29:43\n",
      "Accuracy: 0.9350 - Precision: 0.0037 - Recall: 0.0477 - Specificity: 0.9527 - F1: 0.0063 - Loss: 0.0351\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 17:29:51\n",
      "Accuracy: 0.9379 - Precision: 0.0035 - Recall: 0.0449 - Specificity: 0.9555 - F1: 0.0060 - Loss: 0.0336\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 17:30:00\n",
      "Accuracy: 0.9401 - Precision: 0.0033 - Recall: 0.0424 - Specificity: 0.9580 - F1: 0.0056 - Loss: 0.0323\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 17:30:08\n",
      "Accuracy: 0.9422 - Precision: 0.0031 - Recall: 0.0401 - Specificity: 0.9602 - F1: 0.0053 - Loss: 0.0310\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 17:30:16\n",
      "Accuracy: 0.9443 - Precision: 0.0030 - Recall: 0.0381 - Specificity: 0.9622 - F1: 0.0051 - Loss: 0.0299\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 17:30:24\n",
      "Accuracy: 0.9460 - Precision: 0.0028 - Recall: 0.0363 - Specificity: 0.9640 - F1: 0.0048 - Loss: 0.0289\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 17:30:34\n",
      "Accuracy: 0.9473 - Precision: 0.0027 - Recall: 0.0347 - Specificity: 0.9656 - F1: 0.0046 - Loss: 0.0280\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 17:30:44\n",
      "Accuracy: 0.9487 - Precision: 0.0026 - Recall: 0.0332 - Specificity: 0.9671 - F1: 0.0044 - Loss: 0.0271\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 17:30:57\n",
      "Accuracy: 0.9498 - Precision: 0.0025 - Recall: 0.0318 - Specificity: 0.9685 - F1: 0.0042 - Loss: 0.0263\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 17:31:09\n",
      "Accuracy: 0.9510 - Precision: 0.0024 - Recall: 0.0305 - Specificity: 0.9697 - F1: 0.0041 - Loss: 0.0255\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 17:31:18\n",
      "Accuracy: 0.9523 - Precision: 0.0023 - Recall: 0.0293 - Specificity: 0.9709 - F1: 0.0039 - Loss: 0.0248\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 17:31:28\n",
      "Accuracy: 0.9532 - Precision: 0.0022 - Recall: 0.0282 - Specificity: 0.9720 - F1: 0.0038 - Loss: 0.0241\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 17:31:36\n",
      "Accuracy: 0.9541 - Precision: 0.0021 - Recall: 0.0272 - Specificity: 0.9730 - F1: 0.0036 - Loss: 0.0235\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 17:31:44\n",
      "Accuracy: 0.9547 - Precision: 0.0021 - Recall: 0.0263 - Specificity: 0.9739 - F1: 0.0035 - Loss: 0.0232\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 17:31:52\n",
      "Accuracy: 0.9555 - Precision: 0.0020 - Recall: 0.0254 - Specificity: 0.9748 - F1: 0.0034 - Loss: 0.0226\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 17:32:00\n",
      "Accuracy: 0.9564 - Precision: 0.0019 - Recall: 0.0246 - Specificity: 0.9756 - F1: 0.0033 - Loss: 0.0221\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 17:32:09\n",
      "Accuracy: 0.9571 - Precision: 0.0019 - Recall: 0.0238 - Specificity: 0.9764 - F1: 0.0032 - Loss: 0.0218\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 17:32:18\n",
      "Accuracy: 0.9578 - Precision: 0.0018 - Recall: 0.0231 - Specificity: 0.9771 - F1: 0.0031 - Loss: 0.0213\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 17:32:26\n",
      "Accuracy: 0.9582 - Precision: 0.0018 - Recall: 0.0224 - Specificity: 0.9777 - F1: 0.0030 - Loss: 0.0209\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 17:32:35\n",
      "Accuracy: 0.9588 - Precision: 0.0017 - Recall: 0.0218 - Specificity: 0.9784 - F1: 0.0029 - Loss: 0.0206\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 17:32:43\n",
      "Accuracy: 0.9594 - Precision: 0.0017 - Recall: 0.0212 - Specificity: 0.9790 - F1: 0.0028 - Loss: 0.0202\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 17:32:53\n",
      "Accuracy: 0.9599 - Precision: 0.0016 - Recall: 0.0206 - Specificity: 0.9795 - F1: 0.0027 - Loss: 0.0198\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 17:33:03\n",
      "Accuracy: 0.9604 - Precision: 0.0016 - Recall: 0.0201 - Specificity: 0.9801 - F1: 0.0027 - Loss: 0.0195\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 17:33:19\n",
      "Accuracy: 0.9608 - Precision: 0.0015 - Recall: 0.0196 - Specificity: 0.9806 - F1: 0.0026 - Loss: 0.0192\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 17:33:29\n",
      "Accuracy: 0.9612 - Precision: 0.0015 - Recall: 0.0191 - Specificity: 0.9811 - F1: 0.0025 - Loss: 0.0189\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 17:33:38\n",
      "Accuracy: 0.9615 - Precision: 0.0015 - Recall: 0.0186 - Specificity: 0.9815 - F1: 0.0025 - Loss: 0.0186\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 17:33:47\n",
      "Accuracy: 0.9618 - Precision: 0.0014 - Recall: 0.0182 - Specificity: 0.9820 - F1: 0.0024 - Loss: 0.0183\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 17:33:56\n",
      "Accuracy: 0.9622 - Precision: 0.0014 - Recall: 0.0177 - Specificity: 0.9824 - F1: 0.0024 - Loss: 0.0181\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 17:34:05\n",
      "Accuracy: 0.9627 - Precision: 0.0014 - Recall: 0.0173 - Specificity: 0.9828 - F1: 0.0023 - Loss: 0.0178\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 17:34:14\n",
      "Accuracy: 0.9631 - Precision: 0.0013 - Recall: 0.0169 - Specificity: 0.9832 - F1: 0.0023 - Loss: 0.0175\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 17:34:23\n",
      "Accuracy: 0.9634 - Precision: 0.0013 - Recall: 0.0166 - Specificity: 0.9835 - F1: 0.0022 - Loss: 0.0173\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 17:34:31\n",
      "Accuracy: 0.9637 - Precision: 0.0013 - Recall: 0.0162 - Specificity: 0.9839 - F1: 0.0022 - Loss: 0.0170\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 17:34:40\n",
      "Accuracy: 0.9639 - Precision: 0.0012 - Recall: 0.0159 - Specificity: 0.9842 - F1: 0.0021 - Loss: 0.0168\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 17:34:49\n",
      "Accuracy: 0.9642 - Precision: 0.0012 - Recall: 0.0156 - Specificity: 0.9846 - F1: 0.0021 - Loss: 0.0166\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 17:35:00\n",
      "Accuracy: 0.9644 - Precision: 0.0012 - Recall: 0.0153 - Specificity: 0.9849 - F1: 0.0020 - Loss: 0.0164\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 17:35:10\n",
      "Accuracy: 0.9647 - Precision: 0.0012 - Recall: 0.0150 - Specificity: 0.9852 - F1: 0.0020 - Loss: 0.0162\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 17:35:19\n",
      "Accuracy: 0.9650 - Precision: 0.0012 - Recall: 0.0147 - Specificity: 0.9854 - F1: 0.0019 - Loss: 0.0160\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 17:35:28\n",
      "Accuracy: 0.9653 - Precision: 0.0011 - Recall: 0.0144 - Specificity: 0.9857 - F1: 0.0019 - Loss: 0.0158\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 17:35:36\n",
      "Accuracy: 0.9656 - Precision: 0.0011 - Recall: 0.0141 - Specificity: 0.9860 - F1: 0.0019 - Loss: 0.0156\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 17:35:46\n",
      "Accuracy: 0.9658 - Precision: 0.0011 - Recall: 0.0139 - Specificity: 0.9862 - F1: 0.0018 - Loss: 0.0154\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 17:35:55\n",
      "Accuracy: 0.9661 - Precision: 0.0011 - Recall: 0.0136 - Specificity: 0.9865 - F1: 0.0018 - Loss: 0.0152\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 17:36:04\n",
      "Accuracy: 0.9664 - Precision: 0.0010 - Recall: 0.0134 - Specificity: 0.9867 - F1: 0.0018 - Loss: 0.0150\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 17:36:13\n",
      "Accuracy: 0.9666 - Precision: 0.0010 - Recall: 0.0131 - Specificity: 0.9870 - F1: 0.0017 - Loss: 0.0149\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 17:36:21\n",
      "Accuracy: 0.9669 - Precision: 0.0010 - Recall: 0.0129 - Specificity: 0.9872 - F1: 0.0017 - Loss: 0.0147\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 17:36:30\n",
      "Accuracy: 0.9671 - Precision: 0.0010 - Recall: 0.0127 - Specificity: 0.9874 - F1: 0.0017 - Loss: 0.0145\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 17:36:39\n",
      "Accuracy: 0.9673 - Precision: 0.0010 - Recall: 0.0125 - Specificity: 0.9876 - F1: 0.0017 - Loss: 0.0144\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 17:36:48\n",
      "Accuracy: 0.9675 - Precision: 0.0010 - Recall: 0.0123 - Specificity: 0.9878 - F1: 0.0016 - Loss: 0.0142\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 17:36:59\n",
      "Accuracy: 0.9677 - Precision: 0.0009 - Recall: 0.0121 - Specificity: 0.9880 - F1: 0.0016 - Loss: 0.0141\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 17:37:08\n",
      "Accuracy: 0.9679 - Precision: 0.0009 - Recall: 0.0119 - Specificity: 0.9882 - F1: 0.0016 - Loss: 0.0139\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 17:37:18\n",
      "Accuracy: 0.9680 - Precision: 0.0009 - Recall: 0.0117 - Specificity: 0.9884 - F1: 0.0016 - Loss: 0.0138\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 17:37:26\n",
      "Accuracy: 0.9681 - Precision: 0.0009 - Recall: 0.0116 - Specificity: 0.9885 - F1: 0.0015 - Loss: 0.0137\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 17:37:35\n",
      "Accuracy: 0.9683 - Precision: 0.0009 - Recall: 0.0114 - Specificity: 0.9887 - F1: 0.0015 - Loss: 0.0136\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 17:37:44\n",
      "Accuracy: 0.9684 - Precision: 0.0009 - Recall: 0.0112 - Specificity: 0.9889 - F1: 0.0015 - Loss: 0.0134\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 17:37:53\n",
      "Accuracy: 0.9686 - Precision: 0.0009 - Recall: 0.0111 - Specificity: 0.9890 - F1: 0.0015 - Loss: 0.0133\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 17:38:01\n",
      "Accuracy: 0.9688 - Precision: 0.0009 - Recall: 0.0109 - Specificity: 0.9892 - F1: 0.0014 - Loss: 0.0132\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 17:38:10\n",
      "Accuracy: 0.9690 - Precision: 0.0008 - Recall: 0.0107 - Specificity: 0.9893 - F1: 0.0014 - Loss: 0.0131\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 17:38:19\n",
      "Accuracy: 0.9691 - Precision: 0.0008 - Recall: 0.0106 - Specificity: 0.9895 - F1: 0.0014 - Loss: 0.0130\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 17:38:27\n",
      "Accuracy: 0.9691 - Precision: 0.0008 - Recall: 0.0104 - Specificity: 0.9896 - F1: 0.0014 - Loss: 0.0129\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 17:38:36\n",
      "Accuracy: 0.9692 - Precision: 0.0008 - Recall: 0.0103 - Specificity: 0.9898 - F1: 0.0014 - Loss: 0.0128\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 17:38:45\n",
      "Accuracy: 0.9693 - Precision: 0.0008 - Recall: 0.0102 - Specificity: 0.9899 - F1: 0.0014 - Loss: 0.0127\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 17:38:55\n",
      "Accuracy: 0.9694 - Precision: 0.0008 - Recall: 0.0100 - Specificity: 0.9900 - F1: 0.0013 - Loss: 0.0126\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 17:39:05\n",
      "Accuracy: 0.9696 - Precision: 0.0008 - Recall: 0.0099 - Specificity: 0.9902 - F1: 0.0013 - Loss: 0.0125\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 17:39:14\n",
      "Accuracy: 0.9697 - Precision: 0.0008 - Recall: 0.0098 - Specificity: 0.9903 - F1: 0.0013 - Loss: 0.0124\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 17:39:23\n",
      "Accuracy: 0.9697 - Precision: 0.0008 - Recall: 0.0097 - Specificity: 0.9904 - F1: 0.0013 - Loss: 0.0123\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 17:39:32\n",
      "Accuracy: 0.9698 - Precision: 0.0007 - Recall: 0.0095 - Specificity: 0.9905 - F1: 0.0013 - Loss: 0.0122\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 17:39:41\n",
      "Accuracy: 0.9700 - Precision: 0.0007 - Recall: 0.0094 - Specificity: 0.9907 - F1: 0.0013 - Loss: 0.0121\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 17:39:49\n",
      "Accuracy: 0.9701 - Precision: 0.0007 - Recall: 0.0093 - Specificity: 0.9908 - F1: 0.0012 - Loss: 0.0120\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 17:39:58\n",
      "Accuracy: 0.9702 - Precision: 0.0128 - Recall: 0.0092 - Specificity: 0.9909 - F1: 0.0012 - Loss: 0.0120\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 17:40:06\n",
      "Accuracy: 0.9703 - Precision: 0.0126 - Recall: 0.0091 - Specificity: 0.9910 - F1: 0.0012 - Loss: 0.0119\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 17:40:15\n",
      "Accuracy: 0.9705 - Precision: 0.0125 - Recall: 0.0090 - Specificity: 0.9911 - F1: 0.0012 - Loss: 0.0118\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 17:40:24\n",
      "Accuracy: 0.9706 - Precision: 0.0123 - Recall: 0.0089 - Specificity: 0.9912 - F1: 0.0012 - Loss: 0.0117\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 17:40:34\n",
      "Accuracy: 0.9707 - Precision: 0.0122 - Recall: 0.0088 - Specificity: 0.9913 - F1: 0.0012 - Loss: 0.0116\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 17:40:42\n",
      "Accuracy: 0.9708 - Precision: 0.0120 - Recall: 0.0087 - Specificity: 0.9914 - F1: 0.0012 - Loss: 0.0115\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 17:40:51\n",
      "Accuracy: 0.9708 - Precision: 0.0119 - Recall: 0.0086 - Specificity: 0.9915 - F1: 0.0011 - Loss: 0.0115\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 17:41:01\n",
      "Accuracy: 0.9708 - Precision: 0.0229 - Recall: 0.0085 - Specificity: 0.9916 - F1: 0.0011 - Loss: 0.0114\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 17:41:11\n",
      "Accuracy: 0.9709 - Precision: 0.0336 - Recall: 0.0084 - Specificity: 0.9917 - F1: 0.0011 - Loss: 0.0113\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 17:41:20\n",
      "Accuracy: 0.9710 - Precision: 0.0387 - Recall: 0.0083 - Specificity: 0.9918 - F1: 0.0011 - Loss: 0.0112\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 17:41:30\n",
      "Accuracy: 0.9711 - Precision: 0.0490 - Recall: 0.0082 - Specificity: 0.9919 - F1: 0.0011 - Loss: 0.0112\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 17:41:40\n",
      "Accuracy: 0.9713 - Precision: 0.0485 - Recall: 0.0081 - Specificity: 0.9919 - F1: 0.0011 - Loss: 0.0111\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 17:41:50\n",
      "Accuracy: 0.9713 - Precision: 0.0480 - Recall: 0.0080 - Specificity: 0.9920 - F1: 0.0011 - Loss: 0.0110\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 17:41:59\n",
      "Accuracy: 0.9714 - Precision: 0.0579 - Recall: 0.0080 - Specificity: 0.9921 - F1: 0.0011 - Loss: 0.0109\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 17:42:08\n",
      "Accuracy: 0.9715 - Precision: 0.0573 - Recall: 0.0079 - Specificity: 0.9922 - F1: 0.0011 - Loss: 0.0109\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 17:42:17\n",
      "Accuracy: 0.9716 - Precision: 0.0669 - Recall: 0.0078 - Specificity: 0.9923 - F1: 0.0011 - Loss: 0.0108\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 17:42:26\n",
      "Accuracy: 0.9717 - Precision: 0.0764 - Recall: 0.0077 - Specificity: 0.9924 - F1: 0.0011 - Loss: 0.0107\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 17:42:34\n",
      "Accuracy: 0.9718 - Precision: 0.0756 - Recall: 0.0076 - Specificity: 0.9924 - F1: 0.0010 - Loss: 0.0107\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 17:42:44\n",
      "Accuracy: 0.9720 - Precision: 0.0848 - Recall: 0.0076 - Specificity: 0.9925 - F1: 0.0010 - Loss: 0.0106\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 17:42:53\n",
      "Accuracy: 0.9721 - Precision: 0.0888 - Recall: 0.0075 - Specificity: 0.9926 - F1: 0.0010 - Loss: 0.0105\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 17:43:03\n",
      "Accuracy: 0.9722 - Precision: 0.0880 - Recall: 0.0074 - Specificity: 0.9927 - F1: 0.0010 - Loss: 0.0104\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 17:43:13\n",
      "Accuracy: 0.9723 - Precision: 0.0871 - Recall: 0.0074 - Specificity: 0.9927 - F1: 0.0010 - Loss: 0.0104\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 17:43:22\n",
      "Accuracy: 0.9724 - Precision: 0.0863 - Recall: 0.0073 - Specificity: 0.9928 - F1: 0.0010 - Loss: 0.0103\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 17:43:30\n",
      "Accuracy: 0.9725 - Precision: 0.0949 - Recall: 0.0072 - Specificity: 0.9929 - F1: 0.0010 - Loss: 0.0103\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 17:43:39\n",
      "Accuracy: 0.9726 - Precision: 0.1017 - Recall: 0.0072 - Specificity: 0.9929 - F1: 0.0010 - Loss: 0.0102\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 17:43:48\n",
      "Accuracy: 0.9727 - Precision: 0.1075 - Recall: 0.0071 - Specificity: 0.9930 - F1: 0.0010 - Loss: 0.0101\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 17:43:57\n",
      "Accuracy: 0.9727 - Precision: 0.1157 - Recall: 0.0070 - Specificity: 0.9931 - F1: 0.0010 - Loss: 0.0101\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 17:44:06\n",
      "Accuracy: 0.9728 - Precision: 0.1146 - Recall: 0.0070 - Specificity: 0.9931 - F1: 0.0010 - Loss: 0.0100\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 17:44:14\n",
      "Accuracy: 0.9729 - Precision: 0.1226 - Recall: 0.0069 - Specificity: 0.9932 - F1: 0.0010 - Loss: 0.0100\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 17:44:23\n",
      "Accuracy: 0.9730 - Precision: 0.1260 - Recall: 0.0068 - Specificity: 0.9932 - F1: 0.0010 - Loss: 0.0099\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 17:44:32\n",
      "Accuracy: 0.9731 - Precision: 0.1329 - Recall: 0.0068 - Specificity: 0.9933 - F1: 0.0010 - Loss: 0.0098\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 17:44:41\n",
      "Accuracy: 0.9731 - Precision: 0.1405 - Recall: 0.0067 - Specificity: 0.9934 - F1: 0.0010 - Loss: 0.0098\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 17:44:49\n",
      "Accuracy: 0.9732 - Precision: 0.1480 - Recall: 0.0067 - Specificity: 0.9934 - F1: 0.0010 - Loss: 0.0097\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 17:44:58\n",
      "Accuracy: 0.9733 - Precision: 0.1539 - Recall: 0.0067 - Specificity: 0.9935 - F1: 0.0011 - Loss: 0.0097\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 17:45:08\n",
      "Accuracy: 0.9733 - Precision: 0.1611 - Recall: 0.0066 - Specificity: 0.9935 - F1: 0.0011 - Loss: 0.0096\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 17:45:18\n",
      "Accuracy: 0.9734 - Precision: 0.1648 - Recall: 0.0066 - Specificity: 0.9936 - F1: 0.0011 - Loss: 0.0096\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 17:45:28\n",
      "Accuracy: 0.9734 - Precision: 0.1699 - Recall: 0.0065 - Specificity: 0.9936 - F1: 0.0011 - Loss: 0.0095\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 17:45:38\n",
      "Accuracy: 0.9735 - Precision: 0.1732 - Recall: 0.0065 - Specificity: 0.9937 - F1: 0.0011 - Loss: 0.0095\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 17:45:48\n",
      "Accuracy: 0.9736 - Precision: 0.1786 - Recall: 0.0064 - Specificity: 0.9937 - F1: 0.0011 - Loss: 0.0094\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 17:45:59\n",
      "Accuracy: 0.9736 - Precision: 0.1847 - Recall: 0.0064 - Specificity: 0.9938 - F1: 0.0011 - Loss: 0.0094\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 17:46:09\n",
      "Accuracy: 0.9736 - Precision: 0.1912 - Recall: 0.0064 - Specificity: 0.9938 - F1: 0.0012 - Loss: 0.0093\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 17:46:18\n",
      "Accuracy: 0.9737 - Precision: 0.1973 - Recall: 0.0064 - Specificity: 0.9939 - F1: 0.0013 - Loss: 0.0093\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 17:46:28\n",
      "Accuracy: 0.9738 - Precision: 0.2023 - Recall: 0.0064 - Specificity: 0.9939 - F1: 0.0015 - Loss: 0.0092\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 17:46:38\n",
      "Accuracy: 0.9738 - Precision: 0.2082 - Recall: 0.0065 - Specificity: 0.9940 - F1: 0.0016 - Loss: 0.0092\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 17:46:48\n",
      "Accuracy: 0.9739 - Precision: 0.2132 - Recall: 0.0065 - Specificity: 0.9940 - F1: 0.0018 - Loss: 0.0092\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 17:46:58\n",
      "Accuracy: 0.9739 - Precision: 0.2172 - Recall: 0.0065 - Specificity: 0.9941 - F1: 0.0019 - Loss: 0.0091\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 17:47:12\n",
      "Accuracy: 0.9740 - Precision: 0.2229 - Recall: 0.0067 - Specificity: 0.9941 - F1: 0.0024 - Loss: 0.0091\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 17:47:22\n",
      "Accuracy: 0.9740 - Precision: 0.2270 - Recall: 0.0072 - Specificity: 0.9942 - F1: 0.0033 - Loss: 0.0090\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 17:47:31\n",
      "Accuracy: 0.9741 - Precision: 0.2321 - Recall: 0.0077 - Specificity: 0.9942 - F1: 0.0043 - Loss: 0.0090\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 17:47:40\n",
      "Accuracy: 0.9741 - Precision: 0.2372 - Recall: 0.0081 - Specificity: 0.9943 - F1: 0.0052 - Loss: 0.0090\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 17:47:49\n",
      "Accuracy: 0.9741 - Precision: 0.2428 - Recall: 0.0083 - Specificity: 0.9943 - F1: 0.0056 - Loss: 0.0089\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 17:47:59\n",
      "Accuracy: 0.9742 - Precision: 0.2482 - Recall: 0.0085 - Specificity: 0.9943 - F1: 0.0061 - Loss: 0.0089\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 17:48:08\n",
      "Accuracy: 0.9742 - Precision: 0.2535 - Recall: 0.0091 - Specificity: 0.9944 - F1: 0.0073 - Loss: 0.0088\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 17:48:18\n",
      "Accuracy: 0.9743 - Precision: 0.2582 - Recall: 0.0099 - Specificity: 0.9944 - F1: 0.0087 - Loss: 0.0088\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 17:48:35\n",
      "Accuracy: 0.9743 - Precision: 0.2628 - Recall: 0.0105 - Specificity: 0.9945 - F1: 0.0099 - Loss: 0.0088\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 17:48:44\n",
      "Accuracy: 0.9744 - Precision: 0.2680 - Recall: 0.0111 - Specificity: 0.9945 - F1: 0.0110 - Loss: 0.0087\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 17:48:53\n",
      "Accuracy: 0.9744 - Precision: 0.2732 - Recall: 0.0115 - Specificity: 0.9945 - F1: 0.0119 - Loss: 0.0087\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 17:49:02\n",
      "Accuracy: 0.9745 - Precision: 0.2779 - Recall: 0.0126 - Specificity: 0.9946 - F1: 0.0138 - Loss: 0.0087\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 17:49:13\n",
      "Accuracy: 0.9746 - Precision: 0.2824 - Recall: 0.0143 - Specificity: 0.9946 - F1: 0.0166 - Loss: 0.0086\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 17:49:23\n",
      "Accuracy: 0.9746 - Precision: 0.2868 - Recall: 0.0155 - Specificity: 0.9947 - F1: 0.0185 - Loss: 0.0086\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 17:49:32\n",
      "Accuracy: 0.9746 - Precision: 0.2906 - Recall: 0.0168 - Specificity: 0.9947 - F1: 0.0207 - Loss: 0.0086\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 17:49:40\n",
      "Accuracy: 0.9747 - Precision: 0.2946 - Recall: 0.0182 - Specificity: 0.9947 - F1: 0.0230 - Loss: 0.0085\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 17:49:49\n",
      "Accuracy: 0.9748 - Precision: 0.2993 - Recall: 0.0190 - Specificity: 0.9948 - F1: 0.0245 - Loss: 0.0085\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 17:49:58\n",
      "Accuracy: 0.9748 - Precision: 0.3031 - Recall: 0.0207 - Specificity: 0.9948 - F1: 0.0271 - Loss: 0.0085\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 17:50:07\n",
      "Accuracy: 0.9749 - Precision: 0.3073 - Recall: 0.0222 - Specificity: 0.9948 - F1: 0.0295 - Loss: 0.0084\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 17:50:16\n",
      "Accuracy: 0.9750 - Precision: 0.3115 - Recall: 0.0241 - Specificity: 0.9948 - F1: 0.0324 - Loss: 0.0084\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 17:50:25\n",
      "Accuracy: 0.9750 - Precision: 0.3122 - Recall: 0.0246 - Specificity: 0.9949 - F1: 0.0332 - Loss: 0.0084\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 17:50:36\n",
      "Accuracy: 0.9750 - Precision: 0.3152 - Recall: 0.0249 - Specificity: 0.9949 - F1: 0.0338 - Loss: 0.0083\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 17:50:45\n",
      "Accuracy: 0.9750 - Precision: 0.3187 - Recall: 0.0251 - Specificity: 0.9949 - F1: 0.0344 - Loss: 0.0083\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 17:50:54\n",
      "Accuracy: 0.9751 - Precision: 0.3218 - Recall: 0.0274 - Specificity: 0.9949 - F1: 0.0375 - Loss: 0.0083\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 17:51:03\n",
      "Accuracy: 0.9752 - Precision: 0.3254 - Recall: 0.0301 - Specificity: 0.9950 - F1: 0.0411 - Loss: 0.0083\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 17:51:13\n",
      "Accuracy: 0.9753 - Precision: 0.3295 - Recall: 0.0322 - Specificity: 0.9950 - F1: 0.0441 - Loss: 0.0082\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 17:51:23\n",
      "Accuracy: 0.9753 - Precision: 0.3335 - Recall: 0.0329 - Specificity: 0.9950 - F1: 0.0454 - Loss: 0.0082\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 17:51:33\n",
      "Accuracy: 0.9753 - Precision: 0.3376 - Recall: 0.0343 - Specificity: 0.9951 - F1: 0.0477 - Loss: 0.0082\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 17:51:42\n",
      "Accuracy: 0.9754 - Precision: 0.3413 - Recall: 0.0365 - Specificity: 0.9951 - F1: 0.0508 - Loss: 0.0082\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 17:51:50\n",
      "Accuracy: 0.9755 - Precision: 0.3439 - Recall: 0.0397 - Specificity: 0.9951 - F1: 0.0545 - Loss: 0.0081\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 17:51:59\n",
      "Accuracy: 0.9756 - Precision: 0.3476 - Recall: 0.0418 - Specificity: 0.9951 - F1: 0.0575 - Loss: 0.0081\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 17:52:08\n",
      "Accuracy: 0.9757 - Precision: 0.3514 - Recall: 0.0432 - Specificity: 0.9952 - F1: 0.0598 - Loss: 0.0081\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 17:52:17\n",
      "Accuracy: 0.9757 - Precision: 0.3554 - Recall: 0.0439 - Specificity: 0.9952 - F1: 0.0610 - Loss: 0.0080\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 17:52:25\n",
      "Accuracy: 0.9757 - Precision: 0.3593 - Recall: 0.0446 - Specificity: 0.9952 - F1: 0.0624 - Loss: 0.0080\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 17:52:34\n",
      "Accuracy: 0.9758 - Precision: 0.3624 - Recall: 0.0460 - Specificity: 0.9952 - F1: 0.0645 - Loss: 0.0080\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 17:52:42\n",
      "Accuracy: 0.9759 - Precision: 0.3655 - Recall: 0.0478 - Specificity: 0.9953 - F1: 0.0672 - Loss: 0.0079\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 17:52:51\n",
      "Accuracy: 0.9759 - Precision: 0.3690 - Recall: 0.0497 - Specificity: 0.9953 - F1: 0.0698 - Loss: 0.0079\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 17:52:59\n",
      "Accuracy: 0.9760 - Precision: 0.3710 - Recall: 0.0503 - Specificity: 0.9953 - F1: 0.0710 - Loss: 0.0079\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 17:53:08\n",
      "Accuracy: 0.9760 - Precision: 0.3748 - Recall: 0.0508 - Specificity: 0.9953 - F1: 0.0719 - Loss: 0.0079\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 17:53:18\n",
      "Accuracy: 0.9760 - Precision: 0.3784 - Recall: 0.0519 - Specificity: 0.9954 - F1: 0.0738 - Loss: 0.0079\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 17:53:27\n",
      "Accuracy: 0.9761 - Precision: 0.3808 - Recall: 0.0545 - Specificity: 0.9954 - F1: 0.0769 - Loss: 0.0078\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 17:53:35\n",
      "Accuracy: 0.9762 - Precision: 0.3829 - Recall: 0.0583 - Specificity: 0.9954 - F1: 0.0807 - Loss: 0.0078\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 17:53:43\n",
      "Accuracy: 0.9763 - Precision: 0.3853 - Recall: 0.0607 - Specificity: 0.9954 - F1: 0.0837 - Loss: 0.0078\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 17:53:52\n",
      "Accuracy: 0.9763 - Precision: 0.3882 - Recall: 0.0618 - Specificity: 0.9954 - F1: 0.0855 - Loss: 0.0078\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 17:54:00\n",
      "Accuracy: 0.9763 - Precision: 0.3914 - Recall: 0.0626 - Specificity: 0.9954 - F1: 0.0869 - Loss: 0.0077\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 17:54:09\n",
      "Accuracy: 0.9764 - Precision: 0.3948 - Recall: 0.0641 - Specificity: 0.9955 - F1: 0.0892 - Loss: 0.0077\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 17:54:18\n",
      "Accuracy: 0.9764 - Precision: 0.3975 - Recall: 0.0655 - Specificity: 0.9955 - F1: 0.0912 - Loss: 0.0077\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 17:54:26\n",
      "Accuracy: 0.9765 - Precision: 0.4001 - Recall: 0.0679 - Specificity: 0.9955 - F1: 0.0943 - Loss: 0.0077\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 17:54:34\n",
      "Accuracy: 0.9765 - Precision: 0.4025 - Recall: 0.0703 - Specificity: 0.9955 - F1: 0.0972 - Loss: 0.0076\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 17:54:43\n",
      "Accuracy: 0.9766 - Precision: 0.4055 - Recall: 0.0721 - Specificity: 0.9955 - F1: 0.0998 - Loss: 0.0076\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 17:54:52\n",
      "Accuracy: 0.9767 - Precision: 0.4082 - Recall: 0.0731 - Specificity: 0.9956 - F1: 0.1014 - Loss: 0.0076\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 17:55:01\n",
      "Accuracy: 0.9767 - Precision: 0.4114 - Recall: 0.0735 - Specificity: 0.9956 - F1: 0.1022 - Loss: 0.0076\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 17:55:09\n",
      "Accuracy: 0.9767 - Precision: 0.4146 - Recall: 0.0742 - Specificity: 0.9956 - F1: 0.1035 - Loss: 0.0075\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 17:55:20\n",
      "Accuracy: 0.9768 - Precision: 0.4174 - Recall: 0.0757 - Specificity: 0.9956 - F1: 0.1057 - Loss: 0.0075\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 17:55:28\n",
      "Accuracy: 0.9768 - Precision: 0.4192 - Recall: 0.0783 - Specificity: 0.9956 - F1: 0.1086 - Loss: 0.0075\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 17:55:37\n",
      "Accuracy: 0.9769 - Precision: 0.4214 - Recall: 0.0805 - Specificity: 0.9956 - F1: 0.1113 - Loss: 0.0075\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 17:55:46\n",
      "Accuracy: 0.9770 - Precision: 0.4237 - Recall: 0.0827 - Specificity: 0.9957 - F1: 0.1141 - Loss: 0.0075\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 17:55:54\n",
      "Accuracy: 0.9770 - Precision: 0.4258 - Recall: 0.0837 - Specificity: 0.9957 - F1: 0.1156 - Loss: 0.0074\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 17:56:03\n",
      "Accuracy: 0.9770 - Precision: 0.4284 - Recall: 0.0846 - Specificity: 0.9957 - F1: 0.1172 - Loss: 0.0074\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 17:56:12\n",
      "Accuracy: 0.9771 - Precision: 0.4309 - Recall: 0.0854 - Specificity: 0.9957 - F1: 0.1185 - Loss: 0.0074\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 17:56:21\n",
      "Accuracy: 0.9771 - Precision: 0.4332 - Recall: 0.0867 - Specificity: 0.9957 - F1: 0.1205 - Loss: 0.0074\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 17:56:30\n",
      "Accuracy: 0.9772 - Precision: 0.4356 - Recall: 0.0891 - Specificity: 0.9957 - F1: 0.1234 - Loss: 0.0074\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 17:56:38\n",
      "Accuracy: 0.9772 - Precision: 0.4375 - Recall: 0.0915 - Specificity: 0.9958 - F1: 0.1261 - Loss: 0.0073\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 17:56:47\n",
      "Accuracy: 0.9773 - Precision: 0.4398 - Recall: 0.0934 - Specificity: 0.9958 - F1: 0.1286 - Loss: 0.0073\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 17:56:57\n",
      "Accuracy: 0.9773 - Precision: 0.4410 - Recall: 0.0947 - Specificity: 0.9958 - F1: 0.1302 - Loss: 0.0073\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 17:57:06\n",
      "Accuracy: 0.9774 - Precision: 0.4438 - Recall: 0.0949 - Specificity: 0.9958 - F1: 0.1309 - Loss: 0.0073\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 17:57:15\n",
      "Accuracy: 0.9774 - Precision: 0.4465 - Recall: 0.0952 - Specificity: 0.9958 - F1: 0.1316 - Loss: 0.0073\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 17:57:25\n",
      "Accuracy: 0.9774 - Precision: 0.4491 - Recall: 0.0966 - Specificity: 0.9958 - F1: 0.1336 - Loss: 0.0072\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 17:57:33\n",
      "Accuracy: 0.9775 - Precision: 0.4506 - Recall: 0.0988 - Specificity: 0.9958 - F1: 0.1360 - Loss: 0.0072\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 17:57:42\n",
      "Accuracy: 0.9775 - Precision: 0.4520 - Recall: 0.1008 - Specificity: 0.9958 - F1: 0.1383 - Loss: 0.0072\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 17:57:52\n",
      "Accuracy: 0.9776 - Precision: 0.4543 - Recall: 0.1025 - Specificity: 0.9959 - F1: 0.1406 - Loss: 0.0072\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 17:58:00\n",
      "Accuracy: 0.9776 - Precision: 0.4569 - Recall: 0.1038 - Specificity: 0.9959 - F1: 0.1426 - Loss: 0.0072\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 17:58:10\n",
      "Accuracy: 0.9777 - Precision: 0.4595 - Recall: 0.1048 - Specificity: 0.9959 - F1: 0.1442 - Loss: 0.0071\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 17:58:18\n",
      "Accuracy: 0.9777 - Precision: 0.4621 - Recall: 0.1061 - Specificity: 0.9959 - F1: 0.1460 - Loss: 0.0071\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 17:58:27\n",
      "Accuracy: 0.9778 - Precision: 0.4647 - Recall: 0.1070 - Specificity: 0.9959 - F1: 0.1475 - Loss: 0.0071\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 17:58:36\n",
      "Accuracy: 0.9778 - Precision: 0.4662 - Recall: 0.1084 - Specificity: 0.9959 - F1: 0.1494 - Loss: 0.0071\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 17:58:44\n",
      "Accuracy: 0.9779 - Precision: 0.4683 - Recall: 0.1103 - Specificity: 0.9960 - F1: 0.1518 - Loss: 0.0070\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 17:58:54\n",
      "Accuracy: 0.9779 - Precision: 0.4704 - Recall: 0.1123 - Specificity: 0.9960 - F1: 0.1542 - Loss: 0.0070\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 17:59:03\n",
      "Accuracy: 0.9780 - Precision: 0.4713 - Recall: 0.1141 - Specificity: 0.9960 - F1: 0.1562 - Loss: 0.0070\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 17:59:14\n",
      "Accuracy: 0.9781 - Precision: 0.4732 - Recall: 0.1161 - Specificity: 0.9960 - F1: 0.1586 - Loss: 0.0070\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 17:59:24\n",
      "Accuracy: 0.9781 - Precision: 0.4756 - Recall: 0.1175 - Specificity: 0.9960 - F1: 0.1606 - Loss: 0.0070\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 17:59:33\n",
      "Accuracy: 0.9782 - Precision: 0.4773 - Recall: 0.1193 - Specificity: 0.9960 - F1: 0.1627 - Loss: 0.0069\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 17:59:42\n",
      "Accuracy: 0.9782 - Precision: 0.4793 - Recall: 0.1210 - Specificity: 0.9960 - F1: 0.1650 - Loss: 0.0069\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 17:59:50\n",
      "Accuracy: 0.9783 - Precision: 0.4812 - Recall: 0.1228 - Specificity: 0.9960 - F1: 0.1672 - Loss: 0.0069\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 17:59:59\n",
      "Accuracy: 0.9783 - Precision: 0.4825 - Recall: 0.1240 - Specificity: 0.9961 - F1: 0.1688 - Loss: 0.0069\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 18:00:08\n",
      "Accuracy: 0.9783 - Precision: 0.4835 - Recall: 0.1248 - Specificity: 0.9961 - F1: 0.1699 - Loss: 0.0069\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 18:00:17\n",
      "Accuracy: 0.9783 - Precision: 0.4841 - Recall: 0.1250 - Specificity: 0.9961 - F1: 0.1704 - Loss: 0.0069\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 18:00:25\n",
      "Accuracy: 0.9783 - Precision: 0.4853 - Recall: 0.1249 - Specificity: 0.9961 - F1: 0.1705 - Loss: 0.0069\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 18:00:34\n",
      "Accuracy: 0.9783 - Precision: 0.4873 - Recall: 0.1248 - Specificity: 0.9961 - F1: 0.1705 - Loss: 0.0069\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 18:00:42\n",
      "Accuracy: 0.9783 - Precision: 0.4887 - Recall: 0.1246 - Specificity: 0.9961 - F1: 0.1703 - Loss: 0.0069\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 18:00:52\n",
      "Accuracy: 0.9782 - Precision: 0.4907 - Recall: 0.1244 - Specificity: 0.9961 - F1: 0.1702 - Loss: 0.0069\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 18:01:01\n",
      "Accuracy: 0.9782 - Precision: 0.4918 - Recall: 0.1239 - Specificity: 0.9961 - F1: 0.1697 - Loss: 0.0069\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 18:01:11\n",
      "Accuracy: 0.9782 - Precision: 0.4940 - Recall: 0.1236 - Specificity: 0.9962 - F1: 0.1694 - Loss: 0.0069\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 18:01:21\n",
      "Accuracy: 0.9782 - Precision: 0.4952 - Recall: 0.1235 - Specificity: 0.9962 - F1: 0.1695 - Loss: 0.0069\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 18:01:32\n",
      "Accuracy: 0.9782 - Precision: 0.4968 - Recall: 0.1234 - Specificity: 0.9962 - F1: 0.1694 - Loss: 0.0069\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 18:01:41\n",
      "Accuracy: 0.9782 - Precision: 0.4980 - Recall: 0.1232 - Specificity: 0.9962 - F1: 0.1694 - Loss: 0.0069\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 18:01:49\n",
      "Accuracy: 0.9782 - Precision: 0.5002 - Recall: 0.1229 - Specificity: 0.9962 - F1: 0.1692 - Loss: 0.0069\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 18:01:58\n",
      "Accuracy: 0.9782 - Precision: 0.5019 - Recall: 0.1225 - Specificity: 0.9962 - F1: 0.1687 - Loss: 0.0069\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 18:02:07\n",
      "Accuracy: 0.9782 - Precision: 0.5034 - Recall: 0.1234 - Specificity: 0.9962 - F1: 0.1699 - Loss: 0.0069\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 18:02:16\n",
      "Accuracy: 0.9783 - Precision: 0.5040 - Recall: 0.1250 - Specificity: 0.9962 - F1: 0.1717 - Loss: 0.0069\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 18:02:25\n",
      "Accuracy: 0.9783 - Precision: 0.5042 - Recall: 0.1252 - Specificity: 0.9962 - F1: 0.1719 - Loss: 0.0069\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 18:02:33\n",
      "Accuracy: 0.9783 - Precision: 0.5061 - Recall: 0.1247 - Specificity: 0.9963 - F1: 0.1714 - Loss: 0.0069\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 18:02:42\n",
      "Accuracy: 0.9783 - Precision: 0.5039 - Recall: 0.1242 - Specificity: 0.9963 - F1: 0.1707 - Loss: 0.0069\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 18:02:51\n",
      "Accuracy: 0.9783 - Precision: 0.5060 - Recall: 0.1237 - Specificity: 0.9963 - F1: 0.1700 - Loss: 0.0069\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 18:03:00\n",
      "Accuracy: 0.9782 - Precision: 0.5082 - Recall: 0.1231 - Specificity: 0.9963 - F1: 0.1692 - Loss: 0.0069\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 18:03:08\n",
      "Accuracy: 0.9782 - Precision: 0.5101 - Recall: 0.1226 - Specificity: 0.9963 - F1: 0.1685 - Loss: 0.0069\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 18:03:17\n",
      "Accuracy: 0.9781 - Precision: 0.5118 - Recall: 0.1221 - Specificity: 0.9963 - F1: 0.1678 - Loss: 0.0069\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 18:03:26\n",
      "Accuracy: 0.9781 - Precision: 0.5137 - Recall: 0.1216 - Specificity: 0.9964 - F1: 0.1672 - Loss: 0.0069\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 18:03:36\n",
      "Accuracy: 0.9780 - Precision: 0.5157 - Recall: 0.1211 - Specificity: 0.9964 - F1: 0.1665 - Loss: 0.0069\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 18:03:45\n",
      "Accuracy: 0.9780 - Precision: 0.5177 - Recall: 0.1206 - Specificity: 0.9964 - F1: 0.1658 - Loss: 0.0069\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 18:03:54\n",
      "Accuracy: 0.9780 - Precision: 0.5197 - Recall: 0.1201 - Specificity: 0.9964 - F1: 0.1651 - Loss: 0.0070\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 18:04:03\n",
      "Accuracy: 0.9777 - Precision: 0.5203 - Recall: 0.1196 - Specificity: 0.9964 - F1: 0.1644 - Loss: 0.0072\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 18:04:12\n",
      "Accuracy: 0.9775 - Precision: 0.5223 - Recall: 0.1191 - Specificity: 0.9964 - F1: 0.1638 - Loss: 0.0073\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 18:04:20\n",
      "Accuracy: 0.9772 - Precision: 0.5239 - Recall: 0.1186 - Specificity: 0.9964 - F1: 0.1631 - Loss: 0.0074\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 18:04:29\n",
      "Accuracy: 0.9769 - Precision: 0.5253 - Recall: 0.1181 - Specificity: 0.9965 - F1: 0.1624 - Loss: 0.0075\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 18:04:38\n",
      "Accuracy: 0.9767 - Precision: 0.5232 - Recall: 0.1177 - Specificity: 0.9965 - F1: 0.1618 - Loss: 0.0076\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 18:04:46\n",
      "Accuracy: 0.9765 - Precision: 0.5210 - Recall: 0.1172 - Specificity: 0.9965 - F1: 0.1611 - Loss: 0.0077\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 18:04:54\n",
      "Accuracy: 0.9762 - Precision: 0.5189 - Recall: 0.1167 - Specificity: 0.9965 - F1: 0.1605 - Loss: 0.0078\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 18:05:03\n",
      "Accuracy: 0.9760 - Precision: 0.5168 - Recall: 0.1162 - Specificity: 0.9965 - F1: 0.1598 - Loss: 0.0079\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 18:05:12\n",
      "Accuracy: 0.9757 - Precision: 0.5147 - Recall: 0.1158 - Specificity: 0.9965 - F1: 0.1592 - Loss: 0.0080\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 18:05:20\n",
      "Accuracy: 0.9755 - Precision: 0.5127 - Recall: 0.1153 - Specificity: 0.9965 - F1: 0.1585 - Loss: 0.0081\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 18:05:30\n",
      "Accuracy: 0.9752 - Precision: 0.5106 - Recall: 0.1148 - Specificity: 0.9966 - F1: 0.1579 - Loss: 0.0081\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 18:05:40\n",
      "Accuracy: 0.9751 - Precision: 0.5086 - Recall: 0.1144 - Specificity: 0.9966 - F1: 0.1573 - Loss: 0.0082\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 18:05:49\n",
      "Accuracy: 0.9749 - Precision: 0.5066 - Recall: 0.1139 - Specificity: 0.9966 - F1: 0.1566 - Loss: 0.0082\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 18:05:58\n",
      "Accuracy: 0.9748 - Precision: 0.5046 - Recall: 0.1135 - Specificity: 0.9966 - F1: 0.1560 - Loss: 0.0083\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 18:06:07\n",
      "Accuracy: 0.9745 - Precision: 0.5026 - Recall: 0.1130 - Specificity: 0.9966 - F1: 0.1554 - Loss: 0.0083\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 18:06:16\n",
      "Accuracy: 0.9742 - Precision: 0.5006 - Recall: 0.1126 - Specificity: 0.9966 - F1: 0.1548 - Loss: 0.0084\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 18:06:25\n",
      "Accuracy: 0.9740 - Precision: 0.4986 - Recall: 0.1121 - Specificity: 0.9966 - F1: 0.1542 - Loss: 0.0085\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 18:06:34\n",
      "Accuracy: 0.9738 - Precision: 0.4967 - Recall: 0.1117 - Specificity: 0.9966 - F1: 0.1536 - Loss: 0.0085\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 18:06:43\n",
      "Accuracy: 0.9738 - Precision: 0.4948 - Recall: 0.1113 - Specificity: 0.9967 - F1: 0.1530 - Loss: 0.0085\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 18:06:52\n",
      "Accuracy: 0.9738 - Precision: 0.4929 - Recall: 0.1109 - Specificity: 0.9967 - F1: 0.1524 - Loss: 0.0085\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 18:07:03\n",
      "Accuracy: 0.9738 - Precision: 0.4910 - Recall: 0.1104 - Specificity: 0.9967 - F1: 0.1518 - Loss: 0.0085\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 18:07:12\n",
      "Accuracy: 0.9738 - Precision: 0.4891 - Recall: 0.1100 - Specificity: 0.9967 - F1: 0.1512 - Loss: 0.0085\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 18:07:22\n",
      "Accuracy: 0.9737 - Precision: 0.4910 - Recall: 0.1096 - Specificity: 0.9967 - F1: 0.1507 - Loss: 0.0085\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 18:07:32\n",
      "Accuracy: 0.9737 - Precision: 0.4917 - Recall: 0.1092 - Specificity: 0.9967 - F1: 0.1502 - Loss: 0.0086\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 18:07:44\n",
      "Accuracy: 0.9737 - Precision: 0.4925 - Recall: 0.1089 - Specificity: 0.9967 - F1: 0.1499 - Loss: 0.0086\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 18:07:53\n",
      "Accuracy: 0.9737 - Precision: 0.4932 - Recall: 0.1085 - Specificity: 0.9967 - F1: 0.1493 - Loss: 0.0086\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 18:08:02\n",
      "Accuracy: 0.9737 - Precision: 0.4951 - Recall: 0.1081 - Specificity: 0.9968 - F1: 0.1488 - Loss: 0.0086\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 18:08:11\n",
      "Accuracy: 0.9737 - Precision: 0.4970 - Recall: 0.1077 - Specificity: 0.9968 - F1: 0.1482 - Loss: 0.0086\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 18:08:20\n",
      "Accuracy: 0.9737 - Precision: 0.4989 - Recall: 0.1073 - Specificity: 0.9968 - F1: 0.1477 - Loss: 0.0086\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 18:08:29\n",
      "Accuracy: 0.9737 - Precision: 0.4979 - Recall: 0.1069 - Specificity: 0.9968 - F1: 0.1471 - Loss: 0.0086\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 18:08:39\n",
      "Accuracy: 0.9737 - Precision: 0.4998 - Recall: 0.1065 - Specificity: 0.9968 - F1: 0.1466 - Loss: 0.0086\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 18:08:49\n",
      "Accuracy: 0.9737 - Precision: 0.5016 - Recall: 0.1062 - Specificity: 0.9968 - F1: 0.1461 - Loss: 0.0086\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 18:08:58\n",
      "Accuracy: 0.9737 - Precision: 0.5034 - Recall: 0.1058 - Specificity: 0.9968 - F1: 0.1456 - Loss: 0.0086\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 18:09:07\n",
      "Accuracy: 0.9737 - Precision: 0.5052 - Recall: 0.1054 - Specificity: 0.9968 - F1: 0.1451 - Loss: 0.0086\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 18:09:18\n",
      "Accuracy: 0.9737 - Precision: 0.5066 - Recall: 0.1051 - Specificity: 0.9969 - F1: 0.1446 - Loss: 0.0086\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 18:09:28\n",
      "Accuracy: 0.9737 - Precision: 0.5057 - Recall: 0.1047 - Specificity: 0.9969 - F1: 0.1442 - Loss: 0.0086\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 18:09:38\n",
      "Accuracy: 0.9737 - Precision: 0.5067 - Recall: 0.1045 - Specificity: 0.9969 - F1: 0.1440 - Loss: 0.0086\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 18:09:49\n",
      "Accuracy: 0.9737 - Precision: 0.5054 - Recall: 0.1042 - Specificity: 0.9969 - F1: 0.1435 - Loss: 0.0086\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 18:09:58\n",
      "Accuracy: 0.9737 - Precision: 0.5072 - Recall: 0.1038 - Specificity: 0.9969 - F1: 0.1430 - Loss: 0.0086\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 18:10:07\n",
      "Accuracy: 0.9737 - Precision: 0.5054 - Recall: 0.1034 - Specificity: 0.9969 - F1: 0.1425 - Loss: 0.0086\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 18:10:16\n",
      "Accuracy: 0.9737 - Precision: 0.5036 - Recall: 0.1031 - Specificity: 0.9969 - F1: 0.1420 - Loss: 0.0086\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 18:10:24\n",
      "Accuracy: 0.9738 - Precision: 0.5018 - Recall: 0.1027 - Specificity: 0.9969 - F1: 0.1415 - Loss: 0.0085\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 18:10:33\n",
      "Accuracy: 0.9738 - Precision: 0.5000 - Recall: 0.1023 - Specificity: 0.9969 - F1: 0.1410 - Loss: 0.0085\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 18:10:41\n",
      "Accuracy: 0.9738 - Precision: 0.4982 - Recall: 0.1020 - Specificity: 0.9969 - F1: 0.1405 - Loss: 0.0085\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 18:10:50\n",
      "Accuracy: 0.9738 - Precision: 0.4965 - Recall: 0.1016 - Specificity: 0.9970 - F1: 0.1400 - Loss: 0.0085\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 18:10:59\n",
      "Accuracy: 0.9739 - Precision: 0.4947 - Recall: 0.1013 - Specificity: 0.9970 - F1: 0.1395 - Loss: 0.0085\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 18:11:08\n",
      "Accuracy: 0.9739 - Precision: 0.4930 - Recall: 0.1009 - Specificity: 0.9970 - F1: 0.1390 - Loss: 0.0085\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 18:11:17\n",
      "Accuracy: 0.9738 - Precision: 0.4913 - Recall: 0.1005 - Specificity: 0.9970 - F1: 0.1385 - Loss: 0.0085\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 18:11:25\n",
      "Accuracy: 0.9738 - Precision: 0.4896 - Recall: 0.1002 - Specificity: 0.9970 - F1: 0.1380 - Loss: 0.0085\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 18:11:35\n",
      "Accuracy: 0.9738 - Precision: 0.4879 - Recall: 0.0999 - Specificity: 0.9970 - F1: 0.1376 - Loss: 0.0085\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 18:11:45\n",
      "Accuracy: 0.9738 - Precision: 0.4862 - Recall: 0.0995 - Specificity: 0.9970 - F1: 0.1371 - Loss: 0.0085\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 18:11:54\n",
      "Accuracy: 0.9739 - Precision: 0.4845 - Recall: 0.0992 - Specificity: 0.9970 - F1: 0.1366 - Loss: 0.0085\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 18:12:03\n",
      "Accuracy: 0.9738 - Precision: 0.4829 - Recall: 0.0988 - Specificity: 0.9970 - F1: 0.1362 - Loss: 0.0085\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 18:12:11\n",
      "Accuracy: 0.9738 - Precision: 0.4846 - Recall: 0.0985 - Specificity: 0.9971 - F1: 0.1357 - Loss: 0.0085\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 18:12:23\n",
      "Accuracy: 0.9738 - Precision: 0.4830 - Recall: 0.0982 - Specificity: 0.9971 - F1: 0.1352 - Loss: 0.0085\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 18:12:32\n",
      "Accuracy: 0.9738 - Precision: 0.4814 - Recall: 0.0978 - Specificity: 0.9971 - F1: 0.1348 - Loss: 0.0085\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 18:12:41\n",
      "Accuracy: 0.9738 - Precision: 0.4831 - Recall: 0.0975 - Specificity: 0.9971 - F1: 0.1343 - Loss: 0.0085\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 18:12:51\n",
      "Accuracy: 0.9738 - Precision: 0.4847 - Recall: 0.0972 - Specificity: 0.9971 - F1: 0.1339 - Loss: 0.0085\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 18:13:00\n",
      "Accuracy: 0.9738 - Precision: 0.4862 - Recall: 0.0968 - Specificity: 0.9971 - F1: 0.1334 - Loss: 0.0085\n",
      "\n",
      "Epoch 1/20\n",
      "Train - Accuracy: 0.9738, Precision: 0.4862, Recall: 0.0968, Specificity: 0.9971, F1: 0.1334, Loss: 0.0085\n",
      "Validation - Accuracy: 0.9786, Precision: 0.9534, Recall: 0.0014, Specificity: 1.0000, F1: 0.0027, Loss: 0.0058\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "When providing `x` as a PyDataset, `y` should not be passed. Instead, the targets should be included as part of the PyDataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 209\u001b[0m\n\u001b[0;32m    206\u001b[0m metrics_callback \u001b[38;5;241m=\u001b[39m MetricsCallback(total_batches\u001b[38;5;241m=\u001b[39msteps_per_epoch, X_valid\u001b[38;5;241m=\u001b[39mvalid_gen, y_valid\u001b[38;5;241m=\u001b[39mvalid_gen, X_test\u001b[38;5;241m=\u001b[39mtest_gen, y_test\u001b[38;5;241m=\u001b[39mtest_gen)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    210\u001b[0m     train_gen,\n\u001b[0;32m    211\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[0;32m    212\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m    213\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalid_gen,\n\u001b[0;32m    214\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m    215\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[metrics_callback, early_stopping],\n\u001b[0;32m    216\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    217\u001b[0m )\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[0;32m    220\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdental_xray_vgg16_unet_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[1], line 198\u001b[0m, in \u001b[0;36mMetricsCallback.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain - Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Specificity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspecificity\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation - Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_precision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_recall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Specificity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_specificity\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 198\u001b[0m test_loss, test_accuracy, test_precision, test_recall, test_specificity, test_f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Set Results - Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_precision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_recall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Specificity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_specificity\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: When providing `x` as a PyDataset, `y` should not be passed. Instead, the targets should be included as part of the PyDataset."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import backend as K\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import VGG16  # Import VGG16 for the new model\n",
    "\n",
    "# Directory paths\n",
    "train_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\train\"\n",
    "train_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\train\\train_mask\"\n",
    "test_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\test\"\n",
    "test_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\test\\test_mask\"\n",
    "valid_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\valid\"\n",
    "valid_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\valid\\valid_mask\"\n",
    "\n",
    "# Image generator to load data in batches\n",
    "def image_generator(img_dir, mask_dir, batch_size, img_size=(256, 256)):\n",
    "    img_files = os.listdir(img_dir)\n",
    "    while True:\n",
    "        images = []\n",
    "        masks = []\n",
    "        for img_file in img_files:\n",
    "            img_path = os.path.join(img_dir, img_file)\n",
    "            mask_file = img_file + \"_mask.png\"\n",
    "            mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "            if os.path.exists(mask_path):\n",
    "                # Load image and mask\n",
    "                img = load_img(img_path, color_mode='rgb', target_size=img_size)\n",
    "                img = img_to_array(img) / 255.0\n",
    "                mask = load_img(mask_path, color_mode='grayscale', target_size=img_size)\n",
    "                mask = img_to_array(mask) / 255.0\n",
    "\n",
    "                images.append(img)\n",
    "                masks.append(mask)\n",
    "\n",
    "            if len(images) == batch_size:\n",
    "                yield np.array(images), np.array(masks)\n",
    "                images = []\n",
    "                masks = []\n",
    "\n",
    "# VGG16-based model replacing U-Net\n",
    "def vgg16_unet_model(input_size=(256, 256, 3)):\n",
    "    # Load VGG16 as the encoder with pre-trained ImageNet weights\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=input_size)\n",
    "    \n",
    "    # Freeze VGG16 layers to prevent them from being trained\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Extract layers for skip connections\n",
    "    block1 = vgg16.get_layer('block1_pool').output   # 128x128\n",
    "    block2 = vgg16.get_layer('block2_pool').output   # 64x64\n",
    "    block3 = vgg16.get_layer('block3_pool').output   # 32x32\n",
    "    block4 = vgg16.get_layer('block4_pool').output   # 16x16\n",
    "    block5 = vgg16.get_layer('block5_pool').output   # 8x8\n",
    "    \n",
    "    # Decoder\n",
    "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(block5)  # 16x16\n",
    "    u6 = layers.concatenate([u6, block4])\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "    \n",
    "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)  # 32x32\n",
    "    u7 = layers.concatenate([u7, block3])\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "    \n",
    "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)  # 64x64\n",
    "    u8 = layers.concatenate([u8, block2])\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "    \n",
    "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)    # 128x128\n",
    "    u9 = layers.concatenate([u9, block1])\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "    \n",
    "    # Final upsampling to reach original image size\n",
    "    u10 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c9)  # 256x256\n",
    "    c10 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u10)\n",
    "    c10 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c10)\n",
    "    \n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c10)\n",
    "    \n",
    "    model = models.Model(inputs=vgg16.input, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define custom metrics\n",
    "def custom_precision(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_positives = K.sum(K.round(y_true * y_pred_bin))\n",
    "    predicted_positives = K.sum(y_pred_bin)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def custom_recall(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_positives = K.sum(K.round(y_true * y_pred_bin))\n",
    "    possible_positives = K.sum(y_true)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def custom_specificity(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_negatives = K.sum(K.round((1 - y_true) * (1 - y_pred_bin)))\n",
    "    possible_negatives = K.sum(1 - y_true)\n",
    "    specificity = true_negatives / (possible_negatives + K.epsilon())\n",
    "    return specificity\n",
    "\n",
    "def custom_f1(y_true, y_pred):\n",
    "    precision = custom_precision(y_true, y_pred)\n",
    "    recall = custom_recall(y_true, y_pred)\n",
    "    return 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "\n",
    "# Define Focal Loss\n",
    "def focal_loss_fixed(y_true, y_pred):\n",
    "    gamma = 2.0\n",
    "    alpha = 0.25\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    cross_entropy = -y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred)\n",
    "    weight = alpha * y_true * K.pow((1 - y_pred), gamma) + (1 - alpha) * (1 - y_true) * K.pow(y_pred, gamma)\n",
    "    loss = weight * cross_entropy\n",
    "    return K.mean(loss)\n",
    "\n",
    "# Compile the model\n",
    "model = vgg16_unet_model()\n",
    "model.compile(optimizer='adam', loss=focal_loss_fixed, metrics=['accuracy', custom_precision, custom_recall, custom_specificity, custom_f1])\n",
    "\n",
    "# Batch size for training\n",
    "batch_size = 16\n",
    "\n",
    "# Create data generators\n",
    "train_gen = image_generator(train_img_dir, train_mask_dir, batch_size)\n",
    "valid_gen = image_generator(valid_img_dir, valid_mask_dir, batch_size)\n",
    "test_gen = image_generator(test_img_dir, test_mask_dir, batch_size)\n",
    "\n",
    "# Number of steps per epoch\n",
    "steps_per_epoch = len(os.listdir(train_img_dir)) // batch_size\n",
    "validation_steps = len(os.listdir(valid_img_dir)) // batch_size\n",
    "test_steps = len(os.listdir(test_img_dir)) // batch_size\n",
    "\n",
    "# Custom callback to print more metrics at each batch and epoch for training, validation, and test sets\n",
    "class MetricsCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, total_batches, X_valid, y_valid, X_test, y_test):\n",
    "        super().__init__()\n",
    "        self.batch_counter = 1\n",
    "        self.total_batches = total_batches\n",
    "        self.current_epoch = 1\n",
    "        self.X_valid = X_valid\n",
    "        self.y_valid = y_valid\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.current_epoch = epoch + 1\n",
    "        print(f\"\\nEpoch {self.current_epoch}/{self.params['epochs']}\")\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        accuracy = logs.get('accuracy', 0)\n",
    "        loss = logs.get('loss', 0)\n",
    "        precision = logs.get('custom_precision', 0)\n",
    "        recall = logs.get('custom_recall', 0)\n",
    "        f1 = logs.get('custom_f1', 0)\n",
    "        specificity = logs.get('custom_specificity', 0)\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print(f\"Batch {self.batch_counter}/{self.total_batches} ━━━━━━━━━━━━━━━━━━━━ {current_time}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f} - Precision: {precision:.4f} - Recall: {recall:.4f} - Specificity: {specificity:.4f} - F1: {f1:.4f} - Loss: {loss:.4f}\\n\")\n",
    "        self.batch_counter += 1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        accuracy = logs.get('accuracy', 0)\n",
    "        val_accuracy = logs.get('val_accuracy', 0)\n",
    "        loss = logs.get('loss', 0)\n",
    "        val_loss = logs.get('val_loss', 0)\n",
    "        precision = logs.get('custom_precision', 0)\n",
    "        val_precision = logs.get('val_custom_precision', 0)\n",
    "        recall = logs.get('custom_recall', 0)\n",
    "        val_recall = logs.get('val_custom_recall', 0)\n",
    "        f1 = logs.get('custom_f1', 0)\n",
    "        val_f1 = logs.get('val_custom_f1', 0)\n",
    "        specificity = logs.get('custom_specificity', 0)\n",
    "        val_specificity = logs.get('val_custom_specificity', 0)\n",
    "        print(f\"Epoch {epoch+1}/{self.params['epochs']}\")\n",
    "        print(f\"Train - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Specificity: {specificity:.4f}, F1: {f1:.4f}, Loss: {loss:.4f}\")\n",
    "        print(f\"Validation - Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, Specificity: {val_specificity:.4f}, F1: {val_f1:.4f}, Loss: {val_loss:.4f}\\n\")\n",
    "        test_loss, test_accuracy, test_precision, test_recall, test_specificity, test_f1 = self.model.evaluate(self.X_test, self.y_test, verbose=0)\n",
    "        print(f\"Test Set Results - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, Specificity: {test_specificity:.4f}, F1: {test_f1:.4f}, Loss: {test_loss:.4f}\\n\")\n",
    "        self.batch_counter = 1\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Initialize the custom callback with validation and test data\n",
    "metrics_callback = MetricsCallback(total_batches=steps_per_epoch, X_valid=valid_gen, y_valid=valid_gen, X_test=test_gen, y_test=test_gen)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=20,\n",
    "    validation_data=valid_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[metrics_callback, early_stopping],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('dental_xray_vgg16_unet_model.h5')\n",
    "\n",
    "# Evaluate on the training set\n",
    "train_gen_full = image_generator(train_img_dir, train_mask_dir, batch_size)\n",
    "y_train_pred = model.predict(train_gen_full, steps=steps_per_epoch)\n",
    "y_train_pred_bin = (y_train_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "# Confusion Matrix for training\n",
    "conf_matrix_train = confusion_matrix(y_train_pred_bin.flatten(), y_train_pred_bin.flatten())\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_train, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix for Train\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix for validation set\n",
    "y_valid_pred = model.predict(valid_gen, steps=validation_steps)\n",
    "y_valid_pred_bin = (y_valid_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "conf_matrix_valid = confusion_matrix(y_valid_pred_bin.flatten(), y_valid_pred_bin.flatten())\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_valid, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix for Validation\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix for test set\n",
    "y_test_pred = model.predict(test_gen, steps=test_steps)\n",
    "y_test_pred_bin = (y_test_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "conf_matrix_test = confusion_matrix(y_test_pred_bin.flatten(), y_test_pred_bin.flatten())\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_test, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix for Test\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization: Show input image, true mask, and predicted mask for a few samples\n",
    "def visualize_predictions(images, true_masks, pred_masks, title):\n",
    "    for i in range(3):  # Visualize first 3 predictions\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # Original image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "        \n",
    "        # Ground truth mask\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(true_masks[i].squeeze(), cmap='gray')\n",
    "        plt.title('Ground Truth Mask')\n",
    "        \n",
    "        # Predicted mask\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(pred_masks[i].squeeze(), cmap='gray')\n",
    "        plt.title('Predicted Mask')\n",
    "        \n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "\n",
    "# Visualize predictions for training set\n",
    "visualize_predictions(X_train, y_train, y_train_pred_bin, \"Train Set Predictions\")\n",
    "\n",
    "# Visualize predictions for validation set\n",
    "visualize_predictions(X_valid, y_valid, y_valid_pred_bin, \"Validation Set Predictions\")\n",
    "\n",
    "# Visualize predictions for test set\n",
    "visualize_predictions(X_test, y_test, y_test_pred_bin, \"Test Set Predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d3f7ad-b969-478f-b2de-d0176a46f644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 18:32:13\n",
      "Accuracy: 0.7767 - Precision: 0.0318 - Recall: 0.2546 - Specificity: 0.7908 - F1: 0.0565 - Loss: 0.0979\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 18:32:21\n",
      "Accuracy: 0.8736 - Precision: 0.0159 - Recall: 0.1273 - Specificity: 0.8953 - F1: 0.0282 - Loss: 0.0578\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 18:32:29\n",
      "Accuracy: 0.9053 - Precision: 0.0106 - Recall: 0.0849 - Specificity: 0.9302 - F1: 0.0188 - Loss: 0.0487\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 18:32:38\n",
      "Accuracy: 0.9248 - Precision: 0.0079 - Recall: 0.0637 - Specificity: 0.9476 - F1: 0.0141 - Loss: 0.0390\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 18:32:46\n",
      "Accuracy: 0.9367 - Precision: 0.0064 - Recall: 0.0509 - Specificity: 0.9581 - F1: 0.0113 - Loss: 0.0330\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 18:32:54\n",
      "Accuracy: 0.9433 - Precision: 0.0053 - Recall: 0.0424 - Specificity: 0.9651 - F1: 0.0094 - Loss: 0.0296\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 18:33:02\n",
      "Accuracy: 0.9494 - Precision: 0.0045 - Recall: 0.0364 - Specificity: 0.9701 - F1: 0.0081 - Loss: 0.0264\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 18:33:13\n",
      "Accuracy: 0.9535 - Precision: 0.0040 - Recall: 0.0318 - Specificity: 0.9738 - F1: 0.0071 - Loss: 0.0242\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 18:33:23\n",
      "Accuracy: 0.9569 - Precision: 0.0035 - Recall: 0.0283 - Specificity: 0.9767 - F1: 0.0063 - Loss: 0.0224\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 18:33:32\n",
      "Accuracy: 0.9595 - Precision: 0.0032 - Recall: 0.0255 - Specificity: 0.9791 - F1: 0.0056 - Loss: 0.0209\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 18:33:41\n",
      "Accuracy: 0.9616 - Precision: 0.0029 - Recall: 0.0231 - Specificity: 0.9810 - F1: 0.0051 - Loss: 0.0197\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 18:33:49\n",
      "Accuracy: 0.9633 - Precision: 0.0026 - Recall: 0.0212 - Specificity: 0.9825 - F1: 0.0047 - Loss: 0.0189\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 18:33:57\n",
      "Accuracy: 0.9646 - Precision: 0.0024 - Recall: 0.0196 - Specificity: 0.9839 - F1: 0.0043 - Loss: 0.0181\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 18:34:05\n",
      "Accuracy: 0.9660 - Precision: 0.0023 - Recall: 0.0182 - Specificity: 0.9850 - F1: 0.0040 - Loss: 0.0173\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 18:34:13\n",
      "Accuracy: 0.9670 - Precision: 0.0021 - Recall: 0.0170 - Specificity: 0.9860 - F1: 0.0038 - Loss: 0.0166\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 18:34:22\n",
      "Accuracy: 0.9674 - Precision: 0.0020 - Recall: 0.0159 - Specificity: 0.9869 - F1: 0.0035 - Loss: 0.0162\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 18:34:29\n",
      "Accuracy: 0.9684 - Precision: 0.0019 - Recall: 0.0150 - Specificity: 0.9877 - F1: 0.0033 - Loss: 0.0156\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 18:34:37\n",
      "Accuracy: 0.9689 - Precision: 0.0018 - Recall: 0.0141 - Specificity: 0.9884 - F1: 0.0031 - Loss: 0.0151\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 18:34:45\n",
      "Accuracy: 0.9695 - Precision: 0.0017 - Recall: 0.0134 - Specificity: 0.9890 - F1: 0.0030 - Loss: 0.0146\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 18:34:53\n",
      "Accuracy: 0.9702 - Precision: 0.0016 - Recall: 0.0127 - Specificity: 0.9895 - F1: 0.0028 - Loss: 0.0142\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 18:35:01\n",
      "Accuracy: 0.9707 - Precision: 0.0015 - Recall: 0.0121 - Specificity: 0.9900 - F1: 0.0027 - Loss: 0.0139\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 18:35:09\n",
      "Accuracy: 0.9709 - Precision: 0.0014 - Recall: 0.0116 - Specificity: 0.9905 - F1: 0.0026 - Loss: 0.0137\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 18:35:16\n",
      "Accuracy: 0.9713 - Precision: 0.0014 - Recall: 0.0111 - Specificity: 0.9909 - F1: 0.0025 - Loss: 0.0136\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 18:35:24\n",
      "Accuracy: 0.9714 - Precision: 0.0013 - Recall: 0.0106 - Specificity: 0.9913 - F1: 0.0024 - Loss: 0.0133\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 18:35:33\n",
      "Accuracy: 0.9717 - Precision: 0.0013 - Recall: 0.0102 - Specificity: 0.9916 - F1: 0.0023 - Loss: 0.0130\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 18:35:42\n",
      "Accuracy: 0.9722 - Precision: 0.0012 - Recall: 0.0098 - Specificity: 0.9919 - F1: 0.0022 - Loss: 0.0127\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 18:35:50\n",
      "Accuracy: 0.9725 - Precision: 0.0012 - Recall: 0.0094 - Specificity: 0.9922 - F1: 0.0021 - Loss: 0.0125\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 18:35:58\n",
      "Accuracy: 0.9727 - Precision: 0.0011 - Recall: 0.0091 - Specificity: 0.9925 - F1: 0.0020 - Loss: 0.0123\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 18:36:06\n",
      "Accuracy: 0.9726 - Precision: 0.0011 - Recall: 0.0088 - Specificity: 0.9928 - F1: 0.0019 - Loss: 0.0122\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 18:36:14\n",
      "Accuracy: 0.9728 - Precision: 0.0011 - Recall: 0.0085 - Specificity: 0.9930 - F1: 0.0019 - Loss: 0.0120\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 18:36:22\n",
      "Accuracy: 0.9731 - Precision: 0.0010 - Recall: 0.0082 - Specificity: 0.9932 - F1: 0.0018 - Loss: 0.0118\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 18:36:30\n",
      "Accuracy: 0.9733 - Precision: 0.0010 - Recall: 0.0080 - Specificity: 0.9935 - F1: 0.0018 - Loss: 0.0116\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 18:36:38\n",
      "Accuracy: 0.9735 - Precision: 0.0010 - Recall: 0.0077 - Specificity: 0.9937 - F1: 0.0017 - Loss: 0.0115\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 18:36:46\n",
      "Accuracy: 0.9735 - Precision: 0.0009 - Recall: 0.0075 - Specificity: 0.9938 - F1: 0.0017 - Loss: 0.0113\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 18:36:54\n",
      "Accuracy: 0.9736 - Precision: 0.0009 - Recall: 0.0073 - Specificity: 0.9940 - F1: 0.0016 - Loss: 0.0112\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 18:37:01\n",
      "Accuracy: 0.9739 - Precision: 0.0009 - Recall: 0.0071 - Specificity: 0.9942 - F1: 0.0016 - Loss: 0.0111\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 18:37:09\n",
      "Accuracy: 0.9739 - Precision: 0.0009 - Recall: 0.0069 - Specificity: 0.9943 - F1: 0.0015 - Loss: 0.0109\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 18:37:17\n",
      "Accuracy: 0.9740 - Precision: 0.0008 - Recall: 0.0067 - Specificity: 0.9945 - F1: 0.0015 - Loss: 0.0108\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 18:37:25\n",
      "Accuracy: 0.9741 - Precision: 0.0008 - Recall: 0.0065 - Specificity: 0.9946 - F1: 0.0014 - Loss: 0.0107\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 18:37:34\n",
      "Accuracy: 0.9742 - Precision: 0.0008 - Recall: 0.0064 - Specificity: 0.9948 - F1: 0.0014 - Loss: 0.0105\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 18:37:43\n",
      "Accuracy: 0.9741 - Precision: 0.0008 - Recall: 0.0062 - Specificity: 0.9949 - F1: 0.0014 - Loss: 0.0105\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 18:37:51\n",
      "Accuracy: 0.9742 - Precision: 0.0008 - Recall: 0.0061 - Specificity: 0.9950 - F1: 0.0013 - Loss: 0.0104\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 18:38:00\n",
      "Accuracy: 0.9743 - Precision: 0.0007 - Recall: 0.0059 - Specificity: 0.9951 - F1: 0.0013 - Loss: 0.0102\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 18:38:08\n",
      "Accuracy: 0.9744 - Precision: 0.0007 - Recall: 0.0058 - Specificity: 0.9952 - F1: 0.0013 - Loss: 0.0101\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 18:38:16\n",
      "Accuracy: 0.9747 - Precision: 0.0007 - Recall: 0.0057 - Specificity: 0.9953 - F1: 0.0013 - Loss: 0.0100\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 18:38:24\n",
      "Accuracy: 0.9747 - Precision: 0.0007 - Recall: 0.0055 - Specificity: 0.9954 - F1: 0.0012 - Loss: 0.0099\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 18:38:32\n",
      "Accuracy: 0.9747 - Precision: 0.0007 - Recall: 0.0054 - Specificity: 0.9955 - F1: 0.0012 - Loss: 0.0098\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 18:38:40\n",
      "Accuracy: 0.9747 - Precision: 0.0007 - Recall: 0.0053 - Specificity: 0.9956 - F1: 0.0012 - Loss: 0.0097\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 18:38:48\n",
      "Accuracy: 0.9748 - Precision: 0.0006 - Recall: 0.0052 - Specificity: 0.9957 - F1: 0.0012 - Loss: 0.0096\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 18:38:56\n",
      "Accuracy: 0.9748 - Precision: 0.0006 - Recall: 0.0051 - Specificity: 0.9958 - F1: 0.0011 - Loss: 0.0095\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 18:39:06\n",
      "Accuracy: 0.9749 - Precision: 0.0006 - Recall: 0.0050 - Specificity: 0.9959 - F1: 0.0011 - Loss: 0.0094\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 18:39:16\n",
      "Accuracy: 0.9750 - Precision: 0.0006 - Recall: 0.0049 - Specificity: 0.9960 - F1: 0.0011 - Loss: 0.0093\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 18:39:26\n",
      "Accuracy: 0.9751 - Precision: 0.0006 - Recall: 0.0048 - Specificity: 0.9960 - F1: 0.0011 - Loss: 0.0092\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 18:39:35\n",
      "Accuracy: 0.9752 - Precision: 0.0006 - Recall: 0.0047 - Specificity: 0.9961 - F1: 0.0010 - Loss: 0.0091\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 18:39:44\n",
      "Accuracy: 0.9753 - Precision: 0.0006 - Recall: 0.0046 - Specificity: 0.9962 - F1: 0.0010 - Loss: 0.0091\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 18:39:52\n",
      "Accuracy: 0.9754 - Precision: 0.0006 - Recall: 0.0045 - Specificity: 0.9963 - F1: 0.0010 - Loss: 0.0090\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 18:40:00\n",
      "Accuracy: 0.9755 - Precision: 0.0006 - Recall: 0.0045 - Specificity: 0.9963 - F1: 0.0010 - Loss: 0.0089\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 18:40:08\n",
      "Accuracy: 0.9756 - Precision: 0.0005 - Recall: 0.0044 - Specificity: 0.9964 - F1: 0.0010 - Loss: 0.0088\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 18:40:16\n",
      "Accuracy: 0.9757 - Precision: 0.0175 - Recall: 0.0043 - Specificity: 0.9965 - F1: 0.0010 - Loss: 0.0087\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 18:40:24\n",
      "Accuracy: 0.9757 - Precision: 0.0172 - Recall: 0.0042 - Specificity: 0.9965 - F1: 0.0009 - Loss: 0.0086\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 18:40:32\n",
      "Accuracy: 0.9758 - Precision: 0.0333 - Recall: 0.0042 - Specificity: 0.9966 - F1: 0.0009 - Loss: 0.0086\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 18:40:40\n",
      "Accuracy: 0.9759 - Precision: 0.0441 - Recall: 0.0041 - Specificity: 0.9966 - F1: 0.0009 - Loss: 0.0085\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 18:40:48\n",
      "Accuracy: 0.9759 - Precision: 0.0578 - Recall: 0.0041 - Specificity: 0.9967 - F1: 0.0009 - Loss: 0.0084\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 18:40:56\n",
      "Accuracy: 0.9760 - Precision: 0.0725 - Recall: 0.0040 - Specificity: 0.9967 - F1: 0.0009 - Loss: 0.0083\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 18:41:03\n",
      "Accuracy: 0.9760 - Precision: 0.0714 - Recall: 0.0039 - Specificity: 0.9968 - F1: 0.0009 - Loss: 0.0083\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 18:41:11\n",
      "Accuracy: 0.9760 - Precision: 0.0794 - Recall: 0.0039 - Specificity: 0.9968 - F1: 0.0009 - Loss: 0.0083\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 18:41:19\n",
      "Accuracy: 0.9760 - Precision: 0.0931 - Recall: 0.0038 - Specificity: 0.9969 - F1: 0.0009 - Loss: 0.0082\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 18:41:27\n",
      "Accuracy: 0.9760 - Precision: 0.1040 - Recall: 0.0038 - Specificity: 0.9969 - F1: 0.0009 - Loss: 0.0082\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 18:41:36\n",
      "Accuracy: 0.9761 - Precision: 0.1025 - Recall: 0.0037 - Specificity: 0.9970 - F1: 0.0009 - Loss: 0.0081\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 18:41:45\n",
      "Accuracy: 0.9762 - Precision: 0.1153 - Recall: 0.0037 - Specificity: 0.9970 - F1: 0.0009 - Loss: 0.0080\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 18:41:53\n",
      "Accuracy: 0.9763 - Precision: 0.1137 - Recall: 0.0036 - Specificity: 0.9971 - F1: 0.0009 - Loss: 0.0080\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 18:42:01\n",
      "Accuracy: 0.9763 - Precision: 0.1260 - Recall: 0.0036 - Specificity: 0.9971 - F1: 0.0009 - Loss: 0.0079\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 18:42:09\n",
      "Accuracy: 0.9763 - Precision: 0.1380 - Recall: 0.0035 - Specificity: 0.9971 - F1: 0.0009 - Loss: 0.0079\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 18:42:17\n",
      "Accuracy: 0.9762 - Precision: 0.1463 - Recall: 0.0035 - Specificity: 0.9972 - F1: 0.0008 - Loss: 0.0079\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 18:42:24\n",
      "Accuracy: 0.9762 - Precision: 0.1577 - Recall: 0.0034 - Specificity: 0.9972 - F1: 0.0008 - Loss: 0.0078\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 18:42:32\n",
      "Accuracy: 0.9763 - Precision: 0.1687 - Recall: 0.0034 - Specificity: 0.9972 - F1: 0.0008 - Loss: 0.0078\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 18:42:40\n",
      "Accuracy: 0.9763 - Precision: 0.1795 - Recall: 0.0034 - Specificity: 0.9973 - F1: 0.0008 - Loss: 0.0077\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 18:42:48\n",
      "Accuracy: 0.9763 - Precision: 0.1772 - Recall: 0.0033 - Specificity: 0.9973 - F1: 0.0008 - Loss: 0.0077\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 18:42:56\n",
      "Accuracy: 0.9763 - Precision: 0.1750 - Recall: 0.0033 - Specificity: 0.9973 - F1: 0.0008 - Loss: 0.0077\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 18:43:04\n",
      "Accuracy: 0.9763 - Precision: 0.1832 - Recall: 0.0032 - Specificity: 0.9974 - F1: 0.0008 - Loss: 0.0076\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 18:43:12\n",
      "Accuracy: 0.9764 - Precision: 0.1925 - Recall: 0.0032 - Specificity: 0.9974 - F1: 0.0008 - Loss: 0.0076\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 18:43:20\n",
      "Accuracy: 0.9764 - Precision: 0.1983 - Recall: 0.0032 - Specificity: 0.9974 - F1: 0.0008 - Loss: 0.0075\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 18:43:28\n",
      "Accuracy: 0.9765 - Precision: 0.2079 - Recall: 0.0031 - Specificity: 0.9975 - F1: 0.0008 - Loss: 0.0075\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 18:43:36\n",
      "Accuracy: 0.9765 - Precision: 0.2054 - Recall: 0.0031 - Specificity: 0.9975 - F1: 0.0008 - Loss: 0.0075\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 18:43:45\n",
      "Accuracy: 0.9766 - Precision: 0.2148 - Recall: 0.0031 - Specificity: 0.9975 - F1: 0.0008 - Loss: 0.0074\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 18:43:53\n",
      "Accuracy: 0.9766 - Precision: 0.2239 - Recall: 0.0030 - Specificity: 0.9976 - F1: 0.0008 - Loss: 0.0074\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 18:44:01\n",
      "Accuracy: 0.9766 - Precision: 0.2328 - Recall: 0.0030 - Specificity: 0.9976 - F1: 0.0008 - Loss: 0.0073\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 18:44:09\n",
      "Accuracy: 0.9767 - Precision: 0.2391 - Recall: 0.0030 - Specificity: 0.9976 - F1: 0.0008 - Loss: 0.0073\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 18:44:17\n",
      "Accuracy: 0.9767 - Precision: 0.2477 - Recall: 0.0029 - Specificity: 0.9976 - F1: 0.0008 - Loss: 0.0073\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 18:44:25\n",
      "Accuracy: 0.9766 - Precision: 0.2560 - Recall: 0.0029 - Specificity: 0.9977 - F1: 0.0008 - Loss: 0.0072\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 18:44:33\n",
      "Accuracy: 0.9766 - Precision: 0.2642 - Recall: 0.0029 - Specificity: 0.9977 - F1: 0.0008 - Loss: 0.0072\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 18:44:41\n",
      "Accuracy: 0.9767 - Precision: 0.2722 - Recall: 0.0029 - Specificity: 0.9977 - F1: 0.0008 - Loss: 0.0072\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 18:44:49\n",
      "Accuracy: 0.9767 - Precision: 0.2779 - Recall: 0.0028 - Specificity: 0.9977 - F1: 0.0008 - Loss: 0.0071\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 18:44:57\n",
      "Accuracy: 0.9768 - Precision: 0.2842 - Recall: 0.0028 - Specificity: 0.9978 - F1: 0.0008 - Loss: 0.0071\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 18:45:04\n",
      "Accuracy: 0.9768 - Precision: 0.2911 - Recall: 0.0028 - Specificity: 0.9978 - F1: 0.0009 - Loss: 0.0070\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 18:45:12\n",
      "Accuracy: 0.9768 - Precision: 0.2977 - Recall: 0.0028 - Specificity: 0.9978 - F1: 0.0009 - Loss: 0.0070\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 18:45:20\n",
      "Accuracy: 0.9769 - Precision: 0.3043 - Recall: 0.0028 - Specificity: 0.9978 - F1: 0.0010 - Loss: 0.0070\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 18:45:29\n",
      "Accuracy: 0.9769 - Precision: 0.3102 - Recall: 0.0029 - Specificity: 0.9979 - F1: 0.0011 - Loss: 0.0069\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 18:45:37\n",
      "Accuracy: 0.9769 - Precision: 0.3158 - Recall: 0.0029 - Specificity: 0.9979 - F1: 0.0012 - Loss: 0.0069\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 18:45:46\n",
      "Accuracy: 0.9770 - Precision: 0.3220 - Recall: 0.0029 - Specificity: 0.9979 - F1: 0.0013 - Loss: 0.0068\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 18:45:54\n",
      "Accuracy: 0.9771 - Precision: 0.3277 - Recall: 0.0029 - Specificity: 0.9979 - F1: 0.0014 - Loss: 0.0068\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 18:46:02\n",
      "Accuracy: 0.9772 - Precision: 0.3311 - Recall: 0.0029 - Specificity: 0.9979 - F1: 0.0014 - Loss: 0.0068\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 18:46:10\n",
      "Accuracy: 0.9773 - Precision: 0.3344 - Recall: 0.0030 - Specificity: 0.9980 - F1: 0.0015 - Loss: 0.0067\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 18:46:18\n",
      "Accuracy: 0.9773 - Precision: 0.3390 - Recall: 0.0030 - Specificity: 0.9980 - F1: 0.0017 - Loss: 0.0067\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 18:46:26\n",
      "Accuracy: 0.9773 - Precision: 0.3428 - Recall: 0.0031 - Specificity: 0.9980 - F1: 0.0020 - Loss: 0.0067\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 18:46:34\n",
      "Accuracy: 0.9774 - Precision: 0.3482 - Recall: 0.0033 - Specificity: 0.9980 - F1: 0.0022 - Loss: 0.0066\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 18:46:42\n",
      "Accuracy: 0.9774 - Precision: 0.3522 - Recall: 0.0033 - Specificity: 0.9980 - F1: 0.0024 - Loss: 0.0066\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 18:46:50\n",
      "Accuracy: 0.9775 - Precision: 0.3556 - Recall: 0.0033 - Specificity: 0.9981 - F1: 0.0025 - Loss: 0.0066\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 18:46:58\n",
      "Accuracy: 0.9775 - Precision: 0.3608 - Recall: 0.0034 - Specificity: 0.9981 - F1: 0.0026 - Loss: 0.0066\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 18:47:06\n",
      "Accuracy: 0.9776 - Precision: 0.3654 - Recall: 0.0035 - Specificity: 0.9981 - F1: 0.0029 - Loss: 0.0065\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 18:47:14\n",
      "Accuracy: 0.9776 - Precision: 0.3692 - Recall: 0.0037 - Specificity: 0.9981 - F1: 0.0033 - Loss: 0.0065\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 18:47:22\n",
      "Accuracy: 0.9776 - Precision: 0.3739 - Recall: 0.0038 - Specificity: 0.9981 - F1: 0.0034 - Loss: 0.0065\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 18:47:30\n",
      "Accuracy: 0.9777 - Precision: 0.3780 - Recall: 0.0038 - Specificity: 0.9981 - F1: 0.0036 - Loss: 0.0064\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 18:47:38\n",
      "Accuracy: 0.9777 - Precision: 0.3833 - Recall: 0.0039 - Specificity: 0.9982 - F1: 0.0038 - Loss: 0.0064\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 18:47:47\n",
      "Accuracy: 0.9777 - Precision: 0.3883 - Recall: 0.0040 - Specificity: 0.9982 - F1: 0.0041 - Loss: 0.0064\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 18:47:55\n",
      "Accuracy: 0.9778 - Precision: 0.3925 - Recall: 0.0042 - Specificity: 0.9982 - F1: 0.0045 - Loss: 0.0063\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 18:48:03\n",
      "Accuracy: 0.9778 - Precision: 0.3970 - Recall: 0.0044 - Specificity: 0.9982 - F1: 0.0049 - Loss: 0.0063\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 18:48:11\n",
      "Accuracy: 0.9778 - Precision: 0.4012 - Recall: 0.0046 - Specificity: 0.9982 - F1: 0.0053 - Loss: 0.0063\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 18:48:19\n",
      "Accuracy: 0.9778 - Precision: 0.4047 - Recall: 0.0048 - Specificity: 0.9982 - F1: 0.0057 - Loss: 0.0063\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 18:48:27\n",
      "Accuracy: 0.9779 - Precision: 0.4071 - Recall: 0.0050 - Specificity: 0.9982 - F1: 0.0060 - Loss: 0.0062\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 18:48:35\n",
      "Accuracy: 0.9779 - Precision: 0.4111 - Recall: 0.0051 - Specificity: 0.9983 - F1: 0.0063 - Loss: 0.0062\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 18:48:43\n",
      "Accuracy: 0.9779 - Precision: 0.4153 - Recall: 0.0052 - Specificity: 0.9983 - F1: 0.0065 - Loss: 0.0062\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 18:48:51\n",
      "Accuracy: 0.9779 - Precision: 0.4195 - Recall: 0.0057 - Specificity: 0.9983 - F1: 0.0074 - Loss: 0.0062\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 18:48:59\n",
      "Accuracy: 0.9779 - Precision: 0.4235 - Recall: 0.0066 - Specificity: 0.9983 - F1: 0.0092 - Loss: 0.0062\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 18:49:07\n",
      "Accuracy: 0.9780 - Precision: 0.4269 - Recall: 0.0076 - Specificity: 0.9983 - F1: 0.0109 - Loss: 0.0061\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 18:49:15\n",
      "Accuracy: 0.9780 - Precision: 0.4313 - Recall: 0.0082 - Specificity: 0.9983 - F1: 0.0120 - Loss: 0.0061\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 18:49:23\n",
      "Accuracy: 0.9781 - Precision: 0.4352 - Recall: 0.0086 - Specificity: 0.9983 - F1: 0.0129 - Loss: 0.0061\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 18:49:31\n",
      "Accuracy: 0.9781 - Precision: 0.4383 - Recall: 0.0089 - Specificity: 0.9983 - F1: 0.0134 - Loss: 0.0061\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 18:49:39\n",
      "Accuracy: 0.9781 - Precision: 0.4425 - Recall: 0.0100 - Specificity: 0.9984 - F1: 0.0154 - Loss: 0.0061\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 18:49:49\n",
      "Accuracy: 0.9782 - Precision: 0.4454 - Recall: 0.0118 - Specificity: 0.9984 - F1: 0.0181 - Loss: 0.0060\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 18:49:56\n",
      "Accuracy: 0.9782 - Precision: 0.4489 - Recall: 0.0138 - Specificity: 0.9984 - F1: 0.0211 - Loss: 0.0060\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 18:50:04\n",
      "Accuracy: 0.9782 - Precision: 0.4523 - Recall: 0.0151 - Specificity: 0.9984 - F1: 0.0234 - Loss: 0.0060\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 18:50:12\n",
      "Accuracy: 0.9782 - Precision: 0.4564 - Recall: 0.0157 - Specificity: 0.9984 - F1: 0.0244 - Loss: 0.0060\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 18:50:20\n",
      "Accuracy: 0.9782 - Precision: 0.4603 - Recall: 0.0163 - Specificity: 0.9984 - F1: 0.0256 - Loss: 0.0060\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 18:50:28\n",
      "Accuracy: 0.9783 - Precision: 0.4641 - Recall: 0.0179 - Specificity: 0.9984 - F1: 0.0282 - Loss: 0.0060\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 18:50:36\n",
      "Accuracy: 0.9783 - Precision: 0.4672 - Recall: 0.0202 - Specificity: 0.9984 - F1: 0.0315 - Loss: 0.0059\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 18:50:44\n",
      "Accuracy: 0.9784 - Precision: 0.4703 - Recall: 0.0227 - Specificity: 0.9984 - F1: 0.0351 - Loss: 0.0059\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 18:50:52\n",
      "Accuracy: 0.9785 - Precision: 0.4737 - Recall: 0.0250 - Specificity: 0.9984 - F1: 0.0384 - Loss: 0.0059\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 18:51:00\n",
      "Accuracy: 0.9785 - Precision: 0.4774 - Recall: 0.0271 - Specificity: 0.9984 - F1: 0.0415 - Loss: 0.0059\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 18:51:08\n",
      "Accuracy: 0.9786 - Precision: 0.4805 - Recall: 0.0296 - Specificity: 0.9985 - F1: 0.0451 - Loss: 0.0059\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 18:51:16\n",
      "Accuracy: 0.9786 - Precision: 0.4835 - Recall: 0.0331 - Specificity: 0.9985 - F1: 0.0495 - Loss: 0.0058\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 18:51:24\n",
      "Accuracy: 0.9787 - Precision: 0.4865 - Recall: 0.0355 - Specificity: 0.9985 - F1: 0.0529 - Loss: 0.0058\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 18:51:32\n",
      "Accuracy: 0.9787 - Precision: 0.4886 - Recall: 0.0386 - Specificity: 0.9985 - F1: 0.0567 - Loss: 0.0058\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 18:51:41\n",
      "Accuracy: 0.9788 - Precision: 0.4907 - Recall: 0.0418 - Specificity: 0.9984 - F1: 0.0605 - Loss: 0.0058\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 18:51:50\n",
      "Accuracy: 0.9788 - Precision: 0.4939 - Recall: 0.0437 - Specificity: 0.9985 - F1: 0.0634 - Loss: 0.0058\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 18:51:58\n",
      "Accuracy: 0.9789 - Precision: 0.4963 - Recall: 0.0466 - Specificity: 0.9985 - F1: 0.0671 - Loss: 0.0058\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 18:52:06\n",
      "Accuracy: 0.9789 - Precision: 0.4993 - Recall: 0.0489 - Specificity: 0.9985 - F1: 0.0703 - Loss: 0.0058\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 18:52:13\n",
      "Accuracy: 0.9790 - Precision: 0.5019 - Recall: 0.0522 - Specificity: 0.9985 - F1: 0.0744 - Loss: 0.0057\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 18:52:22\n",
      "Accuracy: 0.9790 - Precision: 0.5016 - Recall: 0.0530 - Specificity: 0.9984 - F1: 0.0756 - Loss: 0.0057\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 18:52:29\n",
      "Accuracy: 0.9791 - Precision: 0.5043 - Recall: 0.0540 - Specificity: 0.9985 - F1: 0.0773 - Loss: 0.0057\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 18:52:37\n",
      "Accuracy: 0.9791 - Precision: 0.5072 - Recall: 0.0542 - Specificity: 0.9985 - F1: 0.0777 - Loss: 0.0057\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 18:52:45\n",
      "Accuracy: 0.9791 - Precision: 0.5093 - Recall: 0.0558 - Specificity: 0.9985 - F1: 0.0801 - Loss: 0.0057\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 18:52:53\n",
      "Accuracy: 0.9791 - Precision: 0.5119 - Recall: 0.0584 - Specificity: 0.9985 - F1: 0.0835 - Loss: 0.0057\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 18:53:01\n",
      "Accuracy: 0.9792 - Precision: 0.5147 - Recall: 0.0611 - Specificity: 0.9985 - F1: 0.0871 - Loss: 0.0057\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 18:53:09\n",
      "Accuracy: 0.9792 - Precision: 0.5175 - Recall: 0.0625 - Specificity: 0.9985 - F1: 0.0893 - Loss: 0.0057\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 18:53:17\n",
      "Accuracy: 0.9793 - Precision: 0.5201 - Recall: 0.0650 - Specificity: 0.9985 - F1: 0.0926 - Loss: 0.0057\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 18:53:25\n",
      "Accuracy: 0.9793 - Precision: 0.5223 - Recall: 0.0681 - Specificity: 0.9985 - F1: 0.0963 - Loss: 0.0056\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 18:53:33\n",
      "Accuracy: 0.9794 - Precision: 0.5239 - Recall: 0.0714 - Specificity: 0.9985 - F1: 0.1000 - Loss: 0.0056\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 18:53:41\n",
      "Accuracy: 0.9794 - Precision: 0.5266 - Recall: 0.0733 - Specificity: 0.9985 - F1: 0.1027 - Loss: 0.0056\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 18:53:50\n",
      "Accuracy: 0.9795 - Precision: 0.5293 - Recall: 0.0749 - Specificity: 0.9985 - F1: 0.1051 - Loss: 0.0056\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 18:53:58\n",
      "Accuracy: 0.9795 - Precision: 0.5321 - Recall: 0.0761 - Specificity: 0.9985 - F1: 0.1071 - Loss: 0.0056\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 18:54:06\n",
      "Accuracy: 0.9796 - Precision: 0.5349 - Recall: 0.0777 - Specificity: 0.9985 - F1: 0.1096 - Loss: 0.0056\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 18:54:14\n",
      "Accuracy: 0.9796 - Precision: 0.5367 - Recall: 0.0802 - Specificity: 0.9985 - F1: 0.1126 - Loss: 0.0056\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 18:54:22\n",
      "Accuracy: 0.9797 - Precision: 0.5384 - Recall: 0.0827 - Specificity: 0.9985 - F1: 0.1157 - Loss: 0.0055\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 18:54:30\n",
      "Accuracy: 0.9798 - Precision: 0.5409 - Recall: 0.0851 - Specificity: 0.9985 - F1: 0.1188 - Loss: 0.0055\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 18:54:38\n",
      "Accuracy: 0.9798 - Precision: 0.5421 - Recall: 0.0859 - Specificity: 0.9985 - F1: 0.1201 - Loss: 0.0055\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 18:54:46\n",
      "Accuracy: 0.9798 - Precision: 0.5448 - Recall: 0.0865 - Specificity: 0.9985 - F1: 0.1213 - Loss: 0.0055\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 18:54:54\n",
      "Accuracy: 0.9798 - Precision: 0.5473 - Recall: 0.0883 - Specificity: 0.9985 - F1: 0.1239 - Loss: 0.0055\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 18:55:02\n",
      "Accuracy: 0.9799 - Precision: 0.5483 - Recall: 0.0919 - Specificity: 0.9985 - F1: 0.1274 - Loss: 0.0055\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 18:55:09\n",
      "Accuracy: 0.9799 - Precision: 0.5495 - Recall: 0.0958 - Specificity: 0.9985 - F1: 0.1310 - Loss: 0.0055\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 18:55:17\n",
      "Accuracy: 0.9800 - Precision: 0.5514 - Recall: 0.0977 - Specificity: 0.9985 - F1: 0.1335 - Loss: 0.0055\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 18:55:25\n",
      "Accuracy: 0.9800 - Precision: 0.5529 - Recall: 0.0976 - Specificity: 0.9985 - F1: 0.1337 - Loss: 0.0055\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 18:55:33\n",
      "Accuracy: 0.9800 - Precision: 0.5552 - Recall: 0.0974 - Specificity: 0.9985 - F1: 0.1335 - Loss: 0.0055\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 18:55:41\n",
      "Accuracy: 0.9800 - Precision: 0.5578 - Recall: 0.0978 - Specificity: 0.9985 - F1: 0.1344 - Loss: 0.0054\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 18:55:51\n",
      "Accuracy: 0.9800 - Precision: 0.5597 - Recall: 0.0982 - Specificity: 0.9985 - F1: 0.1353 - Loss: 0.0054\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 18:55:58\n",
      "Accuracy: 0.9800 - Precision: 0.5618 - Recall: 0.0998 - Specificity: 0.9985 - F1: 0.1376 - Loss: 0.0054\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 18:56:06\n",
      "Accuracy: 0.9801 - Precision: 0.5637 - Recall: 0.1016 - Specificity: 0.9985 - F1: 0.1400 - Loss: 0.0054\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 18:56:14\n",
      "Accuracy: 0.9801 - Precision: 0.5659 - Recall: 0.1031 - Specificity: 0.9985 - F1: 0.1422 - Loss: 0.0054\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 18:56:22\n",
      "Accuracy: 0.9802 - Precision: 0.5675 - Recall: 0.1038 - Specificity: 0.9985 - F1: 0.1435 - Loss: 0.0054\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 18:56:30\n",
      "Accuracy: 0.9802 - Precision: 0.5698 - Recall: 0.1040 - Specificity: 0.9985 - F1: 0.1440 - Loss: 0.0054\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 18:56:38\n",
      "Accuracy: 0.9802 - Precision: 0.5721 - Recall: 0.1045 - Specificity: 0.9985 - F1: 0.1450 - Loss: 0.0054\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 18:56:46\n",
      "Accuracy: 0.9802 - Precision: 0.5742 - Recall: 0.1058 - Specificity: 0.9986 - F1: 0.1469 - Loss: 0.0054\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 18:56:54\n",
      "Accuracy: 0.9803 - Precision: 0.5756 - Recall: 0.1080 - Specificity: 0.9986 - F1: 0.1496 - Loss: 0.0053\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 18:57:02\n",
      "Accuracy: 0.9803 - Precision: 0.5771 - Recall: 0.1100 - Specificity: 0.9985 - F1: 0.1521 - Loss: 0.0053\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 18:57:10\n",
      "Accuracy: 0.9804 - Precision: 0.5786 - Recall: 0.1125 - Specificity: 0.9985 - F1: 0.1550 - Loss: 0.0053\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 18:57:18\n",
      "Accuracy: 0.9804 - Precision: 0.5801 - Recall: 0.1138 - Specificity: 0.9985 - F1: 0.1568 - Loss: 0.0053\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 18:57:26\n",
      "Accuracy: 0.9804 - Precision: 0.5820 - Recall: 0.1147 - Specificity: 0.9986 - F1: 0.1583 - Loss: 0.0053\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 18:57:33\n",
      "Accuracy: 0.9804 - Precision: 0.5838 - Recall: 0.1151 - Specificity: 0.9986 - F1: 0.1592 - Loss: 0.0053\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 18:57:42\n",
      "Accuracy: 0.9804 - Precision: 0.5853 - Recall: 0.1162 - Specificity: 0.9986 - F1: 0.1608 - Loss: 0.0053\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 18:57:51\n",
      "Accuracy: 0.9805 - Precision: 0.5869 - Recall: 0.1186 - Specificity: 0.9986 - F1: 0.1637 - Loss: 0.0053\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 18:57:59\n",
      "Accuracy: 0.9805 - Precision: 0.5880 - Recall: 0.1213 - Specificity: 0.9986 - F1: 0.1665 - Loss: 0.0053\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 18:58:07\n",
      "Accuracy: 0.9806 - Precision: 0.5894 - Recall: 0.1237 - Specificity: 0.9985 - F1: 0.1692 - Loss: 0.0053\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 18:58:15\n",
      "Accuracy: 0.9806 - Precision: 0.5897 - Recall: 0.1255 - Specificity: 0.9985 - F1: 0.1712 - Loss: 0.0053\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 18:58:23\n",
      "Accuracy: 0.9806 - Precision: 0.5917 - Recall: 0.1263 - Specificity: 0.9985 - F1: 0.1725 - Loss: 0.0052\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 18:58:30\n",
      "Accuracy: 0.9807 - Precision: 0.5937 - Recall: 0.1265 - Specificity: 0.9986 - F1: 0.1731 - Loss: 0.0052\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 18:58:38\n",
      "Accuracy: 0.9807 - Precision: 0.5956 - Recall: 0.1274 - Specificity: 0.9986 - F1: 0.1746 - Loss: 0.0052\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 18:58:46\n",
      "Accuracy: 0.9807 - Precision: 0.5968 - Recall: 0.1289 - Specificity: 0.9986 - F1: 0.1766 - Loss: 0.0052\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 18:58:54\n",
      "Accuracy: 0.9807 - Precision: 0.5976 - Recall: 0.1304 - Specificity: 0.9985 - F1: 0.1784 - Loss: 0.0052\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 18:59:02\n",
      "Accuracy: 0.9808 - Precision: 0.5993 - Recall: 0.1318 - Specificity: 0.9986 - F1: 0.1804 - Loss: 0.0052\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 18:59:10\n",
      "Accuracy: 0.9808 - Precision: 0.6011 - Recall: 0.1336 - Specificity: 0.9986 - F1: 0.1828 - Loss: 0.0052\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 18:59:18\n",
      "Accuracy: 0.9808 - Precision: 0.6029 - Recall: 0.1352 - Specificity: 0.9986 - F1: 0.1849 - Loss: 0.0052\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 18:59:26\n",
      "Accuracy: 0.9809 - Precision: 0.6047 - Recall: 0.1369 - Specificity: 0.9986 - F1: 0.1872 - Loss: 0.0052\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 18:59:33\n",
      "Accuracy: 0.9809 - Precision: 0.6066 - Recall: 0.1380 - Specificity: 0.9986 - F1: 0.1888 - Loss: 0.0052\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 18:59:42\n",
      "Accuracy: 0.9810 - Precision: 0.6075 - Recall: 0.1395 - Specificity: 0.9986 - F1: 0.1907 - Loss: 0.0051\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 18:59:51\n",
      "Accuracy: 0.9810 - Precision: 0.6091 - Recall: 0.1413 - Specificity: 0.9986 - F1: 0.1930 - Loss: 0.0051\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 18:59:59\n",
      "Accuracy: 0.9811 - Precision: 0.6104 - Recall: 0.1434 - Specificity: 0.9986 - F1: 0.1954 - Loss: 0.0051\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 19:00:07\n",
      "Accuracy: 0.9811 - Precision: 0.6107 - Recall: 0.1456 - Specificity: 0.9986 - F1: 0.1975 - Loss: 0.0051\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 19:00:15\n",
      "Accuracy: 0.9812 - Precision: 0.6118 - Recall: 0.1479 - Specificity: 0.9986 - F1: 0.2000 - Loss: 0.0051\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 19:00:23\n",
      "Accuracy: 0.9812 - Precision: 0.6135 - Recall: 0.1495 - Specificity: 0.9986 - F1: 0.2021 - Loss: 0.0051\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 19:00:31\n",
      "Accuracy: 0.9812 - Precision: 0.6147 - Recall: 0.1512 - Specificity: 0.9986 - F1: 0.2042 - Loss: 0.0051\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 19:00:38\n",
      "Accuracy: 0.9813 - Precision: 0.6161 - Recall: 0.1528 - Specificity: 0.9986 - F1: 0.2062 - Loss: 0.0051\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 19:00:46\n",
      "Accuracy: 0.9813 - Precision: 0.6175 - Recall: 0.1542 - Specificity: 0.9986 - F1: 0.2081 - Loss: 0.0050\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 19:00:54\n",
      "Accuracy: 0.9813 - Precision: 0.6182 - Recall: 0.1553 - Specificity: 0.9986 - F1: 0.2095 - Loss: 0.0050\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 19:01:02\n",
      "Accuracy: 0.9813 - Precision: 0.6188 - Recall: 0.1558 - Specificity: 0.9986 - F1: 0.2105 - Loss: 0.0050\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 19:01:10\n",
      "Accuracy: 0.9813 - Precision: 0.6188 - Recall: 0.1559 - Specificity: 0.9985 - F1: 0.2107 - Loss: 0.0051\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 19:01:18\n",
      "Accuracy: 0.9813 - Precision: 0.6195 - Recall: 0.1557 - Specificity: 0.9986 - F1: 0.2106 - Loss: 0.0051\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 19:01:26\n",
      "Accuracy: 0.9812 - Precision: 0.6212 - Recall: 0.1555 - Specificity: 0.9986 - F1: 0.2106 - Loss: 0.0051\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 19:01:34\n",
      "Accuracy: 0.9812 - Precision: 0.6223 - Recall: 0.1552 - Specificity: 0.9986 - F1: 0.2104 - Loss: 0.0051\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 19:01:42\n",
      "Accuracy: 0.9812 - Precision: 0.6239 - Recall: 0.1549 - Specificity: 0.9986 - F1: 0.2101 - Loss: 0.0051\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 19:01:51\n",
      "Accuracy: 0.9812 - Precision: 0.6247 - Recall: 0.1543 - Specificity: 0.9986 - F1: 0.2095 - Loss: 0.0051\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 19:01:59\n",
      "Accuracy: 0.9811 - Precision: 0.6263 - Recall: 0.1539 - Specificity: 0.9986 - F1: 0.2090 - Loss: 0.0051\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 19:02:07\n",
      "Accuracy: 0.9811 - Precision: 0.6276 - Recall: 0.1536 - Specificity: 0.9986 - F1: 0.2088 - Loss: 0.0052\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 19:02:15\n",
      "Accuracy: 0.9811 - Precision: 0.6291 - Recall: 0.1530 - Specificity: 0.9986 - F1: 0.2080 - Loss: 0.0052\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 19:02:23\n",
      "Accuracy: 0.9811 - Precision: 0.6304 - Recall: 0.1526 - Specificity: 0.9986 - F1: 0.2076 - Loss: 0.0052\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 19:02:31\n",
      "Accuracy: 0.9811 - Precision: 0.6318 - Recall: 0.1523 - Specificity: 0.9986 - F1: 0.2073 - Loss: 0.0052\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 19:02:38\n",
      "Accuracy: 0.9811 - Precision: 0.6329 - Recall: 0.1519 - Specificity: 0.9986 - F1: 0.2070 - Loss: 0.0052\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 19:02:46\n",
      "Accuracy: 0.9811 - Precision: 0.6332 - Recall: 0.1534 - Specificity: 0.9986 - F1: 0.2086 - Loss: 0.0052\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 19:02:54\n",
      "Accuracy: 0.9811 - Precision: 0.6333 - Recall: 0.1550 - Specificity: 0.9986 - F1: 0.2103 - Loss: 0.0052\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 19:03:02\n",
      "Accuracy: 0.9811 - Precision: 0.6341 - Recall: 0.1547 - Specificity: 0.9986 - F1: 0.2100 - Loss: 0.0052\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 19:03:10\n",
      "Accuracy: 0.9811 - Precision: 0.6357 - Recall: 0.1540 - Specificity: 0.9986 - F1: 0.2092 - Loss: 0.0052\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 19:03:17\n",
      "Accuracy: 0.9811 - Precision: 0.6329 - Recall: 0.1534 - Specificity: 0.9986 - F1: 0.2082 - Loss: 0.0052\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 19:03:25\n",
      "Accuracy: 0.9811 - Precision: 0.6345 - Recall: 0.1527 - Specificity: 0.9986 - F1: 0.2073 - Loss: 0.0052\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 19:03:33\n",
      "Accuracy: 0.9810 - Precision: 0.6361 - Recall: 0.1521 - Specificity: 0.9986 - F1: 0.2065 - Loss: 0.0052\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 19:03:41\n",
      "Accuracy: 0.9809 - Precision: 0.6376 - Recall: 0.1514 - Specificity: 0.9986 - F1: 0.2056 - Loss: 0.0052\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 19:03:50\n",
      "Accuracy: 0.9809 - Precision: 0.6392 - Recall: 0.1508 - Specificity: 0.9986 - F1: 0.2047 - Loss: 0.0053\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 19:03:59\n",
      "Accuracy: 0.9808 - Precision: 0.6365 - Recall: 0.1501 - Specificity: 0.9986 - F1: 0.2038 - Loss: 0.0053\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 19:04:06\n",
      "Accuracy: 0.9808 - Precision: 0.6338 - Recall: 0.1495 - Specificity: 0.9986 - F1: 0.2030 - Loss: 0.0053\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 19:04:14\n",
      "Accuracy: 0.9808 - Precision: 0.6311 - Recall: 0.1489 - Specificity: 0.9986 - F1: 0.2021 - Loss: 0.0053\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 19:04:22\n",
      "Accuracy: 0.9807 - Precision: 0.6285 - Recall: 0.1482 - Specificity: 0.9986 - F1: 0.2013 - Loss: 0.0053\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 19:04:30\n",
      "Accuracy: 0.9804 - Precision: 0.6300 - Recall: 0.1476 - Specificity: 0.9986 - F1: 0.2004 - Loss: 0.0055\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 19:04:38\n",
      "Accuracy: 0.9802 - Precision: 0.6309 - Recall: 0.1470 - Specificity: 0.9986 - F1: 0.1996 - Loss: 0.0056\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 19:04:46\n",
      "Accuracy: 0.9799 - Precision: 0.6283 - Recall: 0.1464 - Specificity: 0.9987 - F1: 0.1988 - Loss: 0.0057\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 19:04:54\n",
      "Accuracy: 0.9796 - Precision: 0.6257 - Recall: 0.1458 - Specificity: 0.9987 - F1: 0.1980 - Loss: 0.0058\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 19:05:02\n",
      "Accuracy: 0.9793 - Precision: 0.6232 - Recall: 0.1452 - Specificity: 0.9987 - F1: 0.1972 - Loss: 0.0059\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 19:05:10\n",
      "Accuracy: 0.9791 - Precision: 0.6206 - Recall: 0.1446 - Specificity: 0.9987 - F1: 0.1964 - Loss: 0.0060\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 19:05:18\n",
      "Accuracy: 0.9789 - Precision: 0.6181 - Recall: 0.1440 - Specificity: 0.9987 - F1: 0.1956 - Loss: 0.0060\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 19:05:26\n",
      "Accuracy: 0.9787 - Precision: 0.6156 - Recall: 0.1434 - Specificity: 0.9987 - F1: 0.1948 - Loss: 0.0061\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 19:05:34\n",
      "Accuracy: 0.9783 - Precision: 0.6131 - Recall: 0.1429 - Specificity: 0.9987 - F1: 0.1940 - Loss: 0.0062\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 19:05:42\n",
      "Accuracy: 0.9781 - Precision: 0.6106 - Recall: 0.1423 - Specificity: 0.9987 - F1: 0.1932 - Loss: 0.0063\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 19:05:51\n",
      "Accuracy: 0.9778 - Precision: 0.6082 - Recall: 0.1417 - Specificity: 0.9987 - F1: 0.1924 - Loss: 0.0064\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 19:05:59\n",
      "Accuracy: 0.9777 - Precision: 0.6058 - Recall: 0.1412 - Specificity: 0.9987 - F1: 0.1917 - Loss: 0.0064\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 19:06:07\n",
      "Accuracy: 0.9775 - Precision: 0.6034 - Recall: 0.1406 - Specificity: 0.9987 - F1: 0.1909 - Loss: 0.0065\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 19:06:15\n",
      "Accuracy: 0.9773 - Precision: 0.6010 - Recall: 0.1400 - Specificity: 0.9987 - F1: 0.1902 - Loss: 0.0065\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 19:06:23\n",
      "Accuracy: 0.9771 - Precision: 0.5986 - Recall: 0.1395 - Specificity: 0.9987 - F1: 0.1894 - Loss: 0.0066\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 19:06:31\n",
      "Accuracy: 0.9767 - Precision: 0.5963 - Recall: 0.1389 - Specificity: 0.9987 - F1: 0.1887 - Loss: 0.0067\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 19:06:39\n",
      "Accuracy: 0.9765 - Precision: 0.5939 - Recall: 0.1384 - Specificity: 0.9987 - F1: 0.1879 - Loss: 0.0068\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 19:06:49\n",
      "Accuracy: 0.9764 - Precision: 0.5916 - Recall: 0.1379 - Specificity: 0.9987 - F1: 0.1872 - Loss: 0.0068\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 19:06:58\n",
      "Accuracy: 0.9763 - Precision: 0.5893 - Recall: 0.1373 - Specificity: 0.9987 - F1: 0.1865 - Loss: 0.0068\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 19:07:06\n",
      "Accuracy: 0.9763 - Precision: 0.5871 - Recall: 0.1368 - Specificity: 0.9987 - F1: 0.1858 - Loss: 0.0068\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 19:07:14\n",
      "Accuracy: 0.9763 - Precision: 0.5848 - Recall: 0.1363 - Specificity: 0.9987 - F1: 0.1850 - Loss: 0.0068\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 19:07:22\n",
      "Accuracy: 0.9763 - Precision: 0.5826 - Recall: 0.1357 - Specificity: 0.9988 - F1: 0.1843 - Loss: 0.0069\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 19:07:30\n",
      "Accuracy: 0.9762 - Precision: 0.5803 - Recall: 0.1352 - Specificity: 0.9988 - F1: 0.1836 - Loss: 0.0069\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 19:07:38\n",
      "Accuracy: 0.9762 - Precision: 0.5781 - Recall: 0.1347 - Specificity: 0.9988 - F1: 0.1829 - Loss: 0.0069\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 19:07:46\n",
      "Accuracy: 0.9761 - Precision: 0.5759 - Recall: 0.1342 - Specificity: 0.9988 - F1: 0.1822 - Loss: 0.0070\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 19:07:55\n",
      "Accuracy: 0.9761 - Precision: 0.5738 - Recall: 0.1337 - Specificity: 0.9988 - F1: 0.1815 - Loss: 0.0070\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 19:08:03\n",
      "Accuracy: 0.9761 - Precision: 0.5716 - Recall: 0.1332 - Specificity: 0.9988 - F1: 0.1809 - Loss: 0.0070\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 19:08:11\n",
      "Accuracy: 0.9761 - Precision: 0.5695 - Recall: 0.1327 - Specificity: 0.9988 - F1: 0.1802 - Loss: 0.0070\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 19:08:19\n",
      "Accuracy: 0.9761 - Precision: 0.5674 - Recall: 0.1322 - Specificity: 0.9988 - F1: 0.1795 - Loss: 0.0070\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 19:08:27\n",
      "Accuracy: 0.9761 - Precision: 0.5652 - Recall: 0.1317 - Specificity: 0.9988 - F1: 0.1788 - Loss: 0.0070\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 19:08:35\n",
      "Accuracy: 0.9761 - Precision: 0.5631 - Recall: 0.1312 - Specificity: 0.9988 - F1: 0.1782 - Loss: 0.0070\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 19:08:43\n",
      "Accuracy: 0.9761 - Precision: 0.5611 - Recall: 0.1307 - Specificity: 0.9988 - F1: 0.1775 - Loss: 0.0070\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 19:08:51\n",
      "Accuracy: 0.9760 - Precision: 0.5590 - Recall: 0.1303 - Specificity: 0.9988 - F1: 0.1769 - Loss: 0.0070\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 19:08:59\n",
      "Accuracy: 0.9760 - Precision: 0.5570 - Recall: 0.1298 - Specificity: 0.9988 - F1: 0.1762 - Loss: 0.0071\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 19:09:06\n",
      "Accuracy: 0.9760 - Precision: 0.5549 - Recall: 0.1293 - Specificity: 0.9988 - F1: 0.1756 - Loss: 0.0070\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 19:09:14\n",
      "Accuracy: 0.9760 - Precision: 0.5529 - Recall: 0.1288 - Specificity: 0.9988 - F1: 0.1749 - Loss: 0.0071\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 19:09:22\n",
      "Accuracy: 0.9760 - Precision: 0.5509 - Recall: 0.1284 - Specificity: 0.9988 - F1: 0.1743 - Loss: 0.0071\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 19:09:29\n",
      "Accuracy: 0.9760 - Precision: 0.5489 - Recall: 0.1279 - Specificity: 0.9988 - F1: 0.1737 - Loss: 0.0071\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 19:09:37\n",
      "Accuracy: 0.9760 - Precision: 0.5469 - Recall: 0.1274 - Specificity: 0.9988 - F1: 0.1731 - Loss: 0.0071\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 19:09:45\n",
      "Accuracy: 0.9760 - Precision: 0.5450 - Recall: 0.1270 - Specificity: 0.9988 - F1: 0.1724 - Loss: 0.0071\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 19:09:55\n",
      "Accuracy: 0.9761 - Precision: 0.5430 - Recall: 0.1265 - Specificity: 0.9988 - F1: 0.1718 - Loss: 0.0071\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 19:10:03\n",
      "Accuracy: 0.9761 - Precision: 0.5411 - Recall: 0.1261 - Specificity: 0.9988 - F1: 0.1712 - Loss: 0.0071\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 19:10:10\n",
      "Accuracy: 0.9761 - Precision: 0.5392 - Recall: 0.1256 - Specificity: 0.9988 - F1: 0.1706 - Loss: 0.0071\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 19:10:18\n",
      "Accuracy: 0.9761 - Precision: 0.5373 - Recall: 0.1252 - Specificity: 0.9989 - F1: 0.1700 - Loss: 0.0071\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 19:10:26\n",
      "Accuracy: 0.9761 - Precision: 0.5354 - Recall: 0.1248 - Specificity: 0.9989 - F1: 0.1694 - Loss: 0.0071\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 19:10:34\n",
      "Accuracy: 0.9761 - Precision: 0.5370 - Recall: 0.1243 - Specificity: 0.9989 - F1: 0.1688 - Loss: 0.0071\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 19:10:41\n",
      "Accuracy: 0.9761 - Precision: 0.5386 - Recall: 0.1239 - Specificity: 0.9989 - F1: 0.1682 - Loss: 0.0071\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 19:10:49\n",
      "Accuracy: 0.9761 - Precision: 0.5402 - Recall: 0.1235 - Specificity: 0.9989 - F1: 0.1676 - Loss: 0.0071\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 19:10:57\n",
      "Accuracy: 0.9761 - Precision: 0.5418 - Recall: 0.1230 - Specificity: 0.9989 - F1: 0.1671 - Loss: 0.0071\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 19:11:04\n",
      "Accuracy: 0.9761 - Precision: 0.5434 - Recall: 0.1226 - Specificity: 0.9989 - F1: 0.1665 - Loss: 0.0071\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 19:11:12\n",
      "Accuracy: 0.9761 - Precision: 0.5449 - Recall: 0.1222 - Specificity: 0.9989 - F1: 0.1659 - Loss: 0.0071\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 19:11:20\n",
      "Accuracy: 0.9761 - Precision: 0.5430 - Recall: 0.1218 - Specificity: 0.9989 - F1: 0.1653 - Loss: 0.0071\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 19:11:28\n",
      "Accuracy: 0.9761 - Precision: 0.5415 - Recall: 0.1213 - Specificity: 0.9989 - F1: 0.1648 - Loss: 0.0071\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 19:11:36\n",
      "Accuracy: 0.9761 - Precision: 0.5428 - Recall: 0.1210 - Specificity: 0.9989 - F1: 0.1644 - Loss: 0.0071\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 19:11:43\n",
      "Accuracy: 0.9760 - Precision: 0.5442 - Recall: 0.1206 - Specificity: 0.9989 - F1: 0.1638 - Loss: 0.0071\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 19:11:52\n",
      "Accuracy: 0.9760 - Precision: 0.5451 - Recall: 0.1202 - Specificity: 0.9989 - F1: 0.1634 - Loss: 0.0071\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 19:12:01\n",
      "Accuracy: 0.9760 - Precision: 0.5460 - Recall: 0.1199 - Specificity: 0.9989 - F1: 0.1630 - Loss: 0.0071\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 19:12:09\n",
      "Accuracy: 0.9760 - Precision: 0.5475 - Recall: 0.1196 - Specificity: 0.9989 - F1: 0.1626 - Loss: 0.0071\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 19:12:17\n",
      "Accuracy: 0.9760 - Precision: 0.5490 - Recall: 0.1192 - Specificity: 0.9989 - F1: 0.1620 - Loss: 0.0071\n",
      "\n",
      "Epoch 1/20\n",
      "Train - Accuracy: 0.9760, Precision: 0.5490, Recall: 0.1192, Specificity: 0.9989, F1: 0.1620, Loss: 0.0071\n",
      "Validation - Accuracy: 0.9788, Precision: 0.9484, Recall: 0.0099, Specificity: 1.0000, F1: 0.0195, Loss: 0.0059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import backend as K\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import VGG16  # Import VGG16 for the new model\n",
    "\n",
    "# Directory paths\n",
    "train_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\train\"\n",
    "train_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\train\\train_mask\"\n",
    "test_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\test\"\n",
    "test_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\test\\test_mask\"\n",
    "valid_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\valid\"\n",
    "valid_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\valid\\valid_mask\"\n",
    "\n",
    "# Image generator to load data in batches\n",
    "def image_generator(img_dir, mask_dir, batch_size, img_size=(256, 256)):\n",
    "    img_files = os.listdir(img_dir)\n",
    "    while True:\n",
    "        images = []\n",
    "        masks = []\n",
    "        for img_file in img_files:\n",
    "            img_path = os.path.join(img_dir, img_file)\n",
    "            mask_file = img_file + \"_mask.png\"\n",
    "            mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "            if os.path.exists(mask_path):\n",
    "                # Load image and mask\n",
    "                img = load_img(img_path, color_mode='rgb', target_size=img_size)\n",
    "                img = img_to_array(img) / 255.0\n",
    "                mask = load_img(mask_path, color_mode='grayscale', target_size=img_size)\n",
    "                mask = img_to_array(mask) / 255.0\n",
    "\n",
    "                images.append(img)\n",
    "                masks.append(mask)\n",
    "\n",
    "            if len(images) == batch_size:\n",
    "                yield np.array(images), np.array(masks)\n",
    "                images = []\n",
    "                masks = []\n",
    "\n",
    "# VGG16-based model replacing U-Net\n",
    "def vgg16_unet_model(input_size=(256, 256, 3)):\n",
    "    # Load VGG16 as the encoder with pre-trained ImageNet weights\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=input_size)\n",
    "    \n",
    "    # Freeze VGG16 layers to prevent them from being trained\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Extract layers for skip connections\n",
    "    block1 = vgg16.get_layer('block1_pool').output   # 128x128\n",
    "    block2 = vgg16.get_layer('block2_pool').output   # 64x64\n",
    "    block3 = vgg16.get_layer('block3_pool').output   # 32x32\n",
    "    block4 = vgg16.get_layer('block4_pool').output   # 16x16\n",
    "    block5 = vgg16.get_layer('block5_pool').output   # 8x8\n",
    "    \n",
    "    # Decoder\n",
    "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(block5)  # 16x16\n",
    "    u6 = layers.concatenate([u6, block4])\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "    \n",
    "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)  # 32x32\n",
    "    u7 = layers.concatenate([u7, block3])\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "    \n",
    "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)  # 64x64\n",
    "    u8 = layers.concatenate([u8, block2])\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "    \n",
    "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)    # 128x128\n",
    "    u9 = layers.concatenate([u9, block1])\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "    \n",
    "    # Final upsampling to reach original image size\n",
    "    u10 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c9)  # 256x256\n",
    "    c10 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u10)\n",
    "    c10 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c10)\n",
    "    \n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c10)\n",
    "    \n",
    "    model = models.Model(inputs=vgg16.input, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define custom metrics\n",
    "def custom_precision(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_positives = K.sum(K.round(y_true * y_pred_bin))\n",
    "    predicted_positives = K.sum(y_pred_bin)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def custom_recall(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_positives = K.sum(K.round(y_true * y_pred_bin))\n",
    "    possible_positives = K.sum(y_true)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def custom_specificity(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_negatives = K.sum(K.round((1 - y_true) * (1 - y_pred_bin)))\n",
    "    possible_negatives = K.sum(1 - y_true)\n",
    "    specificity = true_negatives / (possible_negatives + K.epsilon())\n",
    "    return specificity\n",
    "\n",
    "def custom_f1(y_true, y_pred):\n",
    "    precision = custom_precision(y_true, y_pred)\n",
    "    recall = custom_recall(y_true, y_pred)\n",
    "    return 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "\n",
    "# Define Focal Loss\n",
    "def focal_loss_fixed(y_true, y_pred):\n",
    "    gamma = 2.0\n",
    "    alpha = 0.25\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    cross_entropy = -y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred)\n",
    "    weight = alpha * y_true * K.pow((1 - y_pred), gamma) + (1 - alpha) * (1 - y_true) * K.pow(y_pred, gamma)\n",
    "    loss = weight * cross_entropy\n",
    "    return K.mean(loss)\n",
    "\n",
    "# Compile the model\n",
    "model = vgg16_unet_model()\n",
    "model.compile(optimizer='adam', loss=focal_loss_fixed, metrics=['accuracy', custom_precision, custom_recall, custom_specificity, custom_f1])\n",
    "\n",
    "# Batch size for training\n",
    "batch_size = 16\n",
    "\n",
    "# Create data generators\n",
    "train_gen = image_generator(train_img_dir, train_mask_dir, batch_size)\n",
    "valid_gen = image_generator(valid_img_dir, valid_mask_dir, batch_size)\n",
    "test_gen = image_generator(test_img_dir, test_mask_dir, batch_size)\n",
    "\n",
    "# Number of steps per epoch\n",
    "steps_per_epoch = len(os.listdir(train_img_dir)) // batch_size\n",
    "validation_steps = len(os.listdir(valid_img_dir)) // batch_size\n",
    "test_steps = len(os.listdir(test_img_dir)) // batch_size\n",
    "\n",
    "# Custom callback to print more metrics at each batch and epoch for training, validation, and test sets\n",
    "class MetricsCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, total_batches, X_valid, y_valid, X_test, y_test):\n",
    "        super().__init__()\n",
    "        self.batch_counter = 1\n",
    "        self.total_batches = total_batches\n",
    "        self.current_epoch = 1\n",
    "        self.X_valid = X_valid\n",
    "        self.y_valid = y_valid\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.current_epoch = epoch + 1\n",
    "        print(f\"\\nEpoch {self.current_epoch}/{self.params['epochs']}\")\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        accuracy = logs.get('accuracy', 0)\n",
    "        loss = logs.get('loss', 0)\n",
    "        precision = logs.get('custom_precision', 0)\n",
    "        recall = logs.get('custom_recall', 0)\n",
    "        f1 = logs.get('custom_f1', 0)\n",
    "        specificity = logs.get('custom_specificity', 0)\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print(f\"Batch {self.batch_counter}/{self.total_batches} ━━━━━━━━━━━━━━━━━━━━ {current_time}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f} - Precision: {precision:.4f} - Recall: {recall:.4f} - Specificity: {specificity:.4f} - F1: {f1:.4f} - Loss: {loss:.4f}\\n\")\n",
    "        self.batch_counter += 1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        accuracy = logs.get('accuracy', 0)\n",
    "        val_accuracy = logs.get('val_accuracy', 0)\n",
    "        loss = logs.get('loss', 0)\n",
    "        val_loss = logs.get('val_loss', 0)\n",
    "        precision = logs.get('custom_precision', 0)\n",
    "        val_precision = logs.get('val_custom_precision', 0)\n",
    "        recall = logs.get('custom_recall', 0)\n",
    "        val_recall = logs.get('val_custom_recall', 0)\n",
    "        f1 = logs.get('custom_f1', 0)\n",
    "        val_f1 = logs.get('val_custom_f1', 0)\n",
    "        specificity = logs.get('custom_specificity', 0)\n",
    "        val_specificity = logs.get('val_custom_specificity', 0)\n",
    "        print(f\"Epoch {epoch+1}/{self.params['epochs']}\")\n",
    "        print(f\"Train - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Specificity: {specificity:.4f}, F1: {f1:.4f}, Loss: {loss:.4f}\")\n",
    "        print(f\"Validation - Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, Specificity: {val_specificity:.4f}, F1: {val_f1:.4f}, Loss: {val_loss:.4f}\\n\")\n",
    "        \n",
    "        # Fix: Do not pass y_test separately, only pass test_gen\n",
    "        test_loss, test_accuracy, test_precision, test_recall, test_specificity, test_f1 = self.model.evaluate(self.X_test, verbose=0)\n",
    "        print(f\"Test Set Results - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, Specificity: {test_specificity:.4f}, F1: {test_f1:.4f}, Loss: {test_loss:.4f}\\n\")\n",
    "        self.batch_counter = 1\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Initialize the custom callback with validation and test data\n",
    "metrics_callback = MetricsCallback(total_batches=steps_per_epoch, X_valid=valid_gen, y_valid=None, X_test=test_gen, y_test=None)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=20,\n",
    "    validation_data=valid_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[metrics_callback, early_stopping],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('dental_xray_vgg16_unet_model.h5')\n",
    "\n",
    "# Evaluate on the training set\n",
    "train_gen_full = image_generator(train_img_dir, train_mask_dir, batch_size)\n",
    "y_train_pred = model.predict(train_gen_full, steps=steps_per_epoch)\n",
    "y_train_pred_bin = (y_train_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "# Confusion Matrix for training\n",
    "conf_matrix_train = confusion_matrix(y_train_pred_bin.flatten(), y_train_pred_bin.flatten())\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_train, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix for Train\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix for validation set\n",
    "y_valid_pred = model.predict(valid_gen, steps=validation_steps)\n",
    "y_valid_pred_bin = (y_valid_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "conf_matrix_valid = confusion_matrix(y_valid_pred_bin.flatten(), y_valid_pred_bin.flatten())\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_valid, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix for Validation\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix for test set\n",
    "y_test_pred = model.predict(test_gen, steps=test_steps)\n",
    "y_test_pred_bin = (y_test_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "conf_matrix_test = confusion_matrix(y_test_pred_bin.flatten(), y_test_pred_bin.flatten())\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_test, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix for Test\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization: Show input image, true mask, and predicted mask for a few samples\n",
    "def visualize_predictions(images, true_masks, pred_masks, title):\n",
    "    for i in range(3):  # Visualize first 3 predictions\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # Original image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "        \n",
    "        # Ground truth mask\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(true_masks[i].squeeze(), cmap='gray')\n",
    "        plt.title('Ground Truth Mask')\n",
    "        \n",
    "        # Predicted mask\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(pred_masks[i].squeeze(), cmap='gray')\n",
    "        plt.title('Predicted Mask')\n",
    "        \n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "\n",
    "# Visualize predictions for training set\n",
    "visualize_predictions(X_train, y_train, y_train_pred_bin, \"Train Set Predictions\")\n",
    "\n",
    "# Visualize predictions for validation set\n",
    "visualize_predictions(X_valid, y_valid, y_valid_pred_bin, \"Validation Set Predictions\")\n",
    "\n",
    "# Visualize predictions for test set\n",
    "visualize_predictions(X_test, y_test, y_test_pred_bin, \"Test Set Predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb373843-264b-4433-85ab-28410de7ec0a",
   "metadata": {},
   "outputs": [],
   "source": []
<<<<<<< HEAD
  },
  {
   "cell_type": "markdown",
   "id": "b9169e02-dc0c-4e87-85ff-5f16a8400d03",
   "metadata": {},
   "source": [
    "* Revised code that doesn't show Visulaliztion for Train and Val sets.\n",
    "* Less computational effort\n",
    "* Also uses *plotly* to draw confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "359b9124-f231-431e-83be-4964990e69ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 09:11:42\n",
      "Accuracy: 0.9707 - Precision: 0.0242 - Recall: 0.0029 - Specificity: 0.9968 - F1: 0.0052 - Loss: 0.0395\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 09:11:51\n",
      "Accuracy: 0.9707 - Precision: 0.0121 - Recall: 0.0015 - Specificity: 0.9984 - F1: 0.0026 - Loss: 0.0611\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 09:12:00\n",
      "Accuracy: 0.9701 - Precision: 0.0081 - Recall: 0.0010 - Specificity: 0.9989 - F1: 0.0017 - Loss: 0.0553\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 09:12:08\n",
      "Accuracy: 0.9734 - Precision: 0.0060 - Recall: 0.0007 - Specificity: 0.9992 - F1: 0.0013 - Loss: 0.0445\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 09:12:17\n",
      "Accuracy: 0.9756 - Precision: 0.0048 - Recall: 0.0006 - Specificity: 0.9994 - F1: 0.0010 - Loss: 0.0376\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 09:12:26\n",
      "Accuracy: 0.9757 - Precision: 0.0040 - Recall: 0.0005 - Specificity: 0.9995 - F1: 0.0009 - Loss: 0.0337\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 09:12:35\n",
      "Accuracy: 0.9771 - Precision: 0.0035 - Recall: 0.0004 - Specificity: 0.9995 - F1: 0.0007 - Loss: 0.0302\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 09:12:43\n",
      "Accuracy: 0.9778 - Precision: 0.0030 - Recall: 0.0004 - Specificity: 0.9996 - F1: 0.0006 - Loss: 0.0278\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 09:12:52\n",
      "Accuracy: 0.9785 - Precision: 0.0027 - Recall: 0.0003 - Specificity: 0.9996 - F1: 0.0006 - Loss: 0.0258\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 09:13:01\n",
      "Accuracy: 0.9789 - Precision: 0.0024 - Recall: 0.0003 - Specificity: 0.9997 - F1: 0.0005 - Loss: 0.0243\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 09:13:12\n",
      "Accuracy: 0.9792 - Precision: 0.0022 - Recall: 0.0003 - Specificity: 0.9997 - F1: 0.0005 - Loss: 0.0230\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 09:13:21\n",
      "Accuracy: 0.9795 - Precision: 0.0020 - Recall: 0.0002 - Specificity: 0.9997 - F1: 0.0004 - Loss: 0.0218\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 09:13:29\n",
      "Accuracy: 0.9796 - Precision: 0.0019 - Recall: 0.0002 - Specificity: 0.9998 - F1: 0.0004 - Loss: 0.0209\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 09:13:38\n",
      "Accuracy: 0.9798 - Precision: 0.0017 - Recall: 0.0002 - Specificity: 0.9998 - F1: 0.0004 - Loss: 0.0201\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 09:13:47\n",
      "Accuracy: 0.9800 - Precision: 0.0016 - Recall: 0.0002 - Specificity: 0.9998 - F1: 0.0003 - Loss: 0.0193\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 09:13:56\n",
      "Accuracy: 0.9796 - Precision: 0.0015 - Recall: 0.0002 - Specificity: 0.9998 - F1: 0.0003 - Loss: 0.0190\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 09:14:04\n",
      "Accuracy: 0.9798 - Precision: 0.0014 - Recall: 0.0002 - Specificity: 0.9998 - F1: 0.0003 - Loss: 0.0183\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 09:14:15\n",
      "Accuracy: 0.9797 - Precision: 0.0013 - Recall: 0.0002 - Specificity: 0.9998 - F1: 0.0003 - Loss: 0.0178\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 09:14:24\n",
      "Accuracy: 0.9798 - Precision: 0.0013 - Recall: 0.0002 - Specificity: 0.9998 - F1: 0.0003 - Loss: 0.0174\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 09:14:33\n",
      "Accuracy: 0.9799 - Precision: 0.0012 - Recall: 0.0001 - Specificity: 0.9998 - F1: 0.0003 - Loss: 0.0169\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 09:14:42\n",
      "Accuracy: 0.9799 - Precision: 0.0012 - Recall: 0.0001 - Specificity: 0.9998 - F1: 0.0002 - Loss: 0.0165\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 09:14:51\n",
      "Accuracy: 0.9798 - Precision: 0.0011 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0002 - Loss: 0.0163\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 09:14:59\n",
      "Accuracy: 0.9797 - Precision: 0.0011 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0002 - Loss: 0.0160\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 09:15:09\n",
      "Accuracy: 0.9795 - Precision: 0.0010 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0002 - Loss: 0.0157\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 09:15:18\n",
      "Accuracy: 0.9795 - Precision: 0.0010 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0002 - Loss: 0.0155\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 09:15:27\n",
      "Accuracy: 0.9797 - Precision: 0.0009 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0002 - Loss: 0.0151\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 09:15:36\n",
      "Accuracy: 0.9797 - Precision: 0.0009 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0002 - Loss: 0.0149\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 09:15:44\n",
      "Accuracy: 0.9796 - Precision: 0.0009 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0002 - Loss: 0.0148\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 09:15:53\n",
      "Accuracy: 0.9793 - Precision: 0.0008 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0002 - Loss: 0.0147\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 09:16:02\n",
      "Accuracy: 0.9792 - Precision: 0.0008 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0002 - Loss: 0.0145\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 09:16:10\n",
      "Accuracy: 0.9794 - Precision: 0.0008 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0002 - Loss: 0.0143\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 09:16:19\n",
      "Accuracy: 0.9794 - Precision: 0.0008 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0002 - Loss: 0.0141\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 09:16:28\n",
      "Accuracy: 0.9794 - Precision: 0.0007 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0002 - Loss: 0.0139\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 09:16:36\n",
      "Accuracy: 0.9792 - Precision: 0.0007 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0002 - Loss: 0.0138\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 09:16:45\n",
      "Accuracy: 0.9792 - Precision: 0.0007 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0137\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 09:16:53\n",
      "Accuracy: 0.9793 - Precision: 0.0007 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0135\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 09:17:02\n",
      "Accuracy: 0.9792 - Precision: 0.0007 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0134\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 09:17:12\n",
      "Accuracy: 0.9791 - Precision: 0.0006 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0132\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 09:17:21\n",
      "Accuracy: 0.9791 - Precision: 0.0177 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0130\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 09:17:30\n",
      "Accuracy: 0.9790 - Precision: 0.0173 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0129\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 09:17:38\n",
      "Accuracy: 0.9789 - Precision: 0.0168 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0128\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 09:17:47\n",
      "Accuracy: 0.9788 - Precision: 0.0164 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0127\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 09:17:56\n",
      "Accuracy: 0.9788 - Precision: 0.0161 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0125\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 09:18:04\n",
      "Accuracy: 0.9789 - Precision: 0.0157 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0124\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 09:18:14\n",
      "Accuracy: 0.9790 - Precision: 0.0154 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0122\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 09:18:22\n",
      "Accuracy: 0.9789 - Precision: 0.0150 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0121\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 09:18:31\n",
      "Accuracy: 0.9789 - Precision: 0.0147 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0119\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 09:18:39\n",
      "Accuracy: 0.9788 - Precision: 0.0144 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0118\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 09:18:48\n",
      "Accuracy: 0.9788 - Precision: 0.0141 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0117\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 09:18:56\n",
      "Accuracy: 0.9787 - Precision: 0.0138 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0116\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 09:19:05\n",
      "Accuracy: 0.9787 - Precision: 0.0135 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0114\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 09:19:15\n",
      "Accuracy: 0.9787 - Precision: 0.0325 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0113\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 09:19:28\n",
      "Accuracy: 0.9788 - Precision: 0.0319 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0112\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 09:19:38\n",
      "Accuracy: 0.9788 - Precision: 0.0313 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0111\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 09:19:48\n",
      "Accuracy: 0.9788 - Precision: 0.0307 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0109\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 09:19:58\n",
      "Accuracy: 0.9788 - Precision: 0.0481 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0108\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 09:20:06\n",
      "Accuracy: 0.9789 - Precision: 0.0648 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0107\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 09:20:15\n",
      "Accuracy: 0.9789 - Precision: 0.0636 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0106\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 09:20:24\n",
      "Accuracy: 0.9790 - Precision: 0.0795 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0105\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 09:20:33\n",
      "Accuracy: 0.9790 - Precision: 0.0782 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0104\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 09:20:42\n",
      "Accuracy: 0.9790 - Precision: 0.0824 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0103\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 09:20:50\n",
      "Accuracy: 0.9790 - Precision: 0.0810 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0102\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 09:20:59\n",
      "Accuracy: 0.9790 - Precision: 0.0797 - Recall: 0.0001 - Specificity: 0.9999 - F1: 0.0001 - Loss: 0.0101\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 09:21:08\n",
      "Accuracy: 0.9790 - Precision: 0.0941 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0100\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 09:21:18\n",
      "Accuracy: 0.9790 - Precision: 0.1081 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0099\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 09:21:30\n",
      "Accuracy: 0.9789 - Precision: 0.1216 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0099\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 09:21:38\n",
      "Accuracy: 0.9789 - Precision: 0.1347 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0098\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 09:21:48\n",
      "Accuracy: 0.9789 - Precision: 0.1327 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0097\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 09:21:57\n",
      "Accuracy: 0.9789 - Precision: 0.1308 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0096\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 09:22:06\n",
      "Accuracy: 0.9790 - Precision: 0.1289 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0096\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 09:22:15\n",
      "Accuracy: 0.9790 - Precision: 0.1318 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0095\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 09:22:24\n",
      "Accuracy: 0.9790 - Precision: 0.1300 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0094\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 09:22:33\n",
      "Accuracy: 0.9789 - Precision: 0.1282 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0094\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 09:22:42\n",
      "Accuracy: 0.9788 - Precision: 0.1265 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0093\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 09:22:50\n",
      "Accuracy: 0.9788 - Precision: 0.1248 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0093\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 09:22:59\n",
      "Accuracy: 0.9788 - Precision: 0.1231 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0092\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 09:23:08\n",
      "Accuracy: 0.9788 - Precision: 0.1345 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0091\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 09:23:17\n",
      "Accuracy: 0.9788 - Precision: 0.1328 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0091\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 09:23:28\n",
      "Accuracy: 0.9787 - Precision: 0.1311 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0090\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 09:23:37\n",
      "Accuracy: 0.9787 - Precision: 0.1295 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0090\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 09:23:46\n",
      "Accuracy: 0.9788 - Precision: 0.1279 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0089\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 09:23:55\n",
      "Accuracy: 0.9788 - Precision: 0.1263 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0089\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 09:24:04\n",
      "Accuracy: 0.9788 - Precision: 0.1368 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0088\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 09:24:13\n",
      "Accuracy: 0.9788 - Precision: 0.1352 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0087\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 09:24:21\n",
      "Accuracy: 0.9789 - Precision: 0.1336 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0087\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 09:24:30\n",
      "Accuracy: 0.9789 - Precision: 0.1321 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0086\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 09:24:40\n",
      "Accuracy: 0.9789 - Precision: 0.1305 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0086\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 09:24:48\n",
      "Accuracy: 0.9789 - Precision: 0.1291 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0085\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 09:24:57\n",
      "Accuracy: 0.9788 - Precision: 0.1276 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0085\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 09:25:05\n",
      "Accuracy: 0.9788 - Precision: 0.1262 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0084\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 09:25:15\n",
      "Accuracy: 0.9788 - Precision: 0.1248 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0084\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 09:25:26\n",
      "Accuracy: 0.9788 - Precision: 0.1235 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0083\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 09:25:34\n",
      "Accuracy: 0.9788 - Precision: 0.1221 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0083\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 09:25:43\n",
      "Accuracy: 0.9789 - Precision: 0.1315 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0082\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 09:25:51\n",
      "Accuracy: 0.9789 - Precision: 0.1301 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0082\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 09:26:00\n",
      "Accuracy: 0.9788 - Precision: 0.1287 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0081\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 09:26:09\n",
      "Accuracy: 0.9789 - Precision: 0.1274 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0081\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 09:26:17\n",
      "Accuracy: 0.9789 - Precision: 0.1363 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0080\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 09:26:26\n",
      "Accuracy: 0.9789 - Precision: 0.1450 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0080\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 09:26:34\n",
      "Accuracy: 0.9789 - Precision: 0.1436 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0080\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 09:26:42\n",
      "Accuracy: 0.9790 - Precision: 0.1422 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0079\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 09:26:51\n",
      "Accuracy: 0.9791 - Precision: 0.1408 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0079\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 09:26:59\n",
      "Accuracy: 0.9791 - Precision: 0.1394 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0078\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 09:27:08\n",
      "Accuracy: 0.9791 - Precision: 0.1477 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0078\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 09:27:17\n",
      "Accuracy: 0.9791 - Precision: 0.1558 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0077\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 09:27:27\n",
      "Accuracy: 0.9792 - Precision: 0.1637 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0077\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 09:27:35\n",
      "Accuracy: 0.9792 - Precision: 0.1622 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0077\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 09:27:43\n",
      "Accuracy: 0.9793 - Precision: 0.1607 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0076\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 09:27:52\n",
      "Accuracy: 0.9793 - Precision: 0.1592 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0076\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 09:28:00\n",
      "Accuracy: 0.9793 - Precision: 0.1669 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0075\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 09:28:09\n",
      "Accuracy: 0.9793 - Precision: 0.1654 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0075\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 09:28:17\n",
      "Accuracy: 0.9794 - Precision: 0.1639 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0075\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 09:28:26\n",
      "Accuracy: 0.9794 - Precision: 0.1713 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0074\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 09:28:35\n",
      "Accuracy: 0.9794 - Precision: 0.1698 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0074\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 09:28:43\n",
      "Accuracy: 0.9794 - Precision: 0.1770 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0073\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 09:28:51\n",
      "Accuracy: 0.9794 - Precision: 0.1841 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0073\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 09:29:00\n",
      "Accuracy: 0.9794 - Precision: 0.1911 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0073\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 09:29:08\n",
      "Accuracy: 0.9794 - Precision: 0.1962 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0073\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 09:29:18\n",
      "Accuracy: 0.9794 - Precision: 0.2030 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0072\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 09:29:29\n",
      "Accuracy: 0.9795 - Precision: 0.2013 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0072\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 09:29:38\n",
      "Accuracy: 0.9795 - Precision: 0.1996 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0072\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 09:29:47\n",
      "Accuracy: 0.9795 - Precision: 0.2062 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0071\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 09:29:56\n",
      "Accuracy: 0.9794 - Precision: 0.2127 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0071\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 09:30:05\n",
      "Accuracy: 0.9794 - Precision: 0.2190 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0071\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 09:30:15\n",
      "Accuracy: 0.9795 - Precision: 0.2173 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0070\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 09:30:23\n",
      "Accuracy: 0.9794 - Precision: 0.2235 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0070\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 09:30:32\n",
      "Accuracy: 0.9795 - Precision: 0.2296 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0070\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 09:30:41\n",
      "Accuracy: 0.9795 - Precision: 0.2278 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0070\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 09:30:49\n",
      "Accuracy: 0.9795 - Precision: 0.2338 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0069\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 09:30:58\n",
      "Accuracy: 0.9795 - Precision: 0.2375 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0069\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 09:31:07\n",
      "Accuracy: 0.9795 - Precision: 0.2422 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0069\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 09:31:17\n",
      "Accuracy: 0.9795 - Precision: 0.2433 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0069\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 09:31:27\n",
      "Accuracy: 0.9794 - Precision: 0.2490 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0068\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 09:31:37\n",
      "Accuracy: 0.9794 - Precision: 0.2546 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0068\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 09:31:47\n",
      "Accuracy: 0.9794 - Precision: 0.2601 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0068\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 09:31:56\n",
      "Accuracy: 0.9794 - Precision: 0.2582 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0068\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 09:32:05\n",
      "Accuracy: 0.9795 - Precision: 0.2612 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0067\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 09:32:14\n",
      "Accuracy: 0.9794 - Precision: 0.2657 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0067\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 09:32:23\n",
      "Accuracy: 0.9794 - Precision: 0.2693 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0067\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 09:32:31\n",
      "Accuracy: 0.9794 - Precision: 0.2674 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0067\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 09:32:41\n",
      "Accuracy: 0.9795 - Precision: 0.2655 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0066\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 09:32:49\n",
      "Accuracy: 0.9794 - Precision: 0.2707 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0066\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 09:32:58\n",
      "Accuracy: 0.9794 - Precision: 0.2758 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0066\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 09:33:07\n",
      "Accuracy: 0.9794 - Precision: 0.2808 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0066\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 09:33:15\n",
      "Accuracy: 0.9794 - Precision: 0.2789 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0066\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 09:33:26\n",
      "Accuracy: 0.9794 - Precision: 0.2838 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0065\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 09:33:36\n",
      "Accuracy: 0.9794 - Precision: 0.2853 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0065\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 09:33:46\n",
      "Accuracy: 0.9794 - Precision: 0.2901 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0065\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 09:33:55\n",
      "Accuracy: 0.9795 - Precision: 0.2900 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0065\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 09:34:04\n",
      "Accuracy: 0.9795 - Precision: 0.2947 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0065\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 09:34:13\n",
      "Accuracy: 0.9794 - Precision: 0.2994 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0065\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 09:34:21\n",
      "Accuracy: 0.9794 - Precision: 0.3027 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0065\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 09:34:30\n",
      "Accuracy: 0.9794 - Precision: 0.3072 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0064\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 09:34:39\n",
      "Accuracy: 0.9794 - Precision: 0.3052 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0064\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 09:34:47\n",
      "Accuracy: 0.9794 - Precision: 0.3097 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0064\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 09:34:56\n",
      "Accuracy: 0.9794 - Precision: 0.3141 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0064\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 09:35:04\n",
      "Accuracy: 0.9794 - Precision: 0.3161 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0064\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 09:35:13\n",
      "Accuracy: 0.9794 - Precision: 0.3204 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0063\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 09:35:23\n",
      "Accuracy: 0.9794 - Precision: 0.3247 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0063\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 09:35:32\n",
      "Accuracy: 0.9794 - Precision: 0.3289 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0063\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 09:35:41\n",
      "Accuracy: 0.9794 - Precision: 0.3328 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0063\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 09:35:50\n",
      "Accuracy: 0.9794 - Precision: 0.3369 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0063\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 09:35:59\n",
      "Accuracy: 0.9794 - Precision: 0.3409 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0062\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 09:36:07\n",
      "Accuracy: 0.9795 - Precision: 0.3450 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0062\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 09:36:15\n",
      "Accuracy: 0.9795 - Precision: 0.3489 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0062\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 09:36:23\n",
      "Accuracy: 0.9795 - Precision: 0.3488 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0062\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 09:36:32\n",
      "Accuracy: 0.9795 - Precision: 0.3527 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0062\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 09:36:41\n",
      "Accuracy: 0.9795 - Precision: 0.3566 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0062\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 09:36:49\n",
      "Accuracy: 0.9795 - Precision: 0.3580 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0061\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 09:36:58\n",
      "Accuracy: 0.9795 - Precision: 0.3604 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0003 - Loss: 0.0061\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 09:37:06\n",
      "Accuracy: 0.9795 - Precision: 0.3641 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0003 - Loss: 0.0061\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 09:37:15\n",
      "Accuracy: 0.9795 - Precision: 0.3678 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0003 - Loss: 0.0061\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 09:37:25\n",
      "Accuracy: 0.9795 - Precision: 0.3710 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0003 - Loss: 0.0061\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 09:37:34\n",
      "Accuracy: 0.9795 - Precision: 0.3746 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0003 - Loss: 0.0061\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 09:37:42\n",
      "Accuracy: 0.9795 - Precision: 0.3773 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0003 - Loss: 0.0061\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 09:37:50\n",
      "Accuracy: 0.9795 - Precision: 0.3792 - Recall: 0.0002 - Specificity: 1.0000 - F1: 0.0003 - Loss: 0.0060\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 09:37:58\n",
      "Accuracy: 0.9795 - Precision: 0.3820 - Recall: 0.0002 - Specificity: 1.0000 - F1: 0.0003 - Loss: 0.0060\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 09:38:07\n",
      "Accuracy: 0.9795 - Precision: 0.3847 - Recall: 0.0002 - Specificity: 1.0000 - F1: 0.0004 - Loss: 0.0060\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 09:38:16\n",
      "Accuracy: 0.9795 - Precision: 0.3873 - Recall: 0.0002 - Specificity: 1.0000 - F1: 0.0004 - Loss: 0.0060\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 09:38:25\n",
      "Accuracy: 0.9795 - Precision: 0.3904 - Recall: 0.0002 - Specificity: 1.0000 - F1: 0.0004 - Loss: 0.0060\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 09:38:34\n",
      "Accuracy: 0.9795 - Precision: 0.3932 - Recall: 0.0002 - Specificity: 1.0000 - F1: 0.0004 - Loss: 0.0060\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 09:38:42\n",
      "Accuracy: 0.9795 - Precision: 0.3963 - Recall: 0.0002 - Specificity: 1.0000 - F1: 0.0004 - Loss: 0.0059\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 09:38:50\n",
      "Accuracy: 0.9795 - Precision: 0.3988 - Recall: 0.0002 - Specificity: 1.0000 - F1: 0.0004 - Loss: 0.0059\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 09:38:58\n",
      "Accuracy: 0.9795 - Precision: 0.4016 - Recall: 0.0002 - Specificity: 1.0000 - F1: 0.0005 - Loss: 0.0059\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 09:39:07\n",
      "Accuracy: 0.9795 - Precision: 0.4046 - Recall: 0.0003 - Specificity: 1.0000 - F1: 0.0005 - Loss: 0.0059\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 09:39:16\n",
      "Accuracy: 0.9795 - Precision: 0.4076 - Recall: 0.0003 - Specificity: 1.0000 - F1: 0.0005 - Loss: 0.0059\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 09:39:26\n",
      "Accuracy: 0.9795 - Precision: 0.4105 - Recall: 0.0003 - Specificity: 1.0000 - F1: 0.0006 - Loss: 0.0059\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 09:39:35\n",
      "Accuracy: 0.9795 - Precision: 0.4136 - Recall: 0.0003 - Specificity: 1.0000 - F1: 0.0006 - Loss: 0.0059\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 09:39:43\n",
      "Accuracy: 0.9795 - Precision: 0.4159 - Recall: 0.0003 - Specificity: 1.0000 - F1: 0.0007 - Loss: 0.0059\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 09:39:52\n",
      "Accuracy: 0.9795 - Precision: 0.4184 - Recall: 0.0004 - Specificity: 1.0000 - F1: 0.0008 - Loss: 0.0058\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 09:40:04\n",
      "Accuracy: 0.9795 - Precision: 0.4206 - Recall: 0.0004 - Specificity: 1.0000 - F1: 0.0009 - Loss: 0.0058\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 09:40:13\n",
      "Accuracy: 0.9795 - Precision: 0.4230 - Recall: 0.0005 - Specificity: 1.0000 - F1: 0.0009 - Loss: 0.0058\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 09:40:21\n",
      "Accuracy: 0.9795 - Precision: 0.4243 - Recall: 0.0005 - Specificity: 1.0000 - F1: 0.0010 - Loss: 0.0058\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 09:40:30\n",
      "Accuracy: 0.9795 - Precision: 0.4270 - Recall: 0.0005 - Specificity: 1.0000 - F1: 0.0011 - Loss: 0.0058\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 09:40:43\n",
      "Accuracy: 0.9795 - Precision: 0.4297 - Recall: 0.0006 - Specificity: 1.0000 - F1: 0.0011 - Loss: 0.0058\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 09:40:51\n",
      "Accuracy: 0.9795 - Precision: 0.4322 - Recall: 0.0006 - Specificity: 1.0000 - F1: 0.0012 - Loss: 0.0058\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 09:41:01\n",
      "Accuracy: 0.9796 - Precision: 0.4340 - Recall: 0.0007 - Specificity: 1.0000 - F1: 0.0014 - Loss: 0.0057\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 09:41:10\n",
      "Accuracy: 0.9795 - Precision: 0.4357 - Recall: 0.0008 - Specificity: 1.0000 - F1: 0.0015 - Loss: 0.0057\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 09:41:20\n",
      "Accuracy: 0.9795 - Precision: 0.4382 - Recall: 0.0009 - Specificity: 1.0000 - F1: 0.0017 - Loss: 0.0057\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 09:41:30\n",
      "Accuracy: 0.9795 - Precision: 0.4409 - Recall: 0.0010 - Specificity: 1.0000 - F1: 0.0020 - Loss: 0.0057\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 09:41:40\n",
      "Accuracy: 0.9795 - Precision: 0.4437 - Recall: 0.0016 - Specificity: 1.0000 - F1: 0.0031 - Loss: 0.0057\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 09:41:49\n",
      "Accuracy: 0.9796 - Precision: 0.4464 - Recall: 0.0025 - Specificity: 1.0000 - F1: 0.0045 - Loss: 0.0057\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 09:41:58\n",
      "Accuracy: 0.9796 - Precision: 0.4491 - Recall: 0.0030 - Specificity: 1.0000 - F1: 0.0055 - Loss: 0.0057\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 09:42:07\n",
      "Accuracy: 0.9796 - Precision: 0.4507 - Recall: 0.0039 - Specificity: 1.0000 - F1: 0.0069 - Loss: 0.0057\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 09:42:15\n",
      "Accuracy: 0.9797 - Precision: 0.4532 - Recall: 0.0051 - Specificity: 1.0000 - F1: 0.0088 - Loss: 0.0056\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 09:42:24\n",
      "Accuracy: 0.9797 - Precision: 0.4558 - Recall: 0.0063 - Specificity: 1.0000 - F1: 0.0108 - Loss: 0.0056\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 09:42:32\n",
      "Accuracy: 0.9797 - Precision: 0.4572 - Recall: 0.0073 - Specificity: 1.0000 - F1: 0.0123 - Loss: 0.0056\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 09:42:43\n",
      "Accuracy: 0.9798 - Precision: 0.4597 - Recall: 0.0083 - Specificity: 1.0000 - F1: 0.0139 - Loss: 0.0056\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 09:42:55\n",
      "Accuracy: 0.9798 - Precision: 0.4622 - Recall: 0.0089 - Specificity: 1.0000 - F1: 0.0150 - Loss: 0.0056\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 09:43:09\n",
      "Accuracy: 0.9798 - Precision: 0.4641 - Recall: 0.0097 - Specificity: 1.0000 - F1: 0.0164 - Loss: 0.0056\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 09:43:18\n",
      "Accuracy: 0.9798 - Precision: 0.4664 - Recall: 0.0109 - Specificity: 1.0000 - F1: 0.0182 - Loss: 0.0056\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 09:43:27\n",
      "Accuracy: 0.9799 - Precision: 0.4687 - Recall: 0.0120 - Specificity: 1.0000 - F1: 0.0199 - Loss: 0.0055\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 09:43:38\n",
      "Accuracy: 0.9799 - Precision: 0.4702 - Recall: 0.0126 - Specificity: 1.0000 - F1: 0.0209 - Loss: 0.0055\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 09:43:49\n",
      "Accuracy: 0.9799 - Precision: 0.4721 - Recall: 0.0129 - Specificity: 1.0000 - F1: 0.0216 - Loss: 0.0055\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 09:44:00\n",
      "Accuracy: 0.9798 - Precision: 0.4727 - Recall: 0.0131 - Specificity: 1.0000 - F1: 0.0218 - Loss: 0.0056\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 09:44:11\n",
      "Accuracy: 0.9798 - Precision: 0.4742 - Recall: 0.0131 - Specificity: 1.0000 - F1: 0.0220 - Loss: 0.0056\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 09:44:23\n",
      "Accuracy: 0.9798 - Precision: 0.4763 - Recall: 0.0132 - Specificity: 1.0000 - F1: 0.0221 - Loss: 0.0056\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 09:44:34\n",
      "Accuracy: 0.9798 - Precision: 0.4779 - Recall: 0.0131 - Specificity: 1.0000 - F1: 0.0221 - Loss: 0.0056\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 09:44:44\n",
      "Accuracy: 0.9797 - Precision: 0.4798 - Recall: 0.0131 - Specificity: 1.0000 - F1: 0.0221 - Loss: 0.0056\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 09:44:53\n",
      "Accuracy: 0.9797 - Precision: 0.4815 - Recall: 0.0131 - Specificity: 1.0000 - F1: 0.0220 - Loss: 0.0056\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 09:45:02\n",
      "Accuracy: 0.9797 - Precision: 0.4835 - Recall: 0.0131 - Specificity: 1.0000 - F1: 0.0220 - Loss: 0.0056\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 09:45:11\n",
      "Accuracy: 0.9797 - Precision: 0.4855 - Recall: 0.0131 - Specificity: 1.0000 - F1: 0.0221 - Loss: 0.0056\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 09:45:20\n",
      "Accuracy: 0.9796 - Precision: 0.4873 - Recall: 0.0131 - Specificity: 1.0000 - F1: 0.0220 - Loss: 0.0056\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 09:45:29\n",
      "Accuracy: 0.9797 - Precision: 0.4892 - Recall: 0.0131 - Specificity: 1.0000 - F1: 0.0220 - Loss: 0.0056\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 09:45:39\n",
      "Accuracy: 0.9797 - Precision: 0.4914 - Recall: 0.0131 - Specificity: 1.0000 - F1: 0.0220 - Loss: 0.0056\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 09:45:49\n",
      "Accuracy: 0.9796 - Precision: 0.4934 - Recall: 0.0131 - Specificity: 1.0000 - F1: 0.0222 - Loss: 0.0056\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 09:45:58\n",
      "Accuracy: 0.9796 - Precision: 0.4931 - Recall: 0.0136 - Specificity: 0.9999 - F1: 0.0229 - Loss: 0.0057\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 09:46:07\n",
      "Accuracy: 0.9796 - Precision: 0.4940 - Recall: 0.0136 - Specificity: 0.9999 - F1: 0.0229 - Loss: 0.0057\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 09:46:16\n",
      "Accuracy: 0.9796 - Precision: 0.4962 - Recall: 0.0135 - Specificity: 0.9999 - F1: 0.0228 - Loss: 0.0057\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 09:46:25\n",
      "Accuracy: 0.9796 - Precision: 0.4940 - Recall: 0.0135 - Specificity: 0.9999 - F1: 0.0227 - Loss: 0.0057\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 09:46:35\n",
      "Accuracy: 0.9796 - Precision: 0.4919 - Recall: 0.0134 - Specificity: 0.9999 - F1: 0.0226 - Loss: 0.0056\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 09:46:44\n",
      "Accuracy: 0.9796 - Precision: 0.4898 - Recall: 0.0134 - Specificity: 0.9999 - F1: 0.0225 - Loss: 0.0057\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 09:46:53\n",
      "Accuracy: 0.9795 - Precision: 0.4877 - Recall: 0.0133 - Specificity: 0.9999 - F1: 0.0224 - Loss: 0.0057\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 09:47:02\n",
      "Accuracy: 0.9795 - Precision: 0.4856 - Recall: 0.0132 - Specificity: 0.9999 - F1: 0.0223 - Loss: 0.0057\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 09:47:11\n",
      "Accuracy: 0.9794 - Precision: 0.4878 - Recall: 0.0132 - Specificity: 0.9999 - F1: 0.0222 - Loss: 0.0057\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 09:47:21\n",
      "Accuracy: 0.9794 - Precision: 0.4899 - Recall: 0.0131 - Specificity: 0.9999 - F1: 0.0221 - Loss: 0.0057\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 09:47:30\n",
      "Accuracy: 0.9793 - Precision: 0.4920 - Recall: 0.0131 - Specificity: 0.9999 - F1: 0.0221 - Loss: 0.0057\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 09:47:39\n",
      "Accuracy: 0.9793 - Precision: 0.4941 - Recall: 0.0130 - Specificity: 0.9999 - F1: 0.0220 - Loss: 0.0057\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 09:47:50\n",
      "Accuracy: 0.9793 - Precision: 0.4958 - Recall: 0.0130 - Specificity: 0.9999 - F1: 0.0219 - Loss: 0.0057\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 09:48:00\n",
      "Accuracy: 0.9790 - Precision: 0.4950 - Recall: 0.0129 - Specificity: 0.9999 - F1: 0.0218 - Loss: 0.0060\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 09:48:08\n",
      "Accuracy: 0.9788 - Precision: 0.4952 - Recall: 0.0129 - Specificity: 0.9999 - F1: 0.0217 - Loss: 0.0061\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 09:48:18\n",
      "Accuracy: 0.9785 - Precision: 0.4966 - Recall: 0.0129 - Specificity: 0.9999 - F1: 0.0216 - Loss: 0.0063\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 09:48:28\n",
      "Accuracy: 0.9782 - Precision: 0.4946 - Recall: 0.0128 - Specificity: 0.9999 - F1: 0.0216 - Loss: 0.0064\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 09:48:37\n",
      "Accuracy: 0.9779 - Precision: 0.4925 - Recall: 0.0127 - Specificity: 0.9999 - F1: 0.0215 - Loss: 0.0065\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 09:48:46\n",
      "Accuracy: 0.9777 - Precision: 0.4905 - Recall: 0.0127 - Specificity: 0.9999 - F1: 0.0214 - Loss: 0.0066\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 09:48:54\n",
      "Accuracy: 0.9775 - Precision: 0.4885 - Recall: 0.0126 - Specificity: 0.9999 - F1: 0.0213 - Loss: 0.0067\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 09:49:03\n",
      "Accuracy: 0.9773 - Precision: 0.4866 - Recall: 0.0126 - Specificity: 0.9999 - F1: 0.0212 - Loss: 0.0067\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 09:49:15\n",
      "Accuracy: 0.9769 - Precision: 0.4846 - Recall: 0.0125 - Specificity: 0.9999 - F1: 0.0211 - Loss: 0.0068\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 09:49:24\n",
      "Accuracy: 0.9767 - Precision: 0.4826 - Recall: 0.0125 - Specificity: 0.9999 - F1: 0.0210 - Loss: 0.0069\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 09:49:34\n",
      "Accuracy: 0.9764 - Precision: 0.4807 - Recall: 0.0124 - Specificity: 0.9999 - F1: 0.0210 - Loss: 0.0070\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 09:49:43\n",
      "Accuracy: 0.9764 - Precision: 0.4788 - Recall: 0.0124 - Specificity: 0.9999 - F1: 0.0209 - Loss: 0.0071\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 09:49:54\n",
      "Accuracy: 0.9761 - Precision: 0.4769 - Recall: 0.0123 - Specificity: 0.9999 - F1: 0.0208 - Loss: 0.0072\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 09:50:03\n",
      "Accuracy: 0.9760 - Precision: 0.4750 - Recall: 0.0123 - Specificity: 0.9999 - F1: 0.0207 - Loss: 0.0072\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 09:50:11\n",
      "Accuracy: 0.9757 - Precision: 0.4731 - Recall: 0.0122 - Specificity: 0.9999 - F1: 0.0206 - Loss: 0.0073\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 09:50:20\n",
      "Accuracy: 0.9754 - Precision: 0.4713 - Recall: 0.0122 - Specificity: 0.9999 - F1: 0.0205 - Loss: 0.0074\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 09:50:29\n",
      "Accuracy: 0.9752 - Precision: 0.4695 - Recall: 0.0121 - Specificity: 0.9999 - F1: 0.0205 - Loss: 0.0075\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 09:50:38\n",
      "Accuracy: 0.9750 - Precision: 0.4676 - Recall: 0.0121 - Specificity: 0.9999 - F1: 0.0204 - Loss: 0.0075\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 09:50:48\n",
      "Accuracy: 0.9750 - Precision: 0.4658 - Recall: 0.0121 - Specificity: 0.9999 - F1: 0.0203 - Loss: 0.0075\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 09:50:56\n",
      "Accuracy: 0.9750 - Precision: 0.4640 - Recall: 0.0120 - Specificity: 0.9999 - F1: 0.0202 - Loss: 0.0075\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 09:51:05\n",
      "Accuracy: 0.9750 - Precision: 0.4622 - Recall: 0.0120 - Specificity: 0.9999 - F1: 0.0201 - Loss: 0.0075\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 09:51:14\n",
      "Accuracy: 0.9750 - Precision: 0.4605 - Recall: 0.0119 - Specificity: 0.9999 - F1: 0.0201 - Loss: 0.0078\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 09:51:23\n",
      "Accuracy: 0.9749 - Precision: 0.4587 - Recall: 0.0119 - Specificity: 0.9999 - F1: 0.0200 - Loss: 0.0078\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 09:51:33\n",
      "Accuracy: 0.9749 - Precision: 0.4570 - Recall: 0.0118 - Specificity: 0.9999 - F1: 0.0199 - Loss: 0.0078\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 09:51:42\n",
      "Accuracy: 0.9748 - Precision: 0.4552 - Recall: 0.0118 - Specificity: 0.9999 - F1: 0.0198 - Loss: 0.0078\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 09:51:52\n",
      "Accuracy: 0.9748 - Precision: 0.4535 - Recall: 0.0117 - Specificity: 0.9999 - F1: 0.0198 - Loss: 0.0079\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 09:52:02\n",
      "Accuracy: 0.9748 - Precision: 0.4518 - Recall: 0.0117 - Specificity: 0.9999 - F1: 0.0197 - Loss: 0.0079\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 09:52:11\n",
      "Accuracy: 0.9748 - Precision: 0.4501 - Recall: 0.0116 - Specificity: 0.9999 - F1: 0.0196 - Loss: 0.0079\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 09:52:20\n",
      "Accuracy: 0.9748 - Precision: 0.4484 - Recall: 0.0116 - Specificity: 0.9999 - F1: 0.0195 - Loss: 0.0079\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 09:52:30\n",
      "Accuracy: 0.9748 - Precision: 0.4468 - Recall: 0.0116 - Specificity: 0.9999 - F1: 0.0195 - Loss: 0.0079\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 09:52:40\n",
      "Accuracy: 0.9748 - Precision: 0.4451 - Recall: 0.0115 - Specificity: 0.9999 - F1: 0.0194 - Loss: 0.0079\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 09:52:49\n",
      "Accuracy: 0.9748 - Precision: 0.4435 - Recall: 0.0115 - Specificity: 0.9999 - F1: 0.0193 - Loss: 0.0080\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 09:52:58\n",
      "Accuracy: 0.9748 - Precision: 0.4418 - Recall: 0.0114 - Specificity: 0.9999 - F1: 0.0193 - Loss: 0.0080\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 09:53:07\n",
      "Accuracy: 0.9748 - Precision: 0.4402 - Recall: 0.0114 - Specificity: 0.9999 - F1: 0.0192 - Loss: 0.0080\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 09:53:17\n",
      "Accuracy: 0.9748 - Precision: 0.4386 - Recall: 0.0113 - Specificity: 0.9999 - F1: 0.0191 - Loss: 0.0080\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 09:53:26\n",
      "Accuracy: 0.9748 - Precision: 0.4370 - Recall: 0.0113 - Specificity: 0.9999 - F1: 0.0190 - Loss: 0.0080\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 09:53:35\n",
      "Accuracy: 0.9748 - Precision: 0.4354 - Recall: 0.0113 - Specificity: 1.0000 - F1: 0.0190 - Loss: 0.0080\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 09:53:44\n",
      "Accuracy: 0.9748 - Precision: 0.4339 - Recall: 0.0112 - Specificity: 1.0000 - F1: 0.0189 - Loss: 0.0080\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 09:53:54\n",
      "Accuracy: 0.9748 - Precision: 0.4323 - Recall: 0.0112 - Specificity: 1.0000 - F1: 0.0188 - Loss: 0.0080\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 09:54:06\n",
      "Accuracy: 0.9748 - Precision: 0.4308 - Recall: 0.0111 - Specificity: 1.0000 - F1: 0.0188 - Loss: 0.0080\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 09:54:14\n",
      "Accuracy: 0.9748 - Precision: 0.4292 - Recall: 0.0111 - Specificity: 1.0000 - F1: 0.0187 - Loss: 0.0080\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 09:54:23\n",
      "Accuracy: 0.9748 - Precision: 0.4277 - Recall: 0.0111 - Specificity: 1.0000 - F1: 0.0186 - Loss: 0.0080\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 09:54:31\n",
      "Accuracy: 0.9749 - Precision: 0.4262 - Recall: 0.0110 - Specificity: 1.0000 - F1: 0.0186 - Loss: 0.0080\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 09:54:39\n",
      "Accuracy: 0.9749 - Precision: 0.4282 - Recall: 0.0110 - Specificity: 1.0000 - F1: 0.0185 - Loss: 0.0080\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 09:54:48\n",
      "Accuracy: 0.9749 - Precision: 0.4267 - Recall: 0.0110 - Specificity: 1.0000 - F1: 0.0184 - Loss: 0.0080\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 09:54:56\n",
      "Accuracy: 0.9749 - Precision: 0.4252 - Recall: 0.0109 - Specificity: 1.0000 - F1: 0.0184 - Loss: 0.0080\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 09:55:05\n",
      "Accuracy: 0.9749 - Precision: 0.4237 - Recall: 0.0109 - Specificity: 1.0000 - F1: 0.0183 - Loss: 0.0080\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 09:55:14\n",
      "Accuracy: 0.9749 - Precision: 0.4222 - Recall: 0.0108 - Specificity: 1.0000 - F1: 0.0183 - Loss: 0.0080\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 09:55:23\n",
      "Accuracy: 0.9749 - Precision: 0.4208 - Recall: 0.0108 - Specificity: 1.0000 - F1: 0.0182 - Loss: 0.0081\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 09:55:32\n",
      "Accuracy: 0.9749 - Precision: 0.4193 - Recall: 0.0108 - Specificity: 1.0000 - F1: 0.0181 - Loss: 0.0080\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 09:55:43\n",
      "Accuracy: 0.9749 - Precision: 0.4179 - Recall: 0.0107 - Specificity: 1.0000 - F1: 0.0181 - Loss: 0.0080\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 09:55:54\n",
      "Accuracy: 0.9749 - Precision: 0.4164 - Recall: 0.0107 - Specificity: 1.0000 - F1: 0.0180 - Loss: 0.0080\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 09:56:05\n",
      "Accuracy: 0.9749 - Precision: 0.4150 - Recall: 0.0107 - Specificity: 1.0000 - F1: 0.0179 - Loss: 0.0080\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 09:56:14\n",
      "Accuracy: 0.9749 - Precision: 0.4136 - Recall: 0.0106 - Specificity: 1.0000 - F1: 0.0179 - Loss: 0.0081\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 09:56:24\n",
      "Accuracy: 0.9749 - Precision: 0.4122 - Recall: 0.0106 - Specificity: 1.0000 - F1: 0.0178 - Loss: 0.0081\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 09:56:34\n",
      "Accuracy: 0.9749 - Precision: 0.4108 - Recall: 0.0105 - Specificity: 1.0000 - F1: 0.0178 - Loss: 0.0081\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 09:56:43\n",
      "Accuracy: 0.9749 - Precision: 0.4094 - Recall: 0.0105 - Specificity: 1.0000 - F1: 0.0177 - Loss: 0.0080\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 09:56:53\n",
      "Accuracy: 0.9749 - Precision: 0.4080 - Recall: 0.0105 - Specificity: 1.0000 - F1: 0.0176 - Loss: 0.0080\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 09:57:01\n",
      "Accuracy: 0.9748 - Precision: 0.4066 - Recall: 0.0104 - Specificity: 1.0000 - F1: 0.0176 - Loss: 0.0081\n",
      "\n",
      "Epoch 1/20\n",
      "Train - Accuracy: 0.9748, Precision: 0.4066, Recall: 0.0104, Specificity: 1.0000, F1: 0.0176, Loss: 0.0081\n",
      "Validation - Accuracy: 0.9786, Precision: 0.0646, Recall: 0.0000, Specificity: 1.0000, F1: 0.0000, Loss: 0.0075\n",
      "\n",
      "\u001b[1m298/298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1154s\u001b[0m 4s/step\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 12.0 MiB for an array with shape (16, 256, 256, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 237\u001b[0m\n\u001b[0;32m    234\u001b[0m metrics_callback \u001b[38;5;241m=\u001b[39m MetricsCallback(total_batches\u001b[38;5;241m=\u001b[39msteps_per_epoch, X_valid\u001b[38;5;241m=\u001b[39mvalid_gen, X_test\u001b[38;5;241m=\u001b[39mtest_gen)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    238\u001b[0m     train_gen,\n\u001b[0;32m    239\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[0;32m    240\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m    241\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalid_gen,\n\u001b[0;32m    242\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m    243\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[metrics_callback, early_stopping],\n\u001b[0;32m    244\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    245\u001b[0m )\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[0;32m    248\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdental_xray_vgg16_unet_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[1], line 213\u001b[0m, in \u001b[0;36mMetricsCallback.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    211\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(train_gen, steps\u001b[38;5;241m=\u001b[39msteps_per_epoch)\n\u001b[0;32m    212\u001b[0m y_train_pred_bin \u001b[38;5;241m=\u001b[39m (y_train_pred \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m--> 213\u001b[0m y_train_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([y \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m train_gen], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    214\u001b[0m cm_train \u001b[38;5;241m=\u001b[39m confusion_matrix(y_train_true, y_train_pred_bin\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[0;32m    215\u001b[0m plot_confusion_matrix(cm_train, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Set Confusion Matrix - Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 213\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    211\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(train_gen, steps\u001b[38;5;241m=\u001b[39msteps_per_epoch)\n\u001b[0;32m    212\u001b[0m y_train_pred_bin \u001b[38;5;241m=\u001b[39m (y_train_pred \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m--> 213\u001b[0m y_train_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([y \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m train_gen], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    214\u001b[0m cm_train \u001b[38;5;241m=\u001b[39m confusion_matrix(y_train_true, y_train_pred_bin\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[0;32m    215\u001b[0m plot_confusion_matrix(cm_train, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Set Confusion Matrix - Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 45\u001b[0m, in \u001b[0;36mimage_generator\u001b[1;34m(img_dir, mask_dir, batch_size, img_size)\u001b[0m\n\u001b[0;32m     42\u001b[0m     masks\u001b[38;5;241m.\u001b[39mappend(mask)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(images) \u001b[38;5;241m==\u001b[39m batch_size:\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(images), np\u001b[38;5;241m.\u001b[39marray(masks)\n\u001b[0;32m     46\u001b[0m     images \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     47\u001b[0m     masks \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 12.0 MiB for an array with shape (16, 256, 256, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import backend as K\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import plotly.figure_factory as ff  # For confusion matrix plot\n",
    "\n",
    "# Directory paths\n",
    "train_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\train\"\n",
    "train_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\train\\train_mask\"\n",
    "test_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\test\"\n",
    "test_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\test\\test_mask\"\n",
    "valid_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\valid\"\n",
    "valid_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\valid\\valid_mask\"\n",
    "\n",
    "# Image generator to load data in batches\n",
    "def image_generator(img_dir, mask_dir, batch_size, img_size=(256, 256)):\n",
    "    img_files = os.listdir(img_dir)\n",
    "    while True:\n",
    "        images = []\n",
    "        masks = []\n",
    "        for img_file in img_files:\n",
    "            img_path = os.path.join(img_dir, img_file)\n",
    "            mask_file = img_file + \"_mask.png\"\n",
    "            mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "            if os.path.exists(mask_path):\n",
    "                # Load image and mask\n",
    "                img = load_img(img_path, color_mode='rgb', target_size=img_size)\n",
    "                img = img_to_array(img) / 255.0\n",
    "                mask = load_img(mask_path, color_mode='grayscale', target_size=img_size)\n",
    "                mask = img_to_array(mask) / 255.0\n",
    "\n",
    "                images.append(img)\n",
    "                masks.append(mask)\n",
    "\n",
    "            if len(images) == batch_size:\n",
    "                yield np.array(images), np.array(masks)\n",
    "                images = []\n",
    "                masks = []\n",
    "\n",
    "# VGG16-based model replacing U-Net\n",
    "def vgg16_unet_model(input_size=(256, 256, 3)):\n",
    "    # Load VGG16 as the encoder with pre-trained ImageNet weights\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=input_size)\n",
    "    \n",
    "    # Freeze VGG16 layers to prevent them from being trained\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Extract layers for skip connections\n",
    "    block1 = vgg16.get_layer('block1_pool').output   # 128x128\n",
    "    block2 = vgg16.get_layer('block2_pool').output   # 64x64\n",
    "    block3 = vgg16.get_layer('block3_pool').output   # 32x32\n",
    "    block4 = vgg16.get_layer('block4_pool').output   # 16x16\n",
    "    block5 = vgg16.get_layer('block5_pool').output   # 8x8\n",
    "    \n",
    "    # Decoder\n",
    "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(block5)  # 16x16\n",
    "    u6 = layers.concatenate([u6, block4])\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "    \n",
    "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)  # 32x32\n",
    "    u7 = layers.concatenate([u7, block3])\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "    \n",
    "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)  # 64x64\n",
    "    u8 = layers.concatenate([u8, block2])\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "    \n",
    "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)    # 128x128\n",
    "    u9 = layers.concatenate([u9, block1])\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "    \n",
    "    # Final upsampling to reach original image size\n",
    "    u10 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c9)  # 256x256\n",
    "    c10 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u10)\n",
    "    c10 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c10)\n",
    "    \n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c10)\n",
    "    \n",
    "    model = models.Model(inputs=vgg16.input, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define custom metrics\n",
    "def custom_precision(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_positives = K.sum(K.round(y_true * y_pred_bin))\n",
    "    predicted_positives = K.sum(y_pred_bin)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def custom_recall(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_positives = K.sum(K.round(y_true * y_pred_bin))\n",
    "    possible_positives = K.sum(y_true)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def custom_specificity(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_negatives = K.sum(K.round((1 - y_true) * (1 - y_pred_bin)))\n",
    "    possible_negatives = K.sum(1 - y_true)\n",
    "    specificity = true_negatives / (possible_negatives + K.epsilon())\n",
    "    return specificity\n",
    "\n",
    "def custom_f1(y_true, y_pred):\n",
    "    precision = custom_precision(y_true, y_pred)\n",
    "    recall = custom_recall(y_true, y_pred)\n",
    "    return 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "\n",
    "# Define Focal Loss\n",
    "def focal_loss_fixed(y_true, y_pred):\n",
    "    gamma = 2.0\n",
    "    alpha = 0.25\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    cross_entropy = -y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred)\n",
    "    weight = alpha * y_true * K.pow((1 - y_pred), gamma) + (1 - alpha) * (1 - y_true) * K.pow(y_pred, gamma)\n",
    "    loss = weight * cross_entropy\n",
    "    return K.mean(loss)\n",
    "\n",
    "# Compile the model\n",
    "model = vgg16_unet_model()\n",
    "model.compile(optimizer='adam', loss=focal_loss_fixed, metrics=['accuracy', custom_precision, custom_recall, custom_specificity, custom_f1])\n",
    "\n",
    "# Batch size for training\n",
    "batch_size = 16\n",
    "\n",
    "# Create data generators\n",
    "train_gen = image_generator(train_img_dir, train_mask_dir, batch_size)\n",
    "valid_gen = image_generator(valid_img_dir, valid_mask_dir, batch_size)\n",
    "test_gen = image_generator(test_img_dir, test_mask_dir, batch_size)\n",
    "\n",
    "# Number of steps per epoch\n",
    "steps_per_epoch = len(os.listdir(train_img_dir)) // batch_size\n",
    "validation_steps = len(os.listdir(valid_img_dir)) // batch_size\n",
    "test_steps = len(os.listdir(test_img_dir)) // batch_size\n",
    "\n",
    "# Function to plot confusion matrix using plotly\n",
    "def plot_confusion_matrix(cm, title):\n",
    "    fig = ff.create_annotated_heatmap(z=cm[::-1], x=['Background', 'Target'], y=['Target', 'Background'], colorscale='Blues')\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis=dict(title='Predicted labels', tickfont=dict(size=10)),\n",
    "        yaxis=dict(title='True labels', tickfont=dict(size=10)),\n",
    "        width=400,\n",
    "        height=300,\n",
    "        margin=dict(l=50, r=50, t=100, b=50)\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# Custom callback to print more metrics at each batch and epoch for training, validation, and test sets\n",
    "class MetricsCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, total_batches, X_valid, X_test):\n",
    "        super().__init__()\n",
    "        self.batch_counter = 1\n",
    "        self.total_batches = total_batches\n",
    "        self.current_epoch = 1\n",
    "        self.X_valid = X_valid\n",
    "        self.X_test = X_test\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.current_epoch = epoch + 1\n",
    "        print(f\"\\nEpoch {self.current_epoch}/{self.params['epochs']}\")\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        accuracy = logs.get('accuracy', 0)\n",
    "        loss = logs.get('loss', 0)\n",
    "        precision = logs.get('custom_precision', 0)\n",
    "        recall = logs.get('custom_recall', 0)\n",
    "        f1 = logs.get('custom_f1', 0)\n",
    "        specificity = logs.get('custom_specificity', 0)\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print(f\"Batch {self.batch_counter}/{self.total_batches} ━━━━━━━━━━━━━━━━━━━━ {current_time}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f} - Precision: {precision:.4f} - Recall: {recall:.4f} - Specificity: {specificity:.4f} - F1: {f1:.4f} - Loss: {loss:.4f}\\n\")\n",
    "        self.batch_counter += 1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        accuracy = logs.get('accuracy', 0)\n",
    "        val_accuracy = logs.get('val_accuracy', 0)\n",
    "        loss = logs.get('loss', 0)\n",
    "        val_loss = logs.get('val_loss', 0)\n",
    "        precision = logs.get('custom_precision', 0)\n",
    "        val_precision = logs.get('val_custom_precision', 0)\n",
    "        recall = logs.get('custom_recall', 0)\n",
    "        val_recall = logs.get('val_custom_recall', 0)\n",
    "        f1 = logs.get('custom_f1', 0)\n",
    "        val_f1 = logs.get('val_custom_f1', 0)\n",
    "        specificity = logs.get('custom_specificity', 0)\n",
    "        val_specificity = logs.get('val_custom_specificity', 0)\n",
    "        print(f\"Epoch {epoch+1}/{self.params['epochs']}\")\n",
    "        #print(f\"Train - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Specificity: {specificity:.4f}, F1: {f1:.4f}, Loss: {loss:.4f}\")\n",
    "        print(f\"Validation - Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, Specificity: {val_specificity:.4f}, F1: {val_f1:.4f}, Loss: {val_loss:.4f}\\n\")\n",
    "        \n",
    "        # Confusion Matrix for Training\n",
    "        y_train_pred = model.predict(train_gen, steps=steps_per_epoch)\n",
    "        y_train_pred_bin = (y_train_pred > 0.5).astype(np.uint8)\n",
    "        y_train_true = np.concatenate([y for x, y in train_gen], axis=0).flatten()\n",
    "        cm_train = confusion_matrix(y_train_true, y_train_pred_bin.flatten())\n",
    "        plot_confusion_matrix(cm_train, f\"Training Set Confusion Matrix - Epoch {self.current_epoch}\")\n",
    "\n",
    "        # Confusion Matrix for Validation\n",
    "        y_valid_pred = model.predict(self.X_valid, steps=validation_steps)\n",
    "        y_valid_pred_bin = (y_valid_pred > 0.5).astype(np.uint8)\n",
    "        y_valid_true = np.concatenate([y for x, y in valid_gen], axis=0).flatten()\n",
    "        cm_valid = confusion_matrix(y_valid_true, y_valid_pred_bin.flatten())\n",
    "        plot_confusion_matrix(cm_valid, f\"Validation Set Confusion Matrix - Epoch {self.current_epoch}\")\n",
    "\n",
    "        # Test set results at the end of each epoch\n",
    "        test_loss, test_accuracy, test_precision, test_recall, test_specificity, test_f1 = self.model.evaluate(self.X_test, verbose=0)\n",
    "        print(f\"Test Set Results - Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, Specificity: {test_specificity:.4f}, F1: {test_f1:.4f}, Loss: {test_loss:.4f}\\n\")\n",
    "        \n",
    "        self.batch_counter = 1\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Initialize the custom callback with validation and test data\n",
    "metrics_callback = MetricsCallback(total_batches=steps_per_epoch, X_valid=valid_gen, X_test=test_gen)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=20,\n",
    "    validation_data=valid_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[metrics_callback, early_stopping],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('dental_xray_vgg16_unet_model.h5')\n",
    "\n",
    "# Evaluate on the test set and show confusion matrix\n",
    "y_test_pred = model.predict(test_gen, steps=test_steps)\n",
    "y_test_pred_bin = (y_test_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "# Confusion Matrix for test set\n",
    "y_test_true = np.concatenate([y for x, y in test_gen], axis=0).flatten()\n",
    "cm_test = confusion_matrix(y_test_true, y_test_pred_bin.flatten())\n",
    "plot_confusion_matrix(cm_test, \"Test Set Confusion Matrix\")\n",
    "\n",
    "# Visualization: Show input image, true mask, and predicted mask for TEST set only\n",
    "def visualize_predictions(images, true_masks, pred_masks, title):\n",
    "    for i in range(3):  # Visualize first 3 predictions\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # Original image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "        \n",
    "        # Ground truth mask\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(true_masks[i].squeeze(), cmap='gray')\n",
    "        plt.title('Ground Truth Mask')\n",
    "        \n",
    "        # Predicted mask\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(pred_masks[i].squeeze(), cmap='gray')\n",
    "        plt.title('Predicted Mask')\n",
    "        \n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "\n",
    "# Visualize predictions for test set only\n",
    "X_test, y_test = next(test_gen)\n",
    "visualize_predictions(X_test, y_test, y_test_pred_bin, \"Test Set Predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6361a9a5-e335-4b48-aff4-fb76d4108954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08128006-a100-41cd-807b-fcd770f94337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6421160-b506-4984-83c3-c92c750033db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 11:06:37\n",
      "Accuracy: 0.9663 - Precision: 0.0391 - Recall: 0.0121 - Specificity: 0.9920 - F1: 0.0185 - Loss: 0.0409\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 11:06:46\n",
      "Accuracy: 0.9684 - Precision: 0.0196 - Recall: 0.0060 - Specificity: 0.9960 - F1: 0.0092 - Loss: 0.0624\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 11:06:54\n",
      "Accuracy: 0.9686 - Precision: 0.0130 - Recall: 0.0040 - Specificity: 0.9973 - F1: 0.0062 - Loss: 0.0544\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 11:07:03\n",
      "Accuracy: 0.9723 - Precision: 0.0098 - Recall: 0.0030 - Specificity: 0.9980 - F1: 0.0046 - Loss: 0.0434\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 11:07:11\n",
      "Accuracy: 0.9747 - Precision: 0.0078 - Recall: 0.0024 - Specificity: 0.9984 - F1: 0.0037 - Loss: 0.0372\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 11:07:20\n",
      "Accuracy: 0.9749 - Precision: 0.0065 - Recall: 0.0020 - Specificity: 0.9987 - F1: 0.0031 - Loss: 0.0332\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 11:07:28\n",
      "Accuracy: 0.9765 - Precision: 0.0056 - Recall: 0.0017 - Specificity: 0.9989 - F1: 0.0026 - Loss: 0.0296\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 11:07:37\n",
      "Accuracy: 0.9772 - Precision: 0.0049 - Recall: 0.0015 - Specificity: 0.9990 - F1: 0.0023 - Loss: 0.0272\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 11:07:46\n",
      "Accuracy: 0.9780 - Precision: 0.0043 - Recall: 0.0013 - Specificity: 0.9991 - F1: 0.0021 - Loss: 0.0253\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 11:07:54\n",
      "Accuracy: 0.9785 - Precision: 0.0039 - Recall: 0.0012 - Specificity: 0.9992 - F1: 0.0018 - Loss: 0.0238\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 11:08:03\n",
      "Accuracy: 0.9788 - Precision: 0.0036 - Recall: 0.0011 - Specificity: 0.9993 - F1: 0.0017 - Loss: 0.0225\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 11:08:11\n",
      "Accuracy: 0.9791 - Precision: 0.0033 - Recall: 0.0010 - Specificity: 0.9993 - F1: 0.0015 - Loss: 0.0214\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 11:08:21\n",
      "Accuracy: 0.9792 - Precision: 0.0030 - Recall: 0.0009 - Specificity: 0.9994 - F1: 0.0014 - Loss: 0.0205\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 11:08:30\n",
      "Accuracy: 0.9795 - Precision: 0.0028 - Recall: 0.0009 - Specificity: 0.9994 - F1: 0.0013 - Loss: 0.0197\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 11:08:38\n",
      "Accuracy: 0.9797 - Precision: 0.0026 - Recall: 0.0008 - Specificity: 0.9995 - F1: 0.0012 - Loss: 0.0189\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 11:08:46\n",
      "Accuracy: 0.9793 - Precision: 0.0024 - Recall: 0.0008 - Specificity: 0.9995 - F1: 0.0012 - Loss: 0.0185\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 11:08:55\n",
      "Accuracy: 0.9796 - Precision: 0.0023 - Recall: 0.0007 - Specificity: 0.9995 - F1: 0.0011 - Loss: 0.0179\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 11:09:03\n",
      "Accuracy: 0.9794 - Precision: 0.0022 - Recall: 0.0007 - Specificity: 0.9996 - F1: 0.0010 - Loss: 0.0175\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 11:09:11\n",
      "Accuracy: 0.9795 - Precision: 0.0021 - Recall: 0.0006 - Specificity: 0.9996 - F1: 0.0010 - Loss: 0.0170\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 11:09:20\n",
      "Accuracy: 0.9797 - Precision: 0.0020 - Recall: 0.0006 - Specificity: 0.9996 - F1: 0.0009 - Loss: 0.0166\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 11:09:28\n",
      "Accuracy: 0.9797 - Precision: 0.0019 - Recall: 0.0006 - Specificity: 0.9996 - F1: 0.0009 - Loss: 0.0162\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 11:09:36\n",
      "Accuracy: 0.9796 - Precision: 0.0018 - Recall: 0.0005 - Specificity: 0.9996 - F1: 0.0008 - Loss: 0.0159\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 11:09:44\n",
      "Accuracy: 0.9795 - Precision: 0.0017 - Recall: 0.0005 - Specificity: 0.9997 - F1: 0.0008 - Loss: 0.0156\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 11:09:53\n",
      "Accuracy: 0.9793 - Precision: 0.0016 - Recall: 0.0005 - Specificity: 0.9997 - F1: 0.0008 - Loss: 0.0154\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 11:10:02\n",
      "Accuracy: 0.9793 - Precision: 0.0016 - Recall: 0.0005 - Specificity: 0.9997 - F1: 0.0007 - Loss: 0.0151\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 11:10:12\n",
      "Accuracy: 0.9795 - Precision: 0.0015 - Recall: 0.0005 - Specificity: 0.9997 - F1: 0.0007 - Loss: 0.0148\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 11:10:35\n",
      "Accuracy: 0.9795 - Precision: 0.0014 - Recall: 0.0004 - Specificity: 0.9997 - F1: 0.0007 - Loss: 0.0146\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 11:11:03\n",
      "Accuracy: 0.9795 - Precision: 0.0014 - Recall: 0.0004 - Specificity: 0.9997 - F1: 0.0007 - Loss: 0.0144\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 11:11:28\n",
      "Accuracy: 0.9792 - Precision: 0.0013 - Recall: 0.0004 - Specificity: 0.9997 - F1: 0.0006 - Loss: 0.0144\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 11:11:46\n",
      "Accuracy: 0.9791 - Precision: 0.0013 - Recall: 0.0004 - Specificity: 0.9997 - F1: 0.0006 - Loss: 0.0142\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 11:11:57\n",
      "Accuracy: 0.9792 - Precision: 0.0013 - Recall: 0.0004 - Specificity: 0.9997 - F1: 0.0006 - Loss: 0.0139\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 11:12:06\n",
      "Accuracy: 0.9792 - Precision: 0.0012 - Recall: 0.0004 - Specificity: 0.9997 - F1: 0.0006 - Loss: 0.0138\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 11:12:18\n",
      "Accuracy: 0.9792 - Precision: 0.0012 - Recall: 0.0004 - Specificity: 0.9998 - F1: 0.0006 - Loss: 0.0136\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 11:12:29\n",
      "Accuracy: 0.9791 - Precision: 0.0012 - Recall: 0.0004 - Specificity: 0.9998 - F1: 0.0005 - Loss: 0.0135\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 11:12:38\n",
      "Accuracy: 0.9791 - Precision: 0.0011 - Recall: 0.0003 - Specificity: 0.9998 - F1: 0.0005 - Loss: 0.0133\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 11:12:46\n",
      "Accuracy: 0.9791 - Precision: 0.0011 - Recall: 0.0003 - Specificity: 0.9998 - F1: 0.0005 - Loss: 0.0132\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 11:12:55\n",
      "Accuracy: 0.9791 - Precision: 0.0011 - Recall: 0.0003 - Specificity: 0.9998 - F1: 0.0005 - Loss: 0.0130\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 11:13:03\n",
      "Accuracy: 0.9790 - Precision: 0.0010 - Recall: 0.0003 - Specificity: 0.9998 - F1: 0.0005 - Loss: 0.0129\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 11:13:11\n",
      "Accuracy: 0.9790 - Precision: 0.0010 - Recall: 0.0003 - Specificity: 0.9998 - F1: 0.0005 - Loss: 0.0127\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 11:13:20\n",
      "Accuracy: 0.9789 - Precision: 0.0010 - Recall: 0.0003 - Specificity: 0.9998 - F1: 0.0005 - Loss: 0.0126\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 11:13:29\n",
      "Accuracy: 0.9788 - Precision: 0.0253 - Recall: 0.0003 - Specificity: 0.9998 - F1: 0.0005 - Loss: 0.0125\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 11:13:37\n",
      "Accuracy: 0.9787 - Precision: 0.0247 - Recall: 0.0003 - Specificity: 0.9998 - F1: 0.0005 - Loss: 0.0123\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 11:13:45\n",
      "Accuracy: 0.9787 - Precision: 0.0242 - Recall: 0.0003 - Specificity: 0.9998 - F1: 0.0004 - Loss: 0.0122\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 11:13:54\n",
      "Accuracy: 0.9788 - Precision: 0.0236 - Recall: 0.0003 - Specificity: 0.9998 - F1: 0.0004 - Loss: 0.0120\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 11:14:02\n",
      "Accuracy: 0.9789 - Precision: 0.0231 - Recall: 0.0003 - Specificity: 0.9998 - F1: 0.0004 - Loss: 0.0119\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 11:14:10\n",
      "Accuracy: 0.9788 - Precision: 0.0226 - Recall: 0.0003 - Specificity: 0.9998 - F1: 0.0004 - Loss: 0.0117\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 11:14:19\n",
      "Accuracy: 0.9788 - Precision: 0.0221 - Recall: 0.0003 - Specificity: 0.9998 - F1: 0.0004 - Loss: 0.0116\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 11:14:28\n",
      "Accuracy: 0.9787 - Precision: 0.0216 - Recall: 0.0003 - Specificity: 0.9998 - F1: 0.0004 - Loss: 0.0115\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 11:14:37\n",
      "Accuracy: 0.9787 - Precision: 0.0212 - Recall: 0.0003 - Specificity: 0.9998 - F1: 0.0004 - Loss: 0.0113\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 11:14:45\n",
      "Accuracy: 0.9786 - Precision: 0.0208 - Recall: 0.0002 - Specificity: 0.9998 - F1: 0.0004 - Loss: 0.0112\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 11:14:54\n",
      "Accuracy: 0.9786 - Precision: 0.0204 - Recall: 0.0002 - Specificity: 0.9998 - F1: 0.0004 - Loss: 0.0111\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 11:15:02\n",
      "Accuracy: 0.9786 - Precision: 0.0200 - Recall: 0.0002 - Specificity: 0.9998 - F1: 0.0004 - Loss: 0.0110\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 11:15:11\n",
      "Accuracy: 0.9787 - Precision: 0.0196 - Recall: 0.0002 - Specificity: 0.9998 - F1: 0.0004 - Loss: 0.0109\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 11:15:19\n",
      "Accuracy: 0.9787 - Precision: 0.0192 - Recall: 0.0002 - Specificity: 0.9999 - F1: 0.0004 - Loss: 0.0108\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 11:15:28\n",
      "Accuracy: 0.9787 - Precision: 0.0189 - Recall: 0.0002 - Specificity: 0.9999 - F1: 0.0003 - Loss: 0.0106\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 11:15:37\n",
      "Accuracy: 0.9788 - Precision: 0.0186 - Recall: 0.0002 - Specificity: 0.9999 - F1: 0.0003 - Loss: 0.0105\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 11:15:46\n",
      "Accuracy: 0.9788 - Precision: 0.0358 - Recall: 0.0002 - Specificity: 0.9999 - F1: 0.0003 - Loss: 0.0104\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 11:15:56\n",
      "Accuracy: 0.9788 - Precision: 0.0524 - Recall: 0.0002 - Specificity: 0.9999 - F1: 0.0003 - Loss: 0.0103\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 11:16:06\n",
      "Accuracy: 0.9789 - Precision: 0.0685 - Recall: 0.0002 - Specificity: 0.9999 - F1: 0.0004 - Loss: 0.0102\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 11:16:14\n",
      "Accuracy: 0.9789 - Precision: 0.0840 - Recall: 0.0002 - Specificity: 0.9999 - F1: 0.0004 - Loss: 0.0101\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 11:16:23\n",
      "Accuracy: 0.9789 - Precision: 0.0953 - Recall: 0.0003 - Specificity: 0.9999 - F1: 0.0005 - Loss: 0.0100\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 11:16:33\n",
      "Accuracy: 0.9790 - Precision: 0.1099 - Recall: 0.0003 - Specificity: 0.9999 - F1: 0.0005 - Loss: 0.0099\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 11:16:41\n",
      "Accuracy: 0.9789 - Precision: 0.1240 - Recall: 0.0003 - Specificity: 0.9999 - F1: 0.0005 - Loss: 0.0098\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 11:16:50\n",
      "Accuracy: 0.9790 - Precision: 0.1377 - Recall: 0.0003 - Specificity: 0.9999 - F1: 0.0005 - Loss: 0.0097\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 11:16:58\n",
      "Accuracy: 0.9789 - Precision: 0.1502 - Recall: 0.0003 - Specificity: 0.9999 - F1: 0.0006 - Loss: 0.0097\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 11:17:07\n",
      "Accuracy: 0.9788 - Precision: 0.1607 - Recall: 0.0004 - Specificity: 0.9999 - F1: 0.0007 - Loss: 0.0096\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 11:17:16\n",
      "Accuracy: 0.9788 - Precision: 0.1727 - Recall: 0.0004 - Specificity: 0.9999 - F1: 0.0007 - Loss: 0.0095\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 11:17:24\n",
      "Accuracy: 0.9788 - Precision: 0.1849 - Recall: 0.0004 - Specificity: 0.9999 - F1: 0.0007 - Loss: 0.0095\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 11:17:33\n",
      "Accuracy: 0.9789 - Precision: 0.1967 - Recall: 0.0004 - Specificity: 0.9999 - F1: 0.0007 - Loss: 0.0094\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 11:17:41\n",
      "Accuracy: 0.9789 - Precision: 0.2074 - Recall: 0.0005 - Specificity: 0.9999 - F1: 0.0008 - Loss: 0.0093\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 11:17:50\n",
      "Accuracy: 0.9790 - Precision: 0.2145 - Recall: 0.0006 - Specificity: 0.9999 - F1: 0.0010 - Loss: 0.0092\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 11:17:58\n",
      "Accuracy: 0.9789 - Precision: 0.2249 - Recall: 0.0006 - Specificity: 0.9999 - F1: 0.0011 - Loss: 0.0092\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 11:18:07\n",
      "Accuracy: 0.9789 - Precision: 0.2355 - Recall: 0.0006 - Specificity: 0.9999 - F1: 0.0011 - Loss: 0.0091\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 11:18:15\n",
      "Accuracy: 0.9788 - Precision: 0.2454 - Recall: 0.0006 - Specificity: 0.9999 - F1: 0.0012 - Loss: 0.0091\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 11:18:24\n",
      "Accuracy: 0.9788 - Precision: 0.2548 - Recall: 0.0006 - Specificity: 0.9999 - F1: 0.0012 - Loss: 0.0090\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 11:18:35\n",
      "Accuracy: 0.9788 - Precision: 0.2638 - Recall: 0.0007 - Specificity: 0.9999 - F1: 0.0013 - Loss: 0.0090\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 11:18:46\n",
      "Accuracy: 0.9788 - Precision: 0.2716 - Recall: 0.0007 - Specificity: 0.9999 - F1: 0.0013 - Loss: 0.0089\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 11:18:55\n",
      "Accuracy: 0.9788 - Precision: 0.2809 - Recall: 0.0007 - Specificity: 0.9999 - F1: 0.0013 - Loss: 0.0088\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 11:19:04\n",
      "Accuracy: 0.9787 - Precision: 0.2889 - Recall: 0.0007 - Specificity: 0.9999 - F1: 0.0013 - Loss: 0.0088\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 11:19:12\n",
      "Accuracy: 0.9787 - Precision: 0.2963 - Recall: 0.0010 - Specificity: 0.9999 - F1: 0.0020 - Loss: 0.0088\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 11:19:21\n",
      "Accuracy: 0.9787 - Precision: 0.3016 - Recall: 0.0016 - Specificity: 0.9999 - F1: 0.0030 - Loss: 0.0087\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 11:19:29\n",
      "Accuracy: 0.9788 - Precision: 0.3081 - Recall: 0.0018 - Specificity: 0.9999 - F1: 0.0034 - Loss: 0.0087\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 11:19:38\n",
      "Accuracy: 0.9788 - Precision: 0.3164 - Recall: 0.0018 - Specificity: 0.9999 - F1: 0.0035 - Loss: 0.0086\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 11:19:46\n",
      "Accuracy: 0.9788 - Precision: 0.3237 - Recall: 0.0018 - Specificity: 0.9999 - F1: 0.0035 - Loss: 0.0085\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 11:19:55\n",
      "Accuracy: 0.9788 - Precision: 0.3303 - Recall: 0.0019 - Specificity: 0.9999 - F1: 0.0036 - Loss: 0.0085\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 11:20:03\n",
      "Accuracy: 0.9788 - Precision: 0.3359 - Recall: 0.0019 - Specificity: 0.9999 - F1: 0.0037 - Loss: 0.0084\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 11:20:11\n",
      "Accuracy: 0.9788 - Precision: 0.3435 - Recall: 0.0021 - Specificity: 0.9999 - F1: 0.0041 - Loss: 0.0084\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 11:20:19\n",
      "Accuracy: 0.9789 - Precision: 0.3490 - Recall: 0.0023 - Specificity: 0.9999 - F1: 0.0044 - Loss: 0.0083\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 11:20:28\n",
      "Accuracy: 0.9788 - Precision: 0.3563 - Recall: 0.0024 - Specificity: 0.9999 - F1: 0.0046 - Loss: 0.0083\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 11:20:38\n",
      "Accuracy: 0.9787 - Precision: 0.3631 - Recall: 0.0026 - Specificity: 0.9999 - F1: 0.0050 - Loss: 0.0083\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 11:20:46\n",
      "Accuracy: 0.9788 - Precision: 0.3689 - Recall: 0.0032 - Specificity: 0.9999 - F1: 0.0061 - Loss: 0.0082\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 11:20:55\n",
      "Accuracy: 0.9788 - Precision: 0.3730 - Recall: 0.0038 - Specificity: 0.9999 - F1: 0.0073 - Loss: 0.0082\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 11:21:04\n",
      "Accuracy: 0.9788 - Precision: 0.3786 - Recall: 0.0043 - Specificity: 0.9999 - F1: 0.0081 - Loss: 0.0081\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 11:21:12\n",
      "Accuracy: 0.9789 - Precision: 0.3851 - Recall: 0.0045 - Specificity: 0.9999 - F1: 0.0085 - Loss: 0.0081\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 11:21:21\n",
      "Accuracy: 0.9789 - Precision: 0.3903 - Recall: 0.0045 - Specificity: 0.9999 - F1: 0.0086 - Loss: 0.0080\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 11:21:29\n",
      "Accuracy: 0.9789 - Precision: 0.3962 - Recall: 0.0045 - Specificity: 0.9999 - F1: 0.0087 - Loss: 0.0080\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 11:21:38\n",
      "Accuracy: 0.9789 - Precision: 0.4018 - Recall: 0.0048 - Specificity: 0.9999 - F1: 0.0093 - Loss: 0.0079\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 11:21:46\n",
      "Accuracy: 0.9789 - Precision: 0.4070 - Recall: 0.0056 - Specificity: 0.9999 - F1: 0.0106 - Loss: 0.0079\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 11:21:55\n",
      "Accuracy: 0.9790 - Precision: 0.4116 - Recall: 0.0061 - Specificity: 0.9999 - F1: 0.0116 - Loss: 0.0078\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 11:22:04\n",
      "Accuracy: 0.9790 - Precision: 0.4170 - Recall: 0.0063 - Specificity: 0.9999 - F1: 0.0119 - Loss: 0.0078\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 11:22:13\n",
      "Accuracy: 0.9791 - Precision: 0.4215 - Recall: 0.0064 - Specificity: 0.9999 - F1: 0.0123 - Loss: 0.0077\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 11:22:21\n",
      "Accuracy: 0.9791 - Precision: 0.4247 - Recall: 0.0065 - Specificity: 0.9999 - F1: 0.0125 - Loss: 0.0077\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 11:22:30\n",
      "Accuracy: 0.9792 - Precision: 0.4274 - Recall: 0.0068 - Specificity: 0.9999 - F1: 0.0130 - Loss: 0.0077\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 11:22:41\n",
      "Accuracy: 0.9792 - Precision: 0.4314 - Recall: 0.0079 - Specificity: 0.9999 - F1: 0.0148 - Loss: 0.0076\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 11:22:50\n",
      "Accuracy: 0.9793 - Precision: 0.4341 - Recall: 0.0098 - Specificity: 0.9999 - F1: 0.0178 - Loss: 0.0076\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 11:23:01\n",
      "Accuracy: 0.9793 - Precision: 0.4382 - Recall: 0.0118 - Specificity: 0.9999 - F1: 0.0210 - Loss: 0.0075\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 11:23:10\n",
      "Accuracy: 0.9794 - Precision: 0.4417 - Recall: 0.0127 - Specificity: 0.9999 - F1: 0.0226 - Loss: 0.0075\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 11:23:19\n",
      "Accuracy: 0.9794 - Precision: 0.4442 - Recall: 0.0132 - Specificity: 0.9999 - F1: 0.0234 - Loss: 0.0075\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 11:23:28\n",
      "Accuracy: 0.9794 - Precision: 0.4490 - Recall: 0.0138 - Specificity: 0.9999 - F1: 0.0246 - Loss: 0.0074\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 11:23:37\n",
      "Accuracy: 0.9795 - Precision: 0.4540 - Recall: 0.0148 - Specificity: 0.9999 - F1: 0.0264 - Loss: 0.0074\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 11:23:46\n",
      "Accuracy: 0.9795 - Precision: 0.4573 - Recall: 0.0158 - Specificity: 0.9999 - F1: 0.0281 - Loss: 0.0074\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 11:23:54\n",
      "Accuracy: 0.9796 - Precision: 0.4615 - Recall: 0.0167 - Specificity: 0.9999 - F1: 0.0297 - Loss: 0.0073\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 11:24:03\n",
      "Accuracy: 0.9796 - Precision: 0.4646 - Recall: 0.0181 - Specificity: 0.9999 - F1: 0.0320 - Loss: 0.0073\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 11:24:11\n",
      "Accuracy: 0.9796 - Precision: 0.4691 - Recall: 0.0192 - Specificity: 0.9999 - F1: 0.0338 - Loss: 0.0072\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 11:24:19\n",
      "Accuracy: 0.9797 - Precision: 0.4735 - Recall: 0.0205 - Specificity: 0.9999 - F1: 0.0360 - Loss: 0.0072\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 11:24:27\n",
      "Accuracy: 0.9797 - Precision: 0.4768 - Recall: 0.0228 - Specificity: 0.9999 - F1: 0.0395 - Loss: 0.0072\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 11:24:37\n",
      "Accuracy: 0.9798 - Precision: 0.4806 - Recall: 0.0250 - Specificity: 0.9999 - F1: 0.0428 - Loss: 0.0071\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 11:24:46\n",
      "Accuracy: 0.9798 - Precision: 0.4838 - Recall: 0.0280 - Specificity: 0.9999 - F1: 0.0469 - Loss: 0.0071\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 11:24:55\n",
      "Accuracy: 0.9799 - Precision: 0.4863 - Recall: 0.0309 - Specificity: 0.9998 - F1: 0.0508 - Loss: 0.0071\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 11:25:03\n",
      "Accuracy: 0.9799 - Precision: 0.4885 - Recall: 0.0335 - Specificity: 0.9998 - F1: 0.0542 - Loss: 0.0070\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 11:25:11\n",
      "Accuracy: 0.9800 - Precision: 0.4914 - Recall: 0.0342 - Specificity: 0.9998 - F1: 0.0556 - Loss: 0.0070\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 11:25:20\n",
      "Accuracy: 0.9800 - Precision: 0.4950 - Recall: 0.0352 - Specificity: 0.9998 - F1: 0.0573 - Loss: 0.0070\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 11:25:29\n",
      "Accuracy: 0.9800 - Precision: 0.4985 - Recall: 0.0375 - Specificity: 0.9998 - F1: 0.0606 - Loss: 0.0070\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 11:25:37\n",
      "Accuracy: 0.9801 - Precision: 0.5014 - Recall: 0.0420 - Specificity: 0.9998 - F1: 0.0658 - Loss: 0.0069\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 11:25:46\n",
      "Accuracy: 0.9801 - Precision: 0.5034 - Recall: 0.0463 - Specificity: 0.9998 - F1: 0.0706 - Loss: 0.0069\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 11:25:58\n",
      "Accuracy: 0.9802 - Precision: 0.5070 - Recall: 0.0491 - Specificity: 0.9998 - F1: 0.0744 - Loss: 0.0069\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 11:26:09\n",
      "Accuracy: 0.9802 - Precision: 0.5101 - Recall: 0.0505 - Specificity: 0.9998 - F1: 0.0768 - Loss: 0.0069\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 11:26:18\n",
      "Accuracy: 0.9803 - Precision: 0.5126 - Recall: 0.0511 - Specificity: 0.9998 - F1: 0.0778 - Loss: 0.0068\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 11:26:27\n",
      "Accuracy: 0.9803 - Precision: 0.5162 - Recall: 0.0533 - Specificity: 0.9998 - F1: 0.0811 - Loss: 0.0068\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 11:26:37\n",
      "Accuracy: 0.9804 - Precision: 0.5182 - Recall: 0.0564 - Specificity: 0.9998 - F1: 0.0849 - Loss: 0.0068\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 11:26:46\n",
      "Accuracy: 0.9804 - Precision: 0.5206 - Recall: 0.0599 - Specificity: 0.9997 - F1: 0.0891 - Loss: 0.0068\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 11:26:55\n",
      "Accuracy: 0.9804 - Precision: 0.5234 - Recall: 0.0621 - Specificity: 0.9997 - F1: 0.0923 - Loss: 0.0067\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 11:27:03\n",
      "Accuracy: 0.9804 - Precision: 0.5268 - Recall: 0.0628 - Specificity: 0.9997 - F1: 0.0935 - Loss: 0.0067\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 11:27:12\n",
      "Accuracy: 0.9804 - Precision: 0.5303 - Recall: 0.0632 - Specificity: 0.9997 - F1: 0.0945 - Loss: 0.0067\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 11:27:20\n",
      "Accuracy: 0.9805 - Precision: 0.5337 - Recall: 0.0645 - Specificity: 0.9997 - F1: 0.0966 - Loss: 0.0067\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 11:27:29\n",
      "Accuracy: 0.9805 - Precision: 0.5363 - Recall: 0.0668 - Specificity: 0.9997 - F1: 0.0998 - Loss: 0.0066\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 11:27:37\n",
      "Accuracy: 0.9806 - Precision: 0.5388 - Recall: 0.0698 - Specificity: 0.9997 - F1: 0.1036 - Loss: 0.0066\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 11:27:46\n",
      "Accuracy: 0.9806 - Precision: 0.5413 - Recall: 0.0728 - Specificity: 0.9997 - F1: 0.1073 - Loss: 0.0066\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 11:27:54\n",
      "Accuracy: 0.9807 - Precision: 0.5441 - Recall: 0.0755 - Specificity: 0.9997 - F1: 0.1109 - Loss: 0.0066\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 11:28:05\n",
      "Accuracy: 0.9807 - Precision: 0.5466 - Recall: 0.0785 - Specificity: 0.9997 - F1: 0.1147 - Loss: 0.0066\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 11:28:15\n",
      "Accuracy: 0.9808 - Precision: 0.5490 - Recall: 0.0818 - Specificity: 0.9997 - F1: 0.1186 - Loss: 0.0065\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 11:28:24\n",
      "Accuracy: 0.9808 - Precision: 0.5515 - Recall: 0.0840 - Specificity: 0.9997 - F1: 0.1217 - Loss: 0.0065\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 11:28:32\n",
      "Accuracy: 0.9809 - Precision: 0.5532 - Recall: 0.0865 - Specificity: 0.9997 - F1: 0.1248 - Loss: 0.0065\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 11:28:44\n",
      "Accuracy: 0.9809 - Precision: 0.5553 - Recall: 0.0888 - Specificity: 0.9997 - F1: 0.1278 - Loss: 0.0065\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 11:28:53\n",
      "Accuracy: 0.9809 - Precision: 0.5582 - Recall: 0.0900 - Specificity: 0.9997 - F1: 0.1298 - Loss: 0.0064\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 11:29:02\n",
      "Accuracy: 0.9810 - Precision: 0.5605 - Recall: 0.0922 - Specificity: 0.9997 - F1: 0.1327 - Loss: 0.0064\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 11:29:11\n",
      "Accuracy: 0.9810 - Precision: 0.5630 - Recall: 0.0942 - Specificity: 0.9997 - F1: 0.1356 - Loss: 0.0064\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 11:29:22\n",
      "Accuracy: 0.9811 - Precision: 0.5652 - Recall: 0.0972 - Specificity: 0.9997 - F1: 0.1392 - Loss: 0.0064\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 11:29:31\n",
      "Accuracy: 0.9811 - Precision: 0.5641 - Recall: 0.0976 - Specificity: 0.9996 - F1: 0.1398 - Loss: 0.0064\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 11:29:39\n",
      "Accuracy: 0.9811 - Precision: 0.5664 - Recall: 0.0987 - Specificity: 0.9996 - F1: 0.1416 - Loss: 0.0064\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 11:29:48\n",
      "Accuracy: 0.9811 - Precision: 0.5689 - Recall: 0.0988 - Specificity: 0.9996 - F1: 0.1419 - Loss: 0.0064\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 11:29:57\n",
      "Accuracy: 0.9811 - Precision: 0.5707 - Recall: 0.0996 - Specificity: 0.9996 - F1: 0.1434 - Loss: 0.0063\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 11:30:06\n",
      "Accuracy: 0.9811 - Precision: 0.5731 - Recall: 0.1013 - Specificity: 0.9996 - F1: 0.1458 - Loss: 0.0063\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 11:30:15\n",
      "Accuracy: 0.9811 - Precision: 0.5756 - Recall: 0.1034 - Specificity: 0.9996 - F1: 0.1486 - Loss: 0.0063\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 11:30:26\n",
      "Accuracy: 0.9812 - Precision: 0.5779 - Recall: 0.1046 - Specificity: 0.9996 - F1: 0.1506 - Loss: 0.0063\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 11:30:36\n",
      "Accuracy: 0.9812 - Precision: 0.5803 - Recall: 0.1064 - Specificity: 0.9996 - F1: 0.1531 - Loss: 0.0063\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 11:30:45\n",
      "Accuracy: 0.9812 - Precision: 0.5826 - Recall: 0.1083 - Specificity: 0.9996 - F1: 0.1557 - Loss: 0.0063\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 11:30:53\n",
      "Accuracy: 0.9813 - Precision: 0.5840 - Recall: 0.1111 - Specificity: 0.9996 - F1: 0.1589 - Loss: 0.0062\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 11:31:02\n",
      "Accuracy: 0.9813 - Precision: 0.5862 - Recall: 0.1133 - Specificity: 0.9996 - F1: 0.1617 - Loss: 0.0062\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 11:31:10\n",
      "Accuracy: 0.9814 - Precision: 0.5882 - Recall: 0.1154 - Specificity: 0.9996 - F1: 0.1645 - Loss: 0.0062\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 11:31:19\n",
      "Accuracy: 0.9814 - Precision: 0.5906 - Recall: 0.1170 - Specificity: 0.9996 - F1: 0.1668 - Loss: 0.0062\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 11:31:28\n",
      "Accuracy: 0.9814 - Precision: 0.5929 - Recall: 0.1183 - Specificity: 0.9996 - F1: 0.1688 - Loss: 0.0062\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 11:31:37\n",
      "Accuracy: 0.9815 - Precision: 0.5947 - Recall: 0.1198 - Specificity: 0.9996 - F1: 0.1710 - Loss: 0.0061\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 11:31:46\n",
      "Accuracy: 0.9815 - Precision: 0.5962 - Recall: 0.1218 - Specificity: 0.9996 - F1: 0.1735 - Loss: 0.0061\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 11:31:55\n",
      "Accuracy: 0.9816 - Precision: 0.5983 - Recall: 0.1242 - Specificity: 0.9996 - F1: 0.1765 - Loss: 0.0061\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 11:32:04\n",
      "Accuracy: 0.9816 - Precision: 0.5989 - Recall: 0.1257 - Specificity: 0.9996 - F1: 0.1784 - Loss: 0.0061\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 11:32:12\n",
      "Accuracy: 0.9816 - Precision: 0.6012 - Recall: 0.1268 - Specificity: 0.9996 - F1: 0.1801 - Loss: 0.0061\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 11:32:21\n",
      "Accuracy: 0.9816 - Precision: 0.6033 - Recall: 0.1284 - Specificity: 0.9996 - F1: 0.1823 - Loss: 0.0061\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 11:32:29\n",
      "Accuracy: 0.9817 - Precision: 0.6041 - Recall: 0.1316 - Specificity: 0.9996 - F1: 0.1854 - Loss: 0.0060\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 11:32:38\n",
      "Accuracy: 0.9817 - Precision: 0.6051 - Recall: 0.1350 - Specificity: 0.9995 - F1: 0.1887 - Loss: 0.0060\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 11:32:48\n",
      "Accuracy: 0.9818 - Precision: 0.6067 - Recall: 0.1366 - Specificity: 0.9995 - F1: 0.1908 - Loss: 0.0060\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 11:32:57\n",
      "Accuracy: 0.9818 - Precision: 0.6083 - Recall: 0.1368 - Specificity: 0.9995 - F1: 0.1914 - Loss: 0.0060\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 11:33:05\n",
      "Accuracy: 0.9818 - Precision: 0.6102 - Recall: 0.1367 - Specificity: 0.9995 - F1: 0.1916 - Loss: 0.0060\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 11:33:13\n",
      "Accuracy: 0.9818 - Precision: 0.6124 - Recall: 0.1373 - Specificity: 0.9995 - F1: 0.1928 - Loss: 0.0060\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 11:33:22\n",
      "Accuracy: 0.9818 - Precision: 0.6140 - Recall: 0.1378 - Specificity: 0.9995 - F1: 0.1936 - Loss: 0.0060\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 11:33:30\n",
      "Accuracy: 0.9818 - Precision: 0.6159 - Recall: 0.1391 - Specificity: 0.9995 - F1: 0.1955 - Loss: 0.0059\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 11:33:39\n",
      "Accuracy: 0.9818 - Precision: 0.6175 - Recall: 0.1404 - Specificity: 0.9995 - F1: 0.1974 - Loss: 0.0059\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 11:33:47\n",
      "Accuracy: 0.9819 - Precision: 0.6194 - Recall: 0.1415 - Specificity: 0.9995 - F1: 0.1991 - Loss: 0.0059\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 11:33:56\n",
      "Accuracy: 0.9819 - Precision: 0.6209 - Recall: 0.1421 - Specificity: 0.9995 - F1: 0.2001 - Loss: 0.0059\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 11:34:04\n",
      "Accuracy: 0.9819 - Precision: 0.6228 - Recall: 0.1424 - Specificity: 0.9995 - F1: 0.2008 - Loss: 0.0059\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 11:34:13\n",
      "Accuracy: 0.9819 - Precision: 0.6246 - Recall: 0.1433 - Specificity: 0.9995 - F1: 0.2023 - Loss: 0.0059\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 11:34:22\n",
      "Accuracy: 0.9819 - Precision: 0.6263 - Recall: 0.1448 - Specificity: 0.9995 - F1: 0.2044 - Loss: 0.0059\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 11:34:30\n",
      "Accuracy: 0.9820 - Precision: 0.6277 - Recall: 0.1466 - Specificity: 0.9995 - F1: 0.2066 - Loss: 0.0058\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 11:34:39\n",
      "Accuracy: 0.9820 - Precision: 0.6291 - Recall: 0.1477 - Specificity: 0.9995 - F1: 0.2082 - Loss: 0.0058\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 11:34:50\n",
      "Accuracy: 0.9820 - Precision: 0.6308 - Recall: 0.1486 - Specificity: 0.9995 - F1: 0.2097 - Loss: 0.0058\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 11:34:58\n",
      "Accuracy: 0.9820 - Precision: 0.6319 - Recall: 0.1489 - Specificity: 0.9995 - F1: 0.2103 - Loss: 0.0058\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 11:35:07\n",
      "Accuracy: 0.9820 - Precision: 0.6336 - Recall: 0.1494 - Specificity: 0.9995 - F1: 0.2112 - Loss: 0.0058\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 11:35:16\n",
      "Accuracy: 0.9820 - Precision: 0.6350 - Recall: 0.1502 - Specificity: 0.9995 - F1: 0.2125 - Loss: 0.0058\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 11:35:24\n",
      "Accuracy: 0.9821 - Precision: 0.6361 - Recall: 0.1519 - Specificity: 0.9995 - F1: 0.2145 - Loss: 0.0058\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 11:35:33\n",
      "Accuracy: 0.9821 - Precision: 0.6371 - Recall: 0.1545 - Specificity: 0.9995 - F1: 0.2172 - Loss: 0.0058\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 11:35:41\n",
      "Accuracy: 0.9821 - Precision: 0.6380 - Recall: 0.1568 - Specificity: 0.9995 - F1: 0.2197 - Loss: 0.0058\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 11:35:50\n",
      "Accuracy: 0.9822 - Precision: 0.6394 - Recall: 0.1584 - Specificity: 0.9995 - F1: 0.2217 - Loss: 0.0057\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 11:35:58\n",
      "Accuracy: 0.9822 - Precision: 0.6395 - Recall: 0.1596 - Specificity: 0.9995 - F1: 0.2231 - Loss: 0.0057\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 11:36:07\n",
      "Accuracy: 0.9822 - Precision: 0.6413 - Recall: 0.1602 - Specificity: 0.9995 - F1: 0.2243 - Loss: 0.0057\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 11:36:16\n",
      "Accuracy: 0.9822 - Precision: 0.6429 - Recall: 0.1606 - Specificity: 0.9995 - F1: 0.2250 - Loss: 0.0057\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 11:36:24\n",
      "Accuracy: 0.9823 - Precision: 0.6445 - Recall: 0.1621 - Specificity: 0.9995 - F1: 0.2270 - Loss: 0.0057\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 11:36:33\n",
      "Accuracy: 0.9823 - Precision: 0.6451 - Recall: 0.1641 - Specificity: 0.9995 - F1: 0.2291 - Loss: 0.0057\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 11:36:41\n",
      "Accuracy: 0.9823 - Precision: 0.6456 - Recall: 0.1659 - Specificity: 0.9995 - F1: 0.2310 - Loss: 0.0057\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 11:36:52\n",
      "Accuracy: 0.9823 - Precision: 0.6470 - Recall: 0.1671 - Specificity: 0.9995 - F1: 0.2328 - Loss: 0.0057\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 11:37:00\n",
      "Accuracy: 0.9824 - Precision: 0.6487 - Recall: 0.1684 - Specificity: 0.9995 - F1: 0.2345 - Loss: 0.0056\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 11:37:10\n",
      "Accuracy: 0.9824 - Precision: 0.6503 - Recall: 0.1692 - Specificity: 0.9995 - F1: 0.2358 - Loss: 0.0056\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 11:37:19\n",
      "Accuracy: 0.9824 - Precision: 0.6519 - Recall: 0.1707 - Specificity: 0.9995 - F1: 0.2378 - Loss: 0.0056\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 11:37:28\n",
      "Accuracy: 0.9825 - Precision: 0.6536 - Recall: 0.1715 - Specificity: 0.9995 - F1: 0.2391 - Loss: 0.0056\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 11:37:36\n",
      "Accuracy: 0.9825 - Precision: 0.6541 - Recall: 0.1731 - Specificity: 0.9995 - F1: 0.2408 - Loss: 0.0056\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 11:37:45\n",
      "Accuracy: 0.9825 - Precision: 0.6554 - Recall: 0.1748 - Specificity: 0.9995 - F1: 0.2430 - Loss: 0.0056\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 11:37:54\n",
      "Accuracy: 0.9826 - Precision: 0.6567 - Recall: 0.1767 - Specificity: 0.9995 - F1: 0.2452 - Loss: 0.0055\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 11:38:02\n",
      "Accuracy: 0.9826 - Precision: 0.6571 - Recall: 0.1783 - Specificity: 0.9994 - F1: 0.2469 - Loss: 0.0055\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 11:38:11\n",
      "Accuracy: 0.9826 - Precision: 0.6582 - Recall: 0.1797 - Specificity: 0.9994 - F1: 0.2487 - Loss: 0.0055\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 11:38:20\n",
      "Accuracy: 0.9827 - Precision: 0.6598 - Recall: 0.1806 - Specificity: 0.9994 - F1: 0.2501 - Loss: 0.0055\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 11:38:29\n",
      "Accuracy: 0.9827 - Precision: 0.6607 - Recall: 0.1822 - Specificity: 0.9994 - F1: 0.2520 - Loss: 0.0055\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 11:38:38\n",
      "Accuracy: 0.9827 - Precision: 0.6618 - Recall: 0.1840 - Specificity: 0.9994 - F1: 0.2540 - Loss: 0.0055\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 11:38:49\n",
      "Accuracy: 0.9828 - Precision: 0.6627 - Recall: 0.1857 - Specificity: 0.9994 - F1: 0.2559 - Loss: 0.0055\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 11:38:59\n",
      "Accuracy: 0.9828 - Precision: 0.6632 - Recall: 0.1868 - Specificity: 0.9994 - F1: 0.2573 - Loss: 0.0055\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 11:39:08\n",
      "Accuracy: 0.9828 - Precision: 0.6637 - Recall: 0.1872 - Specificity: 0.9994 - F1: 0.2580 - Loss: 0.0055\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 11:39:18\n",
      "Accuracy: 0.9827 - Precision: 0.6635 - Recall: 0.1871 - Specificity: 0.9994 - F1: 0.2580 - Loss: 0.0055\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 11:39:28\n",
      "Accuracy: 0.9827 - Precision: 0.6641 - Recall: 0.1868 - Specificity: 0.9994 - F1: 0.2577 - Loss: 0.0055\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 11:39:45\n",
      "Accuracy: 0.9827 - Precision: 0.6654 - Recall: 0.1866 - Specificity: 0.9994 - F1: 0.2577 - Loss: 0.0055\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 11:39:55\n",
      "Accuracy: 0.9827 - Precision: 0.6663 - Recall: 0.1862 - Specificity: 0.9994 - F1: 0.2574 - Loss: 0.0055\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 11:40:05\n",
      "Accuracy: 0.9826 - Precision: 0.6676 - Recall: 0.1858 - Specificity: 0.9994 - F1: 0.2571 - Loss: 0.0055\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 11:40:14\n",
      "Accuracy: 0.9826 - Precision: 0.6684 - Recall: 0.1852 - Specificity: 0.9994 - F1: 0.2562 - Loss: 0.0056\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 11:40:22\n",
      "Accuracy: 0.9825 - Precision: 0.6699 - Recall: 0.1845 - Specificity: 0.9994 - F1: 0.2553 - Loss: 0.0056\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 11:40:34\n",
      "Accuracy: 0.9825 - Precision: 0.6711 - Recall: 0.1840 - Specificity: 0.9994 - F1: 0.2549 - Loss: 0.0056\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 11:40:43\n",
      "Accuracy: 0.9825 - Precision: 0.6723 - Recall: 0.1834 - Specificity: 0.9994 - F1: 0.2541 - Loss: 0.0056\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 11:40:54\n",
      "Accuracy: 0.9825 - Precision: 0.6732 - Recall: 0.1829 - Specificity: 0.9994 - F1: 0.2536 - Loss: 0.0056\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 11:41:03\n",
      "Accuracy: 0.9825 - Precision: 0.6747 - Recall: 0.1823 - Specificity: 0.9994 - F1: 0.2529 - Loss: 0.0056\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 11:41:12\n",
      "Accuracy: 0.9825 - Precision: 0.6760 - Recall: 0.1816 - Specificity: 0.9994 - F1: 0.2520 - Loss: 0.0056\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 11:41:20\n",
      "Accuracy: 0.9825 - Precision: 0.6769 - Recall: 0.1822 - Specificity: 0.9994 - F1: 0.2529 - Loss: 0.0056\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 11:41:30\n",
      "Accuracy: 0.9825 - Precision: 0.6766 - Recall: 0.1837 - Specificity: 0.9994 - F1: 0.2543 - Loss: 0.0056\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 11:41:40\n",
      "Accuracy: 0.9825 - Precision: 0.6766 - Recall: 0.1836 - Specificity: 0.9994 - F1: 0.2542 - Loss: 0.0056\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 11:41:48\n",
      "Accuracy: 0.9824 - Precision: 0.6778 - Recall: 0.1829 - Specificity: 0.9994 - F1: 0.2534 - Loss: 0.0056\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 11:41:57\n",
      "Accuracy: 0.9825 - Precision: 0.6748 - Recall: 0.1821 - Specificity: 0.9994 - F1: 0.2523 - Loss: 0.0056\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 11:42:06\n",
      "Accuracy: 0.9824 - Precision: 0.6762 - Recall: 0.1813 - Specificity: 0.9994 - F1: 0.2512 - Loss: 0.0056\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 11:42:14\n",
      "Accuracy: 0.9823 - Precision: 0.6776 - Recall: 0.1805 - Specificity: 0.9994 - F1: 0.2501 - Loss: 0.0056\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 11:42:23\n",
      "Accuracy: 0.9823 - Precision: 0.6790 - Recall: 0.1798 - Specificity: 0.9994 - F1: 0.2490 - Loss: 0.0056\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 11:42:31\n",
      "Accuracy: 0.9822 - Precision: 0.6804 - Recall: 0.1790 - Specificity: 0.9994 - F1: 0.2480 - Loss: 0.0057\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 11:42:40\n",
      "Accuracy: 0.9821 - Precision: 0.6817 - Recall: 0.1782 - Specificity: 0.9994 - F1: 0.2469 - Loss: 0.0057\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 11:42:50\n",
      "Accuracy: 0.9821 - Precision: 0.6831 - Recall: 0.1775 - Specificity: 0.9994 - F1: 0.2459 - Loss: 0.0057\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 11:43:00\n",
      "Accuracy: 0.9821 - Precision: 0.6834 - Recall: 0.1767 - Specificity: 0.9994 - F1: 0.2449 - Loss: 0.0057\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 11:43:08\n",
      "Accuracy: 0.9820 - Precision: 0.6847 - Recall: 0.1760 - Specificity: 0.9994 - F1: 0.2438 - Loss: 0.0057\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 11:43:16\n",
      "Accuracy: 0.9817 - Precision: 0.6848 - Recall: 0.1753 - Specificity: 0.9994 - F1: 0.2428 - Loss: 0.0060\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 11:43:25\n",
      "Accuracy: 0.9815 - Precision: 0.6853 - Recall: 0.1746 - Specificity: 0.9994 - F1: 0.2418 - Loss: 0.0061\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 11:43:34\n",
      "Accuracy: 0.9812 - Precision: 0.6860 - Recall: 0.1738 - Specificity: 0.9994 - F1: 0.2408 - Loss: 0.0062\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 11:43:42\n",
      "Accuracy: 0.9809 - Precision: 0.6831 - Recall: 0.1731 - Specificity: 0.9994 - F1: 0.2398 - Loss: 0.0063\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 11:43:51\n",
      "Accuracy: 0.9806 - Precision: 0.6803 - Recall: 0.1724 - Specificity: 0.9994 - F1: 0.2389 - Loss: 0.0064\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 11:44:00\n",
      "Accuracy: 0.9804 - Precision: 0.6776 - Recall: 0.1717 - Specificity: 0.9994 - F1: 0.2379 - Loss: 0.0065\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 11:44:11\n",
      "Accuracy: 0.9801 - Precision: 0.6748 - Recall: 0.1710 - Specificity: 0.9994 - F1: 0.2369 - Loss: 0.0066\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 11:44:20\n",
      "Accuracy: 0.9799 - Precision: 0.6721 - Recall: 0.1703 - Specificity: 0.9994 - F1: 0.2360 - Loss: 0.0066\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 11:44:30\n",
      "Accuracy: 0.9796 - Precision: 0.6694 - Recall: 0.1696 - Specificity: 0.9994 - F1: 0.2350 - Loss: 0.0067\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 11:44:39\n",
      "Accuracy: 0.9793 - Precision: 0.6667 - Recall: 0.1689 - Specificity: 0.9994 - F1: 0.2341 - Loss: 0.0068\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 11:44:47\n",
      "Accuracy: 0.9790 - Precision: 0.6640 - Recall: 0.1683 - Specificity: 0.9994 - F1: 0.2331 - Loss: 0.0069\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 11:44:57\n",
      "Accuracy: 0.9790 - Precision: 0.6614 - Recall: 0.1676 - Specificity: 0.9994 - F1: 0.2322 - Loss: 0.0069\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 11:45:06\n",
      "Accuracy: 0.9787 - Precision: 0.6587 - Recall: 0.1669 - Specificity: 0.9994 - F1: 0.2313 - Loss: 0.0070\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 11:45:15\n",
      "Accuracy: 0.9785 - Precision: 0.6588 - Recall: 0.1663 - Specificity: 0.9994 - F1: 0.2304 - Loss: 0.0071\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 11:45:24\n",
      "Accuracy: 0.9783 - Precision: 0.6601 - Recall: 0.1656 - Specificity: 0.9994 - F1: 0.2295 - Loss: 0.0072\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 11:45:33\n",
      "Accuracy: 0.9779 - Precision: 0.6575 - Recall: 0.1650 - Specificity: 0.9994 - F1: 0.2286 - Loss: 0.0072\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 11:45:42\n",
      "Accuracy: 0.9777 - Precision: 0.6589 - Recall: 0.1643 - Specificity: 0.9995 - F1: 0.2277 - Loss: 0.0073\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 11:45:51\n",
      "Accuracy: 0.9776 - Precision: 0.6563 - Recall: 0.1637 - Specificity: 0.9995 - F1: 0.2268 - Loss: 0.0073\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 11:45:59\n",
      "Accuracy: 0.9775 - Precision: 0.6538 - Recall: 0.1631 - Specificity: 0.9995 - F1: 0.2259 - Loss: 0.0073\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 11:46:08\n",
      "Accuracy: 0.9775 - Precision: 0.6512 - Recall: 0.1624 - Specificity: 0.9995 - F1: 0.2250 - Loss: 0.0074\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 11:46:16\n",
      "Accuracy: 0.9775 - Precision: 0.6487 - Recall: 0.1618 - Specificity: 0.9995 - F1: 0.2242 - Loss: 0.0074\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 11:46:25\n",
      "Accuracy: 0.9775 - Precision: 0.6462 - Recall: 0.1612 - Specificity: 0.9995 - F1: 0.2233 - Loss: 0.0074\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 11:46:34\n",
      "Accuracy: 0.9774 - Precision: 0.6438 - Recall: 0.1606 - Specificity: 0.9995 - F1: 0.2224 - Loss: 0.0074\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 11:46:43\n",
      "Accuracy: 0.9773 - Precision: 0.6413 - Recall: 0.1600 - Specificity: 0.9995 - F1: 0.2216 - Loss: 0.0074\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 11:46:52\n",
      "Accuracy: 0.9773 - Precision: 0.6389 - Recall: 0.1593 - Specificity: 0.9995 - F1: 0.2208 - Loss: 0.0074\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 11:47:03\n",
      "Accuracy: 0.9773 - Precision: 0.6365 - Recall: 0.1587 - Specificity: 0.9995 - F1: 0.2199 - Loss: 0.0075\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 11:47:15\n",
      "Accuracy: 0.9773 - Precision: 0.6341 - Recall: 0.1582 - Specificity: 0.9995 - F1: 0.2191 - Loss: 0.0075\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 11:47:24\n",
      "Accuracy: 0.9773 - Precision: 0.6317 - Recall: 0.1576 - Specificity: 0.9995 - F1: 0.2183 - Loss: 0.0075\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 11:47:35\n",
      "Accuracy: 0.9772 - Precision: 0.6294 - Recall: 0.1570 - Specificity: 0.9995 - F1: 0.2175 - Loss: 0.0075\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 11:47:44\n",
      "Accuracy: 0.9772 - Precision: 0.6270 - Recall: 0.1564 - Specificity: 0.9995 - F1: 0.2167 - Loss: 0.0075\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 11:47:53\n",
      "Accuracy: 0.9772 - Precision: 0.6284 - Recall: 0.1558 - Specificity: 0.9995 - F1: 0.2159 - Loss: 0.0075\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 11:48:01\n",
      "Accuracy: 0.9772 - Precision: 0.6298 - Recall: 0.1552 - Specificity: 0.9995 - F1: 0.2151 - Loss: 0.0075\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 11:48:10\n",
      "Accuracy: 0.9772 - Precision: 0.6311 - Recall: 0.1547 - Specificity: 0.9995 - F1: 0.2143 - Loss: 0.0075\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 11:48:18\n",
      "Accuracy: 0.9772 - Precision: 0.6325 - Recall: 0.1541 - Specificity: 0.9995 - F1: 0.2135 - Loss: 0.0075\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 11:48:27\n",
      "Accuracy: 0.9772 - Precision: 0.6334 - Recall: 0.1536 - Specificity: 0.9995 - F1: 0.2127 - Loss: 0.0075\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 11:48:35\n",
      "Accuracy: 0.9772 - Precision: 0.6311 - Recall: 0.1530 - Specificity: 0.9995 - F1: 0.2120 - Loss: 0.0075\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 11:48:46\n",
      "Accuracy: 0.9771 - Precision: 0.6324 - Recall: 0.1524 - Specificity: 0.9995 - F1: 0.2112 - Loss: 0.0075\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 11:48:55\n",
      "Accuracy: 0.9772 - Precision: 0.6301 - Recall: 0.1519 - Specificity: 0.9995 - F1: 0.2104 - Loss: 0.0075\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 11:49:06\n",
      "Accuracy: 0.9771 - Precision: 0.6279 - Recall: 0.1513 - Specificity: 0.9995 - F1: 0.2097 - Loss: 0.0075\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 11:49:15\n",
      "Accuracy: 0.9772 - Precision: 0.6256 - Recall: 0.1508 - Specificity: 0.9995 - F1: 0.2089 - Loss: 0.0075\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 11:49:24\n",
      "Accuracy: 0.9772 - Precision: 0.6234 - Recall: 0.1503 - Specificity: 0.9995 - F1: 0.2082 - Loss: 0.0075\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 11:49:33\n",
      "Accuracy: 0.9772 - Precision: 0.6212 - Recall: 0.1497 - Specificity: 0.9995 - F1: 0.2074 - Loss: 0.0075\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 11:49:43\n",
      "Accuracy: 0.9772 - Precision: 0.6189 - Recall: 0.1492 - Specificity: 0.9995 - F1: 0.2067 - Loss: 0.0075\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 11:49:52\n",
      "Accuracy: 0.9772 - Precision: 0.6168 - Recall: 0.1487 - Specificity: 0.9995 - F1: 0.2060 - Loss: 0.0075\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 11:50:01\n",
      "Accuracy: 0.9772 - Precision: 0.6146 - Recall: 0.1481 - Specificity: 0.9995 - F1: 0.2053 - Loss: 0.0075\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 11:50:09\n",
      "Accuracy: 0.9772 - Precision: 0.6124 - Recall: 0.1476 - Specificity: 0.9995 - F1: 0.2045 - Loss: 0.0075\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 11:50:18\n",
      "Accuracy: 0.9772 - Precision: 0.6132 - Recall: 0.1471 - Specificity: 0.9995 - F1: 0.2038 - Loss: 0.0075\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 11:50:26\n",
      "Accuracy: 0.9771 - Precision: 0.6146 - Recall: 0.1466 - Specificity: 0.9995 - F1: 0.2031 - Loss: 0.0075\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 11:50:35\n",
      "Accuracy: 0.9772 - Precision: 0.6155 - Recall: 0.1461 - Specificity: 0.9995 - F1: 0.2024 - Loss: 0.0075\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 11:50:44\n",
      "Accuracy: 0.9771 - Precision: 0.6169 - Recall: 0.1456 - Specificity: 0.9995 - F1: 0.2018 - Loss: 0.0075\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 11:50:53\n",
      "Accuracy: 0.9771 - Precision: 0.6180 - Recall: 0.1451 - Specificity: 0.9995 - F1: 0.2011 - Loss: 0.0075\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 11:51:03\n",
      "Accuracy: 0.9771 - Precision: 0.6159 - Recall: 0.1446 - Specificity: 0.9995 - F1: 0.2004 - Loss: 0.0075\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 11:51:13\n",
      "Accuracy: 0.9771 - Precision: 0.6142 - Recall: 0.1441 - Specificity: 0.9995 - F1: 0.1997 - Loss: 0.0075\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 11:51:22\n",
      "Accuracy: 0.9771 - Precision: 0.6153 - Recall: 0.1437 - Specificity: 0.9995 - F1: 0.1992 - Loss: 0.0075\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 11:51:31\n",
      "Accuracy: 0.9771 - Precision: 0.6165 - Recall: 0.1433 - Specificity: 0.9995 - F1: 0.1986 - Loss: 0.0075\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 11:51:40\n",
      "Accuracy: 0.9771 - Precision: 0.6171 - Recall: 0.1428 - Specificity: 0.9995 - F1: 0.1980 - Loss: 0.0075\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 11:51:49\n",
      "Accuracy: 0.9771 - Precision: 0.6178 - Recall: 0.1425 - Specificity: 0.9995 - F1: 0.1976 - Loss: 0.0075\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 11:51:58\n",
      "Accuracy: 0.9771 - Precision: 0.6189 - Recall: 0.1422 - Specificity: 0.9995 - F1: 0.1972 - Loss: 0.0075\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 11:52:07\n",
      "Accuracy: 0.9770 - Precision: 0.6199 - Recall: 0.1417 - Specificity: 0.9995 - F1: 0.1967 - Loss: 0.0075\n",
      "\n",
      "Epoch 1/20\n",
      "Validation - Accuracy: 0.9793, Precision: 0.9159, Recall: 0.0346, Specificity: 0.9999, F1: 0.0660, Loss: 0.0056\n",
      "\n",
      "\n",
      "Epoch 2/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 12:00:22\n",
      "Accuracy: 0.9757 - Precision: 0.8948 - Recall: 0.0850 - Specificity: 0.9997 - F1: 0.1552 - Loss: 0.0067\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 12:00:30\n",
      "Accuracy: 0.9746 - Precision: 0.8834 - Recall: 0.0983 - Specificity: 0.9996 - F1: 0.1766 - Loss: 0.0068\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 12:00:38\n",
      "Accuracy: 0.9747 - Precision: 0.8972 - Recall: 0.1378 - Specificity: 0.9996 - F1: 0.2348 - Loss: 0.0064\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 12:00:47\n",
      "Accuracy: 0.9772 - Precision: 0.8841 - Recall: 0.1265 - Specificity: 0.9996 - F1: 0.2178 - Loss: 0.0060\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 12:00:55\n",
      "Accuracy: 0.9788 - Precision: 0.8630 - Recall: 0.1180 - Specificity: 0.9996 - F1: 0.2047 - Loss: 0.0057\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 12:01:04\n",
      "Accuracy: 0.9787 - Precision: 0.8820 - Recall: 0.1143 - Specificity: 0.9997 - F1: 0.1995 - Loss: 0.0056\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 12:01:14\n",
      "Accuracy: 0.9799 - Precision: 0.8896 - Recall: 0.1137 - Specificity: 0.9997 - F1: 0.1993 - Loss: 0.0053\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 12:01:22\n",
      "Accuracy: 0.9804 - Precision: 0.8674 - Recall: 0.1163 - Specificity: 0.9996 - F1: 0.2026 - Loss: 0.0051\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 12:01:30\n",
      "Accuracy: 0.9811 - Precision: 0.8761 - Recall: 0.1211 - Specificity: 0.9996 - F1: 0.2104 - Loss: 0.0049\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 12:01:38\n",
      "Accuracy: 0.9814 - Precision: 0.8781 - Recall: 0.1184 - Specificity: 0.9997 - F1: 0.2065 - Loss: 0.0048\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 12:01:47\n",
      "Accuracy: 0.9819 - Precision: 0.8620 - Recall: 0.1479 - Specificity: 0.9994 - F1: 0.2370 - Loss: 0.0047\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 12:01:55\n",
      "Accuracy: 0.9824 - Precision: 0.8683 - Recall: 0.1626 - Specificity: 0.9994 - F1: 0.2575 - Loss: 0.0046\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 12:02:03\n",
      "Accuracy: 0.9826 - Precision: 0.8683 - Recall: 0.1684 - Specificity: 0.9994 - F1: 0.2663 - Loss: 0.0045\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 12:02:11\n",
      "Accuracy: 0.9827 - Precision: 0.8462 - Recall: 0.1702 - Specificity: 0.9992 - F1: 0.2679 - Loss: 0.0046\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 12:02:19\n",
      "Accuracy: 0.9828 - Precision: 0.8563 - Recall: 0.1692 - Specificity: 0.9993 - F1: 0.2679 - Loss: 0.0045\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 12:02:28\n",
      "Accuracy: 0.9824 - Precision: 0.8620 - Recall: 0.1658 - Specificity: 0.9993 - F1: 0.2639 - Loss: 0.0046\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 12:02:36\n",
      "Accuracy: 0.9827 - Precision: 0.8692 - Recall: 0.1692 - Specificity: 0.9994 - F1: 0.2699 - Loss: 0.0045\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 12:02:44\n",
      "Accuracy: 0.9827 - Precision: 0.8727 - Recall: 0.1736 - Specificity: 0.9994 - F1: 0.2767 - Loss: 0.0045\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 12:02:53\n",
      "Accuracy: 0.9828 - Precision: 0.8763 - Recall: 0.1755 - Specificity: 0.9994 - F1: 0.2802 - Loss: 0.0045\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 12:03:01\n",
      "Accuracy: 0.9829 - Precision: 0.8806 - Recall: 0.1745 - Specificity: 0.9994 - F1: 0.2795 - Loss: 0.0044\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 12:03:10\n",
      "Accuracy: 0.9829 - Precision: 0.8813 - Recall: 0.1695 - Specificity: 0.9994 - F1: 0.2723 - Loss: 0.0044\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 12:03:19\n",
      "Accuracy: 0.9825 - Precision: 0.8588 - Recall: 0.1648 - Specificity: 0.9993 - F1: 0.2651 - Loss: 0.0045\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 12:03:28\n",
      "Accuracy: 0.9824 - Precision: 0.8646 - Recall: 0.1611 - Specificity: 0.9994 - F1: 0.2600 - Loss: 0.0045\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 12:03:36\n",
      "Accuracy: 0.9823 - Precision: 0.8678 - Recall: 0.1631 - Specificity: 0.9994 - F1: 0.2634 - Loss: 0.0045\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 12:03:44\n",
      "Accuracy: 0.9824 - Precision: 0.8675 - Recall: 0.1709 - Specificity: 0.9994 - F1: 0.2732 - Loss: 0.0045\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 12:03:52\n",
      "Accuracy: 0.9827 - Precision: 0.8674 - Recall: 0.1812 - Specificity: 0.9993 - F1: 0.2850 - Loss: 0.0044\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 12:04:00\n",
      "Accuracy: 0.9828 - Precision: 0.8712 - Recall: 0.1835 - Specificity: 0.9994 - F1: 0.2889 - Loss: 0.0044\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 12:04:09\n",
      "Accuracy: 0.9827 - Precision: 0.8732 - Recall: 0.1822 - Specificity: 0.9994 - F1: 0.2876 - Loss: 0.0044\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 12:04:17\n",
      "Accuracy: 0.9824 - Precision: 0.8745 - Recall: 0.1802 - Specificity: 0.9994 - F1: 0.2852 - Loss: 0.0045\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 12:04:25\n",
      "Accuracy: 0.9824 - Precision: 0.8781 - Recall: 0.1812 - Specificity: 0.9994 - F1: 0.2872 - Loss: 0.0045\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 12:04:33\n",
      "Accuracy: 0.9826 - Precision: 0.8792 - Recall: 0.1862 - Specificity: 0.9994 - F1: 0.2939 - Loss: 0.0044\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 12:04:41\n",
      "Accuracy: 0.9827 - Precision: 0.8785 - Recall: 0.1912 - Specificity: 0.9994 - F1: 0.3001 - Loss: 0.0044\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 12:04:49\n",
      "Accuracy: 0.9828 - Precision: 0.8806 - Recall: 0.1978 - Specificity: 0.9994 - F1: 0.3083 - Loss: 0.0044\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 12:04:57\n",
      "Accuracy: 0.9828 - Precision: 0.8824 - Recall: 0.2035 - Specificity: 0.9994 - F1: 0.3155 - Loss: 0.0044\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 12:05:05\n",
      "Accuracy: 0.9829 - Precision: 0.8831 - Recall: 0.2065 - Specificity: 0.9994 - F1: 0.3196 - Loss: 0.0044\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 12:05:15\n",
      "Accuracy: 0.9831 - Precision: 0.8835 - Recall: 0.2142 - Specificity: 0.9994 - F1: 0.3282 - Loss: 0.0043\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 12:05:23\n",
      "Accuracy: 0.9832 - Precision: 0.8835 - Recall: 0.2239 - Specificity: 0.9993 - F1: 0.3381 - Loss: 0.0043\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 12:05:32\n",
      "Accuracy: 0.9833 - Precision: 0.8815 - Recall: 0.2306 - Specificity: 0.9993 - F1: 0.3450 - Loss: 0.0043\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 12:05:40\n",
      "Accuracy: 0.9834 - Precision: 0.8805 - Recall: 0.2364 - Specificity: 0.9993 - F1: 0.3514 - Loss: 0.0043\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 12:05:47\n",
      "Accuracy: 0.9834 - Precision: 0.8822 - Recall: 0.2416 - Specificity: 0.9993 - F1: 0.3578 - Loss: 0.0043\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 12:05:55\n",
      "Accuracy: 0.9834 - Precision: 0.8831 - Recall: 0.2437 - Specificity: 0.9993 - F1: 0.3608 - Loss: 0.0043\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 12:06:03\n",
      "Accuracy: 0.9834 - Precision: 0.8846 - Recall: 0.2466 - Specificity: 0.9993 - F1: 0.3647 - Loss: 0.0043\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 12:06:12\n",
      "Accuracy: 0.9835 - Precision: 0.8841 - Recall: 0.2538 - Specificity: 0.9992 - F1: 0.3720 - Loss: 0.0042\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 12:06:20\n",
      "Accuracy: 0.9837 - Precision: 0.8830 - Recall: 0.2619 - Specificity: 0.9992 - F1: 0.3796 - Loss: 0.0042\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 12:06:28\n",
      "Accuracy: 0.9838 - Precision: 0.8780 - Recall: 0.2670 - Specificity: 0.9991 - F1: 0.3836 - Loss: 0.0042\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 12:06:36\n",
      "Accuracy: 0.9837 - Precision: 0.8803 - Recall: 0.2664 - Specificity: 0.9991 - F1: 0.3837 - Loss: 0.0042\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 12:06:44\n",
      "Accuracy: 0.9837 - Precision: 0.8828 - Recall: 0.2641 - Specificity: 0.9992 - F1: 0.3814 - Loss: 0.0042\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 12:06:52\n",
      "Accuracy: 0.9836 - Precision: 0.8852 - Recall: 0.2630 - Specificity: 0.9992 - F1: 0.3807 - Loss: 0.0042\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 12:07:00\n",
      "Accuracy: 0.9836 - Precision: 0.8867 - Recall: 0.2644 - Specificity: 0.9992 - F1: 0.3830 - Loss: 0.0042\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 12:07:08\n",
      "Accuracy: 0.9837 - Precision: 0.8881 - Recall: 0.2682 - Specificity: 0.9992 - F1: 0.3877 - Loss: 0.0042\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 12:07:18\n",
      "Accuracy: 0.9837 - Precision: 0.8866 - Recall: 0.2724 - Specificity: 0.9992 - F1: 0.3919 - Loss: 0.0041\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 12:07:26\n",
      "Accuracy: 0.9838 - Precision: 0.8855 - Recall: 0.2758 - Specificity: 0.9991 - F1: 0.3956 - Loss: 0.0041\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 12:07:34\n",
      "Accuracy: 0.9839 - Precision: 0.8865 - Recall: 0.2801 - Specificity: 0.9992 - F1: 0.4005 - Loss: 0.0041\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 12:07:42\n",
      "Accuracy: 0.9840 - Precision: 0.8881 - Recall: 0.2827 - Specificity: 0.9992 - F1: 0.4039 - Loss: 0.0041\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 12:07:50\n",
      "Accuracy: 0.9840 - Precision: 0.8894 - Recall: 0.2849 - Specificity: 0.9992 - F1: 0.4069 - Loss: 0.0041\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 12:07:58\n",
      "Accuracy: 0.9841 - Precision: 0.8902 - Recall: 0.2889 - Specificity: 0.9992 - F1: 0.4114 - Loss: 0.0040\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 12:08:07\n",
      "Accuracy: 0.9842 - Precision: 0.8903 - Recall: 0.2925 - Specificity: 0.9992 - F1: 0.4154 - Loss: 0.0040\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 12:08:15\n",
      "Accuracy: 0.9843 - Precision: 0.8901 - Recall: 0.2967 - Specificity: 0.9992 - F1: 0.4197 - Loss: 0.0040\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 12:08:23\n",
      "Accuracy: 0.9845 - Precision: 0.8909 - Recall: 0.3010 - Specificity: 0.9992 - F1: 0.4243 - Loss: 0.0040\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 12:08:31\n",
      "Accuracy: 0.9845 - Precision: 0.8895 - Recall: 0.3035 - Specificity: 0.9991 - F1: 0.4269 - Loss: 0.0040\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 12:08:40\n",
      "Accuracy: 0.9845 - Precision: 0.8882 - Recall: 0.3070 - Specificity: 0.9991 - F1: 0.4303 - Loss: 0.0040\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 12:08:48\n",
      "Accuracy: 0.9846 - Precision: 0.8888 - Recall: 0.3095 - Specificity: 0.9991 - F1: 0.4333 - Loss: 0.0039\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 12:08:56\n",
      "Accuracy: 0.9847 - Precision: 0.8901 - Recall: 0.3124 - Specificity: 0.9991 - F1: 0.4368 - Loss: 0.0039\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 12:09:04\n",
      "Accuracy: 0.9847 - Precision: 0.8910 - Recall: 0.3146 - Specificity: 0.9991 - F1: 0.4395 - Loss: 0.0039\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 12:09:13\n",
      "Accuracy: 0.9847 - Precision: 0.8921 - Recall: 0.3155 - Specificity: 0.9991 - F1: 0.4410 - Loss: 0.0039\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 12:09:25\n",
      "Accuracy: 0.9847 - Precision: 0.8915 - Recall: 0.3164 - Specificity: 0.9991 - F1: 0.4422 - Loss: 0.0039\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 12:09:33\n",
      "Accuracy: 0.9847 - Precision: 0.8903 - Recall: 0.3199 - Specificity: 0.9991 - F1: 0.4454 - Loss: 0.0039\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 12:09:42\n",
      "Accuracy: 0.9848 - Precision: 0.8889 - Recall: 0.3238 - Specificity: 0.9991 - F1: 0.4488 - Loss: 0.0039\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 12:09:50\n",
      "Accuracy: 0.9848 - Precision: 0.8899 - Recall: 0.3266 - Specificity: 0.9991 - F1: 0.4520 - Loss: 0.0039\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 12:09:59\n",
      "Accuracy: 0.9849 - Precision: 0.8908 - Recall: 0.3287 - Specificity: 0.9991 - F1: 0.4545 - Loss: 0.0038\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 12:10:08\n",
      "Accuracy: 0.9850 - Precision: 0.8902 - Recall: 0.3288 - Specificity: 0.9991 - F1: 0.4550 - Loss: 0.0038\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 12:10:18\n",
      "Accuracy: 0.9849 - Precision: 0.8903 - Recall: 0.3283 - Specificity: 0.9991 - F1: 0.4548 - Loss: 0.0038\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 12:10:28\n",
      "Accuracy: 0.9849 - Precision: 0.8916 - Recall: 0.3280 - Specificity: 0.9991 - F1: 0.4550 - Loss: 0.0038\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 12:10:36\n",
      "Accuracy: 0.9849 - Precision: 0.8925 - Recall: 0.3296 - Specificity: 0.9991 - F1: 0.4571 - Loss: 0.0038\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 12:10:46\n",
      "Accuracy: 0.9849 - Precision: 0.8912 - Recall: 0.3334 - Specificity: 0.9991 - F1: 0.4602 - Loss: 0.0038\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 12:10:55\n",
      "Accuracy: 0.9850 - Precision: 0.8897 - Recall: 0.3368 - Specificity: 0.9990 - F1: 0.4630 - Loss: 0.0039\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 12:11:03\n",
      "Accuracy: 0.9850 - Precision: 0.8900 - Recall: 0.3388 - Specificity: 0.9990 - F1: 0.4652 - Loss: 0.0038\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 12:11:12\n",
      "Accuracy: 0.9850 - Precision: 0.8913 - Recall: 0.3381 - Specificity: 0.9990 - F1: 0.4649 - Loss: 0.0038\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 12:11:21\n",
      "Accuracy: 0.9849 - Precision: 0.8925 - Recall: 0.3355 - Specificity: 0.9990 - F1: 0.4621 - Loss: 0.0039\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 12:11:29\n",
      "Accuracy: 0.9849 - Precision: 0.8936 - Recall: 0.3344 - Specificity: 0.9990 - F1: 0.4612 - Loss: 0.0039\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 12:11:38\n",
      "Accuracy: 0.9849 - Precision: 0.8944 - Recall: 0.3344 - Specificity: 0.9991 - F1: 0.4617 - Loss: 0.0038\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 12:11:46\n",
      "Accuracy: 0.9849 - Precision: 0.8925 - Recall: 0.3363 - Specificity: 0.9990 - F1: 0.4632 - Loss: 0.0038\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 12:11:55\n",
      "Accuracy: 0.9850 - Precision: 0.8914 - Recall: 0.3389 - Specificity: 0.9990 - F1: 0.4655 - Loss: 0.0038\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 12:12:03\n",
      "Accuracy: 0.9850 - Precision: 0.8909 - Recall: 0.3409 - Specificity: 0.9990 - F1: 0.4675 - Loss: 0.0038\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 12:12:12\n",
      "Accuracy: 0.9851 - Precision: 0.8918 - Recall: 0.3429 - Specificity: 0.9990 - F1: 0.4699 - Loss: 0.0038\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 12:12:21\n",
      "Accuracy: 0.9851 - Precision: 0.8918 - Recall: 0.3426 - Specificity: 0.9990 - F1: 0.4698 - Loss: 0.0038\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 12:12:30\n",
      "Accuracy: 0.9851 - Precision: 0.8930 - Recall: 0.3432 - Specificity: 0.9990 - F1: 0.4709 - Loss: 0.0038\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 12:12:39\n",
      "Accuracy: 0.9851 - Precision: 0.8929 - Recall: 0.3439 - Specificity: 0.9990 - F1: 0.4719 - Loss: 0.0038\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 12:12:47\n",
      "Accuracy: 0.9851 - Precision: 0.8940 - Recall: 0.3445 - Specificity: 0.9990 - F1: 0.4729 - Loss: 0.0038\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 12:12:56\n",
      "Accuracy: 0.9851 - Precision: 0.8947 - Recall: 0.3455 - Specificity: 0.9990 - F1: 0.4743 - Loss: 0.0038\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 12:13:05\n",
      "Accuracy: 0.9852 - Precision: 0.8948 - Recall: 0.3485 - Specificity: 0.9990 - F1: 0.4772 - Loss: 0.0038\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 12:13:13\n",
      "Accuracy: 0.9852 - Precision: 0.8930 - Recall: 0.3522 - Specificity: 0.9990 - F1: 0.4797 - Loss: 0.0038\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 12:13:22\n",
      "Accuracy: 0.9853 - Precision: 0.8927 - Recall: 0.3553 - Specificity: 0.9990 - F1: 0.4825 - Loss: 0.0038\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 12:13:30\n",
      "Accuracy: 0.9853 - Precision: 0.8931 - Recall: 0.3571 - Specificity: 0.9990 - F1: 0.4845 - Loss: 0.0037\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 12:13:39\n",
      "Accuracy: 0.9853 - Precision: 0.8922 - Recall: 0.3576 - Specificity: 0.9990 - F1: 0.4851 - Loss: 0.0037\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 12:13:47\n",
      "Accuracy: 0.9853 - Precision: 0.8921 - Recall: 0.3563 - Specificity: 0.9990 - F1: 0.4839 - Loss: 0.0037\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 12:13:55\n",
      "Accuracy: 0.9853 - Precision: 0.8931 - Recall: 0.3555 - Specificity: 0.9990 - F1: 0.4833 - Loss: 0.0037\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 12:14:04\n",
      "Accuracy: 0.9853 - Precision: 0.8935 - Recall: 0.3560 - Specificity: 0.9990 - F1: 0.4841 - Loss: 0.0037\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 12:14:12\n",
      "Accuracy: 0.9854 - Precision: 0.8931 - Recall: 0.3565 - Specificity: 0.9990 - F1: 0.4849 - Loss: 0.0037\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 12:14:24\n",
      "Accuracy: 0.9854 - Precision: 0.8931 - Recall: 0.3578 - Specificity: 0.9990 - F1: 0.4863 - Loss: 0.0037\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 12:14:36\n",
      "Accuracy: 0.9855 - Precision: 0.8920 - Recall: 0.3592 - Specificity: 0.9990 - F1: 0.4875 - Loss: 0.0037\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 12:14:45\n",
      "Accuracy: 0.9855 - Precision: 0.8897 - Recall: 0.3590 - Specificity: 0.9990 - F1: 0.4871 - Loss: 0.0037\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 12:14:55\n",
      "Accuracy: 0.9855 - Precision: 0.8888 - Recall: 0.3588 - Specificity: 0.9990 - F1: 0.4869 - Loss: 0.0037\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 12:15:04\n",
      "Accuracy: 0.9855 - Precision: 0.8887 - Recall: 0.3579 - Specificity: 0.9990 - F1: 0.4862 - Loss: 0.0037\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 12:15:15\n",
      "Accuracy: 0.9855 - Precision: 0.8877 - Recall: 0.3572 - Specificity: 0.9989 - F1: 0.4855 - Loss: 0.0037\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 12:15:24\n",
      "Accuracy: 0.9855 - Precision: 0.8881 - Recall: 0.3565 - Specificity: 0.9990 - F1: 0.4851 - Loss: 0.0037\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 12:15:33\n",
      "Accuracy: 0.9855 - Precision: 0.8879 - Recall: 0.3554 - Specificity: 0.9990 - F1: 0.4841 - Loss: 0.0037\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 12:15:42\n",
      "Accuracy: 0.9855 - Precision: 0.8868 - Recall: 0.3545 - Specificity: 0.9990 - F1: 0.4831 - Loss: 0.0036\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 12:15:53\n",
      "Accuracy: 0.9855 - Precision: 0.8874 - Recall: 0.3549 - Specificity: 0.9990 - F1: 0.4839 - Loss: 0.0036\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 12:16:02\n",
      "Accuracy: 0.9856 - Precision: 0.8878 - Recall: 0.3561 - Specificity: 0.9990 - F1: 0.4852 - Loss: 0.0036\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 12:16:10\n",
      "Accuracy: 0.9856 - Precision: 0.8872 - Recall: 0.3570 - Specificity: 0.9990 - F1: 0.4862 - Loss: 0.0036\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 12:16:20\n",
      "Accuracy: 0.9857 - Precision: 0.8875 - Recall: 0.3579 - Specificity: 0.9990 - F1: 0.4873 - Loss: 0.0036\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 12:16:30\n",
      "Accuracy: 0.9857 - Precision: 0.8870 - Recall: 0.3593 - Specificity: 0.9990 - F1: 0.4886 - Loss: 0.0036\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 12:16:39\n",
      "Accuracy: 0.9857 - Precision: 0.8878 - Recall: 0.3594 - Specificity: 0.9990 - F1: 0.4891 - Loss: 0.0036\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 12:16:48\n",
      "Accuracy: 0.9857 - Precision: 0.8885 - Recall: 0.3591 - Specificity: 0.9990 - F1: 0.4890 - Loss: 0.0036\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 12:16:57\n",
      "Accuracy: 0.9857 - Precision: 0.8887 - Recall: 0.3595 - Specificity: 0.9990 - F1: 0.4897 - Loss: 0.0036\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 12:17:06\n",
      "Accuracy: 0.9857 - Precision: 0.8889 - Recall: 0.3599 - Specificity: 0.9990 - F1: 0.4903 - Loss: 0.0036\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 12:17:14\n",
      "Accuracy: 0.9858 - Precision: 0.8891 - Recall: 0.3610 - Specificity: 0.9990 - F1: 0.4915 - Loss: 0.0036\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 12:17:23\n",
      "Accuracy: 0.9858 - Precision: 0.8882 - Recall: 0.3632 - Specificity: 0.9990 - F1: 0.4932 - Loss: 0.0036\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 12:17:31\n",
      "Accuracy: 0.9858 - Precision: 0.8868 - Recall: 0.3660 - Specificity: 0.9989 - F1: 0.4950 - Loss: 0.0036\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 12:17:40\n",
      "Accuracy: 0.9859 - Precision: 0.8860 - Recall: 0.3671 - Specificity: 0.9989 - F1: 0.4960 - Loss: 0.0036\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 12:17:48\n",
      "Accuracy: 0.9859 - Precision: 0.8862 - Recall: 0.3673 - Specificity: 0.9989 - F1: 0.4964 - Loss: 0.0036\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 12:17:57\n",
      "Accuracy: 0.9858 - Precision: 0.8869 - Recall: 0.3671 - Specificity: 0.9989 - F1: 0.4965 - Loss: 0.0036\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 12:18:05\n",
      "Accuracy: 0.9858 - Precision: 0.8877 - Recall: 0.3673 - Specificity: 0.9989 - F1: 0.4970 - Loss: 0.0036\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 12:18:14\n",
      "Accuracy: 0.9859 - Precision: 0.8881 - Recall: 0.3673 - Specificity: 0.9989 - F1: 0.4973 - Loss: 0.0036\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 12:18:23\n",
      "Accuracy: 0.9859 - Precision: 0.8888 - Recall: 0.3682 - Specificity: 0.9989 - F1: 0.4984 - Loss: 0.0035\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 12:18:33\n",
      "Accuracy: 0.9859 - Precision: 0.8884 - Recall: 0.3690 - Specificity: 0.9989 - F1: 0.4992 - Loss: 0.0035\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 12:18:41\n",
      "Accuracy: 0.9859 - Precision: 0.8882 - Recall: 0.3694 - Specificity: 0.9989 - F1: 0.4997 - Loss: 0.0035\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 12:18:50\n",
      "Accuracy: 0.9860 - Precision: 0.8888 - Recall: 0.3703 - Specificity: 0.9989 - F1: 0.5009 - Loss: 0.0035\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 12:18:58\n",
      "Accuracy: 0.9860 - Precision: 0.8890 - Recall: 0.3711 - Specificity: 0.9989 - F1: 0.5018 - Loss: 0.0035\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 12:19:07\n",
      "Accuracy: 0.9860 - Precision: 0.8890 - Recall: 0.3720 - Specificity: 0.9989 - F1: 0.5028 - Loss: 0.0035\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 12:19:16\n",
      "Accuracy: 0.9860 - Precision: 0.8887 - Recall: 0.3740 - Specificity: 0.9989 - F1: 0.5045 - Loss: 0.0035\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 12:19:24\n",
      "Accuracy: 0.9860 - Precision: 0.8886 - Recall: 0.3753 - Specificity: 0.9989 - F1: 0.5058 - Loss: 0.0035\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 12:19:33\n",
      "Accuracy: 0.9860 - Precision: 0.8883 - Recall: 0.3772 - Specificity: 0.9989 - F1: 0.5074 - Loss: 0.0035\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 12:19:41\n",
      "Accuracy: 0.9861 - Precision: 0.8885 - Recall: 0.3790 - Specificity: 0.9989 - F1: 0.5092 - Loss: 0.0035\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 12:19:49\n",
      "Accuracy: 0.9861 - Precision: 0.8884 - Recall: 0.3803 - Specificity: 0.9989 - F1: 0.5104 - Loss: 0.0035\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 12:19:59\n",
      "Accuracy: 0.9861 - Precision: 0.8888 - Recall: 0.3811 - Specificity: 0.9989 - F1: 0.5114 - Loss: 0.0035\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 12:20:08\n",
      "Accuracy: 0.9861 - Precision: 0.8892 - Recall: 0.3815 - Specificity: 0.9989 - F1: 0.5120 - Loss: 0.0035\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 12:20:17\n",
      "Accuracy: 0.9861 - Precision: 0.8898 - Recall: 0.3817 - Specificity: 0.9989 - F1: 0.5125 - Loss: 0.0035\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 12:20:27\n",
      "Accuracy: 0.9862 - Precision: 0.8903 - Recall: 0.3828 - Specificity: 0.9989 - F1: 0.5137 - Loss: 0.0035\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 12:20:36\n",
      "Accuracy: 0.9862 - Precision: 0.8904 - Recall: 0.3843 - Specificity: 0.9989 - F1: 0.5151 - Loss: 0.0035\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 12:20:45\n",
      "Accuracy: 0.9862 - Precision: 0.8904 - Recall: 0.3854 - Specificity: 0.9989 - F1: 0.5163 - Loss: 0.0035\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 12:20:53\n",
      "Accuracy: 0.9862 - Precision: 0.8900 - Recall: 0.3870 - Specificity: 0.9989 - F1: 0.5176 - Loss: 0.0035\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 12:21:02\n",
      "Accuracy: 0.9863 - Precision: 0.8895 - Recall: 0.3886 - Specificity: 0.9989 - F1: 0.5189 - Loss: 0.0035\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 12:21:10\n",
      "Accuracy: 0.9863 - Precision: 0.8899 - Recall: 0.3891 - Specificity: 0.9989 - F1: 0.5196 - Loss: 0.0035\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 12:21:18\n",
      "Accuracy: 0.9863 - Precision: 0.8900 - Recall: 0.3900 - Specificity: 0.9989 - F1: 0.5205 - Loss: 0.0035\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 12:21:27\n",
      "Accuracy: 0.9863 - Precision: 0.8904 - Recall: 0.3904 - Specificity: 0.9989 - F1: 0.5211 - Loss: 0.0035\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 12:21:35\n",
      "Accuracy: 0.9863 - Precision: 0.8908 - Recall: 0.3914 - Specificity: 0.9989 - F1: 0.5223 - Loss: 0.0035\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 12:21:43\n",
      "Accuracy: 0.9863 - Precision: 0.8883 - Recall: 0.3902 - Specificity: 0.9989 - F1: 0.5207 - Loss: 0.0035\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 12:21:51\n",
      "Accuracy: 0.9863 - Precision: 0.8882 - Recall: 0.3907 - Specificity: 0.9989 - F1: 0.5214 - Loss: 0.0035\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 12:22:01\n",
      "Accuracy: 0.9863 - Precision: 0.8883 - Recall: 0.3902 - Specificity: 0.9989 - F1: 0.5209 - Loss: 0.0035\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 12:22:10\n",
      "Accuracy: 0.9863 - Precision: 0.8882 - Recall: 0.3903 - Specificity: 0.9989 - F1: 0.5211 - Loss: 0.0035\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 12:22:18\n",
      "Accuracy: 0.9863 - Precision: 0.8887 - Recall: 0.3907 - Specificity: 0.9989 - F1: 0.5218 - Loss: 0.0035\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 12:22:28\n",
      "Accuracy: 0.9863 - Precision: 0.8893 - Recall: 0.3913 - Specificity: 0.9989 - F1: 0.5226 - Loss: 0.0035\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 12:22:36\n",
      "Accuracy: 0.9863 - Precision: 0.8896 - Recall: 0.3920 - Specificity: 0.9989 - F1: 0.5234 - Loss: 0.0035\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 12:22:45\n",
      "Accuracy: 0.9864 - Precision: 0.8900 - Recall: 0.3931 - Specificity: 0.9989 - F1: 0.5246 - Loss: 0.0034\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 12:23:00\n",
      "Accuracy: 0.9864 - Precision: 0.8901 - Recall: 0.3946 - Specificity: 0.9989 - F1: 0.5260 - Loss: 0.0034\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 12:23:20\n",
      "Accuracy: 0.9864 - Precision: 0.8896 - Recall: 0.3963 - Specificity: 0.9989 - F1: 0.5273 - Loss: 0.0034\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 12:23:37\n",
      "Accuracy: 0.9864 - Precision: 0.8901 - Recall: 0.3971 - Specificity: 0.9989 - F1: 0.5283 - Loss: 0.0034\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 12:23:51\n",
      "Accuracy: 0.9865 - Precision: 0.8905 - Recall: 0.3980 - Specificity: 0.9989 - F1: 0.5293 - Loss: 0.0034\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 12:24:05\n",
      "Accuracy: 0.9865 - Precision: 0.8907 - Recall: 0.3986 - Specificity: 0.9989 - F1: 0.5300 - Loss: 0.0034\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 12:24:17\n",
      "Accuracy: 0.9865 - Precision: 0.8910 - Recall: 0.3997 - Specificity: 0.9989 - F1: 0.5312 - Loss: 0.0034\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 12:24:28\n",
      "Accuracy: 0.9865 - Precision: 0.8902 - Recall: 0.4009 - Specificity: 0.9989 - F1: 0.5320 - Loss: 0.0034\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 12:24:38\n",
      "Accuracy: 0.9866 - Precision: 0.8900 - Recall: 0.4015 - Specificity: 0.9989 - F1: 0.5326 - Loss: 0.0034\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 12:24:49\n",
      "Accuracy: 0.9866 - Precision: 0.8905 - Recall: 0.4020 - Specificity: 0.9989 - F1: 0.5333 - Loss: 0.0034\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 12:25:01\n",
      "Accuracy: 0.9866 - Precision: 0.8900 - Recall: 0.4015 - Specificity: 0.9989 - F1: 0.5328 - Loss: 0.0034\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 12:25:10\n",
      "Accuracy: 0.9865 - Precision: 0.8906 - Recall: 0.4009 - Specificity: 0.9989 - F1: 0.5323 - Loss: 0.0034\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 12:25:19\n",
      "Accuracy: 0.9865 - Precision: 0.8912 - Recall: 0.4003 - Specificity: 0.9989 - F1: 0.5320 - Loss: 0.0034\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 12:25:28\n",
      "Accuracy: 0.9866 - Precision: 0.8912 - Recall: 0.4009 - Specificity: 0.9989 - F1: 0.5326 - Loss: 0.0034\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 12:25:37\n",
      "Accuracy: 0.9866 - Precision: 0.8910 - Recall: 0.4026 - Specificity: 0.9989 - F1: 0.5340 - Loss: 0.0034\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 12:25:46\n",
      "Accuracy: 0.9866 - Precision: 0.8903 - Recall: 0.4040 - Specificity: 0.9989 - F1: 0.5350 - Loss: 0.0034\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 12:25:55\n",
      "Accuracy: 0.9866 - Precision: 0.8900 - Recall: 0.4047 - Specificity: 0.9989 - F1: 0.5356 - Loss: 0.0034\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 12:26:04\n",
      "Accuracy: 0.9866 - Precision: 0.8902 - Recall: 0.4050 - Specificity: 0.9989 - F1: 0.5361 - Loss: 0.0034\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 12:26:13\n",
      "Accuracy: 0.9866 - Precision: 0.8908 - Recall: 0.4052 - Specificity: 0.9989 - F1: 0.5365 - Loss: 0.0034\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 12:26:24\n",
      "Accuracy: 0.9866 - Precision: 0.8907 - Recall: 0.4044 - Specificity: 0.9989 - F1: 0.5358 - Loss: 0.0034\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 12:26:33\n",
      "Accuracy: 0.9866 - Precision: 0.8913 - Recall: 0.4045 - Specificity: 0.9989 - F1: 0.5360 - Loss: 0.0034\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 12:26:41\n",
      "Accuracy: 0.9866 - Precision: 0.8915 - Recall: 0.4047 - Specificity: 0.9989 - F1: 0.5364 - Loss: 0.0034\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 12:26:51\n",
      "Accuracy: 0.9866 - Precision: 0.8917 - Recall: 0.4051 - Specificity: 0.9989 - F1: 0.5369 - Loss: 0.0034\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 12:27:00\n",
      "Accuracy: 0.9866 - Precision: 0.8911 - Recall: 0.4056 - Specificity: 0.9989 - F1: 0.5373 - Loss: 0.0034\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 12:27:08\n",
      "Accuracy: 0.9866 - Precision: 0.8915 - Recall: 0.4056 - Specificity: 0.9989 - F1: 0.5375 - Loss: 0.0034\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 12:27:16\n",
      "Accuracy: 0.9867 - Precision: 0.8918 - Recall: 0.4054 - Specificity: 0.9989 - F1: 0.5375 - Loss: 0.0034\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 12:27:25\n",
      "Accuracy: 0.9867 - Precision: 0.8924 - Recall: 0.4052 - Specificity: 0.9989 - F1: 0.5375 - Loss: 0.0034\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 12:27:33\n",
      "Accuracy: 0.9867 - Precision: 0.8928 - Recall: 0.4051 - Specificity: 0.9989 - F1: 0.5376 - Loss: 0.0034\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 12:27:41\n",
      "Accuracy: 0.9867 - Precision: 0.8929 - Recall: 0.4052 - Specificity: 0.9989 - F1: 0.5378 - Loss: 0.0034\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 12:27:49\n",
      "Accuracy: 0.9867 - Precision: 0.8930 - Recall: 0.4061 - Specificity: 0.9989 - F1: 0.5387 - Loss: 0.0034\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 12:27:58\n",
      "Accuracy: 0.9867 - Precision: 0.8926 - Recall: 0.4068 - Specificity: 0.9989 - F1: 0.5393 - Loss: 0.0034\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 12:28:06\n",
      "Accuracy: 0.9867 - Precision: 0.8926 - Recall: 0.4075 - Specificity: 0.9989 - F1: 0.5400 - Loss: 0.0034\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 12:28:14\n",
      "Accuracy: 0.9867 - Precision: 0.8926 - Recall: 0.4082 - Specificity: 0.9989 - F1: 0.5407 - Loss: 0.0034\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 12:28:22\n",
      "Accuracy: 0.9867 - Precision: 0.8926 - Recall: 0.4087 - Specificity: 0.9989 - F1: 0.5412 - Loss: 0.0034\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 12:28:31\n",
      "Accuracy: 0.9867 - Precision: 0.8929 - Recall: 0.4093 - Specificity: 0.9989 - F1: 0.5419 - Loss: 0.0034\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 12:28:39\n",
      "Accuracy: 0.9867 - Precision: 0.8932 - Recall: 0.4099 - Specificity: 0.9989 - F1: 0.5426 - Loss: 0.0034\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 12:28:47\n",
      "Accuracy: 0.9867 - Precision: 0.8932 - Recall: 0.4105 - Specificity: 0.9989 - F1: 0.5433 - Loss: 0.0034\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 12:28:57\n",
      "Accuracy: 0.9868 - Precision: 0.8921 - Recall: 0.4115 - Specificity: 0.9989 - F1: 0.5437 - Loss: 0.0034\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 12:29:06\n",
      "Accuracy: 0.9868 - Precision: 0.8924 - Recall: 0.4124 - Specificity: 0.9989 - F1: 0.5447 - Loss: 0.0033\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 12:29:15\n",
      "Accuracy: 0.9868 - Precision: 0.8926 - Recall: 0.4125 - Specificity: 0.9989 - F1: 0.5450 - Loss: 0.0033\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 12:29:24\n",
      "Accuracy: 0.9868 - Precision: 0.8928 - Recall: 0.4133 - Specificity: 0.9989 - F1: 0.5457 - Loss: 0.0033\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 12:29:32\n",
      "Accuracy: 0.9868 - Precision: 0.8924 - Recall: 0.4138 - Specificity: 0.9989 - F1: 0.5462 - Loss: 0.0033\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 12:29:40\n",
      "Accuracy: 0.9868 - Precision: 0.8921 - Recall: 0.4143 - Specificity: 0.9989 - F1: 0.5466 - Loss: 0.0033\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 12:29:49\n",
      "Accuracy: 0.9868 - Precision: 0.8923 - Recall: 0.4148 - Specificity: 0.9989 - F1: 0.5472 - Loss: 0.0033\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 12:29:58\n",
      "Accuracy: 0.9869 - Precision: 0.8926 - Recall: 0.4157 - Specificity: 0.9989 - F1: 0.5481 - Loss: 0.0033\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 12:30:07\n",
      "Accuracy: 0.9869 - Precision: 0.8927 - Recall: 0.4168 - Specificity: 0.9989 - F1: 0.5491 - Loss: 0.0033\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 12:30:16\n",
      "Accuracy: 0.9869 - Precision: 0.8928 - Recall: 0.4184 - Specificity: 0.9989 - F1: 0.5505 - Loss: 0.0033\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 12:30:25\n",
      "Accuracy: 0.9869 - Precision: 0.8930 - Recall: 0.4193 - Specificity: 0.9989 - F1: 0.5514 - Loss: 0.0033\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 12:30:35\n",
      "Accuracy: 0.9870 - Precision: 0.8926 - Recall: 0.4199 - Specificity: 0.9989 - F1: 0.5519 - Loss: 0.0033\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 12:30:44\n",
      "Accuracy: 0.9870 - Precision: 0.8929 - Recall: 0.4204 - Specificity: 0.9989 - F1: 0.5524 - Loss: 0.0033\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 12:30:54\n",
      "Accuracy: 0.9870 - Precision: 0.8932 - Recall: 0.4210 - Specificity: 0.9989 - F1: 0.5531 - Loss: 0.0033\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 12:31:04\n",
      "Accuracy: 0.9870 - Precision: 0.8926 - Recall: 0.4216 - Specificity: 0.9989 - F1: 0.5535 - Loss: 0.0033\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 12:31:14\n",
      "Accuracy: 0.9871 - Precision: 0.8925 - Recall: 0.4224 - Specificity: 0.9989 - F1: 0.5543 - Loss: 0.0033\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 12:31:23\n",
      "Accuracy: 0.9871 - Precision: 0.8927 - Recall: 0.4235 - Specificity: 0.9989 - F1: 0.5553 - Loss: 0.0033\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 12:31:32\n",
      "Accuracy: 0.9871 - Precision: 0.8923 - Recall: 0.4246 - Specificity: 0.9989 - F1: 0.5561 - Loss: 0.0033\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 12:31:41\n",
      "Accuracy: 0.9871 - Precision: 0.8924 - Recall: 0.4255 - Specificity: 0.9989 - F1: 0.5569 - Loss: 0.0033\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 12:31:49\n",
      "Accuracy: 0.9871 - Precision: 0.8925 - Recall: 0.4261 - Specificity: 0.9989 - F1: 0.5575 - Loss: 0.0033\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 12:31:57\n",
      "Accuracy: 0.9871 - Precision: 0.8923 - Recall: 0.4260 - Specificity: 0.9989 - F1: 0.5575 - Loss: 0.0033\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 12:32:06\n",
      "Accuracy: 0.9871 - Precision: 0.8922 - Recall: 0.4254 - Specificity: 0.9989 - F1: 0.5569 - Loss: 0.0033\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 12:32:15\n",
      "Accuracy: 0.9870 - Precision: 0.8913 - Recall: 0.4245 - Specificity: 0.9989 - F1: 0.5559 - Loss: 0.0033\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 12:32:26\n",
      "Accuracy: 0.9870 - Precision: 0.8909 - Recall: 0.4233 - Specificity: 0.9989 - F1: 0.5546 - Loss: 0.0033\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 12:32:35\n",
      "Accuracy: 0.9870 - Precision: 0.8911 - Recall: 0.4225 - Specificity: 0.9989 - F1: 0.5539 - Loss: 0.0033\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 12:32:45\n",
      "Accuracy: 0.9870 - Precision: 0.8912 - Recall: 0.4218 - Specificity: 0.9989 - F1: 0.5533 - Loss: 0.0033\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 12:32:54\n",
      "Accuracy: 0.9869 - Precision: 0.8914 - Recall: 0.4209 - Specificity: 0.9989 - F1: 0.5524 - Loss: 0.0033\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 12:33:04\n",
      "Accuracy: 0.9868 - Precision: 0.8910 - Recall: 0.4195 - Specificity: 0.9989 - F1: 0.5508 - Loss: 0.0034\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 12:33:14\n",
      "Accuracy: 0.9868 - Precision: 0.8914 - Recall: 0.4181 - Specificity: 0.9989 - F1: 0.5493 - Loss: 0.0034\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 12:33:23\n",
      "Accuracy: 0.9868 - Precision: 0.8911 - Recall: 0.4171 - Specificity: 0.9989 - F1: 0.5482 - Loss: 0.0034\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 12:33:33\n",
      "Accuracy: 0.9867 - Precision: 0.8909 - Recall: 0.4162 - Specificity: 0.9989 - F1: 0.5473 - Loss: 0.0034\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 12:33:42\n",
      "Accuracy: 0.9868 - Precision: 0.8906 - Recall: 0.4162 - Specificity: 0.9989 - F1: 0.5473 - Loss: 0.0034\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 12:33:51\n",
      "Accuracy: 0.9868 - Precision: 0.8905 - Recall: 0.4155 - Specificity: 0.9989 - F1: 0.5466 - Loss: 0.0034\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 12:34:00\n",
      "Accuracy: 0.9867 - Precision: 0.8906 - Recall: 0.4142 - Specificity: 0.9989 - F1: 0.5452 - Loss: 0.0034\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 12:34:09\n",
      "Accuracy: 0.9867 - Precision: 0.8908 - Recall: 0.4137 - Specificity: 0.9989 - F1: 0.5449 - Loss: 0.0034\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 12:34:19\n",
      "Accuracy: 0.9867 - Precision: 0.8906 - Recall: 0.4139 - Specificity: 0.9989 - F1: 0.5450 - Loss: 0.0034\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 12:34:28\n",
      "Accuracy: 0.9867 - Precision: 0.8898 - Recall: 0.4132 - Specificity: 0.9989 - F1: 0.5443 - Loss: 0.0034\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 12:34:38\n",
      "Accuracy: 0.9867 - Precision: 0.8897 - Recall: 0.4129 - Specificity: 0.9989 - F1: 0.5440 - Loss: 0.0034\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 12:34:50\n",
      "Accuracy: 0.9867 - Precision: 0.8897 - Recall: 0.4126 - Specificity: 0.9989 - F1: 0.5439 - Loss: 0.0034\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 12:34:59\n",
      "Accuracy: 0.9866 - Precision: 0.8900 - Recall: 0.4117 - Specificity: 0.9989 - F1: 0.5430 - Loss: 0.0034\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 12:35:10\n",
      "Accuracy: 0.9865 - Precision: 0.8901 - Recall: 0.4104 - Specificity: 0.9989 - F1: 0.5415 - Loss: 0.0035\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 12:35:19\n",
      "Accuracy: 0.9865 - Precision: 0.8904 - Recall: 0.4096 - Specificity: 0.9989 - F1: 0.5407 - Loss: 0.0035\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 12:35:28\n",
      "Accuracy: 0.9864 - Precision: 0.8906 - Recall: 0.4088 - Specificity: 0.9989 - F1: 0.5399 - Loss: 0.0035\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 12:35:37\n",
      "Accuracy: 0.9864 - Precision: 0.8903 - Recall: 0.4087 - Specificity: 0.9989 - F1: 0.5398 - Loss: 0.0035\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 12:35:46\n",
      "Accuracy: 0.9863 - Precision: 0.8903 - Recall: 0.4083 - Specificity: 0.9989 - F1: 0.5395 - Loss: 0.0035\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 12:35:57\n",
      "Accuracy: 0.9863 - Precision: 0.8906 - Recall: 0.4078 - Specificity: 0.9989 - F1: 0.5391 - Loss: 0.0035\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 12:36:06\n",
      "Accuracy: 0.9863 - Precision: 0.8907 - Recall: 0.4072 - Specificity: 0.9989 - F1: 0.5386 - Loss: 0.0035\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 12:36:15\n",
      "Accuracy: 0.9859 - Precision: 0.8878 - Recall: 0.4055 - Specificity: 0.9989 - F1: 0.5364 - Loss: 0.0039\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 12:36:24\n",
      "Accuracy: 0.9858 - Precision: 0.8862 - Recall: 0.4041 - Specificity: 0.9989 - F1: 0.5347 - Loss: 0.0040\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 12:36:33\n",
      "Accuracy: 0.9854 - Precision: 0.8858 - Recall: 0.4026 - Specificity: 0.9989 - F1: 0.5328 - Loss: 0.0041\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 12:36:42\n",
      "Accuracy: 0.9851 - Precision: 0.8862 - Recall: 0.4010 - Specificity: 0.9989 - F1: 0.5307 - Loss: 0.0042\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 12:36:51\n",
      "Accuracy: 0.9848 - Precision: 0.8831 - Recall: 0.3994 - Specificity: 0.9989 - F1: 0.5286 - Loss: 0.0043\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 12:36:59\n",
      "Accuracy: 0.9846 - Precision: 0.8795 - Recall: 0.3978 - Specificity: 0.9989 - F1: 0.5264 - Loss: 0.0044\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 12:37:10\n",
      "Accuracy: 0.9843 - Precision: 0.8759 - Recall: 0.3962 - Specificity: 0.9989 - F1: 0.5243 - Loss: 0.0045\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 12:37:19\n",
      "Accuracy: 0.9841 - Precision: 0.8724 - Recall: 0.3945 - Specificity: 0.9989 - F1: 0.5221 - Loss: 0.0046\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 12:37:28\n",
      "Accuracy: 0.9837 - Precision: 0.8711 - Recall: 0.3933 - Specificity: 0.9989 - F1: 0.5207 - Loss: 0.0047\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 12:37:37\n",
      "Accuracy: 0.9834 - Precision: 0.8676 - Recall: 0.3918 - Specificity: 0.9989 - F1: 0.5186 - Loss: 0.0048\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 12:37:45\n",
      "Accuracy: 0.9832 - Precision: 0.8641 - Recall: 0.3902 - Specificity: 0.9989 - F1: 0.5165 - Loss: 0.0049\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 12:37:54\n",
      "Accuracy: 0.9831 - Precision: 0.8606 - Recall: 0.3886 - Specificity: 0.9989 - F1: 0.5145 - Loss: 0.0050\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 12:38:02\n",
      "Accuracy: 0.9828 - Precision: 0.8572 - Recall: 0.3871 - Specificity: 0.9989 - F1: 0.5124 - Loss: 0.0051\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 12:38:11\n",
      "Accuracy: 0.9826 - Precision: 0.8538 - Recall: 0.3856 - Specificity: 0.9989 - F1: 0.5104 - Loss: 0.0051\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 12:38:20\n",
      "Accuracy: 0.9823 - Precision: 0.8505 - Recall: 0.3841 - Specificity: 0.9989 - F1: 0.5084 - Loss: 0.0052\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 12:38:30\n",
      "Accuracy: 0.9820 - Precision: 0.8471 - Recall: 0.3825 - Specificity: 0.9989 - F1: 0.5064 - Loss: 0.0053\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 12:38:39\n",
      "Accuracy: 0.9817 - Precision: 0.8464 - Recall: 0.3811 - Specificity: 0.9989 - F1: 0.5044 - Loss: 0.0054\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 12:38:48\n",
      "Accuracy: 0.9816 - Precision: 0.8431 - Recall: 0.3796 - Specificity: 0.9989 - F1: 0.5025 - Loss: 0.0054\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 12:38:56\n",
      "Accuracy: 0.9815 - Precision: 0.8398 - Recall: 0.3781 - Specificity: 0.9989 - F1: 0.5005 - Loss: 0.0055\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 12:39:06\n",
      "Accuracy: 0.9815 - Precision: 0.8366 - Recall: 0.3766 - Specificity: 0.9989 - F1: 0.4986 - Loss: 0.0055\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 12:39:16\n",
      "Accuracy: 0.9815 - Precision: 0.8333 - Recall: 0.3752 - Specificity: 0.9989 - F1: 0.4967 - Loss: 0.0055\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 12:39:27\n",
      "Accuracy: 0.9815 - Precision: 0.8301 - Recall: 0.3738 - Specificity: 0.9989 - F1: 0.4948 - Loss: 0.0055\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 12:39:36\n",
      "Accuracy: 0.9813 - Precision: 0.8270 - Recall: 0.3723 - Specificity: 0.9989 - F1: 0.4929 - Loss: 0.0056\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 12:39:45\n",
      "Accuracy: 0.9813 - Precision: 0.8238 - Recall: 0.3709 - Specificity: 0.9989 - F1: 0.4910 - Loss: 0.0056\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 12:39:54\n",
      "Accuracy: 0.9812 - Precision: 0.8207 - Recall: 0.3695 - Specificity: 0.9989 - F1: 0.4891 - Loss: 0.0056\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 12:40:03\n",
      "Accuracy: 0.9812 - Precision: 0.8176 - Recall: 0.3681 - Specificity: 0.9989 - F1: 0.4873 - Loss: 0.0057\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 12:40:12\n",
      "Accuracy: 0.9811 - Precision: 0.8145 - Recall: 0.3667 - Specificity: 0.9989 - F1: 0.4855 - Loss: 0.0057\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 12:40:24\n",
      "Accuracy: 0.9811 - Precision: 0.8115 - Recall: 0.3654 - Specificity: 0.9989 - F1: 0.4836 - Loss: 0.0057\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 12:40:34\n",
      "Accuracy: 0.9811 - Precision: 0.8085 - Recall: 0.3640 - Specificity: 0.9989 - F1: 0.4818 - Loss: 0.0057\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 12:40:43\n",
      "Accuracy: 0.9811 - Precision: 0.8055 - Recall: 0.3626 - Specificity: 0.9989 - F1: 0.4800 - Loss: 0.0057\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 12:40:53\n",
      "Accuracy: 0.9810 - Precision: 0.8025 - Recall: 0.3613 - Specificity: 0.9990 - F1: 0.4783 - Loss: 0.0057\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 12:41:05\n",
      "Accuracy: 0.9810 - Precision: 0.7995 - Recall: 0.3600 - Specificity: 0.9990 - F1: 0.4765 - Loss: 0.0057\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 12:41:15\n",
      "Accuracy: 0.9810 - Precision: 0.7966 - Recall: 0.3586 - Specificity: 0.9990 - F1: 0.4747 - Loss: 0.0057\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 12:41:27\n",
      "Accuracy: 0.9809 - Precision: 0.7937 - Recall: 0.3573 - Specificity: 0.9990 - F1: 0.4730 - Loss: 0.0058\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 12:41:37\n",
      "Accuracy: 0.9809 - Precision: 0.7908 - Recall: 0.3560 - Specificity: 0.9990 - F1: 0.4713 - Loss: 0.0058\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 12:41:48\n",
      "Accuracy: 0.9809 - Precision: 0.7879 - Recall: 0.3547 - Specificity: 0.9990 - F1: 0.4696 - Loss: 0.0058\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 12:41:56\n",
      "Accuracy: 0.9809 - Precision: 0.7850 - Recall: 0.3534 - Specificity: 0.9990 - F1: 0.4679 - Loss: 0.0058\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 12:42:05\n",
      "Accuracy: 0.9809 - Precision: 0.7822 - Recall: 0.3522 - Specificity: 0.9990 - F1: 0.4662 - Loss: 0.0058\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 12:42:14\n",
      "Accuracy: 0.9808 - Precision: 0.7794 - Recall: 0.3509 - Specificity: 0.9990 - F1: 0.4645 - Loss: 0.0058\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 12:42:24\n",
      "Accuracy: 0.9808 - Precision: 0.7766 - Recall: 0.3496 - Specificity: 0.9990 - F1: 0.4628 - Loss: 0.0058\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 12:42:33\n",
      "Accuracy: 0.9808 - Precision: 0.7738 - Recall: 0.3484 - Specificity: 0.9990 - F1: 0.4612 - Loss: 0.0058\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 12:42:41\n",
      "Accuracy: 0.9808 - Precision: 0.7711 - Recall: 0.3472 - Specificity: 0.9990 - F1: 0.4595 - Loss: 0.0058\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 12:42:50\n",
      "Accuracy: 0.9808 - Precision: 0.7683 - Recall: 0.3459 - Specificity: 0.9990 - F1: 0.4579 - Loss: 0.0058\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 12:42:59\n",
      "Accuracy: 0.9808 - Precision: 0.7656 - Recall: 0.3447 - Specificity: 0.9990 - F1: 0.4563 - Loss: 0.0058\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 12:43:09\n",
      "Accuracy: 0.9808 - Precision: 0.7629 - Recall: 0.3435 - Specificity: 0.9990 - F1: 0.4547 - Loss: 0.0058\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 12:43:18\n",
      "Accuracy: 0.9808 - Precision: 0.7602 - Recall: 0.3423 - Specificity: 0.9990 - F1: 0.4531 - Loss: 0.0058\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 12:43:27\n",
      "Accuracy: 0.9808 - Precision: 0.7576 - Recall: 0.3411 - Specificity: 0.9990 - F1: 0.4515 - Loss: 0.0058\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 12:43:38\n",
      "Accuracy: 0.9807 - Precision: 0.7549 - Recall: 0.3399 - Specificity: 0.9990 - F1: 0.4499 - Loss: 0.0058\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 12:43:49\n",
      "Accuracy: 0.9807 - Precision: 0.7523 - Recall: 0.3387 - Specificity: 0.9990 - F1: 0.4484 - Loss: 0.0058\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 12:43:58\n",
      "Accuracy: 0.9807 - Precision: 0.7497 - Recall: 0.3375 - Specificity: 0.9990 - F1: 0.4468 - Loss: 0.0058\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 12:44:07\n",
      "Accuracy: 0.9807 - Precision: 0.7471 - Recall: 0.3364 - Specificity: 0.9990 - F1: 0.4453 - Loss: 0.0058\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 12:44:16\n",
      "Accuracy: 0.9807 - Precision: 0.7446 - Recall: 0.3352 - Specificity: 0.9990 - F1: 0.4438 - Loss: 0.0058\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 12:44:27\n",
      "Accuracy: 0.9806 - Precision: 0.7420 - Recall: 0.3341 - Specificity: 0.9990 - F1: 0.4422 - Loss: 0.0058\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 12:44:39\n",
      "Accuracy: 0.9806 - Precision: 0.7395 - Recall: 0.3329 - Specificity: 0.9990 - F1: 0.4407 - Loss: 0.0058\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 12:44:51\n",
      "Accuracy: 0.9806 - Precision: 0.7370 - Recall: 0.3318 - Specificity: 0.9990 - F1: 0.4392 - Loss: 0.0058\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 12:45:04\n",
      "Accuracy: 0.9806 - Precision: 0.7345 - Recall: 0.3307 - Specificity: 0.9990 - F1: 0.4377 - Loss: 0.0058\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 12:45:18\n",
      "Accuracy: 0.9805 - Precision: 0.7320 - Recall: 0.3296 - Specificity: 0.9990 - F1: 0.4363 - Loss: 0.0058\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 12:45:30\n",
      "Accuracy: 0.9805 - Precision: 0.7295 - Recall: 0.3285 - Specificity: 0.9990 - F1: 0.4348 - Loss: 0.0058\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 12:45:42\n",
      "Accuracy: 0.9805 - Precision: 0.7271 - Recall: 0.3273 - Specificity: 0.9991 - F1: 0.4333 - Loss: 0.0059\n",
      "\n",
      "Epoch 2/20\n",
      "Validation - Accuracy: 0.9786, Precision: 0.0000, Recall: 0.0000, Specificity: 1.0000, F1: 0.0000, Loss: 0.0055\n",
      "\n",
      "\n",
      "Epoch 3/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 12:54:11\n",
      "Accuracy: 0.9738 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0070\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 12:54:20\n",
      "Accuracy: 0.9722 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0072\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 12:54:30\n",
      "Accuracy: 0.9711 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0068\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 12:54:39\n",
      "Accuracy: 0.9742 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0062\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 12:54:48\n",
      "Accuracy: 0.9762 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0058\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 12:54:57\n",
      "Accuracy: 0.9762 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0056\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 12:55:05\n",
      "Accuracy: 0.9775 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0053\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 12:55:15\n",
      "Accuracy: 0.9781 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0051\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 12:55:23\n",
      "Accuracy: 0.9788 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0049\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 12:55:32\n",
      "Accuracy: 0.9792 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0048\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 12:55:41\n",
      "Accuracy: 0.9795 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0047\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 12:55:49\n",
      "Accuracy: 0.9797 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0046\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 12:55:58\n",
      "Accuracy: 0.9798 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0045\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 12:56:07\n",
      "Accuracy: 0.9800 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0045\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 12:56:16\n",
      "Accuracy: 0.9802 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 12:56:25\n",
      "Accuracy: 0.9797 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0045\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 12:56:36\n",
      "Accuracy: 0.9800 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 12:56:45\n",
      "Accuracy: 0.9799 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 12:56:54\n",
      "Accuracy: 0.9799 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 12:57:05\n",
      "Accuracy: 0.9801 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0043\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 12:57:14\n",
      "Accuracy: 0.9801 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0043\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 12:57:23\n",
      "Accuracy: 0.9799 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 12:57:32\n",
      "Accuracy: 0.9798 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 12:57:40\n",
      "Accuracy: 0.9796 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 12:57:49\n",
      "Accuracy: 0.9796 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 12:57:58\n",
      "Accuracy: 0.9798 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 12:58:07\n",
      "Accuracy: 0.9798 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 12:58:16\n",
      "Accuracy: 0.9797 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 12:58:25\n",
      "Accuracy: 0.9794 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0045\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 12:58:35\n",
      "Accuracy: 0.9793 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 12:58:47\n",
      "Accuracy: 0.9795 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 12:58:56\n",
      "Accuracy: 0.9794 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 12:59:05\n",
      "Accuracy: 0.9795 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 12:59:15\n",
      "Accuracy: 0.9793 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 12:59:25\n",
      "Accuracy: 0.9793 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 12:59:34\n",
      "Accuracy: 0.9793 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 12:59:43\n",
      "Accuracy: 0.9793 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0043\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 12:59:53\n",
      "Accuracy: 0.9792 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0043\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 13:00:03\n",
      "Accuracy: 0.9792 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0043\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 13:00:11\n",
      "Accuracy: 0.9791 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0043\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 13:00:20\n",
      "Accuracy: 0.9790 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 13:00:30\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0043\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 13:00:40\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0043\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 13:00:49\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0043\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 13:00:58\n",
      "Accuracy: 0.9791 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0043\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 13:01:06\n",
      "Accuracy: 0.9790 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0043\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 13:01:15\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0042\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 13:01:23\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0042\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 13:01:32\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0042\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 13:01:41\n",
      "Accuracy: 0.9788 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0042\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 13:01:51\n",
      "Accuracy: 0.9788 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0042\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 13:01:59\n",
      "Accuracy: 0.9788 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0042\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 13:02:08\n",
      "Accuracy: 0.9788 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0041\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 13:02:17\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0041\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 13:02:26\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0041\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 13:02:37\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0041\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 13:02:47\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0041\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 13:02:56\n",
      "Accuracy: 0.9790 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0040\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 13:03:04\n",
      "Accuracy: 0.9790 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0040\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 13:03:14\n",
      "Accuracy: 0.9790 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0040\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 13:03:22\n",
      "Accuracy: 0.9790 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0040\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 13:03:32\n",
      "Accuracy: 0.9791 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0040\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 13:03:40\n",
      "Accuracy: 0.9791 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0040\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 13:03:49\n",
      "Accuracy: 0.9791 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 13:03:58\n",
      "Accuracy: 0.9790 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 13:04:06\n",
      "Accuracy: 0.9790 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 13:04:16\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 13:04:25\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 13:04:35\n",
      "Accuracy: 0.9790 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 13:04:45\n",
      "Accuracy: 0.9790 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 13:04:54\n",
      "Accuracy: 0.9791 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 13:05:04\n",
      "Accuracy: 0.9790 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 13:05:13\n",
      "Accuracy: 0.9790 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 13:05:22\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 13:05:33\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 13:05:43\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 13:05:51\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 13:06:01\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 13:06:11\n",
      "Accuracy: 0.9788 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 13:06:20\n",
      "Accuracy: 0.9788 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 13:06:29\n",
      "Accuracy: 0.9788 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 13:06:39\n",
      "Accuracy: 0.9788 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 13:06:48\n",
      "Accuracy: 0.9788 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 13:06:57\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 13:07:05\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 13:07:13\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 13:07:22\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 13:07:31\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 13:07:39\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 13:07:48\n",
      "Accuracy: 0.9788 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 13:07:57\n",
      "Accuracy: 0.9788 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 13:08:06\n",
      "Accuracy: 0.9788 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 13:08:15\n",
      "Accuracy: 0.9788 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 13:08:24\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 13:08:33\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 13:08:43\n",
      "Accuracy: 0.9789 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 13:08:52\n",
      "Accuracy: 0.9789 - Precision: 0.0103 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 13:09:01\n",
      "Accuracy: 0.9789 - Precision: 0.0102 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 13:09:11\n",
      "Accuracy: 0.9789 - Precision: 0.0101 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0037\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 13:09:20\n",
      "Accuracy: 0.9790 - Precision: 0.0100 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0037\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 13:09:30\n",
      "Accuracy: 0.9791 - Precision: 0.0099 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0037\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 13:09:40\n",
      "Accuracy: 0.9791 - Precision: 0.0196 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0037\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 13:09:54\n",
      "Accuracy: 0.9792 - Precision: 0.0194 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0037\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 13:10:08\n",
      "Accuracy: 0.9791 - Precision: 0.0288 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0037\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 13:10:19\n",
      "Accuracy: 0.9792 - Precision: 0.0381 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0037\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 13:10:27\n",
      "Accuracy: 0.9792 - Precision: 0.0377 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0037\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 13:10:36\n",
      "Accuracy: 0.9792 - Precision: 0.0374 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0037\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 13:10:46\n",
      "Accuracy: 0.9793 - Precision: 0.0370 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0037\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 13:10:55\n",
      "Accuracy: 0.9793 - Precision: 0.0459 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0037\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 13:11:04\n",
      "Accuracy: 0.9793 - Precision: 0.0455 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0036\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 13:11:13\n",
      "Accuracy: 0.9794 - Precision: 0.0541 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0036\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 13:11:22\n",
      "Accuracy: 0.9794 - Precision: 0.0625 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0036\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 13:11:31\n",
      "Accuracy: 0.9794 - Precision: 0.0708 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0036\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 13:11:40\n",
      "Accuracy: 0.9794 - Precision: 0.0789 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0036\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 13:11:49\n",
      "Accuracy: 0.9794 - Precision: 0.0870 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0036\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 13:11:58\n",
      "Accuracy: 0.9795 - Precision: 0.0948 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0036\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 13:12:07\n",
      "Accuracy: 0.9794 - Precision: 0.1026 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0036\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 13:12:16\n",
      "Accuracy: 0.9794 - Precision: 0.1102 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0036\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 13:12:25\n",
      "Accuracy: 0.9794 - Precision: 0.1176 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0036\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 13:12:34\n",
      "Accuracy: 0.9795 - Precision: 0.1187 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0036\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 13:12:44\n",
      "Accuracy: 0.9795 - Precision: 0.1205 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0036\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 13:12:55\n",
      "Accuracy: 0.9795 - Precision: 0.1277 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0036\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 13:13:04\n",
      "Accuracy: 0.9794 - Precision: 0.1348 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0036\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 13:13:14\n",
      "Accuracy: 0.9794 - Precision: 0.1418 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0036\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 13:13:24\n",
      "Accuracy: 0.9795 - Precision: 0.1467 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0036\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 13:13:33\n",
      "Accuracy: 0.9795 - Precision: 0.1534 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0036\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 13:13:44\n",
      "Accuracy: 0.9795 - Precision: 0.1575 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0036\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 13:13:54\n",
      "Accuracy: 0.9795 - Precision: 0.1634 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0035\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 13:14:03\n",
      "Accuracy: 0.9795 - Precision: 0.1698 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0035\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 13:14:13\n",
      "Accuracy: 0.9795 - Precision: 0.1759 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0035\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 13:14:23\n",
      "Accuracy: 0.9795 - Precision: 0.1822 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0035\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 13:14:34\n",
      "Accuracy: 0.9795 - Precision: 0.1879 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0035\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 13:14:45\n",
      "Accuracy: 0.9794 - Precision: 0.1940 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0035\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 13:14:55\n",
      "Accuracy: 0.9795 - Precision: 0.1993 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0035\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 13:15:06\n",
      "Accuracy: 0.9794 - Precision: 0.2050 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0003 - Loss: 0.0035\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 13:15:15\n",
      "Accuracy: 0.9795 - Precision: 0.2103 - Recall: 0.0002 - Specificity: 1.0000 - F1: 0.0003 - Loss: 0.0035\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 13:15:24\n",
      "Accuracy: 0.9795 - Precision: 0.2161 - Recall: 0.0002 - Specificity: 1.0000 - F1: 0.0004 - Loss: 0.0035\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 13:15:33\n",
      "Accuracy: 0.9795 - Precision: 0.2216 - Recall: 0.0002 - Specificity: 1.0000 - F1: 0.0005 - Loss: 0.0035\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 13:15:42\n",
      "Accuracy: 0.9794 - Precision: 0.2270 - Recall: 0.0003 - Specificity: 1.0000 - F1: 0.0005 - Loss: 0.0035\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 13:15:51\n",
      "Accuracy: 0.9795 - Precision: 0.2326 - Recall: 0.0003 - Specificity: 1.0000 - F1: 0.0006 - Loss: 0.0035\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 13:16:00\n",
      "Accuracy: 0.9795 - Precision: 0.2375 - Recall: 0.0004 - Specificity: 1.0000 - F1: 0.0007 - Loss: 0.0035\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 13:16:10\n",
      "Accuracy: 0.9794 - Precision: 0.2427 - Recall: 0.0004 - Specificity: 1.0000 - F1: 0.0008 - Loss: 0.0035\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 13:16:19\n",
      "Accuracy: 0.9795 - Precision: 0.2471 - Recall: 0.0005 - Specificity: 1.0000 - F1: 0.0010 - Loss: 0.0035\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 13:16:30\n",
      "Accuracy: 0.9795 - Precision: 0.2509 - Recall: 0.0006 - Specificity: 1.0000 - F1: 0.0011 - Loss: 0.0035\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 13:16:41\n",
      "Accuracy: 0.9794 - Precision: 0.2557 - Recall: 0.0006 - Specificity: 1.0000 - F1: 0.0013 - Loss: 0.0035\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 13:16:51\n",
      "Accuracy: 0.9795 - Precision: 0.2603 - Recall: 0.0007 - Specificity: 1.0000 - F1: 0.0015 - Loss: 0.0035\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 13:17:00\n",
      "Accuracy: 0.9794 - Precision: 0.2652 - Recall: 0.0008 - Specificity: 1.0000 - F1: 0.0017 - Loss: 0.0035\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 13:17:11\n",
      "Accuracy: 0.9795 - Precision: 0.2702 - Recall: 0.0010 - Specificity: 1.0000 - F1: 0.0019 - Loss: 0.0035\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 13:17:19\n",
      "Accuracy: 0.9795 - Precision: 0.2734 - Recall: 0.0011 - Specificity: 1.0000 - F1: 0.0021 - Loss: 0.0035\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 13:17:30\n",
      "Accuracy: 0.9795 - Precision: 0.2773 - Recall: 0.0012 - Specificity: 1.0000 - F1: 0.0023 - Loss: 0.0035\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 13:17:39\n",
      "Accuracy: 0.9795 - Precision: 0.2811 - Recall: 0.0013 - Specificity: 1.0000 - F1: 0.0025 - Loss: 0.0035\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 13:17:47\n",
      "Accuracy: 0.9795 - Precision: 0.2853 - Recall: 0.0015 - Specificity: 1.0000 - F1: 0.0030 - Loss: 0.0035\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 13:17:55\n",
      "Accuracy: 0.9795 - Precision: 0.2899 - Recall: 0.0017 - Specificity: 1.0000 - F1: 0.0033 - Loss: 0.0035\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 13:18:04\n",
      "Accuracy: 0.9795 - Precision: 0.2944 - Recall: 0.0019 - Specificity: 1.0000 - F1: 0.0037 - Loss: 0.0035\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 13:18:12\n",
      "Accuracy: 0.9795 - Precision: 0.2987 - Recall: 0.0021 - Specificity: 1.0000 - F1: 0.0042 - Loss: 0.0035\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 13:18:21\n",
      "Accuracy: 0.9795 - Precision: 0.3028 - Recall: 0.0024 - Specificity: 1.0000 - F1: 0.0046 - Loss: 0.0035\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 13:18:29\n",
      "Accuracy: 0.9794 - Precision: 0.3070 - Recall: 0.0027 - Specificity: 1.0000 - F1: 0.0052 - Loss: 0.0035\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 13:18:37\n",
      "Accuracy: 0.9795 - Precision: 0.3104 - Recall: 0.0031 - Specificity: 1.0000 - F1: 0.0060 - Loss: 0.0035\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 13:18:49\n",
      "Accuracy: 0.9795 - Precision: 0.3147 - Recall: 0.0035 - Specificity: 1.0000 - F1: 0.0067 - Loss: 0.0035\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 13:18:59\n",
      "Accuracy: 0.9795 - Precision: 0.3186 - Recall: 0.0040 - Specificity: 1.0000 - F1: 0.0076 - Loss: 0.0034\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 13:19:09\n",
      "Accuracy: 0.9795 - Precision: 0.3227 - Recall: 0.0046 - Specificity: 1.0000 - F1: 0.0087 - Loss: 0.0035\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 13:19:20\n",
      "Accuracy: 0.9795 - Precision: 0.3267 - Recall: 0.0054 - Specificity: 1.0000 - F1: 0.0101 - Loss: 0.0034\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 13:19:29\n",
      "Accuracy: 0.9796 - Precision: 0.3294 - Recall: 0.0063 - Specificity: 1.0000 - F1: 0.0116 - Loss: 0.0034\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 13:19:40\n",
      "Accuracy: 0.9796 - Precision: 0.3328 - Recall: 0.0071 - Specificity: 1.0000 - F1: 0.0131 - Loss: 0.0034\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 13:19:51\n",
      "Accuracy: 0.9796 - Precision: 0.3367 - Recall: 0.0082 - Specificity: 1.0000 - F1: 0.0148 - Loss: 0.0034\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 13:20:00\n",
      "Accuracy: 0.9797 - Precision: 0.3396 - Recall: 0.0092 - Specificity: 1.0000 - F1: 0.0165 - Loss: 0.0034\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 13:20:10\n",
      "Accuracy: 0.9797 - Precision: 0.3436 - Recall: 0.0101 - Specificity: 1.0000 - F1: 0.0181 - Loss: 0.0034\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 13:20:19\n",
      "Accuracy: 0.9797 - Precision: 0.3474 - Recall: 0.0113 - Specificity: 1.0000 - F1: 0.0200 - Loss: 0.0034\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 13:20:29\n",
      "Accuracy: 0.9797 - Precision: 0.3505 - Recall: 0.0131 - Specificity: 1.0000 - F1: 0.0226 - Loss: 0.0034\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 13:20:39\n",
      "Accuracy: 0.9798 - Precision: 0.3535 - Recall: 0.0157 - Specificity: 1.0000 - F1: 0.0260 - Loss: 0.0034\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 13:20:50\n",
      "Accuracy: 0.9798 - Precision: 0.3560 - Recall: 0.0183 - Specificity: 1.0000 - F1: 0.0292 - Loss: 0.0034\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 13:21:00\n",
      "Accuracy: 0.9798 - Precision: 0.3588 - Recall: 0.0202 - Specificity: 0.9999 - F1: 0.0319 - Loss: 0.0034\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 13:21:09\n",
      "Accuracy: 0.9799 - Precision: 0.3621 - Recall: 0.0224 - Specificity: 0.9999 - F1: 0.0349 - Loss: 0.0034\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 13:21:17\n",
      "Accuracy: 0.9799 - Precision: 0.3656 - Recall: 0.0247 - Specificity: 0.9999 - F1: 0.0382 - Loss: 0.0034\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 13:21:26\n",
      "Accuracy: 0.9800 - Precision: 0.3684 - Recall: 0.0267 - Specificity: 0.9999 - F1: 0.0409 - Loss: 0.0034\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 13:21:36\n",
      "Accuracy: 0.9800 - Precision: 0.3718 - Recall: 0.0293 - Specificity: 0.9999 - F1: 0.0443 - Loss: 0.0034\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 13:21:44\n",
      "Accuracy: 0.9801 - Precision: 0.3749 - Recall: 0.0322 - Specificity: 0.9999 - F1: 0.0479 - Loss: 0.0034\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 13:21:52\n",
      "Accuracy: 0.9801 - Precision: 0.3776 - Recall: 0.0351 - Specificity: 0.9999 - F1: 0.0515 - Loss: 0.0034\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 13:22:00\n",
      "Accuracy: 0.9802 - Precision: 0.3798 - Recall: 0.0381 - Specificity: 0.9999 - F1: 0.0548 - Loss: 0.0034\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 13:22:08\n",
      "Accuracy: 0.9802 - Precision: 0.3830 - Recall: 0.0404 - Specificity: 0.9999 - F1: 0.0579 - Loss: 0.0034\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 13:22:18\n",
      "Accuracy: 0.9803 - Precision: 0.3861 - Recall: 0.0427 - Specificity: 0.9999 - F1: 0.0610 - Loss: 0.0034\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 13:22:27\n",
      "Accuracy: 0.9803 - Precision: 0.3893 - Recall: 0.0452 - Specificity: 0.9999 - F1: 0.0642 - Loss: 0.0034\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 13:22:35\n",
      "Accuracy: 0.9804 - Precision: 0.3918 - Recall: 0.0481 - Specificity: 0.9999 - F1: 0.0677 - Loss: 0.0034\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 13:22:44\n",
      "Accuracy: 0.9804 - Precision: 0.3942 - Recall: 0.0513 - Specificity: 0.9999 - F1: 0.0712 - Loss: 0.0034\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 13:22:54\n",
      "Accuracy: 0.9805 - Precision: 0.3965 - Recall: 0.0549 - Specificity: 0.9999 - F1: 0.0749 - Loss: 0.0034\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 13:23:03\n",
      "Accuracy: 0.9805 - Precision: 0.3989 - Recall: 0.0576 - Specificity: 0.9998 - F1: 0.0782 - Loss: 0.0034\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 13:23:11\n",
      "Accuracy: 0.9806 - Precision: 0.4018 - Recall: 0.0598 - Specificity: 0.9998 - F1: 0.0811 - Loss: 0.0034\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 13:23:20\n",
      "Accuracy: 0.9806 - Precision: 0.4046 - Recall: 0.0615 - Specificity: 0.9998 - F1: 0.0835 - Loss: 0.0034\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 13:23:27\n",
      "Accuracy: 0.9806 - Precision: 0.4072 - Recall: 0.0633 - Specificity: 0.9998 - F1: 0.0860 - Loss: 0.0034\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 13:23:36\n",
      "Accuracy: 0.9807 - Precision: 0.4101 - Recall: 0.0653 - Specificity: 0.9998 - F1: 0.0888 - Loss: 0.0034\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 13:23:44\n",
      "Accuracy: 0.9807 - Precision: 0.4130 - Recall: 0.0677 - Specificity: 0.9998 - F1: 0.0918 - Loss: 0.0034\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 13:23:53\n",
      "Accuracy: 0.9807 - Precision: 0.4155 - Recall: 0.0704 - Specificity: 0.9998 - F1: 0.0951 - Loss: 0.0034\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 13:24:01\n",
      "Accuracy: 0.9808 - Precision: 0.4167 - Recall: 0.0732 - Specificity: 0.9998 - F1: 0.0979 - Loss: 0.0034\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 13:24:10\n",
      "Accuracy: 0.9808 - Precision: 0.4194 - Recall: 0.0758 - Specificity: 0.9998 - F1: 0.1010 - Loss: 0.0034\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 13:24:18\n",
      "Accuracy: 0.9809 - Precision: 0.4220 - Recall: 0.0776 - Specificity: 0.9998 - F1: 0.1035 - Loss: 0.0034\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 13:24:26\n",
      "Accuracy: 0.9809 - Precision: 0.4247 - Recall: 0.0798 - Specificity: 0.9998 - F1: 0.1063 - Loss: 0.0034\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 13:24:35\n",
      "Accuracy: 0.9810 - Precision: 0.4266 - Recall: 0.0819 - Specificity: 0.9998 - F1: 0.1089 - Loss: 0.0034\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 13:24:43\n",
      "Accuracy: 0.9810 - Precision: 0.4287 - Recall: 0.0840 - Specificity: 0.9998 - F1: 0.1115 - Loss: 0.0034\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 13:24:53\n",
      "Accuracy: 0.9810 - Precision: 0.4311 - Recall: 0.0863 - Specificity: 0.9998 - F1: 0.1143 - Loss: 0.0033\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 13:25:02\n",
      "Accuracy: 0.9811 - Precision: 0.4336 - Recall: 0.0889 - Specificity: 0.9998 - F1: 0.1175 - Loss: 0.0033\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 13:25:10\n",
      "Accuracy: 0.9811 - Precision: 0.4360 - Recall: 0.0916 - Specificity: 0.9998 - F1: 0.1206 - Loss: 0.0033\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 13:25:20\n",
      "Accuracy: 0.9812 - Precision: 0.4384 - Recall: 0.0944 - Specificity: 0.9998 - F1: 0.1238 - Loss: 0.0033\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 13:25:28\n",
      "Accuracy: 0.9812 - Precision: 0.4410 - Recall: 0.0966 - Specificity: 0.9998 - F1: 0.1266 - Loss: 0.0033\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 13:25:37\n",
      "Accuracy: 0.9813 - Precision: 0.4428 - Recall: 0.0986 - Specificity: 0.9998 - F1: 0.1290 - Loss: 0.0033\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 13:25:45\n",
      "Accuracy: 0.9813 - Precision: 0.4452 - Recall: 0.1005 - Specificity: 0.9997 - F1: 0.1315 - Loss: 0.0033\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 13:25:54\n",
      "Accuracy: 0.9814 - Precision: 0.4477 - Recall: 0.1025 - Specificity: 0.9997 - F1: 0.1342 - Loss: 0.0033\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 13:26:02\n",
      "Accuracy: 0.9814 - Precision: 0.4493 - Recall: 0.1049 - Specificity: 0.9997 - F1: 0.1367 - Loss: 0.0033\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 13:26:10\n",
      "Accuracy: 0.9815 - Precision: 0.4513 - Recall: 0.1073 - Specificity: 0.9997 - F1: 0.1395 - Loss: 0.0033\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 13:26:19\n",
      "Accuracy: 0.9815 - Precision: 0.4535 - Recall: 0.1099 - Specificity: 0.9997 - F1: 0.1425 - Loss: 0.0033\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 13:26:28\n",
      "Accuracy: 0.9816 - Precision: 0.4551 - Recall: 0.1127 - Specificity: 0.9997 - F1: 0.1453 - Loss: 0.0033\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 13:26:37\n",
      "Accuracy: 0.9816 - Precision: 0.4573 - Recall: 0.1151 - Specificity: 0.9997 - F1: 0.1481 - Loss: 0.0033\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 13:26:46\n",
      "Accuracy: 0.9817 - Precision: 0.4594 - Recall: 0.1168 - Specificity: 0.9997 - F1: 0.1504 - Loss: 0.0033\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 13:26:56\n",
      "Accuracy: 0.9817 - Precision: 0.4613 - Recall: 0.1176 - Specificity: 0.9997 - F1: 0.1517 - Loss: 0.0033\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 13:27:05\n",
      "Accuracy: 0.9817 - Precision: 0.4635 - Recall: 0.1181 - Specificity: 0.9997 - F1: 0.1526 - Loss: 0.0033\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 13:27:13\n",
      "Accuracy: 0.9816 - Precision: 0.4648 - Recall: 0.1182 - Specificity: 0.9997 - F1: 0.1530 - Loss: 0.0033\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 13:27:22\n",
      "Accuracy: 0.9816 - Precision: 0.4666 - Recall: 0.1181 - Specificity: 0.9997 - F1: 0.1532 - Loss: 0.0033\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 13:27:30\n",
      "Accuracy: 0.9816 - Precision: 0.4689 - Recall: 0.1182 - Specificity: 0.9997 - F1: 0.1535 - Loss: 0.0033\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 13:27:40\n",
      "Accuracy: 0.9816 - Precision: 0.4711 - Recall: 0.1185 - Specificity: 0.9997 - F1: 0.1542 - Loss: 0.0033\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 13:27:50\n",
      "Accuracy: 0.9816 - Precision: 0.4733 - Recall: 0.1187 - Specificity: 0.9997 - F1: 0.1548 - Loss: 0.0033\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 13:28:00\n",
      "Accuracy: 0.9815 - Precision: 0.4745 - Recall: 0.1187 - Specificity: 0.9997 - F1: 0.1551 - Loss: 0.0034\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 13:28:08\n",
      "Accuracy: 0.9815 - Precision: 0.4768 - Recall: 0.1194 - Specificity: 0.9997 - F1: 0.1563 - Loss: 0.0034\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 13:28:17\n",
      "Accuracy: 0.9815 - Precision: 0.4782 - Recall: 0.1199 - Specificity: 0.9997 - F1: 0.1572 - Loss: 0.0034\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 13:28:26\n",
      "Accuracy: 0.9815 - Precision: 0.4798 - Recall: 0.1208 - Specificity: 0.9997 - F1: 0.1586 - Loss: 0.0034\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 13:28:34\n",
      "Accuracy: 0.9816 - Precision: 0.4813 - Recall: 0.1224 - Specificity: 0.9997 - F1: 0.1606 - Loss: 0.0034\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 13:28:42\n",
      "Accuracy: 0.9816 - Precision: 0.4834 - Recall: 0.1231 - Specificity: 0.9997 - F1: 0.1618 - Loss: 0.0034\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 13:28:53\n",
      "Accuracy: 0.9815 - Precision: 0.4854 - Recall: 0.1232 - Specificity: 0.9997 - F1: 0.1622 - Loss: 0.0034\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 13:29:02\n",
      "Accuracy: 0.9816 - Precision: 0.4873 - Recall: 0.1241 - Specificity: 0.9997 - F1: 0.1636 - Loss: 0.0034\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 13:29:10\n",
      "Accuracy: 0.9816 - Precision: 0.4889 - Recall: 0.1258 - Specificity: 0.9997 - F1: 0.1657 - Loss: 0.0034\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 13:29:19\n",
      "Accuracy: 0.9816 - Precision: 0.4898 - Recall: 0.1264 - Specificity: 0.9997 - F1: 0.1667 - Loss: 0.0034\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 13:29:27\n",
      "Accuracy: 0.9816 - Precision: 0.4915 - Recall: 0.1274 - Specificity: 0.9997 - F1: 0.1681 - Loss: 0.0034\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 13:29:36\n",
      "Accuracy: 0.9816 - Precision: 0.4932 - Recall: 0.1283 - Specificity: 0.9997 - F1: 0.1696 - Loss: 0.0034\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 13:29:44\n",
      "Accuracy: 0.9816 - Precision: 0.4952 - Recall: 0.1285 - Specificity: 0.9997 - F1: 0.1700 - Loss: 0.0034\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 13:29:53\n",
      "Accuracy: 0.9816 - Precision: 0.4972 - Recall: 0.1283 - Specificity: 0.9997 - F1: 0.1700 - Loss: 0.0034\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 13:30:01\n",
      "Accuracy: 0.9815 - Precision: 0.4993 - Recall: 0.1286 - Specificity: 0.9997 - F1: 0.1707 - Loss: 0.0035\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 13:30:10\n",
      "Accuracy: 0.9815 - Precision: 0.5010 - Recall: 0.1289 - Specificity: 0.9997 - F1: 0.1714 - Loss: 0.0035\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 13:30:19\n",
      "Accuracy: 0.9815 - Precision: 0.5024 - Recall: 0.1300 - Specificity: 0.9996 - F1: 0.1728 - Loss: 0.0035\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 13:30:29\n",
      "Accuracy: 0.9814 - Precision: 0.5041 - Recall: 0.1308 - Specificity: 0.9996 - F1: 0.1742 - Loss: 0.0035\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 13:30:41\n",
      "Accuracy: 0.9814 - Precision: 0.5060 - Recall: 0.1315 - Specificity: 0.9996 - F1: 0.1753 - Loss: 0.0035\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 13:30:58\n",
      "Accuracy: 0.9814 - Precision: 0.5077 - Recall: 0.1323 - Specificity: 0.9996 - F1: 0.1766 - Loss: 0.0035\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 13:31:09\n",
      "Accuracy: 0.9811 - Precision: 0.5069 - Recall: 0.1318 - Specificity: 0.9996 - F1: 0.1759 - Loss: 0.0038\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 13:31:17\n",
      "Accuracy: 0.9810 - Precision: 0.5072 - Recall: 0.1316 - Specificity: 0.9996 - F1: 0.1757 - Loss: 0.0038\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 13:31:25\n",
      "Accuracy: 0.9806 - Precision: 0.5083 - Recall: 0.1312 - Specificity: 0.9996 - F1: 0.1754 - Loss: 0.0040\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 13:31:34\n",
      "Accuracy: 0.9803 - Precision: 0.5099 - Recall: 0.1308 - Specificity: 0.9996 - F1: 0.1749 - Loss: 0.0041\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 13:31:42\n",
      "Accuracy: 0.9801 - Precision: 0.5098 - Recall: 0.1303 - Specificity: 0.9996 - F1: 0.1742 - Loss: 0.0041\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 13:31:50\n",
      "Accuracy: 0.9799 - Precision: 0.5113 - Recall: 0.1298 - Specificity: 0.9996 - F1: 0.1735 - Loss: 0.0042\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 13:31:58\n",
      "Accuracy: 0.9796 - Precision: 0.5093 - Recall: 0.1292 - Specificity: 0.9996 - F1: 0.1728 - Loss: 0.0043\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 13:32:06\n",
      "Accuracy: 0.9794 - Precision: 0.5072 - Recall: 0.1287 - Specificity: 0.9996 - F1: 0.1721 - Loss: 0.0044\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 13:32:14\n",
      "Accuracy: 0.9791 - Precision: 0.5052 - Recall: 0.1282 - Specificity: 0.9996 - F1: 0.1714 - Loss: 0.0044\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 13:32:22\n",
      "Accuracy: 0.9788 - Precision: 0.5054 - Recall: 0.1277 - Specificity: 0.9996 - F1: 0.1708 - Loss: 0.0045\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 13:32:31\n",
      "Accuracy: 0.9785 - Precision: 0.5067 - Recall: 0.1272 - Specificity: 0.9996 - F1: 0.1701 - Loss: 0.0046\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 13:32:39\n",
      "Accuracy: 0.9784 - Precision: 0.5047 - Recall: 0.1267 - Specificity: 0.9996 - F1: 0.1695 - Loss: 0.0046\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 13:32:47\n",
      "Accuracy: 0.9782 - Precision: 0.5027 - Recall: 0.1262 - Specificity: 0.9996 - F1: 0.1688 - Loss: 0.0047\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 13:32:57\n",
      "Accuracy: 0.9780 - Precision: 0.5007 - Recall: 0.1257 - Specificity: 0.9996 - F1: 0.1681 - Loss: 0.0047\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 13:33:05\n",
      "Accuracy: 0.9778 - Precision: 0.4987 - Recall: 0.1252 - Specificity: 0.9996 - F1: 0.1674 - Loss: 0.0048\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 13:33:13\n",
      "Accuracy: 0.9774 - Precision: 0.4975 - Recall: 0.1247 - Specificity: 0.9996 - F1: 0.1668 - Loss: 0.0049\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 13:33:22\n",
      "Accuracy: 0.9772 - Precision: 0.4978 - Recall: 0.1243 - Specificity: 0.9996 - F1: 0.1662 - Loss: 0.0049\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 13:33:30\n",
      "Accuracy: 0.9771 - Precision: 0.4972 - Recall: 0.1238 - Specificity: 0.9996 - F1: 0.1656 - Loss: 0.0050\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 13:33:38\n",
      "Accuracy: 0.9770 - Precision: 0.4953 - Recall: 0.1233 - Specificity: 0.9996 - F1: 0.1649 - Loss: 0.0050\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 13:33:46\n",
      "Accuracy: 0.9770 - Precision: 0.4934 - Recall: 0.1228 - Specificity: 0.9996 - F1: 0.1643 - Loss: 0.0050\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 13:33:55\n",
      "Accuracy: 0.9770 - Precision: 0.4915 - Recall: 0.1224 - Specificity: 0.9996 - F1: 0.1636 - Loss: 0.0050\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 13:34:03\n",
      "Accuracy: 0.9770 - Precision: 0.4896 - Recall: 0.1219 - Specificity: 0.9996 - F1: 0.1630 - Loss: 0.0051\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 13:34:11\n",
      "Accuracy: 0.9769 - Precision: 0.4878 - Recall: 0.1214 - Specificity: 0.9996 - F1: 0.1624 - Loss: 0.0051\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 13:34:20\n",
      "Accuracy: 0.9769 - Precision: 0.4859 - Recall: 0.1210 - Specificity: 0.9996 - F1: 0.1618 - Loss: 0.0052\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 13:34:28\n",
      "Accuracy: 0.9768 - Precision: 0.4841 - Recall: 0.1205 - Specificity: 0.9996 - F1: 0.1612 - Loss: 0.0052\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 13:34:36\n",
      "Accuracy: 0.9768 - Precision: 0.4822 - Recall: 0.1200 - Specificity: 0.9996 - F1: 0.1606 - Loss: 0.0052\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 13:34:45\n",
      "Accuracy: 0.9768 - Precision: 0.4804 - Recall: 0.1196 - Specificity: 0.9996 - F1: 0.1600 - Loss: 0.0053\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 13:34:57\n",
      "Accuracy: 0.9768 - Precision: 0.4786 - Recall: 0.1191 - Specificity: 0.9996 - F1: 0.1594 - Loss: 0.0053\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 13:35:06\n",
      "Accuracy: 0.9767 - Precision: 0.4768 - Recall: 0.1187 - Specificity: 0.9996 - F1: 0.1588 - Loss: 0.0053\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 13:35:18\n",
      "Accuracy: 0.9768 - Precision: 0.4751 - Recall: 0.1183 - Specificity: 0.9996 - F1: 0.1582 - Loss: 0.0053\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 13:35:27\n",
      "Accuracy: 0.9768 - Precision: 0.4733 - Recall: 0.1178 - Specificity: 0.9996 - F1: 0.1576 - Loss: 0.0053\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 13:35:37\n",
      "Accuracy: 0.9768 - Precision: 0.4716 - Recall: 0.1174 - Specificity: 0.9996 - F1: 0.1570 - Loss: 0.0053\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 13:35:47\n",
      "Accuracy: 0.9767 - Precision: 0.4698 - Recall: 0.1170 - Specificity: 0.9996 - F1: 0.1564 - Loss: 0.0054\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 13:35:57\n",
      "Accuracy: 0.9767 - Precision: 0.4681 - Recall: 0.1165 - Specificity: 0.9997 - F1: 0.1559 - Loss: 0.0054\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 13:36:07\n",
      "Accuracy: 0.9767 - Precision: 0.4664 - Recall: 0.1161 - Specificity: 0.9997 - F1: 0.1553 - Loss: 0.0054\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 13:36:17\n",
      "Accuracy: 0.9767 - Precision: 0.4647 - Recall: 0.1157 - Specificity: 0.9997 - F1: 0.1547 - Loss: 0.0054\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 13:36:26\n",
      "Accuracy: 0.9767 - Precision: 0.4630 - Recall: 0.1153 - Specificity: 0.9997 - F1: 0.1542 - Loss: 0.0054\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 13:36:34\n",
      "Accuracy: 0.9767 - Precision: 0.4613 - Recall: 0.1148 - Specificity: 0.9997 - F1: 0.1536 - Loss: 0.0054\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 13:36:42\n",
      "Accuracy: 0.9767 - Precision: 0.4597 - Recall: 0.1144 - Specificity: 0.9997 - F1: 0.1530 - Loss: 0.0054\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 13:36:51\n",
      "Accuracy: 0.9767 - Precision: 0.4580 - Recall: 0.1140 - Specificity: 0.9997 - F1: 0.1525 - Loss: 0.0054\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 13:37:01\n",
      "Accuracy: 0.9767 - Precision: 0.4564 - Recall: 0.1136 - Specificity: 0.9997 - F1: 0.1520 - Loss: 0.0054\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 13:37:10\n",
      "Accuracy: 0.9767 - Precision: 0.4548 - Recall: 0.1132 - Specificity: 0.9997 - F1: 0.1514 - Loss: 0.0054\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 13:37:19\n",
      "Accuracy: 0.9767 - Precision: 0.4532 - Recall: 0.1128 - Specificity: 0.9997 - F1: 0.1509 - Loss: 0.0055\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 13:37:27\n",
      "Accuracy: 0.9767 - Precision: 0.4516 - Recall: 0.1124 - Specificity: 0.9997 - F1: 0.1503 - Loss: 0.0055\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 13:37:35\n",
      "Accuracy: 0.9767 - Precision: 0.4500 - Recall: 0.1120 - Specificity: 0.9997 - F1: 0.1498 - Loss: 0.0055\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 13:37:43\n",
      "Accuracy: 0.9768 - Precision: 0.4484 - Recall: 0.1116 - Specificity: 0.9997 - F1: 0.1493 - Loss: 0.0055\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 13:37:51\n",
      "Accuracy: 0.9768 - Precision: 0.4468 - Recall: 0.1112 - Specificity: 0.9997 - F1: 0.1488 - Loss: 0.0055\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 13:38:00\n",
      "Accuracy: 0.9767 - Precision: 0.4453 - Recall: 0.1108 - Specificity: 0.9997 - F1: 0.1483 - Loss: 0.0055\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 13:38:08\n",
      "Accuracy: 0.9767 - Precision: 0.4437 - Recall: 0.1105 - Specificity: 0.9997 - F1: 0.1477 - Loss: 0.0055\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 13:38:18\n",
      "Accuracy: 0.9767 - Precision: 0.4422 - Recall: 0.1101 - Specificity: 0.9997 - F1: 0.1472 - Loss: 0.0055\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 13:38:31\n",
      "Accuracy: 0.9767 - Precision: 0.4407 - Recall: 0.1097 - Specificity: 0.9997 - F1: 0.1467 - Loss: 0.0055\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 13:38:41\n",
      "Accuracy: 0.9767 - Precision: 0.4391 - Recall: 0.1093 - Specificity: 0.9997 - F1: 0.1462 - Loss: 0.0055\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 13:38:49\n",
      "Accuracy: 0.9767 - Precision: 0.4376 - Recall: 0.1089 - Specificity: 0.9997 - F1: 0.1457 - Loss: 0.0055\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 13:39:01\n",
      "Accuracy: 0.9767 - Precision: 0.4362 - Recall: 0.1086 - Specificity: 0.9997 - F1: 0.1452 - Loss: 0.0055\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 13:39:10\n",
      "Accuracy: 0.9766 - Precision: 0.4347 - Recall: 0.1082 - Specificity: 0.9997 - F1: 0.1447 - Loss: 0.0055\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 13:39:20\n",
      "Accuracy: 0.9766 - Precision: 0.4332 - Recall: 0.1078 - Specificity: 0.9997 - F1: 0.1442 - Loss: 0.0055\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 13:39:28\n",
      "Accuracy: 0.9766 - Precision: 0.4317 - Recall: 0.1075 - Specificity: 0.9997 - F1: 0.1437 - Loss: 0.0055\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 13:39:36\n",
      "Accuracy: 0.9766 - Precision: 0.4303 - Recall: 0.1071 - Specificity: 0.9997 - F1: 0.1433 - Loss: 0.0055\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 13:39:44\n",
      "Accuracy: 0.9766 - Precision: 0.4288 - Recall: 0.1068 - Specificity: 0.9997 - F1: 0.1428 - Loss: 0.0055\n",
      "\n",
      "Epoch 3/20\n",
      "Validation - Accuracy: 0.9786, Precision: 0.0000, Recall: 0.0000, Specificity: 1.0000, F1: 0.0000, Loss: 0.0060\n",
      "\n",
      "\n",
      "Epoch 4/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 13:47:55\n",
      "Accuracy: 0.9738 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0065\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 13:48:03\n",
      "Accuracy: 0.9722 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0068\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 13:48:12\n",
      "Accuracy: 0.9711 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0067\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 13:48:20\n",
      "Accuracy: 0.9742 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0062\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 13:48:28\n",
      "Accuracy: 0.9762 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0060\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 13:48:36\n",
      "Accuracy: 0.9762 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0059\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 13:48:45\n",
      "Accuracy: 0.9775 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0055\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 13:48:53\n",
      "Accuracy: 0.9781 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0053\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 13:49:03\n",
      "Accuracy: 0.9788 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0051\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 13:49:12\n",
      "Accuracy: 0.9792 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0049\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 13:49:20\n",
      "Accuracy: 0.9795 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0048\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 13:49:28\n",
      "Accuracy: 0.9797 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0047\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 13:49:37\n",
      "Accuracy: 0.9798 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0046\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 13:49:45\n",
      "Accuracy: 0.9800 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0046\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 13:49:53\n",
      "Accuracy: 0.9802 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0045\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 13:50:02\n",
      "Accuracy: 0.9797 - Precision: 0.0625 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0046\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 13:50:10\n",
      "Accuracy: 0.9800 - Precision: 0.0588 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0045\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 13:50:18\n",
      "Accuracy: 0.9799 - Precision: 0.1111 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 13:50:27\n",
      "Accuracy: 0.9799 - Precision: 0.1579 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 13:50:35\n",
      "Accuracy: 0.9801 - Precision: 0.2000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0043\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 13:50:44\n",
      "Accuracy: 0.9801 - Precision: 0.1905 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0043\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 13:50:52\n",
      "Accuracy: 0.9799 - Precision: 0.2239 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0044\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 13:51:03\n",
      "Accuracy: 0.9798 - Precision: 0.2576 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0044\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 13:51:11\n",
      "Accuracy: 0.9796 - Precision: 0.2832 - Recall: 0.0003 - Specificity: 1.0000 - F1: 0.0005 - Loss: 0.0044\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 13:51:20\n",
      "Accuracy: 0.9796 - Precision: 0.3095 - Recall: 0.0010 - Specificity: 1.0000 - F1: 0.0019 - Loss: 0.0044\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 13:51:28\n",
      "Accuracy: 0.9798 - Precision: 0.3349 - Recall: 0.0014 - Specificity: 1.0000 - F1: 0.0027 - Loss: 0.0043\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 13:51:37\n",
      "Accuracy: 0.9798 - Precision: 0.3595 - Recall: 0.0014 - Specificity: 1.0000 - F1: 0.0027 - Loss: 0.0043\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 13:51:45\n",
      "Accuracy: 0.9797 - Precision: 0.3824 - Recall: 0.0014 - Specificity: 1.0000 - F1: 0.0027 - Loss: 0.0043\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 13:51:53\n",
      "Accuracy: 0.9795 - Precision: 0.4001 - Recall: 0.0014 - Specificity: 1.0000 - F1: 0.0028 - Loss: 0.0043\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 13:52:02\n",
      "Accuracy: 0.9794 - Precision: 0.4189 - Recall: 0.0015 - Specificity: 1.0000 - F1: 0.0030 - Loss: 0.0043\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 13:52:10\n",
      "Accuracy: 0.9795 - Precision: 0.4376 - Recall: 0.0021 - Specificity: 1.0000 - F1: 0.0042 - Loss: 0.0043\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 13:52:18\n",
      "Accuracy: 0.9795 - Precision: 0.4545 - Recall: 0.0028 - Specificity: 1.0000 - F1: 0.0055 - Loss: 0.0043\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 13:52:26\n",
      "Accuracy: 0.9795 - Precision: 0.4707 - Recall: 0.0037 - Specificity: 1.0000 - F1: 0.0073 - Loss: 0.0043\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 13:52:35\n",
      "Accuracy: 0.9794 - Precision: 0.4861 - Recall: 0.0050 - Specificity: 1.0000 - F1: 0.0098 - Loss: 0.0043\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 13:52:43\n",
      "Accuracy: 0.9794 - Precision: 0.4998 - Recall: 0.0063 - Specificity: 1.0000 - F1: 0.0121 - Loss: 0.0043\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 13:52:51\n",
      "Accuracy: 0.9795 - Precision: 0.5133 - Recall: 0.0103 - Specificity: 1.0000 - F1: 0.0191 - Loss: 0.0042\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 13:53:01\n",
      "Accuracy: 0.9796 - Precision: 0.5260 - Recall: 0.0169 - Specificity: 1.0000 - F1: 0.0295 - Loss: 0.0042\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 13:53:11\n",
      "Accuracy: 0.9797 - Precision: 0.5356 - Recall: 0.0252 - Specificity: 1.0000 - F1: 0.0415 - Loss: 0.0042\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 13:53:20\n",
      "Accuracy: 0.9799 - Precision: 0.5437 - Recall: 0.0365 - Specificity: 0.9999 - F1: 0.0559 - Loss: 0.0041\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 13:53:28\n",
      "Accuracy: 0.9801 - Precision: 0.5525 - Recall: 0.0495 - Specificity: 0.9999 - F1: 0.0716 - Loss: 0.0041\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 13:53:37\n",
      "Accuracy: 0.9801 - Precision: 0.5597 - Recall: 0.0579 - Specificity: 0.9998 - F1: 0.0830 - Loss: 0.0042\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 13:53:45\n",
      "Accuracy: 0.9803 - Precision: 0.5693 - Recall: 0.0665 - Specificity: 0.9998 - F1: 0.0949 - Loss: 0.0041\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 13:53:53\n",
      "Accuracy: 0.9804 - Precision: 0.5782 - Recall: 0.0746 - Specificity: 0.9998 - F1: 0.1062 - Loss: 0.0041\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 13:54:02\n",
      "Accuracy: 0.9806 - Precision: 0.5868 - Recall: 0.0838 - Specificity: 0.9998 - F1: 0.1183 - Loss: 0.0041\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 13:54:10\n",
      "Accuracy: 0.9808 - Precision: 0.5893 - Recall: 0.0936 - Specificity: 0.9997 - F1: 0.1289 - Loss: 0.0041\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 13:54:18\n",
      "Accuracy: 0.9809 - Precision: 0.5977 - Recall: 0.0986 - Specificity: 0.9997 - F1: 0.1367 - Loss: 0.0040\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 13:54:27\n",
      "Accuracy: 0.9809 - Precision: 0.6052 - Recall: 0.1017 - Specificity: 0.9997 - F1: 0.1421 - Loss: 0.0040\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 13:54:35\n",
      "Accuracy: 0.9809 - Precision: 0.6132 - Recall: 0.1051 - Specificity: 0.9998 - F1: 0.1479 - Loss: 0.0040\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 13:54:44\n",
      "Accuracy: 0.9811 - Precision: 0.6195 - Recall: 0.1114 - Specificity: 0.9997 - F1: 0.1565 - Loss: 0.0040\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 13:54:52\n",
      "Accuracy: 0.9811 - Precision: 0.6266 - Recall: 0.1182 - Specificity: 0.9997 - F1: 0.1657 - Loss: 0.0040\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 13:55:02\n",
      "Accuracy: 0.9813 - Precision: 0.6324 - Recall: 0.1257 - Specificity: 0.9997 - F1: 0.1752 - Loss: 0.0040\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 13:55:11\n",
      "Accuracy: 0.9814 - Precision: 0.6369 - Recall: 0.1327 - Specificity: 0.9997 - F1: 0.1838 - Loss: 0.0040\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 13:55:20\n",
      "Accuracy: 0.9816 - Precision: 0.6424 - Recall: 0.1396 - Specificity: 0.9997 - F1: 0.1926 - Loss: 0.0039\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 13:55:28\n",
      "Accuracy: 0.9817 - Precision: 0.6480 - Recall: 0.1465 - Specificity: 0.9997 - F1: 0.2013 - Loss: 0.0039\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 13:55:37\n",
      "Accuracy: 0.9818 - Precision: 0.6527 - Recall: 0.1527 - Specificity: 0.9997 - F1: 0.2092 - Loss: 0.0039\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 13:55:46\n",
      "Accuracy: 0.9820 - Precision: 0.6568 - Recall: 0.1615 - Specificity: 0.9997 - F1: 0.2188 - Loss: 0.0039\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 13:55:55\n",
      "Accuracy: 0.9822 - Precision: 0.6601 - Recall: 0.1689 - Specificity: 0.9996 - F1: 0.2271 - Loss: 0.0038\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 13:56:05\n",
      "Accuracy: 0.9823 - Precision: 0.6648 - Recall: 0.1749 - Specificity: 0.9996 - F1: 0.2346 - Loss: 0.0038\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 13:56:14\n",
      "Accuracy: 0.9824 - Precision: 0.6700 - Recall: 0.1796 - Specificity: 0.9996 - F1: 0.2411 - Loss: 0.0038\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 13:56:24\n",
      "Accuracy: 0.9825 - Precision: 0.6728 - Recall: 0.1830 - Specificity: 0.9996 - F1: 0.2458 - Loss: 0.0038\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 13:56:33\n",
      "Accuracy: 0.9825 - Precision: 0.6757 - Recall: 0.1875 - Specificity: 0.9996 - F1: 0.2515 - Loss: 0.0038\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 13:56:42\n",
      "Accuracy: 0.9827 - Precision: 0.6799 - Recall: 0.1930 - Specificity: 0.9996 - F1: 0.2584 - Loss: 0.0038\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 13:56:51\n",
      "Accuracy: 0.9828 - Precision: 0.6842 - Recall: 0.1997 - Specificity: 0.9996 - F1: 0.2662 - Loss: 0.0037\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 13:57:01\n",
      "Accuracy: 0.9830 - Precision: 0.6879 - Recall: 0.2062 - Specificity: 0.9996 - F1: 0.2735 - Loss: 0.0037\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 13:57:11\n",
      "Accuracy: 0.9830 - Precision: 0.6917 - Recall: 0.2110 - Specificity: 0.9995 - F1: 0.2796 - Loss: 0.0037\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 13:57:19\n",
      "Accuracy: 0.9830 - Precision: 0.6942 - Recall: 0.2144 - Specificity: 0.9995 - F1: 0.2841 - Loss: 0.0037\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 13:57:28\n",
      "Accuracy: 0.9831 - Precision: 0.6972 - Recall: 0.2183 - Specificity: 0.9995 - F1: 0.2891 - Loss: 0.0037\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 13:57:37\n",
      "Accuracy: 0.9832 - Precision: 0.7003 - Recall: 0.2218 - Specificity: 0.9995 - F1: 0.2938 - Loss: 0.0037\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 13:57:46\n",
      "Accuracy: 0.9833 - Precision: 0.7041 - Recall: 0.2262 - Specificity: 0.9995 - F1: 0.2994 - Loss: 0.0037\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 13:57:54\n",
      "Accuracy: 0.9834 - Precision: 0.7073 - Recall: 0.2317 - Specificity: 0.9995 - F1: 0.3056 - Loss: 0.0037\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 13:58:06\n",
      "Accuracy: 0.9835 - Precision: 0.7088 - Recall: 0.2358 - Specificity: 0.9995 - F1: 0.3103 - Loss: 0.0036\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 13:58:17\n",
      "Accuracy: 0.9835 - Precision: 0.7102 - Recall: 0.2397 - Specificity: 0.9994 - F1: 0.3147 - Loss: 0.0036\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 13:58:26\n",
      "Accuracy: 0.9835 - Precision: 0.7139 - Recall: 0.2422 - Specificity: 0.9995 - F1: 0.3185 - Loss: 0.0036\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 13:58:34\n",
      "Accuracy: 0.9835 - Precision: 0.7173 - Recall: 0.2446 - Specificity: 0.9995 - F1: 0.3221 - Loss: 0.0037\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 13:58:43\n",
      "Accuracy: 0.9836 - Precision: 0.7196 - Recall: 0.2480 - Specificity: 0.9994 - F1: 0.3264 - Loss: 0.0036\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 13:58:52\n",
      "Accuracy: 0.9837 - Precision: 0.7218 - Recall: 0.2525 - Specificity: 0.9994 - F1: 0.3314 - Loss: 0.0036\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 13:59:02\n",
      "Accuracy: 0.9837 - Precision: 0.7233 - Recall: 0.2575 - Specificity: 0.9994 - F1: 0.3365 - Loss: 0.0036\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 13:59:11\n",
      "Accuracy: 0.9838 - Precision: 0.7262 - Recall: 0.2615 - Specificity: 0.9994 - F1: 0.3413 - Loss: 0.0036\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 13:59:20\n",
      "Accuracy: 0.9838 - Precision: 0.7290 - Recall: 0.2641 - Specificity: 0.9994 - F1: 0.3449 - Loss: 0.0036\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 13:59:29\n",
      "Accuracy: 0.9839 - Precision: 0.7318 - Recall: 0.2665 - Specificity: 0.9994 - F1: 0.3483 - Loss: 0.0036\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 13:59:38\n",
      "Accuracy: 0.9839 - Precision: 0.7348 - Recall: 0.2680 - Specificity: 0.9994 - F1: 0.3508 - Loss: 0.0036\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 13:59:47\n",
      "Accuracy: 0.9840 - Precision: 0.7354 - Recall: 0.2707 - Specificity: 0.9994 - F1: 0.3539 - Loss: 0.0036\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 13:59:55\n",
      "Accuracy: 0.9840 - Precision: 0.7375 - Recall: 0.2733 - Specificity: 0.9994 - F1: 0.3573 - Loss: 0.0036\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 14:00:04\n",
      "Accuracy: 0.9841 - Precision: 0.7391 - Recall: 0.2764 - Specificity: 0.9994 - F1: 0.3609 - Loss: 0.0036\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 14:00:12\n",
      "Accuracy: 0.9842 - Precision: 0.7414 - Recall: 0.2805 - Specificity: 0.9994 - F1: 0.3655 - Loss: 0.0036\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 14:00:21\n",
      "Accuracy: 0.9842 - Precision: 0.7428 - Recall: 0.2830 - Specificity: 0.9994 - F1: 0.3686 - Loss: 0.0036\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 14:00:31\n",
      "Accuracy: 0.9843 - Precision: 0.7452 - Recall: 0.2865 - Specificity: 0.9994 - F1: 0.3727 - Loss: 0.0035\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 14:00:41\n",
      "Accuracy: 0.9844 - Precision: 0.7466 - Recall: 0.2896 - Specificity: 0.9993 - F1: 0.3762 - Loss: 0.0035\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 14:00:50\n",
      "Accuracy: 0.9844 - Precision: 0.7492 - Recall: 0.2918 - Specificity: 0.9993 - F1: 0.3793 - Loss: 0.0035\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 14:00:59\n",
      "Accuracy: 0.9844 - Precision: 0.7516 - Recall: 0.2935 - Specificity: 0.9993 - F1: 0.3818 - Loss: 0.0035\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 14:01:10\n",
      "Accuracy: 0.9845 - Precision: 0.7536 - Recall: 0.2971 - Specificity: 0.9993 - F1: 0.3858 - Loss: 0.0035\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 14:01:18\n",
      "Accuracy: 0.9845 - Precision: 0.7539 - Recall: 0.3012 - Specificity: 0.9993 - F1: 0.3895 - Loss: 0.0035\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 14:01:27\n",
      "Accuracy: 0.9846 - Precision: 0.7554 - Recall: 0.3050 - Specificity: 0.9993 - F1: 0.3934 - Loss: 0.0035\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 14:01:36\n",
      "Accuracy: 0.9847 - Precision: 0.7573 - Recall: 0.3078 - Specificity: 0.9993 - F1: 0.3968 - Loss: 0.0035\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 14:01:48\n",
      "Accuracy: 0.9847 - Precision: 0.7578 - Recall: 0.3095 - Specificity: 0.9993 - F1: 0.3988 - Loss: 0.0035\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 14:01:57\n",
      "Accuracy: 0.9847 - Precision: 0.7593 - Recall: 0.3096 - Specificity: 0.9993 - F1: 0.3995 - Loss: 0.0035\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 14:02:06\n",
      "Accuracy: 0.9847 - Precision: 0.7617 - Recall: 0.3094 - Specificity: 0.9993 - F1: 0.4001 - Loss: 0.0035\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 14:02:15\n",
      "Accuracy: 0.9848 - Precision: 0.7633 - Recall: 0.3104 - Specificity: 0.9993 - F1: 0.4018 - Loss: 0.0035\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 14:02:25\n",
      "Accuracy: 0.9848 - Precision: 0.7645 - Recall: 0.3116 - Specificity: 0.9993 - F1: 0.4035 - Loss: 0.0035\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 14:02:34\n",
      "Accuracy: 0.9848 - Precision: 0.7659 - Recall: 0.3134 - Specificity: 0.9993 - F1: 0.4059 - Loss: 0.0034\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 14:02:43\n",
      "Accuracy: 0.9849 - Precision: 0.7661 - Recall: 0.3154 - Specificity: 0.9993 - F1: 0.4081 - Loss: 0.0034\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 14:02:52\n",
      "Accuracy: 0.9849 - Precision: 0.7650 - Recall: 0.3163 - Specificity: 0.9992 - F1: 0.4089 - Loss: 0.0034\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 14:03:01\n",
      "Accuracy: 0.9850 - Precision: 0.7655 - Recall: 0.3179 - Specificity: 0.9992 - F1: 0.4108 - Loss: 0.0034\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 14:03:11\n",
      "Accuracy: 0.9850 - Precision: 0.7667 - Recall: 0.3185 - Specificity: 0.9992 - F1: 0.4121 - Loss: 0.0034\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 14:03:20\n",
      "Accuracy: 0.9850 - Precision: 0.7671 - Recall: 0.3192 - Specificity: 0.9992 - F1: 0.4132 - Loss: 0.0034\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 14:03:29\n",
      "Accuracy: 0.9851 - Precision: 0.7686 - Recall: 0.3197 - Specificity: 0.9992 - F1: 0.4142 - Loss: 0.0034\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 14:03:38\n",
      "Accuracy: 0.9851 - Precision: 0.7693 - Recall: 0.3193 - Specificity: 0.9992 - F1: 0.4143 - Loss: 0.0034\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 14:03:46\n",
      "Accuracy: 0.9851 - Precision: 0.7693 - Recall: 0.3189 - Specificity: 0.9992 - F1: 0.4142 - Loss: 0.0034\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 14:03:55\n",
      "Accuracy: 0.9851 - Precision: 0.7711 - Recall: 0.3197 - Specificity: 0.9992 - F1: 0.4156 - Loss: 0.0034\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 14:04:04\n",
      "Accuracy: 0.9852 - Precision: 0.7726 - Recall: 0.3214 - Specificity: 0.9992 - F1: 0.4178 - Loss: 0.0034\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 14:04:13\n",
      "Accuracy: 0.9852 - Precision: 0.7732 - Recall: 0.3227 - Specificity: 0.9992 - F1: 0.4195 - Loss: 0.0034\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 14:04:21\n",
      "Accuracy: 0.9852 - Precision: 0.7742 - Recall: 0.3243 - Specificity: 0.9992 - F1: 0.4215 - Loss: 0.0034\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 14:04:30\n",
      "Accuracy: 0.9853 - Precision: 0.7746 - Recall: 0.3263 - Specificity: 0.9992 - F1: 0.4235 - Loss: 0.0034\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 14:04:38\n",
      "Accuracy: 0.9853 - Precision: 0.7761 - Recall: 0.3274 - Specificity: 0.9992 - F1: 0.4252 - Loss: 0.0033\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 14:04:47\n",
      "Accuracy: 0.9853 - Precision: 0.7779 - Recall: 0.3277 - Specificity: 0.9992 - F1: 0.4261 - Loss: 0.0033\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 14:04:55\n",
      "Accuracy: 0.9854 - Precision: 0.7789 - Recall: 0.3282 - Specificity: 0.9992 - F1: 0.4271 - Loss: 0.0033\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 14:05:04\n",
      "Accuracy: 0.9853 - Precision: 0.7801 - Recall: 0.3286 - Specificity: 0.9992 - F1: 0.4280 - Loss: 0.0033\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 14:05:15\n",
      "Accuracy: 0.9854 - Precision: 0.7813 - Recall: 0.3300 - Specificity: 0.9992 - F1: 0.4298 - Loss: 0.0033\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 14:05:24\n",
      "Accuracy: 0.9854 - Precision: 0.7814 - Recall: 0.3327 - Specificity: 0.9992 - F1: 0.4322 - Loss: 0.0033\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 14:05:32\n",
      "Accuracy: 0.9855 - Precision: 0.7808 - Recall: 0.3357 - Specificity: 0.9992 - F1: 0.4344 - Loss: 0.0033\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 14:05:41\n",
      "Accuracy: 0.9855 - Precision: 0.7810 - Recall: 0.3375 - Specificity: 0.9991 - F1: 0.4363 - Loss: 0.0033\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 14:05:49\n",
      "Accuracy: 0.9855 - Precision: 0.7821 - Recall: 0.3387 - Specificity: 0.9991 - F1: 0.4379 - Loss: 0.0033\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 14:05:58\n",
      "Accuracy: 0.9855 - Precision: 0.7836 - Recall: 0.3396 - Specificity: 0.9991 - F1: 0.4393 - Loss: 0.0033\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 14:06:07\n",
      "Accuracy: 0.9855 - Precision: 0.7852 - Recall: 0.3406 - Specificity: 0.9992 - F1: 0.4409 - Loss: 0.0033\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 14:06:16\n",
      "Accuracy: 0.9856 - Precision: 0.7863 - Recall: 0.3411 - Specificity: 0.9992 - F1: 0.4418 - Loss: 0.0033\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 14:06:24\n",
      "Accuracy: 0.9856 - Precision: 0.7878 - Recall: 0.3423 - Specificity: 0.9992 - F1: 0.4435 - Loss: 0.0033\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 14:06:33\n",
      "Accuracy: 0.9856 - Precision: 0.7882 - Recall: 0.3430 - Specificity: 0.9992 - F1: 0.4445 - Loss: 0.0033\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 14:06:41\n",
      "Accuracy: 0.9856 - Precision: 0.7888 - Recall: 0.3434 - Specificity: 0.9992 - F1: 0.4452 - Loss: 0.0033\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 14:06:50\n",
      "Accuracy: 0.9857 - Precision: 0.7903 - Recall: 0.3442 - Specificity: 0.9992 - F1: 0.4466 - Loss: 0.0033\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 14:06:58\n",
      "Accuracy: 0.9857 - Precision: 0.7914 - Recall: 0.3449 - Specificity: 0.9992 - F1: 0.4477 - Loss: 0.0033\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 14:07:06\n",
      "Accuracy: 0.9857 - Precision: 0.7925 - Recall: 0.3458 - Specificity: 0.9992 - F1: 0.4490 - Loss: 0.0033\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 14:07:16\n",
      "Accuracy: 0.9857 - Precision: 0.7932 - Recall: 0.3477 - Specificity: 0.9992 - F1: 0.4510 - Loss: 0.0033\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 14:07:25\n",
      "Accuracy: 0.9857 - Precision: 0.7941 - Recall: 0.3492 - Specificity: 0.9991 - F1: 0.4527 - Loss: 0.0033\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 14:07:33\n",
      "Accuracy: 0.9858 - Precision: 0.7946 - Recall: 0.3515 - Specificity: 0.9991 - F1: 0.4549 - Loss: 0.0033\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 14:07:42\n",
      "Accuracy: 0.9858 - Precision: 0.7953 - Recall: 0.3539 - Specificity: 0.9991 - F1: 0.4572 - Loss: 0.0033\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 14:07:50\n",
      "Accuracy: 0.9859 - Precision: 0.7958 - Recall: 0.3560 - Specificity: 0.9991 - F1: 0.4593 - Loss: 0.0033\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 14:07:58\n",
      "Accuracy: 0.9859 - Precision: 0.7967 - Recall: 0.3577 - Specificity: 0.9991 - F1: 0.4612 - Loss: 0.0033\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 14:08:06\n",
      "Accuracy: 0.9859 - Precision: 0.7976 - Recall: 0.3592 - Specificity: 0.9991 - F1: 0.4629 - Loss: 0.0032\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 14:08:15\n",
      "Accuracy: 0.9859 - Precision: 0.7988 - Recall: 0.3601 - Specificity: 0.9991 - F1: 0.4642 - Loss: 0.0032\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 14:08:24\n",
      "Accuracy: 0.9860 - Precision: 0.8000 - Recall: 0.3618 - Specificity: 0.9991 - F1: 0.4662 - Loss: 0.0032\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 14:08:32\n",
      "Accuracy: 0.9860 - Precision: 0.8007 - Recall: 0.3637 - Specificity: 0.9991 - F1: 0.4681 - Loss: 0.0032\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 14:08:41\n",
      "Accuracy: 0.9860 - Precision: 0.8015 - Recall: 0.3651 - Specificity: 0.9991 - F1: 0.4697 - Loss: 0.0032\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 14:08:49\n",
      "Accuracy: 0.9860 - Precision: 0.8017 - Recall: 0.3670 - Specificity: 0.9991 - F1: 0.4714 - Loss: 0.0032\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 14:08:58\n",
      "Accuracy: 0.9861 - Precision: 0.8017 - Recall: 0.3691 - Specificity: 0.9991 - F1: 0.4733 - Loss: 0.0032\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 14:09:06\n",
      "Accuracy: 0.9861 - Precision: 0.8027 - Recall: 0.3701 - Specificity: 0.9991 - F1: 0.4746 - Loss: 0.0032\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 14:09:17\n",
      "Accuracy: 0.9861 - Precision: 0.8033 - Recall: 0.3713 - Specificity: 0.9991 - F1: 0.4760 - Loss: 0.0032\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 14:09:25\n",
      "Accuracy: 0.9861 - Precision: 0.8044 - Recall: 0.3718 - Specificity: 0.9991 - F1: 0.4769 - Loss: 0.0032\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 14:09:37\n",
      "Accuracy: 0.9862 - Precision: 0.8055 - Recall: 0.3725 - Specificity: 0.9991 - F1: 0.4780 - Loss: 0.0032\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 14:09:46\n",
      "Accuracy: 0.9861 - Precision: 0.8041 - Recall: 0.3712 - Specificity: 0.9991 - F1: 0.4767 - Loss: 0.0032\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 14:09:55\n",
      "Accuracy: 0.9862 - Precision: 0.8047 - Recall: 0.3717 - Specificity: 0.9991 - F1: 0.4774 - Loss: 0.0032\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 14:10:04\n",
      "Accuracy: 0.9861 - Precision: 0.8054 - Recall: 0.3715 - Specificity: 0.9991 - F1: 0.4775 - Loss: 0.0032\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 14:10:13\n",
      "Accuracy: 0.9861 - Precision: 0.8059 - Recall: 0.3720 - Specificity: 0.9991 - F1: 0.4783 - Loss: 0.0032\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 14:10:22\n",
      "Accuracy: 0.9862 - Precision: 0.8069 - Recall: 0.3728 - Specificity: 0.9991 - F1: 0.4794 - Loss: 0.0032\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 14:10:31\n",
      "Accuracy: 0.9862 - Precision: 0.8079 - Recall: 0.3739 - Specificity: 0.9991 - F1: 0.4808 - Loss: 0.0032\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 14:10:40\n",
      "Accuracy: 0.9862 - Precision: 0.8089 - Recall: 0.3750 - Specificity: 0.9991 - F1: 0.4822 - Loss: 0.0032\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 14:10:49\n",
      "Accuracy: 0.9862 - Precision: 0.8097 - Recall: 0.3764 - Specificity: 0.9991 - F1: 0.4838 - Loss: 0.0032\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 14:10:58\n",
      "Accuracy: 0.9862 - Precision: 0.8104 - Recall: 0.3781 - Specificity: 0.9991 - F1: 0.4855 - Loss: 0.0032\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 14:11:07\n",
      "Accuracy: 0.9863 - Precision: 0.8105 - Recall: 0.3799 - Specificity: 0.9991 - F1: 0.4871 - Loss: 0.0032\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 14:11:17\n",
      "Accuracy: 0.9863 - Precision: 0.8115 - Recall: 0.3813 - Specificity: 0.9991 - F1: 0.4887 - Loss: 0.0032\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 14:11:27\n",
      "Accuracy: 0.9864 - Precision: 0.8123 - Recall: 0.3825 - Specificity: 0.9991 - F1: 0.4901 - Loss: 0.0032\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 14:11:37\n",
      "Accuracy: 0.9864 - Precision: 0.8131 - Recall: 0.3833 - Specificity: 0.9991 - F1: 0.4912 - Loss: 0.0032\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 14:11:46\n",
      "Accuracy: 0.9864 - Precision: 0.8138 - Recall: 0.3847 - Specificity: 0.9991 - F1: 0.4927 - Loss: 0.0032\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 14:11:55\n",
      "Accuracy: 0.9864 - Precision: 0.8136 - Recall: 0.3862 - Specificity: 0.9991 - F1: 0.4939 - Loss: 0.0032\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 14:12:04\n",
      "Accuracy: 0.9865 - Precision: 0.8140 - Recall: 0.3871 - Specificity: 0.9991 - F1: 0.4949 - Loss: 0.0032\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 14:12:12\n",
      "Accuracy: 0.9865 - Precision: 0.8150 - Recall: 0.3879 - Specificity: 0.9991 - F1: 0.4961 - Loss: 0.0032\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 14:12:21\n",
      "Accuracy: 0.9865 - Precision: 0.8151 - Recall: 0.3881 - Specificity: 0.9991 - F1: 0.4964 - Loss: 0.0032\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 14:12:32\n",
      "Accuracy: 0.9865 - Precision: 0.8162 - Recall: 0.3881 - Specificity: 0.9991 - F1: 0.4968 - Loss: 0.0032\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 14:12:41\n",
      "Accuracy: 0.9865 - Precision: 0.8172 - Recall: 0.3878 - Specificity: 0.9991 - F1: 0.4968 - Loss: 0.0032\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 14:12:50\n",
      "Accuracy: 0.9865 - Precision: 0.8177 - Recall: 0.3883 - Specificity: 0.9991 - F1: 0.4976 - Loss: 0.0032\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 14:12:58\n",
      "Accuracy: 0.9865 - Precision: 0.8182 - Recall: 0.3898 - Specificity: 0.9991 - F1: 0.4991 - Loss: 0.0032\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 14:13:07\n",
      "Accuracy: 0.9865 - Precision: 0.8182 - Recall: 0.3912 - Specificity: 0.9991 - F1: 0.5003 - Loss: 0.0032\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 14:13:17\n",
      "Accuracy: 0.9865 - Precision: 0.8185 - Recall: 0.3921 - Specificity: 0.9991 - F1: 0.5013 - Loss: 0.0032\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 14:13:26\n",
      "Accuracy: 0.9866 - Precision: 0.8190 - Recall: 0.3930 - Specificity: 0.9991 - F1: 0.5023 - Loss: 0.0032\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 14:13:34\n",
      "Accuracy: 0.9866 - Precision: 0.8199 - Recall: 0.3939 - Specificity: 0.9991 - F1: 0.5035 - Loss: 0.0032\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 14:13:43\n",
      "Accuracy: 0.9866 - Precision: 0.8202 - Recall: 0.3942 - Specificity: 0.9991 - F1: 0.5040 - Loss: 0.0032\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 14:13:52\n",
      "Accuracy: 0.9866 - Precision: 0.8210 - Recall: 0.3950 - Specificity: 0.9991 - F1: 0.5050 - Loss: 0.0032\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 14:14:00\n",
      "Accuracy: 0.9866 - Precision: 0.8216 - Recall: 0.3957 - Specificity: 0.9991 - F1: 0.5060 - Loss: 0.0032\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 14:14:09\n",
      "Accuracy: 0.9866 - Precision: 0.8223 - Recall: 0.3964 - Specificity: 0.9991 - F1: 0.5069 - Loss: 0.0031\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 14:14:18\n",
      "Accuracy: 0.9867 - Precision: 0.8221 - Recall: 0.3971 - Specificity: 0.9991 - F1: 0.5076 - Loss: 0.0031\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 14:14:26\n",
      "Accuracy: 0.9867 - Precision: 0.8228 - Recall: 0.3975 - Specificity: 0.9991 - F1: 0.5082 - Loss: 0.0031\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 14:14:35\n",
      "Accuracy: 0.9867 - Precision: 0.8235 - Recall: 0.3979 - Specificity: 0.9991 - F1: 0.5088 - Loss: 0.0031\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 14:14:44\n",
      "Accuracy: 0.9867 - Precision: 0.8244 - Recall: 0.3984 - Specificity: 0.9991 - F1: 0.5097 - Loss: 0.0031\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 14:14:53\n",
      "Accuracy: 0.9867 - Precision: 0.8248 - Recall: 0.3991 - Specificity: 0.9991 - F1: 0.5105 - Loss: 0.0031\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 14:15:01\n",
      "Accuracy: 0.9867 - Precision: 0.8251 - Recall: 0.3999 - Specificity: 0.9991 - F1: 0.5114 - Loss: 0.0031\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 14:15:10\n",
      "Accuracy: 0.9868 - Precision: 0.8254 - Recall: 0.4014 - Specificity: 0.9991 - F1: 0.5128 - Loss: 0.0031\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 14:15:21\n",
      "Accuracy: 0.9868 - Precision: 0.8255 - Recall: 0.4024 - Specificity: 0.9991 - F1: 0.5137 - Loss: 0.0031\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 14:15:30\n",
      "Accuracy: 0.9868 - Precision: 0.8259 - Recall: 0.4033 - Specificity: 0.9990 - F1: 0.5147 - Loss: 0.0031\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 14:15:40\n",
      "Accuracy: 0.9868 - Precision: 0.8263 - Recall: 0.4042 - Specificity: 0.9990 - F1: 0.5157 - Loss: 0.0031\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 14:15:48\n",
      "Accuracy: 0.9868 - Precision: 0.8266 - Recall: 0.4049 - Specificity: 0.9990 - F1: 0.5165 - Loss: 0.0031\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 14:15:58\n",
      "Accuracy: 0.9868 - Precision: 0.8273 - Recall: 0.4056 - Specificity: 0.9990 - F1: 0.5174 - Loss: 0.0031\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 14:16:09\n",
      "Accuracy: 0.9868 - Precision: 0.8280 - Recall: 0.4064 - Specificity: 0.9990 - F1: 0.5184 - Loss: 0.0031\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 14:16:17\n",
      "Accuracy: 0.9868 - Precision: 0.8284 - Recall: 0.4075 - Specificity: 0.9990 - F1: 0.5195 - Loss: 0.0031\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 14:16:26\n",
      "Accuracy: 0.9869 - Precision: 0.8277 - Recall: 0.4087 - Specificity: 0.9990 - F1: 0.5203 - Loss: 0.0031\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 14:16:35\n",
      "Accuracy: 0.9869 - Precision: 0.8283 - Recall: 0.4098 - Specificity: 0.9990 - F1: 0.5214 - Loss: 0.0031\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 14:16:44\n",
      "Accuracy: 0.9869 - Precision: 0.8288 - Recall: 0.4101 - Specificity: 0.9990 - F1: 0.5221 - Loss: 0.0031\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 14:16:52\n",
      "Accuracy: 0.9869 - Precision: 0.8294 - Recall: 0.4110 - Specificity: 0.9990 - F1: 0.5231 - Loss: 0.0031\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 14:17:01\n",
      "Accuracy: 0.9869 - Precision: 0.8295 - Recall: 0.4113 - Specificity: 0.9990 - F1: 0.5235 - Loss: 0.0031\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 14:17:10\n",
      "Accuracy: 0.9869 - Precision: 0.8298 - Recall: 0.4117 - Specificity: 0.9990 - F1: 0.5240 - Loss: 0.0031\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 14:17:20\n",
      "Accuracy: 0.9869 - Precision: 0.8304 - Recall: 0.4120 - Specificity: 0.9990 - F1: 0.5246 - Loss: 0.0031\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 14:17:30\n",
      "Accuracy: 0.9870 - Precision: 0.8310 - Recall: 0.4128 - Specificity: 0.9990 - F1: 0.5255 - Loss: 0.0031\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 14:17:38\n",
      "Accuracy: 0.9870 - Precision: 0.8315 - Recall: 0.4139 - Specificity: 0.9990 - F1: 0.5267 - Loss: 0.0031\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 14:17:46\n",
      "Accuracy: 0.9870 - Precision: 0.8318 - Recall: 0.4156 - Specificity: 0.9990 - F1: 0.5281 - Loss: 0.0031\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 14:17:55\n",
      "Accuracy: 0.9871 - Precision: 0.8322 - Recall: 0.4170 - Specificity: 0.9990 - F1: 0.5294 - Loss: 0.0031\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 14:18:04\n",
      "Accuracy: 0.9871 - Precision: 0.8319 - Recall: 0.4181 - Specificity: 0.9990 - F1: 0.5302 - Loss: 0.0031\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 14:18:13\n",
      "Accuracy: 0.9871 - Precision: 0.8324 - Recall: 0.4189 - Specificity: 0.9990 - F1: 0.5311 - Loss: 0.0031\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 14:18:22\n",
      "Accuracy: 0.9871 - Precision: 0.8330 - Recall: 0.4194 - Specificity: 0.9990 - F1: 0.5319 - Loss: 0.0031\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 14:18:30\n",
      "Accuracy: 0.9871 - Precision: 0.8330 - Recall: 0.4196 - Specificity: 0.9990 - F1: 0.5321 - Loss: 0.0031\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 14:18:39\n",
      "Accuracy: 0.9872 - Precision: 0.8335 - Recall: 0.4201 - Specificity: 0.9990 - F1: 0.5328 - Loss: 0.0031\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 14:18:48\n",
      "Accuracy: 0.9872 - Precision: 0.8341 - Recall: 0.4211 - Specificity: 0.9990 - F1: 0.5339 - Loss: 0.0030\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 14:18:56\n",
      "Accuracy: 0.9872 - Precision: 0.8339 - Recall: 0.4226 - Specificity: 0.9990 - F1: 0.5350 - Loss: 0.0030\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 14:19:05\n",
      "Accuracy: 0.9872 - Precision: 0.8341 - Recall: 0.4239 - Specificity: 0.9990 - F1: 0.5361 - Loss: 0.0030\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 14:19:13\n",
      "Accuracy: 0.9872 - Precision: 0.8342 - Recall: 0.4250 - Specificity: 0.9990 - F1: 0.5371 - Loss: 0.0030\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 14:19:23\n",
      "Accuracy: 0.9872 - Precision: 0.8342 - Recall: 0.4252 - Specificity: 0.9990 - F1: 0.5374 - Loss: 0.0030\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 14:19:41\n",
      "Accuracy: 0.9872 - Precision: 0.8343 - Recall: 0.4247 - Specificity: 0.9990 - F1: 0.5370 - Loss: 0.0030\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 14:19:53\n",
      "Accuracy: 0.9872 - Precision: 0.8339 - Recall: 0.4238 - Specificity: 0.9990 - F1: 0.5362 - Loss: 0.0031\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 14:20:03\n",
      "Accuracy: 0.9871 - Precision: 0.8338 - Recall: 0.4226 - Specificity: 0.9990 - F1: 0.5350 - Loss: 0.0031\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 14:20:14\n",
      "Accuracy: 0.9871 - Precision: 0.8343 - Recall: 0.4216 - Specificity: 0.9990 - F1: 0.5341 - Loss: 0.0031\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 14:20:24\n",
      "Accuracy: 0.9871 - Precision: 0.8347 - Recall: 0.4209 - Specificity: 0.9990 - F1: 0.5335 - Loss: 0.0031\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 14:20:37\n",
      "Accuracy: 0.9870 - Precision: 0.8350 - Recall: 0.4200 - Specificity: 0.9990 - F1: 0.5328 - Loss: 0.0031\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 14:20:47\n",
      "Accuracy: 0.9870 - Precision: 0.8349 - Recall: 0.4186 - Specificity: 0.9990 - F1: 0.5312 - Loss: 0.0031\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 14:20:56\n",
      "Accuracy: 0.9869 - Precision: 0.8356 - Recall: 0.4173 - Specificity: 0.9990 - F1: 0.5299 - Loss: 0.0031\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 14:21:08\n",
      "Accuracy: 0.9869 - Precision: 0.8356 - Recall: 0.4160 - Specificity: 0.9990 - F1: 0.5285 - Loss: 0.0031\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 14:21:17\n",
      "Accuracy: 0.9868 - Precision: 0.8356 - Recall: 0.4149 - Specificity: 0.9990 - F1: 0.5274 - Loss: 0.0031\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 14:21:27\n",
      "Accuracy: 0.9869 - Precision: 0.8359 - Recall: 0.4147 - Specificity: 0.9990 - F1: 0.5273 - Loss: 0.0031\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 14:21:38\n",
      "Accuracy: 0.9869 - Precision: 0.8364 - Recall: 0.4141 - Specificity: 0.9990 - F1: 0.5269 - Loss: 0.0031\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 14:21:49\n",
      "Accuracy: 0.9868 - Precision: 0.8368 - Recall: 0.4130 - Specificity: 0.9990 - F1: 0.5259 - Loss: 0.0031\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 14:22:00\n",
      "Accuracy: 0.9868 - Precision: 0.8373 - Recall: 0.4128 - Specificity: 0.9990 - F1: 0.5259 - Loss: 0.0031\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 14:22:09\n",
      "Accuracy: 0.9868 - Precision: 0.8374 - Recall: 0.4129 - Specificity: 0.9990 - F1: 0.5261 - Loss: 0.0031\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 14:22:18\n",
      "Accuracy: 0.9868 - Precision: 0.8371 - Recall: 0.4122 - Specificity: 0.9990 - F1: 0.5255 - Loss: 0.0032\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 14:22:28\n",
      "Accuracy: 0.9868 - Precision: 0.8374 - Recall: 0.4119 - Specificity: 0.9990 - F1: 0.5253 - Loss: 0.0032\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 14:22:37\n",
      "Accuracy: 0.9868 - Precision: 0.8376 - Recall: 0.4119 - Specificity: 0.9990 - F1: 0.5255 - Loss: 0.0032\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 14:22:46\n",
      "Accuracy: 0.9868 - Precision: 0.8379 - Recall: 0.4114 - Specificity: 0.9990 - F1: 0.5252 - Loss: 0.0032\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 14:22:55\n",
      "Accuracy: 0.9867 - Precision: 0.8379 - Recall: 0.4106 - Specificity: 0.9990 - F1: 0.5244 - Loss: 0.0032\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 14:23:05\n",
      "Accuracy: 0.9866 - Precision: 0.8383 - Recall: 0.4100 - Specificity: 0.9990 - F1: 0.5240 - Loss: 0.0032\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 14:23:14\n",
      "Accuracy: 0.9866 - Precision: 0.8386 - Recall: 0.4094 - Specificity: 0.9990 - F1: 0.5234 - Loss: 0.0032\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 14:23:23\n",
      "Accuracy: 0.9865 - Precision: 0.8386 - Recall: 0.4092 - Specificity: 0.9990 - F1: 0.5234 - Loss: 0.0032\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 14:23:33\n",
      "Accuracy: 0.9865 - Precision: 0.8387 - Recall: 0.4089 - Specificity: 0.9990 - F1: 0.5232 - Loss: 0.0032\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 14:23:42\n",
      "Accuracy: 0.9865 - Precision: 0.8393 - Recall: 0.4083 - Specificity: 0.9990 - F1: 0.5229 - Loss: 0.0032\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 14:23:51\n",
      "Accuracy: 0.9865 - Precision: 0.8397 - Recall: 0.4080 - Specificity: 0.9990 - F1: 0.5227 - Loss: 0.0033\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 14:24:00\n",
      "Accuracy: 0.9861 - Precision: 0.8379 - Recall: 0.4063 - Specificity: 0.9990 - F1: 0.5206 - Loss: 0.0035\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 14:24:09\n",
      "Accuracy: 0.9859 - Precision: 0.8373 - Recall: 0.4049 - Specificity: 0.9990 - F1: 0.5190 - Loss: 0.0036\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 14:24:18\n",
      "Accuracy: 0.9856 - Precision: 0.8371 - Recall: 0.4035 - Specificity: 0.9990 - F1: 0.5173 - Loss: 0.0037\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 14:24:28\n",
      "Accuracy: 0.9853 - Precision: 0.8374 - Recall: 0.4022 - Specificity: 0.9990 - F1: 0.5158 - Loss: 0.0038\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 14:24:36\n",
      "Accuracy: 0.9850 - Precision: 0.8375 - Recall: 0.4007 - Specificity: 0.9990 - F1: 0.5140 - Loss: 0.0039\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 14:24:45\n",
      "Accuracy: 0.9848 - Precision: 0.8372 - Recall: 0.3992 - Specificity: 0.9990 - F1: 0.5122 - Loss: 0.0039\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 14:24:54\n",
      "Accuracy: 0.9845 - Precision: 0.8374 - Recall: 0.3976 - Specificity: 0.9990 - F1: 0.5102 - Loss: 0.0040\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 14:25:04\n",
      "Accuracy: 0.9843 - Precision: 0.8353 - Recall: 0.3964 - Specificity: 0.9990 - F1: 0.5087 - Loss: 0.0041\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 14:25:13\n",
      "Accuracy: 0.9839 - Precision: 0.8319 - Recall: 0.3948 - Specificity: 0.9990 - F1: 0.5066 - Loss: 0.0042\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 14:25:24\n",
      "Accuracy: 0.9836 - Precision: 0.8300 - Recall: 0.3932 - Specificity: 0.9990 - F1: 0.5046 - Loss: 0.0043\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 14:25:33\n",
      "Accuracy: 0.9834 - Precision: 0.8267 - Recall: 0.3916 - Specificity: 0.9990 - F1: 0.5026 - Loss: 0.0044\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 14:25:42\n",
      "Accuracy: 0.9833 - Precision: 0.8234 - Recall: 0.3901 - Specificity: 0.9990 - F1: 0.5006 - Loss: 0.0044\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 14:25:52\n",
      "Accuracy: 0.9830 - Precision: 0.8201 - Recall: 0.3885 - Specificity: 0.9990 - F1: 0.4986 - Loss: 0.0045\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 14:26:01\n",
      "Accuracy: 0.9828 - Precision: 0.8169 - Recall: 0.3870 - Specificity: 0.9990 - F1: 0.4966 - Loss: 0.0046\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 14:26:09\n",
      "Accuracy: 0.9825 - Precision: 0.8137 - Recall: 0.3855 - Specificity: 0.9990 - F1: 0.4947 - Loss: 0.0046\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 14:26:18\n",
      "Accuracy: 0.9821 - Precision: 0.8105 - Recall: 0.3840 - Specificity: 0.9990 - F1: 0.4927 - Loss: 0.0047\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 14:26:26\n",
      "Accuracy: 0.9819 - Precision: 0.8095 - Recall: 0.3825 - Specificity: 0.9990 - F1: 0.4908 - Loss: 0.0048\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 14:26:35\n",
      "Accuracy: 0.9818 - Precision: 0.8072 - Recall: 0.3810 - Specificity: 0.9990 - F1: 0.4889 - Loss: 0.0048\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 14:26:44\n",
      "Accuracy: 0.9817 - Precision: 0.8042 - Recall: 0.3795 - Specificity: 0.9990 - F1: 0.4870 - Loss: 0.0049\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 14:26:53\n",
      "Accuracy: 0.9817 - Precision: 0.8011 - Recall: 0.3780 - Specificity: 0.9990 - F1: 0.4851 - Loss: 0.0049\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 14:27:02\n",
      "Accuracy: 0.9817 - Precision: 0.7985 - Recall: 0.3766 - Specificity: 0.9990 - F1: 0.4833 - Loss: 0.0049\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 14:27:11\n",
      "Accuracy: 0.9816 - Precision: 0.7980 - Recall: 0.3751 - Specificity: 0.9990 - F1: 0.4814 - Loss: 0.0049\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 14:27:21\n",
      "Accuracy: 0.9815 - Precision: 0.7988 - Recall: 0.3737 - Specificity: 0.9990 - F1: 0.4796 - Loss: 0.0049\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 14:27:32\n",
      "Accuracy: 0.9814 - Precision: 0.7957 - Recall: 0.3723 - Specificity: 0.9990 - F1: 0.4778 - Loss: 0.0050\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 14:27:40\n",
      "Accuracy: 0.9814 - Precision: 0.7927 - Recall: 0.3709 - Specificity: 0.9990 - F1: 0.4759 - Loss: 0.0050\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 14:27:49\n",
      "Accuracy: 0.9813 - Precision: 0.7897 - Recall: 0.3695 - Specificity: 0.9990 - F1: 0.4741 - Loss: 0.0050\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 14:27:58\n",
      "Accuracy: 0.9813 - Precision: 0.7896 - Recall: 0.3681 - Specificity: 0.9990 - F1: 0.4724 - Loss: 0.0050\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 14:28:07\n",
      "Accuracy: 0.9813 - Precision: 0.7885 - Recall: 0.3668 - Specificity: 0.9990 - F1: 0.4707 - Loss: 0.0050\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 14:28:15\n",
      "Accuracy: 0.9812 - Precision: 0.7893 - Recall: 0.3654 - Specificity: 0.9990 - F1: 0.4689 - Loss: 0.0051\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 14:28:25\n",
      "Accuracy: 0.9812 - Precision: 0.7863 - Recall: 0.3640 - Specificity: 0.9990 - F1: 0.4672 - Loss: 0.0051\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 14:28:36\n",
      "Accuracy: 0.9812 - Precision: 0.7834 - Recall: 0.3627 - Specificity: 0.9990 - F1: 0.4655 - Loss: 0.0051\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 14:28:46\n",
      "Accuracy: 0.9812 - Precision: 0.7842 - Recall: 0.3614 - Specificity: 0.9990 - F1: 0.4637 - Loss: 0.0051\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 14:28:54\n",
      "Accuracy: 0.9811 - Precision: 0.7813 - Recall: 0.3600 - Specificity: 0.9991 - F1: 0.4620 - Loss: 0.0051\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 14:29:05\n",
      "Accuracy: 0.9811 - Precision: 0.7785 - Recall: 0.3587 - Specificity: 0.9991 - F1: 0.4604 - Loss: 0.0051\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 14:29:15\n",
      "Accuracy: 0.9811 - Precision: 0.7756 - Recall: 0.3574 - Specificity: 0.9991 - F1: 0.4587 - Loss: 0.0051\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 14:29:29\n",
      "Accuracy: 0.9811 - Precision: 0.7728 - Recall: 0.3561 - Specificity: 0.9991 - F1: 0.4570 - Loss: 0.0051\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 14:30:37\n",
      "Accuracy: 0.9810 - Precision: 0.7700 - Recall: 0.3548 - Specificity: 0.9991 - F1: 0.4553 - Loss: 0.0051\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 14:31:43\n",
      "Accuracy: 0.9811 - Precision: 0.7672 - Recall: 0.3535 - Specificity: 0.9991 - F1: 0.4537 - Loss: 0.0051\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 14:32:10\n",
      "Accuracy: 0.9810 - Precision: 0.7645 - Recall: 0.3523 - Specificity: 0.9991 - F1: 0.4521 - Loss: 0.0052\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 14:32:33\n",
      "Accuracy: 0.9810 - Precision: 0.7617 - Recall: 0.3510 - Specificity: 0.9991 - F1: 0.4505 - Loss: 0.0052\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 14:32:45\n",
      "Accuracy: 0.9810 - Precision: 0.7590 - Recall: 0.3497 - Specificity: 0.9991 - F1: 0.4488 - Loss: 0.0052\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 14:32:56\n",
      "Accuracy: 0.9810 - Precision: 0.7563 - Recall: 0.3485 - Specificity: 0.9991 - F1: 0.4472 - Loss: 0.0052\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 14:33:05\n",
      "Accuracy: 0.9810 - Precision: 0.7536 - Recall: 0.3473 - Specificity: 0.9991 - F1: 0.4457 - Loss: 0.0052\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 14:33:13\n",
      "Accuracy: 0.9810 - Precision: 0.7510 - Recall: 0.3460 - Specificity: 0.9991 - F1: 0.4441 - Loss: 0.0052\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 14:33:22\n",
      "Accuracy: 0.9810 - Precision: 0.7483 - Recall: 0.3448 - Specificity: 0.9991 - F1: 0.4425 - Loss: 0.0052\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 14:33:32\n",
      "Accuracy: 0.9810 - Precision: 0.7457 - Recall: 0.3436 - Specificity: 0.9991 - F1: 0.4410 - Loss: 0.0052\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 14:33:40\n",
      "Accuracy: 0.9810 - Precision: 0.7431 - Recall: 0.3424 - Specificity: 0.9991 - F1: 0.4394 - Loss: 0.0052\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 14:33:49\n",
      "Accuracy: 0.9809 - Precision: 0.7405 - Recall: 0.3412 - Specificity: 0.9991 - F1: 0.4379 - Loss: 0.0052\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 14:33:57\n",
      "Accuracy: 0.9809 - Precision: 0.7379 - Recall: 0.3400 - Specificity: 0.9991 - F1: 0.4364 - Loss: 0.0052\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 14:34:05\n",
      "Accuracy: 0.9809 - Precision: 0.7388 - Recall: 0.3388 - Specificity: 0.9991 - F1: 0.4349 - Loss: 0.0052\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 14:34:14\n",
      "Accuracy: 0.9809 - Precision: 0.7363 - Recall: 0.3377 - Specificity: 0.9991 - F1: 0.4334 - Loss: 0.0052\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 14:34:23\n",
      "Accuracy: 0.9808 - Precision: 0.7338 - Recall: 0.3365 - Specificity: 0.9991 - F1: 0.4319 - Loss: 0.0052\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 14:34:31\n",
      "Accuracy: 0.9808 - Precision: 0.7312 - Recall: 0.3354 - Specificity: 0.9991 - F1: 0.4304 - Loss: 0.0052\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 14:34:40\n",
      "Accuracy: 0.9808 - Precision: 0.7288 - Recall: 0.3342 - Specificity: 0.9991 - F1: 0.4289 - Loss: 0.0052\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 14:34:50\n",
      "Accuracy: 0.9807 - Precision: 0.7263 - Recall: 0.3331 - Specificity: 0.9991 - F1: 0.4275 - Loss: 0.0052\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 14:34:59\n",
      "Accuracy: 0.9807 - Precision: 0.7238 - Recall: 0.3320 - Specificity: 0.9991 - F1: 0.4260 - Loss: 0.0052\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 14:35:07\n",
      "Accuracy: 0.9807 - Precision: 0.7214 - Recall: 0.3308 - Specificity: 0.9991 - F1: 0.4246 - Loss: 0.0052\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 14:35:16\n",
      "Accuracy: 0.9807 - Precision: 0.7189 - Recall: 0.3297 - Specificity: 0.9991 - F1: 0.4232 - Loss: 0.0052\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 14:35:24\n",
      "Accuracy: 0.9806 - Precision: 0.7165 - Recall: 0.3286 - Specificity: 0.9991 - F1: 0.4217 - Loss: 0.0053\n",
      "\n",
      "Epoch 4/20\n",
      "Validation - Accuracy: 0.9786, Precision: 0.0000, Recall: 0.0000, Specificity: 1.0000, F1: 0.0000, Loss: 0.0054\n",
      "\n",
      "\n",
      "Epoch 5/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 14:43:06\n",
      "Accuracy: 0.9738 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0061\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 14:43:15\n",
      "Accuracy: 0.9722 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0065\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 14:43:23\n",
      "Accuracy: 0.9711 - Precision: 0.3333 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0062\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 14:43:31\n",
      "Accuracy: 0.9742 - Precision: 0.5000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0056\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 14:43:40\n",
      "Accuracy: 0.9762 - Precision: 0.4000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0054\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 14:43:48\n",
      "Accuracy: 0.9762 - Precision: 0.3333 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0053\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 14:43:57\n",
      "Accuracy: 0.9775 - Precision: 0.2857 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0050\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 14:44:05\n",
      "Accuracy: 0.9781 - Precision: 0.2500 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0048\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 14:44:14\n",
      "Accuracy: 0.9788 - Precision: 0.3333 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0046\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 14:44:22\n",
      "Accuracy: 0.9792 - Precision: 0.3000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0045\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 14:44:30\n",
      "Accuracy: 0.9795 - Precision: 0.2727 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0044\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 14:44:39\n",
      "Accuracy: 0.9797 - Precision: 0.2500 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0043\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 14:44:49\n",
      "Accuracy: 0.9798 - Precision: 0.2308 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0042\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 14:44:58\n",
      "Accuracy: 0.9800 - Precision: 0.2857 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0042\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 14:45:06\n",
      "Accuracy: 0.9802 - Precision: 0.2667 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0042\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 14:45:14\n",
      "Accuracy: 0.9797 - Precision: 0.3125 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0043\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 14:45:23\n",
      "Accuracy: 0.9800 - Precision: 0.2941 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0042\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 14:45:31\n",
      "Accuracy: 0.9799 - Precision: 0.3333 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0041\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 14:45:40\n",
      "Accuracy: 0.9799 - Precision: 0.3684 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0041\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 14:45:48\n",
      "Accuracy: 0.9801 - Precision: 0.3917 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0040\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 14:45:56\n",
      "Accuracy: 0.9801 - Precision: 0.4070 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0040\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 14:46:04\n",
      "Accuracy: 0.9799 - Precision: 0.4183 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0003 - Loss: 0.0042\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 14:46:13\n",
      "Accuracy: 0.9798 - Precision: 0.4436 - Recall: 0.0002 - Specificity: 1.0000 - F1: 0.0003 - Loss: 0.0041\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 14:46:21\n",
      "Accuracy: 0.9796 - Precision: 0.4668 - Recall: 0.0002 - Specificity: 1.0000 - F1: 0.0004 - Loss: 0.0042\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 14:46:30\n",
      "Accuracy: 0.9796 - Precision: 0.4881 - Recall: 0.0003 - Specificity: 1.0000 - F1: 0.0006 - Loss: 0.0041\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 14:46:38\n",
      "Accuracy: 0.9798 - Precision: 0.5078 - Recall: 0.0004 - Specificity: 1.0000 - F1: 0.0008 - Loss: 0.0041\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 14:46:48\n",
      "Accuracy: 0.9798 - Precision: 0.5260 - Recall: 0.0005 - Specificity: 1.0000 - F1: 0.0009 - Loss: 0.0041\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 14:46:57\n",
      "Accuracy: 0.9797 - Precision: 0.5430 - Recall: 0.0005 - Specificity: 1.0000 - F1: 0.0010 - Loss: 0.0040\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 14:47:05\n",
      "Accuracy: 0.9795 - Precision: 0.5541 - Recall: 0.0006 - Specificity: 1.0000 - F1: 0.0011 - Loss: 0.0041\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 14:47:13\n",
      "Accuracy: 0.9794 - Precision: 0.5690 - Recall: 0.0007 - Specificity: 1.0000 - F1: 0.0014 - Loss: 0.0041\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 14:47:22\n",
      "Accuracy: 0.9795 - Precision: 0.5822 - Recall: 0.0009 - Specificity: 1.0000 - F1: 0.0018 - Loss: 0.0040\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 14:47:30\n",
      "Accuracy: 0.9795 - Precision: 0.5934 - Recall: 0.0012 - Specificity: 1.0000 - F1: 0.0023 - Loss: 0.0040\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 14:47:40\n",
      "Accuracy: 0.9795 - Precision: 0.6058 - Recall: 0.0014 - Specificity: 1.0000 - F1: 0.0028 - Loss: 0.0040\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 14:47:49\n",
      "Accuracy: 0.9793 - Precision: 0.6171 - Recall: 0.0016 - Specificity: 1.0000 - F1: 0.0033 - Loss: 0.0040\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 14:47:58\n",
      "Accuracy: 0.9793 - Precision: 0.6281 - Recall: 0.0018 - Specificity: 1.0000 - F1: 0.0035 - Loss: 0.0040\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 14:48:06\n",
      "Accuracy: 0.9794 - Precision: 0.6384 - Recall: 0.0022 - Specificity: 1.0000 - F1: 0.0044 - Loss: 0.0040\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 14:48:15\n",
      "Accuracy: 0.9793 - Precision: 0.6480 - Recall: 0.0029 - Specificity: 1.0000 - F1: 0.0057 - Loss: 0.0039\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 14:48:24\n",
      "Accuracy: 0.9793 - Precision: 0.6559 - Recall: 0.0035 - Specificity: 1.0000 - F1: 0.0068 - Loss: 0.0039\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 14:48:32\n",
      "Accuracy: 0.9793 - Precision: 0.6643 - Recall: 0.0043 - Specificity: 1.0000 - F1: 0.0083 - Loss: 0.0039\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 14:48:41\n",
      "Accuracy: 0.9792 - Precision: 0.6726 - Recall: 0.0051 - Specificity: 1.0000 - F1: 0.0101 - Loss: 0.0039\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 14:48:51\n",
      "Accuracy: 0.9791 - Precision: 0.6801 - Recall: 0.0057 - Specificity: 1.0000 - F1: 0.0111 - Loss: 0.0039\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 14:49:00\n",
      "Accuracy: 0.9791 - Precision: 0.6877 - Recall: 0.0066 - Specificity: 1.0000 - F1: 0.0129 - Loss: 0.0039\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 14:49:09\n",
      "Accuracy: 0.9791 - Precision: 0.6945 - Recall: 0.0081 - Specificity: 1.0000 - F1: 0.0156 - Loss: 0.0039\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 14:49:18\n",
      "Accuracy: 0.9791 - Precision: 0.7003 - Recall: 0.0100 - Specificity: 1.0000 - F1: 0.0190 - Loss: 0.0039\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 14:49:27\n",
      "Accuracy: 0.9793 - Precision: 0.7020 - Recall: 0.0123 - Specificity: 1.0000 - F1: 0.0231 - Loss: 0.0038\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 14:49:40\n",
      "Accuracy: 0.9793 - Precision: 0.7082 - Recall: 0.0145 - Specificity: 1.0000 - F1: 0.0269 - Loss: 0.0038\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 14:49:49\n",
      "Accuracy: 0.9793 - Precision: 0.7133 - Recall: 0.0166 - Specificity: 1.0000 - F1: 0.0307 - Loss: 0.0038\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 14:49:58\n",
      "Accuracy: 0.9793 - Precision: 0.7189 - Recall: 0.0189 - Specificity: 1.0000 - F1: 0.0348 - Loss: 0.0038\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 14:50:08\n",
      "Accuracy: 0.9793 - Precision: 0.7236 - Recall: 0.0227 - Specificity: 1.0000 - F1: 0.0410 - Loss: 0.0038\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 14:50:17\n",
      "Accuracy: 0.9793 - Precision: 0.7290 - Recall: 0.0266 - Specificity: 1.0000 - F1: 0.0473 - Loss: 0.0038\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 14:50:30\n",
      "Accuracy: 0.9794 - Precision: 0.7333 - Recall: 0.0310 - Specificity: 1.0000 - F1: 0.0541 - Loss: 0.0038\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 14:50:41\n",
      "Accuracy: 0.9795 - Precision: 0.7369 - Recall: 0.0358 - Specificity: 1.0000 - F1: 0.0614 - Loss: 0.0038\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 14:50:54\n",
      "Accuracy: 0.9797 - Precision: 0.7411 - Recall: 0.0425 - Specificity: 1.0000 - F1: 0.0707 - Loss: 0.0037\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 14:51:10\n",
      "Accuracy: 0.9799 - Precision: 0.7454 - Recall: 0.0502 - Specificity: 1.0000 - F1: 0.0809 - Loss: 0.0037\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 14:51:21\n",
      "Accuracy: 0.9800 - Precision: 0.7492 - Recall: 0.0571 - Specificity: 0.9999 - F1: 0.0903 - Loss: 0.0037\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 14:51:30\n",
      "Accuracy: 0.9802 - Precision: 0.7521 - Recall: 0.0661 - Specificity: 0.9999 - F1: 0.1010 - Loss: 0.0037\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 14:51:39\n",
      "Accuracy: 0.9804 - Precision: 0.7551 - Recall: 0.0739 - Specificity: 0.9999 - F1: 0.1108 - Loss: 0.0036\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 14:51:50\n",
      "Accuracy: 0.9805 - Precision: 0.7580 - Recall: 0.0821 - Specificity: 0.9999 - F1: 0.1207 - Loss: 0.0036\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 14:52:00\n",
      "Accuracy: 0.9807 - Precision: 0.7616 - Recall: 0.0898 - Specificity: 0.9999 - F1: 0.1304 - Loss: 0.0036\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 14:52:11\n",
      "Accuracy: 0.9808 - Precision: 0.7624 - Recall: 0.0966 - Specificity: 0.9999 - F1: 0.1385 - Loss: 0.0036\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 14:52:21\n",
      "Accuracy: 0.9809 - Precision: 0.7635 - Recall: 0.1041 - Specificity: 0.9998 - F1: 0.1471 - Loss: 0.0036\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 14:52:30\n",
      "Accuracy: 0.9811 - Precision: 0.7656 - Recall: 0.1127 - Specificity: 0.9998 - F1: 0.1567 - Loss: 0.0036\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 14:52:39\n",
      "Accuracy: 0.9813 - Precision: 0.7683 - Recall: 0.1216 - Specificity: 0.9998 - F1: 0.1667 - Loss: 0.0035\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 14:52:48\n",
      "Accuracy: 0.9815 - Precision: 0.7706 - Recall: 0.1299 - Specificity: 0.9998 - F1: 0.1760 - Loss: 0.0035\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 14:52:59\n",
      "Accuracy: 0.9816 - Precision: 0.7730 - Recall: 0.1359 - Specificity: 0.9998 - F1: 0.1835 - Loss: 0.0035\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 14:53:08\n",
      "Accuracy: 0.9816 - Precision: 0.7745 - Recall: 0.1403 - Specificity: 0.9997 - F1: 0.1894 - Loss: 0.0035\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 14:53:17\n",
      "Accuracy: 0.9817 - Precision: 0.7761 - Recall: 0.1461 - Specificity: 0.9997 - F1: 0.1965 - Loss: 0.0035\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 14:53:26\n",
      "Accuracy: 0.9818 - Precision: 0.7775 - Recall: 0.1517 - Specificity: 0.9997 - F1: 0.2032 - Loss: 0.0035\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 14:53:34\n",
      "Accuracy: 0.9819 - Precision: 0.7800 - Recall: 0.1582 - Specificity: 0.9997 - F1: 0.2109 - Loss: 0.0035\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 14:53:43\n",
      "Accuracy: 0.9821 - Precision: 0.7823 - Recall: 0.1642 - Specificity: 0.9997 - F1: 0.2182 - Loss: 0.0035\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 14:53:52\n",
      "Accuracy: 0.9822 - Precision: 0.7831 - Recall: 0.1686 - Specificity: 0.9997 - F1: 0.2237 - Loss: 0.0035\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 14:54:00\n",
      "Accuracy: 0.9822 - Precision: 0.7841 - Recall: 0.1722 - Specificity: 0.9996 - F1: 0.2284 - Loss: 0.0035\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 14:54:09\n",
      "Accuracy: 0.9822 - Precision: 0.7869 - Recall: 0.1747 - Specificity: 0.9997 - F1: 0.2325 - Loss: 0.0035\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 14:54:17\n",
      "Accuracy: 0.9822 - Precision: 0.7896 - Recall: 0.1775 - Specificity: 0.9997 - F1: 0.2368 - Loss: 0.0035\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 14:54:26\n",
      "Accuracy: 0.9823 - Precision: 0.7911 - Recall: 0.1822 - Specificity: 0.9996 - F1: 0.2425 - Loss: 0.0035\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 14:54:35\n",
      "Accuracy: 0.9824 - Precision: 0.7918 - Recall: 0.1881 - Specificity: 0.9996 - F1: 0.2489 - Loss: 0.0035\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 14:54:43\n",
      "Accuracy: 0.9825 - Precision: 0.7920 - Recall: 0.1949 - Specificity: 0.9996 - F1: 0.2555 - Loss: 0.0035\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 14:54:51\n",
      "Accuracy: 0.9826 - Precision: 0.7941 - Recall: 0.2002 - Specificity: 0.9996 - F1: 0.2617 - Loss: 0.0035\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 14:55:01\n",
      "Accuracy: 0.9826 - Precision: 0.7960 - Recall: 0.2038 - Specificity: 0.9996 - F1: 0.2665 - Loss: 0.0035\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 14:55:10\n",
      "Accuracy: 0.9827 - Precision: 0.7981 - Recall: 0.2068 - Specificity: 0.9996 - F1: 0.2708 - Loss: 0.0034\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 14:55:20\n",
      "Accuracy: 0.9828 - Precision: 0.8004 - Recall: 0.2087 - Specificity: 0.9996 - F1: 0.2739 - Loss: 0.0034\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 14:55:29\n",
      "Accuracy: 0.9828 - Precision: 0.8010 - Recall: 0.2109 - Specificity: 0.9996 - F1: 0.2771 - Loss: 0.0034\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 14:55:37\n",
      "Accuracy: 0.9829 - Precision: 0.8025 - Recall: 0.2135 - Specificity: 0.9996 - F1: 0.2808 - Loss: 0.0034\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 14:55:46\n",
      "Accuracy: 0.9830 - Precision: 0.8035 - Recall: 0.2170 - Specificity: 0.9995 - F1: 0.2852 - Loss: 0.0034\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 14:55:54\n",
      "Accuracy: 0.9831 - Precision: 0.8051 - Recall: 0.2223 - Specificity: 0.9995 - F1: 0.2910 - Loss: 0.0034\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 14:56:03\n",
      "Accuracy: 0.9832 - Precision: 0.8057 - Recall: 0.2268 - Specificity: 0.9995 - F1: 0.2959 - Loss: 0.0034\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 14:56:12\n",
      "Accuracy: 0.9833 - Precision: 0.8071 - Recall: 0.2314 - Specificity: 0.9995 - F1: 0.3011 - Loss: 0.0034\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 14:56:21\n",
      "Accuracy: 0.9833 - Precision: 0.8080 - Recall: 0.2349 - Specificity: 0.9995 - F1: 0.3053 - Loss: 0.0034\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 14:56:29\n",
      "Accuracy: 0.9834 - Precision: 0.8100 - Recall: 0.2375 - Specificity: 0.9995 - F1: 0.3090 - Loss: 0.0034\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 14:56:38\n",
      "Accuracy: 0.9834 - Precision: 0.8118 - Recall: 0.2397 - Specificity: 0.9995 - F1: 0.3122 - Loss: 0.0034\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 14:56:47\n",
      "Accuracy: 0.9834 - Precision: 0.8132 - Recall: 0.2436 - Specificity: 0.9995 - F1: 0.3168 - Loss: 0.0034\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 14:56:57\n",
      "Accuracy: 0.9835 - Precision: 0.8129 - Recall: 0.2484 - Specificity: 0.9995 - F1: 0.3213 - Loss: 0.0034\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 14:57:07\n",
      "Accuracy: 0.9836 - Precision: 0.8137 - Recall: 0.2531 - Specificity: 0.9995 - F1: 0.3262 - Loss: 0.0034\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 14:57:15\n",
      "Accuracy: 0.9837 - Precision: 0.8149 - Recall: 0.2570 - Specificity: 0.9995 - F1: 0.3306 - Loss: 0.0033\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 14:57:23\n",
      "Accuracy: 0.9837 - Precision: 0.8146 - Recall: 0.2596 - Specificity: 0.9994 - F1: 0.3336 - Loss: 0.0033\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 14:57:32\n",
      "Accuracy: 0.9837 - Precision: 0.8151 - Recall: 0.2603 - Specificity: 0.9994 - F1: 0.3351 - Loss: 0.0033\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 14:57:40\n",
      "Accuracy: 0.9838 - Precision: 0.8169 - Recall: 0.2601 - Specificity: 0.9994 - F1: 0.3356 - Loss: 0.0033\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 14:57:49\n",
      "Accuracy: 0.9838 - Precision: 0.8180 - Recall: 0.2607 - Specificity: 0.9994 - F1: 0.3370 - Loss: 0.0033\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 14:57:58\n",
      "Accuracy: 0.9838 - Precision: 0.8187 - Recall: 0.2613 - Specificity: 0.9994 - F1: 0.3383 - Loss: 0.0033\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 14:58:06\n",
      "Accuracy: 0.9839 - Precision: 0.8197 - Recall: 0.2625 - Specificity: 0.9994 - F1: 0.3403 - Loss: 0.0033\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 14:58:15\n",
      "Accuracy: 0.9839 - Precision: 0.8202 - Recall: 0.2643 - Specificity: 0.9994 - F1: 0.3428 - Loss: 0.0033\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 14:58:24\n",
      "Accuracy: 0.9840 - Precision: 0.8186 - Recall: 0.2655 - Specificity: 0.9994 - F1: 0.3442 - Loss: 0.0033\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 14:58:33\n",
      "Accuracy: 0.9840 - Precision: 0.8187 - Recall: 0.2677 - Specificity: 0.9994 - F1: 0.3468 - Loss: 0.0033\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 14:58:42\n",
      "Accuracy: 0.9841 - Precision: 0.8191 - Recall: 0.2697 - Specificity: 0.9994 - F1: 0.3494 - Loss: 0.0033\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 14:58:51\n",
      "Accuracy: 0.9841 - Precision: 0.8190 - Recall: 0.2718 - Specificity: 0.9994 - F1: 0.3519 - Loss: 0.0033\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 14:59:02\n",
      "Accuracy: 0.9842 - Precision: 0.8199 - Recall: 0.2733 - Specificity: 0.9994 - F1: 0.3541 - Loss: 0.0033\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 14:59:12\n",
      "Accuracy: 0.9842 - Precision: 0.8203 - Recall: 0.2741 - Specificity: 0.9994 - F1: 0.3556 - Loss: 0.0033\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 14:59:21\n",
      "Accuracy: 0.9842 - Precision: 0.8199 - Recall: 0.2744 - Specificity: 0.9994 - F1: 0.3563 - Loss: 0.0033\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 14:59:30\n",
      "Accuracy: 0.9843 - Precision: 0.8212 - Recall: 0.2756 - Specificity: 0.9994 - F1: 0.3583 - Loss: 0.0033\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 14:59:40\n",
      "Accuracy: 0.9843 - Precision: 0.8224 - Recall: 0.2773 - Specificity: 0.9994 - F1: 0.3606 - Loss: 0.0032\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 14:59:49\n",
      "Accuracy: 0.9844 - Precision: 0.8225 - Recall: 0.2784 - Specificity: 0.9993 - F1: 0.3623 - Loss: 0.0032\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 14:59:57\n",
      "Accuracy: 0.9844 - Precision: 0.8233 - Recall: 0.2803 - Specificity: 0.9993 - F1: 0.3648 - Loss: 0.0032\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 15:00:06\n",
      "Accuracy: 0.9845 - Precision: 0.8235 - Recall: 0.2828 - Specificity: 0.9993 - F1: 0.3675 - Loss: 0.0032\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 15:00:15\n",
      "Accuracy: 0.9845 - Precision: 0.8246 - Recall: 0.2847 - Specificity: 0.9993 - F1: 0.3700 - Loss: 0.0032\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 15:00:24\n",
      "Accuracy: 0.9845 - Precision: 0.8259 - Recall: 0.2861 - Specificity: 0.9993 - F1: 0.3721 - Loss: 0.0032\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 15:00:32\n",
      "Accuracy: 0.9846 - Precision: 0.8265 - Recall: 0.2875 - Specificity: 0.9993 - F1: 0.3741 - Loss: 0.0032\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 15:00:41\n",
      "Accuracy: 0.9846 - Precision: 0.8273 - Recall: 0.2887 - Specificity: 0.9993 - F1: 0.3759 - Loss: 0.0032\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 15:00:50\n",
      "Accuracy: 0.9846 - Precision: 0.8283 - Recall: 0.2903 - Specificity: 0.9993 - F1: 0.3780 - Loss: 0.0032\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 15:01:00\n",
      "Accuracy: 0.9847 - Precision: 0.8281 - Recall: 0.2928 - Specificity: 0.9993 - F1: 0.3806 - Loss: 0.0032\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 15:01:10\n",
      "Accuracy: 0.9847 - Precision: 0.8274 - Recall: 0.2960 - Specificity: 0.9993 - F1: 0.3833 - Loss: 0.0032\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 15:01:19\n",
      "Accuracy: 0.9848 - Precision: 0.8273 - Recall: 0.2982 - Specificity: 0.9993 - F1: 0.3856 - Loss: 0.0032\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 15:01:28\n",
      "Accuracy: 0.9848 - Precision: 0.8281 - Recall: 0.3001 - Specificity: 0.9993 - F1: 0.3880 - Loss: 0.0032\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 15:01:38\n",
      "Accuracy: 0.9848 - Precision: 0.8291 - Recall: 0.3018 - Specificity: 0.9993 - F1: 0.3903 - Loss: 0.0032\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 15:01:47\n",
      "Accuracy: 0.9849 - Precision: 0.8302 - Recall: 0.3039 - Specificity: 0.9993 - F1: 0.3928 - Loss: 0.0032\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 15:01:58\n",
      "Accuracy: 0.9849 - Precision: 0.8308 - Recall: 0.3056 - Specificity: 0.9993 - F1: 0.3950 - Loss: 0.0032\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 15:02:08\n",
      "Accuracy: 0.9850 - Precision: 0.8318 - Recall: 0.3079 - Specificity: 0.9993 - F1: 0.3977 - Loss: 0.0032\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 15:02:16\n",
      "Accuracy: 0.9850 - Precision: 0.8318 - Recall: 0.3097 - Specificity: 0.9993 - F1: 0.3997 - Loss: 0.0032\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 15:02:25\n",
      "Accuracy: 0.9850 - Precision: 0.8322 - Recall: 0.3108 - Specificity: 0.9993 - F1: 0.4012 - Loss: 0.0032\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 15:02:35\n",
      "Accuracy: 0.9851 - Precision: 0.8333 - Recall: 0.3121 - Specificity: 0.9993 - F1: 0.4031 - Loss: 0.0031\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 15:02:43\n",
      "Accuracy: 0.9851 - Precision: 0.8342 - Recall: 0.3131 - Specificity: 0.9993 - F1: 0.4046 - Loss: 0.0031\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 15:02:52\n",
      "Accuracy: 0.9851 - Precision: 0.8349 - Recall: 0.3144 - Specificity: 0.9993 - F1: 0.4064 - Loss: 0.0031\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 15:03:01\n",
      "Accuracy: 0.9851 - Precision: 0.8352 - Recall: 0.3169 - Specificity: 0.9993 - F1: 0.4089 - Loss: 0.0031\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 15:03:11\n",
      "Accuracy: 0.9852 - Precision: 0.8358 - Recall: 0.3187 - Specificity: 0.9993 - F1: 0.4110 - Loss: 0.0031\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 15:03:20\n",
      "Accuracy: 0.9852 - Precision: 0.8361 - Recall: 0.3211 - Specificity: 0.9993 - F1: 0.4135 - Loss: 0.0031\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 15:03:28\n",
      "Accuracy: 0.9852 - Precision: 0.8366 - Recall: 0.3235 - Specificity: 0.9992 - F1: 0.4161 - Loss: 0.0031\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 15:03:36\n",
      "Accuracy: 0.9853 - Precision: 0.8371 - Recall: 0.3256 - Specificity: 0.9992 - F1: 0.4183 - Loss: 0.0031\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 15:03:45\n",
      "Accuracy: 0.9853 - Precision: 0.8379 - Recall: 0.3271 - Specificity: 0.9992 - F1: 0.4203 - Loss: 0.0031\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 15:03:53\n",
      "Accuracy: 0.9853 - Precision: 0.8386 - Recall: 0.3285 - Specificity: 0.9992 - F1: 0.4220 - Loss: 0.0031\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 15:04:02\n",
      "Accuracy: 0.9854 - Precision: 0.8396 - Recall: 0.3296 - Specificity: 0.9992 - F1: 0.4236 - Loss: 0.0031\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 15:04:11\n",
      "Accuracy: 0.9854 - Precision: 0.8406 - Recall: 0.3315 - Specificity: 0.9993 - F1: 0.4258 - Loss: 0.0031\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 15:04:20\n",
      "Accuracy: 0.9855 - Precision: 0.8410 - Recall: 0.3336 - Specificity: 0.9992 - F1: 0.4281 - Loss: 0.0031\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 15:04:28\n",
      "Accuracy: 0.9855 - Precision: 0.8415 - Recall: 0.3353 - Specificity: 0.9992 - F1: 0.4301 - Loss: 0.0031\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 15:04:37\n",
      "Accuracy: 0.9855 - Precision: 0.8415 - Recall: 0.3374 - Specificity: 0.9992 - F1: 0.4321 - Loss: 0.0031\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 15:04:45\n",
      "Accuracy: 0.9856 - Precision: 0.8414 - Recall: 0.3398 - Specificity: 0.9992 - F1: 0.4343 - Loss: 0.0031\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 15:04:53\n",
      "Accuracy: 0.9856 - Precision: 0.8421 - Recall: 0.3411 - Specificity: 0.9992 - F1: 0.4360 - Loss: 0.0031\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 15:05:02\n",
      "Accuracy: 0.9856 - Precision: 0.8426 - Recall: 0.3424 - Specificity: 0.9992 - F1: 0.4376 - Loss: 0.0031\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 15:05:12\n",
      "Accuracy: 0.9856 - Precision: 0.8434 - Recall: 0.3431 - Specificity: 0.9992 - F1: 0.4387 - Loss: 0.0031\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 15:05:22\n",
      "Accuracy: 0.9856 - Precision: 0.8442 - Recall: 0.3441 - Specificity: 0.9992 - F1: 0.4402 - Loss: 0.0031\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 15:05:30\n",
      "Accuracy: 0.9856 - Precision: 0.8428 - Recall: 0.3429 - Specificity: 0.9992 - F1: 0.4391 - Loss: 0.0031\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 15:05:38\n",
      "Accuracy: 0.9856 - Precision: 0.8432 - Recall: 0.3436 - Specificity: 0.9992 - F1: 0.4401 - Loss: 0.0031\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 15:05:47\n",
      "Accuracy: 0.9856 - Precision: 0.8436 - Recall: 0.3438 - Specificity: 0.9992 - F1: 0.4407 - Loss: 0.0031\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 15:05:55\n",
      "Accuracy: 0.9856 - Precision: 0.8440 - Recall: 0.3447 - Specificity: 0.9992 - F1: 0.4419 - Loss: 0.0031\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 15:06:04\n",
      "Accuracy: 0.9857 - Precision: 0.8447 - Recall: 0.3458 - Specificity: 0.9992 - F1: 0.4434 - Loss: 0.0031\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 15:06:13\n",
      "Accuracy: 0.9857 - Precision: 0.8455 - Recall: 0.3473 - Specificity: 0.9992 - F1: 0.4452 - Loss: 0.0031\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 15:06:21\n",
      "Accuracy: 0.9857 - Precision: 0.8461 - Recall: 0.3488 - Specificity: 0.9992 - F1: 0.4469 - Loss: 0.0031\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 15:06:30\n",
      "Accuracy: 0.9858 - Precision: 0.8467 - Recall: 0.3505 - Specificity: 0.9992 - F1: 0.4488 - Loss: 0.0031\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 15:06:39\n",
      "Accuracy: 0.9858 - Precision: 0.8470 - Recall: 0.3524 - Specificity: 0.9992 - F1: 0.4508 - Loss: 0.0031\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 15:06:51\n",
      "Accuracy: 0.9858 - Precision: 0.8470 - Recall: 0.3545 - Specificity: 0.9992 - F1: 0.4527 - Loss: 0.0031\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 15:07:01\n",
      "Accuracy: 0.9859 - Precision: 0.8478 - Recall: 0.3560 - Specificity: 0.9992 - F1: 0.4545 - Loss: 0.0031\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 15:07:11\n",
      "Accuracy: 0.9859 - Precision: 0.8484 - Recall: 0.3573 - Specificity: 0.9992 - F1: 0.4561 - Loss: 0.0031\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 15:07:22\n",
      "Accuracy: 0.9859 - Precision: 0.8491 - Recall: 0.3584 - Specificity: 0.9992 - F1: 0.4575 - Loss: 0.0031\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 15:07:32\n",
      "Accuracy: 0.9860 - Precision: 0.8496 - Recall: 0.3600 - Specificity: 0.9992 - F1: 0.4593 - Loss: 0.0031\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 15:07:42\n",
      "Accuracy: 0.9860 - Precision: 0.8492 - Recall: 0.3617 - Specificity: 0.9992 - F1: 0.4607 - Loss: 0.0031\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 15:07:51\n",
      "Accuracy: 0.9860 - Precision: 0.8495 - Recall: 0.3626 - Specificity: 0.9992 - F1: 0.4619 - Loss: 0.0031\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 15:08:00\n",
      "Accuracy: 0.9860 - Precision: 0.8502 - Recall: 0.3635 - Specificity: 0.9992 - F1: 0.4631 - Loss: 0.0030\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 15:08:09\n",
      "Accuracy: 0.9861 - Precision: 0.8504 - Recall: 0.3637 - Specificity: 0.9992 - F1: 0.4637 - Loss: 0.0030\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 15:08:18\n",
      "Accuracy: 0.9861 - Precision: 0.8512 - Recall: 0.3638 - Specificity: 0.9992 - F1: 0.4641 - Loss: 0.0030\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 15:08:26\n",
      "Accuracy: 0.9860 - Precision: 0.8521 - Recall: 0.3636 - Specificity: 0.9992 - F1: 0.4643 - Loss: 0.0030\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 15:08:35\n",
      "Accuracy: 0.9861 - Precision: 0.8525 - Recall: 0.3643 - Specificity: 0.9992 - F1: 0.4653 - Loss: 0.0030\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 15:08:43\n",
      "Accuracy: 0.9861 - Precision: 0.8528 - Recall: 0.3660 - Specificity: 0.9992 - F1: 0.4671 - Loss: 0.0030\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 15:08:52\n",
      "Accuracy: 0.9861 - Precision: 0.8527 - Recall: 0.3675 - Specificity: 0.9992 - F1: 0.4685 - Loss: 0.0030\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 15:09:00\n",
      "Accuracy: 0.9861 - Precision: 0.8528 - Recall: 0.3687 - Specificity: 0.9992 - F1: 0.4698 - Loss: 0.0030\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 15:09:09\n",
      "Accuracy: 0.9862 - Precision: 0.8531 - Recall: 0.3698 - Specificity: 0.9992 - F1: 0.4711 - Loss: 0.0030\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 15:09:20\n",
      "Accuracy: 0.9862 - Precision: 0.8538 - Recall: 0.3710 - Specificity: 0.9992 - F1: 0.4725 - Loss: 0.0030\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 15:09:29\n",
      "Accuracy: 0.9862 - Precision: 0.8538 - Recall: 0.3716 - Specificity: 0.9992 - F1: 0.4733 - Loss: 0.0030\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 15:09:37\n",
      "Accuracy: 0.9862 - Precision: 0.8545 - Recall: 0.3725 - Specificity: 0.9992 - F1: 0.4745 - Loss: 0.0030\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 15:09:46\n",
      "Accuracy: 0.9862 - Precision: 0.8550 - Recall: 0.3735 - Specificity: 0.9992 - F1: 0.4758 - Loss: 0.0030\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 15:09:55\n",
      "Accuracy: 0.9863 - Precision: 0.8554 - Recall: 0.3745 - Specificity: 0.9992 - F1: 0.4770 - Loss: 0.0030\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 15:10:04\n",
      "Accuracy: 0.9863 - Precision: 0.8551 - Recall: 0.3755 - Specificity: 0.9992 - F1: 0.4780 - Loss: 0.0030\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 15:10:13\n",
      "Accuracy: 0.9863 - Precision: 0.8558 - Recall: 0.3761 - Specificity: 0.9992 - F1: 0.4789 - Loss: 0.0030\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 15:10:22\n",
      "Accuracy: 0.9863 - Precision: 0.8565 - Recall: 0.3766 - Specificity: 0.9992 - F1: 0.4798 - Loss: 0.0030\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 15:10:31\n",
      "Accuracy: 0.9863 - Precision: 0.8571 - Recall: 0.3773 - Specificity: 0.9992 - F1: 0.4808 - Loss: 0.0030\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 15:10:40\n",
      "Accuracy: 0.9863 - Precision: 0.8574 - Recall: 0.3780 - Specificity: 0.9992 - F1: 0.4817 - Loss: 0.0030\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 15:10:51\n",
      "Accuracy: 0.9864 - Precision: 0.8576 - Recall: 0.3790 - Specificity: 0.9992 - F1: 0.4829 - Loss: 0.0030\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 15:11:00\n",
      "Accuracy: 0.9864 - Precision: 0.8577 - Recall: 0.3808 - Specificity: 0.9992 - F1: 0.4845 - Loss: 0.0030\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 15:11:11\n",
      "Accuracy: 0.9864 - Precision: 0.8575 - Recall: 0.3820 - Specificity: 0.9992 - F1: 0.4856 - Loss: 0.0030\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 15:11:22\n",
      "Accuracy: 0.9864 - Precision: 0.8579 - Recall: 0.3831 - Specificity: 0.9992 - F1: 0.4869 - Loss: 0.0030\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 15:11:31\n",
      "Accuracy: 0.9864 - Precision: 0.8581 - Recall: 0.3841 - Specificity: 0.9992 - F1: 0.4880 - Loss: 0.0030\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 15:11:40\n",
      "Accuracy: 0.9865 - Precision: 0.8583 - Recall: 0.3849 - Specificity: 0.9991 - F1: 0.4890 - Loss: 0.0030\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 15:11:49\n",
      "Accuracy: 0.9865 - Precision: 0.8589 - Recall: 0.3856 - Specificity: 0.9992 - F1: 0.4900 - Loss: 0.0030\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 15:11:58\n",
      "Accuracy: 0.9865 - Precision: 0.8595 - Recall: 0.3865 - Specificity: 0.9992 - F1: 0.4911 - Loss: 0.0030\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 15:12:07\n",
      "Accuracy: 0.9865 - Precision: 0.8598 - Recall: 0.3875 - Specificity: 0.9992 - F1: 0.4922 - Loss: 0.0030\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 15:12:16\n",
      "Accuracy: 0.9865 - Precision: 0.8591 - Recall: 0.3888 - Specificity: 0.9991 - F1: 0.4932 - Loss: 0.0030\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 15:12:24\n",
      "Accuracy: 0.9866 - Precision: 0.8595 - Recall: 0.3900 - Specificity: 0.9991 - F1: 0.4945 - Loss: 0.0030\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 15:12:33\n",
      "Accuracy: 0.9866 - Precision: 0.8599 - Recall: 0.3906 - Specificity: 0.9991 - F1: 0.4954 - Loss: 0.0030\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 15:12:42\n",
      "Accuracy: 0.9866 - Precision: 0.8603 - Recall: 0.3917 - Specificity: 0.9991 - F1: 0.4966 - Loss: 0.0030\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 15:12:51\n",
      "Accuracy: 0.9866 - Precision: 0.8602 - Recall: 0.3923 - Specificity: 0.9991 - F1: 0.4973 - Loss: 0.0030\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 15:13:00\n",
      "Accuracy: 0.9866 - Precision: 0.8604 - Recall: 0.3930 - Specificity: 0.9991 - F1: 0.4981 - Loss: 0.0030\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 15:13:08\n",
      "Accuracy: 0.9866 - Precision: 0.8608 - Recall: 0.3935 - Specificity: 0.9991 - F1: 0.4989 - Loss: 0.0030\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 15:13:18\n",
      "Accuracy: 0.9866 - Precision: 0.8613 - Recall: 0.3943 - Specificity: 0.9991 - F1: 0.4999 - Loss: 0.0030\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 15:13:28\n",
      "Accuracy: 0.9867 - Precision: 0.8617 - Recall: 0.3954 - Specificity: 0.9991 - F1: 0.5012 - Loss: 0.0030\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 15:13:36\n",
      "Accuracy: 0.9867 - Precision: 0.8619 - Recall: 0.3972 - Specificity: 0.9991 - F1: 0.5027 - Loss: 0.0030\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 15:13:45\n",
      "Accuracy: 0.9867 - Precision: 0.8622 - Recall: 0.3988 - Specificity: 0.9991 - F1: 0.5042 - Loss: 0.0030\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 15:13:54\n",
      "Accuracy: 0.9868 - Precision: 0.8619 - Recall: 0.4001 - Specificity: 0.9991 - F1: 0.5053 - Loss: 0.0029\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 15:14:03\n",
      "Accuracy: 0.9868 - Precision: 0.8622 - Recall: 0.4011 - Specificity: 0.9991 - F1: 0.5064 - Loss: 0.0029\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 15:14:11\n",
      "Accuracy: 0.9868 - Precision: 0.8627 - Recall: 0.4017 - Specificity: 0.9991 - F1: 0.5073 - Loss: 0.0029\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 15:14:20\n",
      "Accuracy: 0.9868 - Precision: 0.8626 - Recall: 0.4023 - Specificity: 0.9991 - F1: 0.5079 - Loss: 0.0029\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 15:14:28\n",
      "Accuracy: 0.9869 - Precision: 0.8630 - Recall: 0.4028 - Specificity: 0.9991 - F1: 0.5086 - Loss: 0.0029\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 15:14:37\n",
      "Accuracy: 0.9869 - Precision: 0.8635 - Recall: 0.4038 - Specificity: 0.9991 - F1: 0.5098 - Loss: 0.0029\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 15:14:45\n",
      "Accuracy: 0.9869 - Precision: 0.8632 - Recall: 0.4051 - Specificity: 0.9991 - F1: 0.5109 - Loss: 0.0029\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 15:14:56\n",
      "Accuracy: 0.9869 - Precision: 0.8633 - Recall: 0.4064 - Specificity: 0.9991 - F1: 0.5121 - Loss: 0.0029\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 15:15:05\n",
      "Accuracy: 0.9870 - Precision: 0.8634 - Recall: 0.4077 - Specificity: 0.9991 - F1: 0.5133 - Loss: 0.0029\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 15:15:14\n",
      "Accuracy: 0.9870 - Precision: 0.8633 - Recall: 0.4080 - Specificity: 0.9991 - F1: 0.5138 - Loss: 0.0029\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 15:15:25\n",
      "Accuracy: 0.9870 - Precision: 0.8633 - Recall: 0.4076 - Specificity: 0.9991 - F1: 0.5136 - Loss: 0.0029\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 15:15:34\n",
      "Accuracy: 0.9869 - Precision: 0.8629 - Recall: 0.4067 - Specificity: 0.9991 - F1: 0.5128 - Loss: 0.0029\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 15:15:43\n",
      "Accuracy: 0.9868 - Precision: 0.8628 - Recall: 0.4054 - Specificity: 0.9991 - F1: 0.5113 - Loss: 0.0029\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 15:15:52\n",
      "Accuracy: 0.9868 - Precision: 0.8634 - Recall: 0.4041 - Specificity: 0.9991 - F1: 0.5100 - Loss: 0.0030\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 15:16:00\n",
      "Accuracy: 0.9868 - Precision: 0.8637 - Recall: 0.4030 - Specificity: 0.9991 - F1: 0.5089 - Loss: 0.0030\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 15:16:09\n",
      "Accuracy: 0.9867 - Precision: 0.8642 - Recall: 0.4018 - Specificity: 0.9991 - F1: 0.5077 - Loss: 0.0030\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 15:16:18\n",
      "Accuracy: 0.9867 - Precision: 0.8638 - Recall: 0.4006 - Specificity: 0.9991 - F1: 0.5065 - Loss: 0.0030\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 15:16:26\n",
      "Accuracy: 0.9866 - Precision: 0.8643 - Recall: 0.4001 - Specificity: 0.9991 - F1: 0.5062 - Loss: 0.0030\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 15:16:35\n",
      "Accuracy: 0.9866 - Precision: 0.8639 - Recall: 0.3995 - Specificity: 0.9991 - F1: 0.5057 - Loss: 0.0030\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 15:16:44\n",
      "Accuracy: 0.9866 - Precision: 0.8635 - Recall: 0.3993 - Specificity: 0.9991 - F1: 0.5056 - Loss: 0.0030\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 15:16:53\n",
      "Accuracy: 0.9866 - Precision: 0.8634 - Recall: 0.3998 - Specificity: 0.9991 - F1: 0.5062 - Loss: 0.0030\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 15:17:01\n",
      "Accuracy: 0.9866 - Precision: 0.8637 - Recall: 0.3996 - Specificity: 0.9991 - F1: 0.5063 - Loss: 0.0030\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 15:17:11\n",
      "Accuracy: 0.9866 - Precision: 0.8641 - Recall: 0.3989 - Specificity: 0.9991 - F1: 0.5057 - Loss: 0.0030\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 15:17:21\n",
      "Accuracy: 0.9866 - Precision: 0.8643 - Recall: 0.3989 - Specificity: 0.9991 - F1: 0.5060 - Loss: 0.0030\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 15:17:31\n",
      "Accuracy: 0.9866 - Precision: 0.8642 - Recall: 0.3995 - Specificity: 0.9991 - F1: 0.5066 - Loss: 0.0030\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 15:17:41\n",
      "Accuracy: 0.9866 - Precision: 0.8638 - Recall: 0.3991 - Specificity: 0.9991 - F1: 0.5063 - Loss: 0.0030\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 15:17:50\n",
      "Accuracy: 0.9866 - Precision: 0.8639 - Recall: 0.3990 - Specificity: 0.9991 - F1: 0.5064 - Loss: 0.0030\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 15:17:58\n",
      "Accuracy: 0.9866 - Precision: 0.8640 - Recall: 0.3991 - Specificity: 0.9991 - F1: 0.5067 - Loss: 0.0030\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 15:18:07\n",
      "Accuracy: 0.9865 - Precision: 0.8642 - Recall: 0.3985 - Specificity: 0.9991 - F1: 0.5063 - Loss: 0.0030\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 15:18:16\n",
      "Accuracy: 0.9865 - Precision: 0.8644 - Recall: 0.3978 - Specificity: 0.9991 - F1: 0.5057 - Loss: 0.0031\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 15:18:25\n",
      "Accuracy: 0.9864 - Precision: 0.8647 - Recall: 0.3971 - Specificity: 0.9991 - F1: 0.5051 - Loss: 0.0031\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 15:18:33\n",
      "Accuracy: 0.9864 - Precision: 0.8649 - Recall: 0.3967 - Specificity: 0.9991 - F1: 0.5049 - Loss: 0.0031\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 15:18:42\n",
      "Accuracy: 0.9863 - Precision: 0.8649 - Recall: 0.3966 - Specificity: 0.9991 - F1: 0.5050 - Loss: 0.0031\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 15:18:52\n",
      "Accuracy: 0.9863 - Precision: 0.8646 - Recall: 0.3963 - Specificity: 0.9991 - F1: 0.5049 - Loss: 0.0031\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 15:19:01\n",
      "Accuracy: 0.9863 - Precision: 0.8651 - Recall: 0.3958 - Specificity: 0.9991 - F1: 0.5045 - Loss: 0.0031\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 15:19:10\n",
      "Accuracy: 0.9862 - Precision: 0.8655 - Recall: 0.3954 - Specificity: 0.9991 - F1: 0.5043 - Loss: 0.0031\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 15:19:19\n",
      "Accuracy: 0.9859 - Precision: 0.8637 - Recall: 0.3938 - Specificity: 0.9991 - F1: 0.5023 - Loss: 0.0034\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 15:19:29\n",
      "Accuracy: 0.9857 - Precision: 0.8631 - Recall: 0.3924 - Specificity: 0.9991 - F1: 0.5007 - Loss: 0.0034\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 15:19:39\n",
      "Accuracy: 0.9854 - Precision: 0.8629 - Recall: 0.3910 - Specificity: 0.9991 - F1: 0.4990 - Loss: 0.0035\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 15:19:47\n",
      "Accuracy: 0.9851 - Precision: 0.8629 - Recall: 0.3896 - Specificity: 0.9991 - F1: 0.4973 - Loss: 0.0036\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 15:19:56\n",
      "Accuracy: 0.9848 - Precision: 0.8629 - Recall: 0.3881 - Specificity: 0.9991 - F1: 0.4954 - Loss: 0.0037\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 15:20:04\n",
      "Accuracy: 0.9846 - Precision: 0.8627 - Recall: 0.3866 - Specificity: 0.9991 - F1: 0.4936 - Loss: 0.0037\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 15:20:13\n",
      "Accuracy: 0.9843 - Precision: 0.8629 - Recall: 0.3850 - Specificity: 0.9991 - F1: 0.4917 - Loss: 0.0038\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 15:20:22\n",
      "Accuracy: 0.9841 - Precision: 0.8626 - Recall: 0.3835 - Specificity: 0.9991 - F1: 0.4898 - Loss: 0.0039\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 15:20:30\n",
      "Accuracy: 0.9837 - Precision: 0.8630 - Recall: 0.3820 - Specificity: 0.9991 - F1: 0.4879 - Loss: 0.0040\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 15:20:39\n",
      "Accuracy: 0.9834 - Precision: 0.8621 - Recall: 0.3806 - Specificity: 0.9991 - F1: 0.4861 - Loss: 0.0040\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 15:20:48\n",
      "Accuracy: 0.9832 - Precision: 0.8611 - Recall: 0.3805 - Specificity: 0.9990 - F1: 0.4860 - Loss: 0.0041\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 15:20:57\n",
      "Accuracy: 0.9831 - Precision: 0.8615 - Recall: 0.3790 - Specificity: 0.9990 - F1: 0.4841 - Loss: 0.0041\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 15:21:06\n",
      "Accuracy: 0.9828 - Precision: 0.8581 - Recall: 0.3775 - Specificity: 0.9990 - F1: 0.4822 - Loss: 0.0042\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 15:21:15\n",
      "Accuracy: 0.9827 - Precision: 0.8587 - Recall: 0.3760 - Specificity: 0.9990 - F1: 0.4803 - Loss: 0.0043\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 15:21:25\n",
      "Accuracy: 0.9824 - Precision: 0.8583 - Recall: 0.3745 - Specificity: 0.9990 - F1: 0.4784 - Loss: 0.0043\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 15:21:35\n",
      "Accuracy: 0.9820 - Precision: 0.8588 - Recall: 0.3731 - Specificity: 0.9990 - F1: 0.4765 - Loss: 0.0044\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 15:21:44\n",
      "Accuracy: 0.9818 - Precision: 0.8594 - Recall: 0.3716 - Specificity: 0.9990 - F1: 0.4746 - Loss: 0.0044\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 15:21:53\n",
      "Accuracy: 0.9816 - Precision: 0.8561 - Recall: 0.3702 - Specificity: 0.9990 - F1: 0.4728 - Loss: 0.0045\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 15:22:02\n",
      "Accuracy: 0.9816 - Precision: 0.8527 - Recall: 0.3687 - Specificity: 0.9990 - F1: 0.4710 - Loss: 0.0045\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 15:22:11\n",
      "Accuracy: 0.9815 - Precision: 0.8494 - Recall: 0.3673 - Specificity: 0.9991 - F1: 0.4691 - Loss: 0.0045\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 15:22:20\n",
      "Accuracy: 0.9815 - Precision: 0.8462 - Recall: 0.3659 - Specificity: 0.9991 - F1: 0.4673 - Loss: 0.0045\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 15:22:29\n",
      "Accuracy: 0.9815 - Precision: 0.8429 - Recall: 0.3645 - Specificity: 0.9991 - F1: 0.4655 - Loss: 0.0046\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 15:22:38\n",
      "Accuracy: 0.9814 - Precision: 0.8435 - Recall: 0.3631 - Specificity: 0.9991 - F1: 0.4638 - Loss: 0.0046\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 15:22:47\n",
      "Accuracy: 0.9813 - Precision: 0.8426 - Recall: 0.3617 - Specificity: 0.9991 - F1: 0.4620 - Loss: 0.0046\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 15:22:55\n",
      "Accuracy: 0.9813 - Precision: 0.8425 - Recall: 0.3604 - Specificity: 0.9991 - F1: 0.4603 - Loss: 0.0046\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 15:23:05\n",
      "Accuracy: 0.9812 - Precision: 0.8421 - Recall: 0.3590 - Specificity: 0.9991 - F1: 0.4585 - Loss: 0.0047\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 15:23:14\n",
      "Accuracy: 0.9812 - Precision: 0.8389 - Recall: 0.3577 - Specificity: 0.9991 - F1: 0.4568 - Loss: 0.0047\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 15:23:23\n",
      "Accuracy: 0.9812 - Precision: 0.8358 - Recall: 0.3563 - Specificity: 0.9991 - F1: 0.4551 - Loss: 0.0047\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 15:23:34\n",
      "Accuracy: 0.9811 - Precision: 0.8326 - Recall: 0.3550 - Specificity: 0.9991 - F1: 0.4534 - Loss: 0.0047\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 15:23:43\n",
      "Accuracy: 0.9811 - Precision: 0.8295 - Recall: 0.3537 - Specificity: 0.9991 - F1: 0.4517 - Loss: 0.0047\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 15:23:52\n",
      "Accuracy: 0.9811 - Precision: 0.8265 - Recall: 0.3524 - Specificity: 0.9991 - F1: 0.4501 - Loss: 0.0047\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 15:24:02\n",
      "Accuracy: 0.9811 - Precision: 0.8271 - Recall: 0.3511 - Specificity: 0.9991 - F1: 0.4484 - Loss: 0.0047\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 15:24:13\n",
      "Accuracy: 0.9810 - Precision: 0.8277 - Recall: 0.3498 - Specificity: 0.9991 - F1: 0.4467 - Loss: 0.0047\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 15:24:22\n",
      "Accuracy: 0.9810 - Precision: 0.8247 - Recall: 0.3485 - Specificity: 0.9991 - F1: 0.4451 - Loss: 0.0048\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 15:24:30\n",
      "Accuracy: 0.9810 - Precision: 0.8217 - Recall: 0.3472 - Specificity: 0.9991 - F1: 0.4435 - Loss: 0.0048\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 15:24:40\n",
      "Accuracy: 0.9809 - Precision: 0.8187 - Recall: 0.3460 - Specificity: 0.9991 - F1: 0.4419 - Loss: 0.0048\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 15:24:49\n",
      "Accuracy: 0.9809 - Precision: 0.8157 - Recall: 0.3447 - Specificity: 0.9991 - F1: 0.4403 - Loss: 0.0048\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 15:24:58\n",
      "Accuracy: 0.9809 - Precision: 0.8128 - Recall: 0.3435 - Specificity: 0.9991 - F1: 0.4387 - Loss: 0.0048\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 15:25:07\n",
      "Accuracy: 0.9809 - Precision: 0.8099 - Recall: 0.3422 - Specificity: 0.9991 - F1: 0.4371 - Loss: 0.0048\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 15:25:16\n",
      "Accuracy: 0.9809 - Precision: 0.8070 - Recall: 0.3410 - Specificity: 0.9991 - F1: 0.4355 - Loss: 0.0048\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 15:25:26\n",
      "Accuracy: 0.9809 - Precision: 0.8041 - Recall: 0.3398 - Specificity: 0.9991 - F1: 0.4340 - Loss: 0.0048\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 15:25:37\n",
      "Accuracy: 0.9809 - Precision: 0.8012 - Recall: 0.3386 - Specificity: 0.9991 - F1: 0.4324 - Loss: 0.0048\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 15:25:46\n",
      "Accuracy: 0.9809 - Precision: 0.7984 - Recall: 0.3374 - Specificity: 0.9991 - F1: 0.4309 - Loss: 0.0048\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 15:25:55\n",
      "Accuracy: 0.9809 - Precision: 0.7956 - Recall: 0.3362 - Specificity: 0.9991 - F1: 0.4294 - Loss: 0.0048\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 15:26:03\n",
      "Accuracy: 0.9809 - Precision: 0.7928 - Recall: 0.3350 - Specificity: 0.9991 - F1: 0.4279 - Loss: 0.0048\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 15:26:12\n",
      "Accuracy: 0.9809 - Precision: 0.7900 - Recall: 0.3338 - Specificity: 0.9991 - F1: 0.4264 - Loss: 0.0048\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 15:26:21\n",
      "Accuracy: 0.9809 - Precision: 0.7872 - Recall: 0.3327 - Specificity: 0.9991 - F1: 0.4249 - Loss: 0.0048\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 15:26:30\n",
      "Accuracy: 0.9808 - Precision: 0.7845 - Recall: 0.3315 - Specificity: 0.9991 - F1: 0.4234 - Loss: 0.0048\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 15:26:39\n",
      "Accuracy: 0.9808 - Precision: 0.7818 - Recall: 0.3303 - Specificity: 0.9991 - F1: 0.4219 - Loss: 0.0048\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 15:26:48\n",
      "Accuracy: 0.9808 - Precision: 0.7791 - Recall: 0.3292 - Specificity: 0.9992 - F1: 0.4205 - Loss: 0.0048\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 15:26:58\n",
      "Accuracy: 0.9807 - Precision: 0.7764 - Recall: 0.3281 - Specificity: 0.9992 - F1: 0.4190 - Loss: 0.0049\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 15:27:07\n",
      "Accuracy: 0.9807 - Precision: 0.7737 - Recall: 0.3269 - Specificity: 0.9992 - F1: 0.4176 - Loss: 0.0049\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 15:27:16\n",
      "Accuracy: 0.9807 - Precision: 0.7710 - Recall: 0.3258 - Specificity: 0.9992 - F1: 0.4161 - Loss: 0.0049\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 15:27:26\n",
      "Accuracy: 0.9807 - Precision: 0.7684 - Recall: 0.3247 - Specificity: 0.9992 - F1: 0.4147 - Loss: 0.0049\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 15:27:36\n",
      "Accuracy: 0.9806 - Precision: 0.7658 - Recall: 0.3236 - Specificity: 0.9992 - F1: 0.4133 - Loss: 0.0049\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 15:27:46\n",
      "Accuracy: 0.9806 - Precision: 0.7632 - Recall: 0.3225 - Specificity: 0.9992 - F1: 0.4119 - Loss: 0.0049\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 15:27:55\n",
      "Accuracy: 0.9806 - Precision: 0.7606 - Recall: 0.3214 - Specificity: 0.9992 - F1: 0.4105 - Loss: 0.0049\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 15:28:04\n",
      "Accuracy: 0.9806 - Precision: 0.7581 - Recall: 0.3203 - Specificity: 0.9992 - F1: 0.4091 - Loss: 0.0049\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 15:28:13\n",
      "Accuracy: 0.9805 - Precision: 0.7555 - Recall: 0.3193 - Specificity: 0.9992 - F1: 0.4078 - Loss: 0.0049\n",
      "\n",
      "Epoch 5/20\n",
      "Validation - Accuracy: 0.9786, Precision: 0.0000, Recall: 0.0000, Specificity: 1.0000, F1: 0.0000, Loss: 0.0051\n",
      "\n",
      "\n",
      "Epoch 6/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 15:36:03\n",
      "Accuracy: 0.9738 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0061\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 15:36:12\n",
      "Accuracy: 0.9722 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0063\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 15:36:20\n",
      "Accuracy: 0.9711 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0059\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 15:36:29\n",
      "Accuracy: 0.9742 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0054\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 15:36:38\n",
      "Accuracy: 0.9762 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0051\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 15:36:46\n",
      "Accuracy: 0.9762 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0050\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 15:36:55\n",
      "Accuracy: 0.9775 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0046\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 15:37:04\n",
      "Accuracy: 0.9781 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0045\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 15:37:14\n",
      "Accuracy: 0.9788 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0043\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 15:37:23\n",
      "Accuracy: 0.9792 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0042\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 15:37:31\n",
      "Accuracy: 0.9795 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0041\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 15:37:41\n",
      "Accuracy: 0.9797 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0040\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 15:37:51\n",
      "Accuracy: 0.9798 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 15:37:59\n",
      "Accuracy: 0.9800 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0040\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 15:38:08\n",
      "Accuracy: 0.9802 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 15:38:16\n",
      "Accuracy: 0.9797 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0040\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 15:38:25\n",
      "Accuracy: 0.9800 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 15:38:33\n",
      "Accuracy: 0.9799 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 15:38:42\n",
      "Accuracy: 0.9799 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 15:38:50\n",
      "Accuracy: 0.9801 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 15:38:59\n",
      "Accuracy: 0.9801 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 15:39:07\n",
      "Accuracy: 0.9799 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 15:39:16\n",
      "Accuracy: 0.9798 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 15:39:25\n",
      "Accuracy: 0.9796 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 15:39:33\n",
      "Accuracy: 0.9796 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 15:39:43\n",
      "Accuracy: 0.9798 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 15:39:52\n",
      "Accuracy: 0.9798 - Precision: 0.0370 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 15:40:01\n",
      "Accuracy: 0.9797 - Precision: 0.0357 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0038\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 15:40:09\n",
      "Accuracy: 0.9794 - Precision: 0.0345 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 15:40:17\n",
      "Accuracy: 0.9793 - Precision: 0.0667 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0039\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 15:40:25\n",
      "Accuracy: 0.9795 - Precision: 0.0882 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0038\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 15:40:34\n",
      "Accuracy: 0.9794 - Precision: 0.1063 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0038\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 15:40:43\n",
      "Accuracy: 0.9795 - Precision: 0.1232 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0038\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 15:40:51\n",
      "Accuracy: 0.9793 - Precision: 0.1441 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0038\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 15:41:00\n",
      "Accuracy: 0.9793 - Precision: 0.1686 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0038\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 15:41:08\n",
      "Accuracy: 0.9793 - Precision: 0.1840 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0002 - Loss: 0.0038\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 15:41:17\n",
      "Accuracy: 0.9793 - Precision: 0.2043 - Recall: 0.0002 - Specificity: 1.0000 - F1: 0.0004 - Loss: 0.0037\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 15:41:25\n",
      "Accuracy: 0.9792 - Precision: 0.2204 - Recall: 0.0003 - Specificity: 1.0000 - F1: 0.0007 - Loss: 0.0037\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 15:41:34\n",
      "Accuracy: 0.9792 - Precision: 0.2382 - Recall: 0.0009 - Specificity: 1.0000 - F1: 0.0018 - Loss: 0.0037\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 15:41:43\n",
      "Accuracy: 0.9792 - Precision: 0.2561 - Recall: 0.0017 - Specificity: 1.0000 - F1: 0.0034 - Loss: 0.0037\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 15:41:52\n",
      "Accuracy: 0.9790 - Precision: 0.2718 - Recall: 0.0026 - Specificity: 1.0000 - F1: 0.0050 - Loss: 0.0037\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 15:42:01\n",
      "Accuracy: 0.9790 - Precision: 0.2887 - Recall: 0.0034 - Specificity: 1.0000 - F1: 0.0066 - Loss: 0.0037\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 15:42:10\n",
      "Accuracy: 0.9790 - Precision: 0.3046 - Recall: 0.0051 - Specificity: 1.0000 - F1: 0.0098 - Loss: 0.0037\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 15:42:19\n",
      "Accuracy: 0.9791 - Precision: 0.3190 - Recall: 0.0074 - Specificity: 1.0000 - F1: 0.0139 - Loss: 0.0037\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 15:42:28\n",
      "Accuracy: 0.9792 - Precision: 0.3277 - Recall: 0.0096 - Specificity: 1.0000 - F1: 0.0177 - Loss: 0.0037\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 15:42:37\n",
      "Accuracy: 0.9792 - Precision: 0.3416 - Recall: 0.0106 - Specificity: 1.0000 - F1: 0.0196 - Loss: 0.0037\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 15:42:45\n",
      "Accuracy: 0.9792 - Precision: 0.3546 - Recall: 0.0114 - Specificity: 1.0000 - F1: 0.0211 - Loss: 0.0036\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 15:42:54\n",
      "Accuracy: 0.9791 - Precision: 0.3678 - Recall: 0.0126 - Specificity: 1.0000 - F1: 0.0233 - Loss: 0.0036\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 15:43:03\n",
      "Accuracy: 0.9791 - Precision: 0.3796 - Recall: 0.0140 - Specificity: 1.0000 - F1: 0.0260 - Loss: 0.0036\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 15:43:13\n",
      "Accuracy: 0.9791 - Precision: 0.3915 - Recall: 0.0163 - Specificity: 1.0000 - F1: 0.0300 - Loss: 0.0036\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 15:43:21\n",
      "Accuracy: 0.9792 - Precision: 0.4021 - Recall: 0.0191 - Specificity: 1.0000 - F1: 0.0347 - Loss: 0.0036\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 15:43:31\n",
      "Accuracy: 0.9792 - Precision: 0.4113 - Recall: 0.0219 - Specificity: 1.0000 - F1: 0.0393 - Loss: 0.0036\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 15:43:40\n",
      "Accuracy: 0.9793 - Precision: 0.4213 - Recall: 0.0250 - Specificity: 1.0000 - F1: 0.0445 - Loss: 0.0036\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 15:43:50\n",
      "Accuracy: 0.9794 - Precision: 0.4311 - Recall: 0.0289 - Specificity: 1.0000 - F1: 0.0507 - Loss: 0.0035\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 15:43:59\n",
      "Accuracy: 0.9795 - Precision: 0.4402 - Recall: 0.0329 - Specificity: 0.9999 - F1: 0.0569 - Loss: 0.0035\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 15:44:09\n",
      "Accuracy: 0.9796 - Precision: 0.4479 - Recall: 0.0382 - Specificity: 0.9999 - F1: 0.0645 - Loss: 0.0035\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 15:44:20\n",
      "Accuracy: 0.9797 - Precision: 0.4552 - Recall: 0.0431 - Specificity: 0.9999 - F1: 0.0714 - Loss: 0.0035\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 15:44:29\n",
      "Accuracy: 0.9798 - Precision: 0.4627 - Recall: 0.0477 - Specificity: 0.9999 - F1: 0.0782 - Loss: 0.0035\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 15:44:38\n",
      "Accuracy: 0.9800 - Precision: 0.4712 - Recall: 0.0518 - Specificity: 0.9999 - F1: 0.0844 - Loss: 0.0034\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 15:44:47\n",
      "Accuracy: 0.9800 - Precision: 0.4772 - Recall: 0.0553 - Specificity: 0.9999 - F1: 0.0896 - Loss: 0.0034\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 15:44:56\n",
      "Accuracy: 0.9801 - Precision: 0.4831 - Recall: 0.0591 - Specificity: 0.9999 - F1: 0.0951 - Loss: 0.0034\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 15:45:05\n",
      "Accuracy: 0.9802 - Precision: 0.4893 - Recall: 0.0637 - Specificity: 0.9999 - F1: 0.1015 - Loss: 0.0034\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 15:45:14\n",
      "Accuracy: 0.9803 - Precision: 0.4962 - Recall: 0.0687 - Specificity: 0.9998 - F1: 0.1084 - Loss: 0.0034\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 15:45:23\n",
      "Accuracy: 0.9804 - Precision: 0.5029 - Recall: 0.0738 - Specificity: 0.9998 - F1: 0.1154 - Loss: 0.0034\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 15:45:31\n",
      "Accuracy: 0.9805 - Precision: 0.5094 - Recall: 0.0779 - Specificity: 0.9998 - F1: 0.1212 - Loss: 0.0034\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 15:45:40\n",
      "Accuracy: 0.9805 - Precision: 0.5150 - Recall: 0.0813 - Specificity: 0.9998 - F1: 0.1262 - Loss: 0.0034\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 15:45:51\n",
      "Accuracy: 0.9805 - Precision: 0.5208 - Recall: 0.0865 - Specificity: 0.9998 - F1: 0.1330 - Loss: 0.0034\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 15:46:00\n",
      "Accuracy: 0.9807 - Precision: 0.5260 - Recall: 0.0930 - Specificity: 0.9998 - F1: 0.1408 - Loss: 0.0034\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 15:46:09\n",
      "Accuracy: 0.9808 - Precision: 0.5319 - Recall: 0.1006 - Specificity: 0.9998 - F1: 0.1495 - Loss: 0.0034\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 15:46:17\n",
      "Accuracy: 0.9810 - Precision: 0.5378 - Recall: 0.1076 - Specificity: 0.9998 - F1: 0.1578 - Loss: 0.0034\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 15:46:26\n",
      "Accuracy: 0.9811 - Precision: 0.5420 - Recall: 0.1130 - Specificity: 0.9997 - F1: 0.1643 - Loss: 0.0033\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 15:46:35\n",
      "Accuracy: 0.9811 - Precision: 0.5459 - Recall: 0.1170 - Specificity: 0.9997 - F1: 0.1695 - Loss: 0.0033\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 15:46:43\n",
      "Accuracy: 0.9812 - Precision: 0.5520 - Recall: 0.1200 - Specificity: 0.9997 - F1: 0.1741 - Loss: 0.0034\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 15:46:52\n",
      "Accuracy: 0.9812 - Precision: 0.5576 - Recall: 0.1245 - Specificity: 0.9997 - F1: 0.1800 - Loss: 0.0034\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 15:47:01\n",
      "Accuracy: 0.9813 - Precision: 0.5613 - Recall: 0.1315 - Specificity: 0.9997 - F1: 0.1873 - Loss: 0.0034\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 15:47:10\n",
      "Accuracy: 0.9814 - Precision: 0.5648 - Recall: 0.1390 - Specificity: 0.9996 - F1: 0.1949 - Loss: 0.0034\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 15:47:19\n",
      "Accuracy: 0.9816 - Precision: 0.5685 - Recall: 0.1461 - Specificity: 0.9996 - F1: 0.2022 - Loss: 0.0033\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 15:47:28\n",
      "Accuracy: 0.9817 - Precision: 0.5737 - Recall: 0.1508 - Specificity: 0.9996 - F1: 0.2083 - Loss: 0.0033\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 15:47:37\n",
      "Accuracy: 0.9817 - Precision: 0.5789 - Recall: 0.1536 - Specificity: 0.9996 - F1: 0.2125 - Loss: 0.0033\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 15:47:47\n",
      "Accuracy: 0.9817 - Precision: 0.5839 - Recall: 0.1564 - Specificity: 0.9996 - F1: 0.2166 - Loss: 0.0033\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 15:47:56\n",
      "Accuracy: 0.9818 - Precision: 0.5886 - Recall: 0.1599 - Specificity: 0.9996 - F1: 0.2214 - Loss: 0.0033\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 15:48:05\n",
      "Accuracy: 0.9819 - Precision: 0.5910 - Recall: 0.1647 - Specificity: 0.9996 - F1: 0.2266 - Loss: 0.0033\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 15:48:14\n",
      "Accuracy: 0.9820 - Precision: 0.5943 - Recall: 0.1696 - Specificity: 0.9996 - F1: 0.2321 - Loss: 0.0033\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 15:48:22\n",
      "Accuracy: 0.9821 - Precision: 0.5976 - Recall: 0.1740 - Specificity: 0.9996 - F1: 0.2373 - Loss: 0.0033\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 15:48:31\n",
      "Accuracy: 0.9822 - Precision: 0.6019 - Recall: 0.1792 - Specificity: 0.9996 - F1: 0.2433 - Loss: 0.0033\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 15:48:40\n",
      "Accuracy: 0.9823 - Precision: 0.6053 - Recall: 0.1824 - Specificity: 0.9996 - F1: 0.2475 - Loss: 0.0033\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 15:48:48\n",
      "Accuracy: 0.9824 - Precision: 0.6094 - Recall: 0.1867 - Specificity: 0.9996 - F1: 0.2528 - Loss: 0.0033\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 15:48:57\n",
      "Accuracy: 0.9825 - Precision: 0.6126 - Recall: 0.1909 - Specificity: 0.9995 - F1: 0.2578 - Loss: 0.0033\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 15:49:05\n",
      "Accuracy: 0.9825 - Precision: 0.6166 - Recall: 0.1952 - Specificity: 0.9995 - F1: 0.2629 - Loss: 0.0033\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 15:49:15\n",
      "Accuracy: 0.9826 - Precision: 0.6201 - Recall: 0.1993 - Specificity: 0.9995 - F1: 0.2679 - Loss: 0.0033\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 15:49:24\n",
      "Accuracy: 0.9827 - Precision: 0.6232 - Recall: 0.2046 - Specificity: 0.9995 - F1: 0.2734 - Loss: 0.0032\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 15:49:32\n",
      "Accuracy: 0.9828 - Precision: 0.6250 - Recall: 0.2102 - Specificity: 0.9995 - F1: 0.2787 - Loss: 0.0032\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 15:49:41\n",
      "Accuracy: 0.9829 - Precision: 0.6282 - Recall: 0.2147 - Specificity: 0.9995 - F1: 0.2837 - Loss: 0.0032\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 15:49:51\n",
      "Accuracy: 0.9829 - Precision: 0.6318 - Recall: 0.2177 - Specificity: 0.9995 - F1: 0.2876 - Loss: 0.0032\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 15:50:00\n",
      "Accuracy: 0.9830 - Precision: 0.6335 - Recall: 0.2194 - Specificity: 0.9995 - F1: 0.2900 - Loss: 0.0032\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 15:50:09\n",
      "Accuracy: 0.9830 - Precision: 0.6362 - Recall: 0.2198 - Specificity: 0.9995 - F1: 0.2912 - Loss: 0.0032\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 15:50:17\n",
      "Accuracy: 0.9830 - Precision: 0.6399 - Recall: 0.2203 - Specificity: 0.9995 - F1: 0.2926 - Loss: 0.0032\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 15:50:26\n",
      "Accuracy: 0.9830 - Precision: 0.6427 - Recall: 0.2215 - Specificity: 0.9995 - F1: 0.2946 - Loss: 0.0032\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 15:50:36\n",
      "Accuracy: 0.9831 - Precision: 0.6449 - Recall: 0.2229 - Specificity: 0.9995 - F1: 0.2967 - Loss: 0.0032\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 15:50:45\n",
      "Accuracy: 0.9831 - Precision: 0.6474 - Recall: 0.2247 - Specificity: 0.9995 - F1: 0.2994 - Loss: 0.0032\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 15:50:54\n",
      "Accuracy: 0.9832 - Precision: 0.6490 - Recall: 0.2269 - Specificity: 0.9995 - F1: 0.3021 - Loss: 0.0032\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 15:51:03\n",
      "Accuracy: 0.9832 - Precision: 0.6492 - Recall: 0.2280 - Specificity: 0.9994 - F1: 0.3035 - Loss: 0.0032\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 15:51:11\n",
      "Accuracy: 0.9833 - Precision: 0.6512 - Recall: 0.2292 - Specificity: 0.9994 - F1: 0.3054 - Loss: 0.0032\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 15:51:21\n",
      "Accuracy: 0.9833 - Precision: 0.6539 - Recall: 0.2299 - Specificity: 0.9994 - F1: 0.3068 - Loss: 0.0032\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 15:51:30\n",
      "Accuracy: 0.9833 - Precision: 0.6554 - Recall: 0.2310 - Specificity: 0.9994 - F1: 0.3085 - Loss: 0.0032\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 15:51:38\n",
      "Accuracy: 0.9834 - Precision: 0.6580 - Recall: 0.2321 - Specificity: 0.9994 - F1: 0.3104 - Loss: 0.0032\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 15:51:48\n",
      "Accuracy: 0.9834 - Precision: 0.6597 - Recall: 0.2332 - Specificity: 0.9994 - F1: 0.3121 - Loss: 0.0032\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 15:51:57\n",
      "Accuracy: 0.9835 - Precision: 0.6608 - Recall: 0.2342 - Specificity: 0.9994 - F1: 0.3136 - Loss: 0.0032\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 15:52:06\n",
      "Accuracy: 0.9835 - Precision: 0.6633 - Recall: 0.2366 - Specificity: 0.9994 - F1: 0.3167 - Loss: 0.0031\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 15:52:15\n",
      "Accuracy: 0.9836 - Precision: 0.6656 - Recall: 0.2397 - Specificity: 0.9994 - F1: 0.3202 - Loss: 0.0031\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 15:52:24\n",
      "Accuracy: 0.9837 - Precision: 0.6670 - Recall: 0.2418 - Specificity: 0.9994 - F1: 0.3228 - Loss: 0.0031\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 15:52:34\n",
      "Accuracy: 0.9837 - Precision: 0.6692 - Recall: 0.2441 - Specificity: 0.9994 - F1: 0.3257 - Loss: 0.0031\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 15:52:43\n",
      "Accuracy: 0.9838 - Precision: 0.6709 - Recall: 0.2466 - Specificity: 0.9994 - F1: 0.3286 - Loss: 0.0031\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 15:52:52\n",
      "Accuracy: 0.9838 - Precision: 0.6735 - Recall: 0.2484 - Specificity: 0.9994 - F1: 0.3311 - Loss: 0.0031\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 15:53:01\n",
      "Accuracy: 0.9839 - Precision: 0.6763 - Recall: 0.2498 - Specificity: 0.9994 - F1: 0.3332 - Loss: 0.0031\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 15:53:09\n",
      "Accuracy: 0.9839 - Precision: 0.6783 - Recall: 0.2515 - Specificity: 0.9994 - F1: 0.3356 - Loss: 0.0031\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 15:53:18\n",
      "Accuracy: 0.9839 - Precision: 0.6803 - Recall: 0.2536 - Specificity: 0.9994 - F1: 0.3382 - Loss: 0.0031\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 15:53:27\n",
      "Accuracy: 0.9840 - Precision: 0.6823 - Recall: 0.2565 - Specificity: 0.9994 - F1: 0.3414 - Loss: 0.0031\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 15:53:36\n",
      "Accuracy: 0.9840 - Precision: 0.6831 - Recall: 0.2603 - Specificity: 0.9994 - F1: 0.3448 - Loss: 0.0031\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 15:53:45\n",
      "Accuracy: 0.9841 - Precision: 0.6834 - Recall: 0.2641 - Specificity: 0.9993 - F1: 0.3479 - Loss: 0.0031\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 15:53:55\n",
      "Accuracy: 0.9841 - Precision: 0.6848 - Recall: 0.2662 - Specificity: 0.9993 - F1: 0.3504 - Loss: 0.0031\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 15:54:05\n",
      "Accuracy: 0.9842 - Precision: 0.6869 - Recall: 0.2673 - Specificity: 0.9993 - F1: 0.3521 - Loss: 0.0031\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 15:54:13\n",
      "Accuracy: 0.9841 - Precision: 0.6893 - Recall: 0.2682 - Specificity: 0.9993 - F1: 0.3537 - Loss: 0.0031\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 15:54:22\n",
      "Accuracy: 0.9842 - Precision: 0.6917 - Recall: 0.2697 - Specificity: 0.9993 - F1: 0.3558 - Loss: 0.0031\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 15:54:31\n",
      "Accuracy: 0.9842 - Precision: 0.6935 - Recall: 0.2712 - Specificity: 0.9993 - F1: 0.3579 - Loss: 0.0031\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 15:54:39\n",
      "Accuracy: 0.9843 - Precision: 0.6957 - Recall: 0.2734 - Specificity: 0.9993 - F1: 0.3606 - Loss: 0.0031\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 15:54:47\n",
      "Accuracy: 0.9843 - Precision: 0.6966 - Recall: 0.2755 - Specificity: 0.9993 - F1: 0.3629 - Loss: 0.0031\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 15:54:56\n",
      "Accuracy: 0.9844 - Precision: 0.6980 - Recall: 0.2769 - Specificity: 0.9993 - F1: 0.3647 - Loss: 0.0031\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 15:55:05\n",
      "Accuracy: 0.9844 - Precision: 0.7002 - Recall: 0.2784 - Specificity: 0.9993 - F1: 0.3668 - Loss: 0.0031\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 15:55:13\n",
      "Accuracy: 0.9844 - Precision: 0.7021 - Recall: 0.2794 - Specificity: 0.9993 - F1: 0.3684 - Loss: 0.0031\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 15:55:22\n",
      "Accuracy: 0.9844 - Precision: 0.7040 - Recall: 0.2807 - Specificity: 0.9993 - F1: 0.3702 - Loss: 0.0031\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 15:55:31\n",
      "Accuracy: 0.9845 - Precision: 0.7054 - Recall: 0.2833 - Specificity: 0.9993 - F1: 0.3729 - Loss: 0.0031\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 15:55:40\n",
      "Accuracy: 0.9845 - Precision: 0.7069 - Recall: 0.2851 - Specificity: 0.9993 - F1: 0.3752 - Loss: 0.0031\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 15:55:49\n",
      "Accuracy: 0.9846 - Precision: 0.7082 - Recall: 0.2880 - Specificity: 0.9993 - F1: 0.3781 - Loss: 0.0031\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 15:55:59\n",
      "Accuracy: 0.9846 - Precision: 0.7097 - Recall: 0.2910 - Specificity: 0.9993 - F1: 0.3811 - Loss: 0.0030\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 15:56:08\n",
      "Accuracy: 0.9847 - Precision: 0.7109 - Recall: 0.2937 - Specificity: 0.9993 - F1: 0.3838 - Loss: 0.0030\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 15:56:17\n",
      "Accuracy: 0.9847 - Precision: 0.7126 - Recall: 0.2957 - Specificity: 0.9993 - F1: 0.3862 - Loss: 0.0030\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 15:56:26\n",
      "Accuracy: 0.9847 - Precision: 0.7141 - Recall: 0.2977 - Specificity: 0.9993 - F1: 0.3885 - Loss: 0.0030\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 15:56:34\n",
      "Accuracy: 0.9848 - Precision: 0.7159 - Recall: 0.2990 - Specificity: 0.9993 - F1: 0.3904 - Loss: 0.0030\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 15:56:43\n",
      "Accuracy: 0.9848 - Precision: 0.7178 - Recall: 0.3013 - Specificity: 0.9993 - F1: 0.3929 - Loss: 0.0030\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 15:56:51\n",
      "Accuracy: 0.9849 - Precision: 0.7191 - Recall: 0.3038 - Specificity: 0.9993 - F1: 0.3955 - Loss: 0.0030\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 15:57:00\n",
      "Accuracy: 0.9849 - Precision: 0.7206 - Recall: 0.3058 - Specificity: 0.9993 - F1: 0.3978 - Loss: 0.0030\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 15:57:08\n",
      "Accuracy: 0.9849 - Precision: 0.7214 - Recall: 0.3083 - Specificity: 0.9993 - F1: 0.4002 - Loss: 0.0030\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 15:57:16\n",
      "Accuracy: 0.9850 - Precision: 0.7220 - Recall: 0.3111 - Specificity: 0.9992 - F1: 0.4027 - Loss: 0.0030\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 15:57:25\n",
      "Accuracy: 0.9850 - Precision: 0.7234 - Recall: 0.3128 - Specificity: 0.9992 - F1: 0.4047 - Loss: 0.0030\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 15:57:34\n",
      "Accuracy: 0.9850 - Precision: 0.7246 - Recall: 0.3146 - Specificity: 0.9992 - F1: 0.4067 - Loss: 0.0030\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 15:57:43\n",
      "Accuracy: 0.9851 - Precision: 0.7262 - Recall: 0.3157 - Specificity: 0.9992 - F1: 0.4083 - Loss: 0.0030\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 15:57:52\n",
      "Accuracy: 0.9851 - Precision: 0.7278 - Recall: 0.3174 - Specificity: 0.9992 - F1: 0.4103 - Loss: 0.0030\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 15:58:03\n",
      "Accuracy: 0.9851 - Precision: 0.7273 - Recall: 0.3167 - Specificity: 0.9992 - F1: 0.4098 - Loss: 0.0030\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 15:58:13\n",
      "Accuracy: 0.9851 - Precision: 0.7286 - Recall: 0.3180 - Specificity: 0.9992 - F1: 0.4115 - Loss: 0.0030\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 15:58:22\n",
      "Accuracy: 0.9851 - Precision: 0.7297 - Recall: 0.3187 - Specificity: 0.9992 - F1: 0.4125 - Loss: 0.0030\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 15:58:31\n",
      "Accuracy: 0.9852 - Precision: 0.7305 - Recall: 0.3201 - Specificity: 0.9992 - F1: 0.4142 - Loss: 0.0030\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 15:58:40\n",
      "Accuracy: 0.9852 - Precision: 0.7320 - Recall: 0.3216 - Specificity: 0.9992 - F1: 0.4160 - Loss: 0.0030\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 15:58:49\n",
      "Accuracy: 0.9852 - Precision: 0.7335 - Recall: 0.3233 - Specificity: 0.9992 - F1: 0.4180 - Loss: 0.0030\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 15:58:58\n",
      "Accuracy: 0.9852 - Precision: 0.7349 - Recall: 0.3250 - Specificity: 0.9992 - F1: 0.4200 - Loss: 0.0030\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 15:59:07\n",
      "Accuracy: 0.9853 - Precision: 0.7363 - Recall: 0.3266 - Specificity: 0.9992 - F1: 0.4219 - Loss: 0.0030\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 15:59:17\n",
      "Accuracy: 0.9853 - Precision: 0.7374 - Recall: 0.3286 - Specificity: 0.9992 - F1: 0.4240 - Loss: 0.0030\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 15:59:27\n",
      "Accuracy: 0.9854 - Precision: 0.7382 - Recall: 0.3308 - Specificity: 0.9992 - F1: 0.4261 - Loss: 0.0030\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 15:59:36\n",
      "Accuracy: 0.9854 - Precision: 0.7397 - Recall: 0.3326 - Specificity: 0.9992 - F1: 0.4282 - Loss: 0.0030\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 15:59:46\n",
      "Accuracy: 0.9855 - Precision: 0.7410 - Recall: 0.3342 - Specificity: 0.9992 - F1: 0.4300 - Loss: 0.0030\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 15:59:55\n",
      "Accuracy: 0.9855 - Precision: 0.7423 - Recall: 0.3354 - Specificity: 0.9992 - F1: 0.4316 - Loss: 0.0030\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 16:00:07\n",
      "Accuracy: 0.9855 - Precision: 0.7434 - Recall: 0.3373 - Specificity: 0.9992 - F1: 0.4336 - Loss: 0.0030\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 16:00:16\n",
      "Accuracy: 0.9855 - Precision: 0.7437 - Recall: 0.3394 - Specificity: 0.9992 - F1: 0.4354 - Loss: 0.0030\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 16:00:24\n",
      "Accuracy: 0.9856 - Precision: 0.7447 - Recall: 0.3407 - Specificity: 0.9992 - F1: 0.4370 - Loss: 0.0030\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 16:00:33\n",
      "Accuracy: 0.9856 - Precision: 0.7460 - Recall: 0.3421 - Specificity: 0.9992 - F1: 0.4386 - Loss: 0.0030\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 16:00:41\n",
      "Accuracy: 0.9856 - Precision: 0.7468 - Recall: 0.3426 - Specificity: 0.9992 - F1: 0.4395 - Loss: 0.0030\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 16:00:49\n",
      "Accuracy: 0.9856 - Precision: 0.7482 - Recall: 0.3431 - Specificity: 0.9992 - F1: 0.4403 - Loss: 0.0030\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 16:00:58\n",
      "Accuracy: 0.9856 - Precision: 0.7496 - Recall: 0.3434 - Specificity: 0.9992 - F1: 0.4411 - Loss: 0.0030\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 16:01:07\n",
      "Accuracy: 0.9857 - Precision: 0.7505 - Recall: 0.3446 - Specificity: 0.9992 - F1: 0.4425 - Loss: 0.0030\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 16:01:18\n",
      "Accuracy: 0.9857 - Precision: 0.7514 - Recall: 0.3467 - Specificity: 0.9992 - F1: 0.4445 - Loss: 0.0029\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 16:01:26\n",
      "Accuracy: 0.9857 - Precision: 0.7520 - Recall: 0.3485 - Specificity: 0.9992 - F1: 0.4463 - Loss: 0.0029\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 16:01:34\n",
      "Accuracy: 0.9858 - Precision: 0.7527 - Recall: 0.3500 - Specificity: 0.9992 - F1: 0.4478 - Loss: 0.0030\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 16:01:43\n",
      "Accuracy: 0.9858 - Precision: 0.7537 - Recall: 0.3511 - Specificity: 0.9992 - F1: 0.4492 - Loss: 0.0029\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 16:01:51\n",
      "Accuracy: 0.9858 - Precision: 0.7550 - Recall: 0.3522 - Specificity: 0.9992 - F1: 0.4506 - Loss: 0.0029\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 16:02:01\n",
      "Accuracy: 0.9858 - Precision: 0.7556 - Recall: 0.3528 - Specificity: 0.9992 - F1: 0.4515 - Loss: 0.0029\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 16:02:12\n",
      "Accuracy: 0.9858 - Precision: 0.7569 - Recall: 0.3539 - Specificity: 0.9992 - F1: 0.4529 - Loss: 0.0029\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 16:02:21\n",
      "Accuracy: 0.9859 - Precision: 0.7578 - Recall: 0.3553 - Specificity: 0.9992 - F1: 0.4544 - Loss: 0.0029\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 16:02:31\n",
      "Accuracy: 0.9859 - Precision: 0.7588 - Recall: 0.3566 - Specificity: 0.9992 - F1: 0.4560 - Loss: 0.0029\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 16:02:40\n",
      "Accuracy: 0.9859 - Precision: 0.7589 - Recall: 0.3580 - Specificity: 0.9992 - F1: 0.4572 - Loss: 0.0029\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 16:02:51\n",
      "Accuracy: 0.9859 - Precision: 0.7600 - Recall: 0.3589 - Specificity: 0.9992 - F1: 0.4585 - Loss: 0.0029\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 16:03:00\n",
      "Accuracy: 0.9860 - Precision: 0.7612 - Recall: 0.3596 - Specificity: 0.9992 - F1: 0.4595 - Loss: 0.0029\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 16:03:09\n",
      "Accuracy: 0.9860 - Precision: 0.7624 - Recall: 0.3603 - Specificity: 0.9992 - F1: 0.4605 - Loss: 0.0029\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 16:03:18\n",
      "Accuracy: 0.9860 - Precision: 0.7634 - Recall: 0.3610 - Specificity: 0.9992 - F1: 0.4615 - Loss: 0.0029\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 16:03:27\n",
      "Accuracy: 0.9860 - Precision: 0.7642 - Recall: 0.3620 - Specificity: 0.9992 - F1: 0.4627 - Loss: 0.0029\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 16:03:36\n",
      "Accuracy: 0.9861 - Precision: 0.7648 - Recall: 0.3638 - Specificity: 0.9992 - F1: 0.4644 - Loss: 0.0029\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 16:03:45\n",
      "Accuracy: 0.9861 - Precision: 0.7651 - Recall: 0.3652 - Specificity: 0.9992 - F1: 0.4657 - Loss: 0.0029\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 16:03:54\n",
      "Accuracy: 0.9861 - Precision: 0.7658 - Recall: 0.3666 - Specificity: 0.9992 - F1: 0.4672 - Loss: 0.0029\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 16:04:02\n",
      "Accuracy: 0.9861 - Precision: 0.7665 - Recall: 0.3678 - Specificity: 0.9992 - F1: 0.4685 - Loss: 0.0029\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 16:04:13\n",
      "Accuracy: 0.9861 - Precision: 0.7673 - Recall: 0.3688 - Specificity: 0.9992 - F1: 0.4697 - Loss: 0.0029\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 16:04:21\n",
      "Accuracy: 0.9861 - Precision: 0.7684 - Recall: 0.3696 - Specificity: 0.9992 - F1: 0.4707 - Loss: 0.0029\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 16:04:30\n",
      "Accuracy: 0.9862 - Precision: 0.7695 - Recall: 0.3704 - Specificity: 0.9992 - F1: 0.4719 - Loss: 0.0029\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 16:04:39\n",
      "Accuracy: 0.9862 - Precision: 0.7702 - Recall: 0.3714 - Specificity: 0.9992 - F1: 0.4731 - Loss: 0.0029\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 16:04:48\n",
      "Accuracy: 0.9862 - Precision: 0.7700 - Recall: 0.3728 - Specificity: 0.9992 - F1: 0.4742 - Loss: 0.0029\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 16:04:56\n",
      "Accuracy: 0.9862 - Precision: 0.7709 - Recall: 0.3741 - Specificity: 0.9992 - F1: 0.4756 - Loss: 0.0029\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 16:05:05\n",
      "Accuracy: 0.9863 - Precision: 0.7718 - Recall: 0.3749 - Specificity: 0.9992 - F1: 0.4766 - Loss: 0.0029\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 16:05:16\n",
      "Accuracy: 0.9863 - Precision: 0.7726 - Recall: 0.3761 - Specificity: 0.9992 - F1: 0.4779 - Loss: 0.0029\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 16:05:25\n",
      "Accuracy: 0.9863 - Precision: 0.7730 - Recall: 0.3769 - Specificity: 0.9991 - F1: 0.4788 - Loss: 0.0029\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 16:05:36\n",
      "Accuracy: 0.9863 - Precision: 0.7736 - Recall: 0.3778 - Specificity: 0.9991 - F1: 0.4799 - Loss: 0.0029\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 16:05:46\n",
      "Accuracy: 0.9863 - Precision: 0.7745 - Recall: 0.3786 - Specificity: 0.9991 - F1: 0.4809 - Loss: 0.0029\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 16:05:56\n",
      "Accuracy: 0.9864 - Precision: 0.7755 - Recall: 0.3796 - Specificity: 0.9991 - F1: 0.4821 - Loss: 0.0029\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 16:06:05\n",
      "Accuracy: 0.9864 - Precision: 0.7762 - Recall: 0.3809 - Specificity: 0.9991 - F1: 0.4835 - Loss: 0.0029\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 16:06:16\n",
      "Accuracy: 0.9864 - Precision: 0.7767 - Recall: 0.3830 - Specificity: 0.9991 - F1: 0.4853 - Loss: 0.0029\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 16:06:25\n",
      "Accuracy: 0.9865 - Precision: 0.7773 - Recall: 0.3848 - Specificity: 0.9991 - F1: 0.4869 - Loss: 0.0029\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 16:06:35\n",
      "Accuracy: 0.9865 - Precision: 0.7775 - Recall: 0.3861 - Specificity: 0.9991 - F1: 0.4881 - Loss: 0.0029\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 16:06:45\n",
      "Accuracy: 0.9865 - Precision: 0.7781 - Recall: 0.3872 - Specificity: 0.9991 - F1: 0.4892 - Loss: 0.0029\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 16:06:54\n",
      "Accuracy: 0.9865 - Precision: 0.7791 - Recall: 0.3879 - Specificity: 0.9991 - F1: 0.4902 - Loss: 0.0029\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 16:07:03\n",
      "Accuracy: 0.9866 - Precision: 0.7794 - Recall: 0.3886 - Specificity: 0.9991 - F1: 0.4910 - Loss: 0.0028\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 16:07:12\n",
      "Accuracy: 0.9866 - Precision: 0.7803 - Recall: 0.3894 - Specificity: 0.9991 - F1: 0.4920 - Loss: 0.0028\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 16:07:21\n",
      "Accuracy: 0.9866 - Precision: 0.7812 - Recall: 0.3905 - Specificity: 0.9991 - F1: 0.4933 - Loss: 0.0028\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 16:07:30\n",
      "Accuracy: 0.9866 - Precision: 0.7815 - Recall: 0.3917 - Specificity: 0.9991 - F1: 0.4944 - Loss: 0.0028\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 16:07:39\n",
      "Accuracy: 0.9867 - Precision: 0.7821 - Recall: 0.3929 - Specificity: 0.9991 - F1: 0.4956 - Loss: 0.0028\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 16:07:47\n",
      "Accuracy: 0.9867 - Precision: 0.7827 - Recall: 0.3942 - Specificity: 0.9991 - F1: 0.4969 - Loss: 0.0028\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 16:07:56\n",
      "Accuracy: 0.9867 - Precision: 0.7829 - Recall: 0.3948 - Specificity: 0.9991 - F1: 0.4976 - Loss: 0.0028\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 16:08:04\n",
      "Accuracy: 0.9867 - Precision: 0.7831 - Recall: 0.3946 - Specificity: 0.9991 - F1: 0.4976 - Loss: 0.0028\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 16:08:15\n",
      "Accuracy: 0.9866 - Precision: 0.7831 - Recall: 0.3943 - Specificity: 0.9991 - F1: 0.4974 - Loss: 0.0028\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 16:08:24\n",
      "Accuracy: 0.9866 - Precision: 0.7834 - Recall: 0.3935 - Specificity: 0.9991 - F1: 0.4967 - Loss: 0.0029\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 16:08:33\n",
      "Accuracy: 0.9866 - Precision: 0.7842 - Recall: 0.3928 - Specificity: 0.9991 - F1: 0.4962 - Loss: 0.0029\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 16:08:42\n",
      "Accuracy: 0.9866 - Precision: 0.7850 - Recall: 0.3924 - Specificity: 0.9991 - F1: 0.4960 - Loss: 0.0029\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 16:08:51\n",
      "Accuracy: 0.9865 - Precision: 0.7857 - Recall: 0.3917 - Specificity: 0.9991 - F1: 0.4956 - Loss: 0.0029\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 16:09:00\n",
      "Accuracy: 0.9865 - Precision: 0.7858 - Recall: 0.3906 - Specificity: 0.9991 - F1: 0.4945 - Loss: 0.0029\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 16:09:09\n",
      "Accuracy: 0.9864 - Precision: 0.7867 - Recall: 0.3904 - Specificity: 0.9991 - F1: 0.4946 - Loss: 0.0029\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 16:09:19\n",
      "Accuracy: 0.9864 - Precision: 0.7870 - Recall: 0.3899 - Specificity: 0.9991 - F1: 0.4942 - Loss: 0.0029\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 16:09:28\n",
      "Accuracy: 0.9864 - Precision: 0.7872 - Recall: 0.3897 - Specificity: 0.9991 - F1: 0.4942 - Loss: 0.0029\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 16:09:37\n",
      "Accuracy: 0.9864 - Precision: 0.7876 - Recall: 0.3905 - Specificity: 0.9991 - F1: 0.4951 - Loss: 0.0029\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 16:09:46\n",
      "Accuracy: 0.9864 - Precision: 0.7881 - Recall: 0.3906 - Specificity: 0.9991 - F1: 0.4954 - Loss: 0.0029\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 16:09:56\n",
      "Accuracy: 0.9864 - Precision: 0.7889 - Recall: 0.3901 - Specificity: 0.9991 - F1: 0.4950 - Loss: 0.0029\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 16:10:06\n",
      "Accuracy: 0.9864 - Precision: 0.7895 - Recall: 0.3902 - Specificity: 0.9991 - F1: 0.4954 - Loss: 0.0029\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 16:10:17\n",
      "Accuracy: 0.9864 - Precision: 0.7899 - Recall: 0.3908 - Specificity: 0.9991 - F1: 0.4962 - Loss: 0.0029\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 16:10:26\n",
      "Accuracy: 0.9864 - Precision: 0.7902 - Recall: 0.3905 - Specificity: 0.9991 - F1: 0.4961 - Loss: 0.0029\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 16:10:34\n",
      "Accuracy: 0.9864 - Precision: 0.7905 - Recall: 0.3907 - Specificity: 0.9991 - F1: 0.4964 - Loss: 0.0029\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 16:10:43\n",
      "Accuracy: 0.9864 - Precision: 0.7910 - Recall: 0.3911 - Specificity: 0.9991 - F1: 0.4970 - Loss: 0.0029\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 16:10:52\n",
      "Accuracy: 0.9864 - Precision: 0.7914 - Recall: 0.3909 - Specificity: 0.9991 - F1: 0.4970 - Loss: 0.0029\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 16:11:00\n",
      "Accuracy: 0.9863 - Precision: 0.7919 - Recall: 0.3902 - Specificity: 0.9991 - F1: 0.4964 - Loss: 0.0029\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 16:11:09\n",
      "Accuracy: 0.9863 - Precision: 0.7926 - Recall: 0.3897 - Specificity: 0.9991 - F1: 0.4960 - Loss: 0.0030\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 16:11:17\n",
      "Accuracy: 0.9862 - Precision: 0.7929 - Recall: 0.3894 - Specificity: 0.9991 - F1: 0.4959 - Loss: 0.0030\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 16:11:26\n",
      "Accuracy: 0.9862 - Precision: 0.7931 - Recall: 0.3895 - Specificity: 0.9991 - F1: 0.4962 - Loss: 0.0030\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 16:11:35\n",
      "Accuracy: 0.9862 - Precision: 0.7936 - Recall: 0.3895 - Specificity: 0.9991 - F1: 0.4964 - Loss: 0.0030\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 16:11:44\n",
      "Accuracy: 0.9862 - Precision: 0.7943 - Recall: 0.3892 - Specificity: 0.9991 - F1: 0.4963 - Loss: 0.0030\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 16:11:53\n",
      "Accuracy: 0.9861 - Precision: 0.7949 - Recall: 0.3891 - Specificity: 0.9991 - F1: 0.4964 - Loss: 0.0030\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 16:12:01\n",
      "Accuracy: 0.9858 - Precision: 0.7937 - Recall: 0.3875 - Specificity: 0.9991 - F1: 0.4945 - Loss: 0.0033\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 16:12:10\n",
      "Accuracy: 0.9856 - Precision: 0.7927 - Recall: 0.3865 - Specificity: 0.9991 - F1: 0.4934 - Loss: 0.0033\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 16:12:21\n",
      "Accuracy: 0.9853 - Precision: 0.7925 - Recall: 0.3855 - Specificity: 0.9991 - F1: 0.4923 - Loss: 0.0034\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 16:12:30\n",
      "Accuracy: 0.9850 - Precision: 0.7930 - Recall: 0.3841 - Specificity: 0.9991 - F1: 0.4906 - Loss: 0.0035\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 16:12:39\n",
      "Accuracy: 0.9847 - Precision: 0.7938 - Recall: 0.3825 - Specificity: 0.9991 - F1: 0.4887 - Loss: 0.0035\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 16:12:47\n",
      "Accuracy: 0.9845 - Precision: 0.7947 - Recall: 0.3810 - Specificity: 0.9991 - F1: 0.4867 - Loss: 0.0036\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 16:12:56\n",
      "Accuracy: 0.9842 - Precision: 0.7951 - Recall: 0.3794 - Specificity: 0.9991 - F1: 0.4847 - Loss: 0.0037\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 16:13:05\n",
      "Accuracy: 0.9840 - Precision: 0.7933 - Recall: 0.3780 - Specificity: 0.9991 - F1: 0.4829 - Loss: 0.0037\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 16:13:14\n",
      "Accuracy: 0.9836 - Precision: 0.7937 - Recall: 0.3765 - Specificity: 0.9991 - F1: 0.4810 - Loss: 0.0038\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 16:13:23\n",
      "Accuracy: 0.9834 - Precision: 0.7926 - Recall: 0.3750 - Specificity: 0.9991 - F1: 0.4791 - Loss: 0.0039\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 16:13:32\n",
      "Accuracy: 0.9831 - Precision: 0.7934 - Recall: 0.3735 - Specificity: 0.9991 - F1: 0.4772 - Loss: 0.0039\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 16:13:41\n",
      "Accuracy: 0.9830 - Precision: 0.7935 - Recall: 0.3720 - Specificity: 0.9991 - F1: 0.4753 - Loss: 0.0040\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 16:13:49\n",
      "Accuracy: 0.9827 - Precision: 0.7943 - Recall: 0.3705 - Specificity: 0.9991 - F1: 0.4734 - Loss: 0.0040\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 16:13:58\n",
      "Accuracy: 0.9825 - Precision: 0.7951 - Recall: 0.3691 - Specificity: 0.9991 - F1: 0.4716 - Loss: 0.0041\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 16:14:07\n",
      "Accuracy: 0.9822 - Precision: 0.7959 - Recall: 0.3676 - Specificity: 0.9991 - F1: 0.4697 - Loss: 0.0041\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 16:14:15\n",
      "Accuracy: 0.9819 - Precision: 0.7967 - Recall: 0.3662 - Specificity: 0.9991 - F1: 0.4679 - Loss: 0.0042\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 16:14:26\n",
      "Accuracy: 0.9816 - Precision: 0.7965 - Recall: 0.3648 - Specificity: 0.9991 - F1: 0.4661 - Loss: 0.0042\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 16:14:34\n",
      "Accuracy: 0.9815 - Precision: 0.7971 - Recall: 0.3634 - Specificity: 0.9991 - F1: 0.4643 - Loss: 0.0043\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 16:14:44\n",
      "Accuracy: 0.9814 - Precision: 0.7978 - Recall: 0.3620 - Specificity: 0.9991 - F1: 0.4625 - Loss: 0.0043\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 16:14:53\n",
      "Accuracy: 0.9814 - Precision: 0.7986 - Recall: 0.3606 - Specificity: 0.9991 - F1: 0.4607 - Loss: 0.0043\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 16:15:02\n",
      "Accuracy: 0.9814 - Precision: 0.7993 - Recall: 0.3592 - Specificity: 0.9991 - F1: 0.4591 - Loss: 0.0043\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 16:15:11\n",
      "Accuracy: 0.9814 - Precision: 0.7994 - Recall: 0.3579 - Specificity: 0.9991 - F1: 0.4574 - Loss: 0.0044\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 16:15:21\n",
      "Accuracy: 0.9812 - Precision: 0.8002 - Recall: 0.3566 - Specificity: 0.9991 - F1: 0.4558 - Loss: 0.0044\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 16:15:29\n",
      "Accuracy: 0.9812 - Precision: 0.8005 - Recall: 0.3553 - Specificity: 0.9991 - F1: 0.4541 - Loss: 0.0044\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 16:15:38\n",
      "Accuracy: 0.9811 - Precision: 0.8012 - Recall: 0.3540 - Specificity: 0.9991 - F1: 0.4525 - Loss: 0.0044\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 16:15:46\n",
      "Accuracy: 0.9811 - Precision: 0.8014 - Recall: 0.3526 - Specificity: 0.9991 - F1: 0.4508 - Loss: 0.0045\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 16:15:56\n",
      "Accuracy: 0.9811 - Precision: 0.8021 - Recall: 0.3513 - Specificity: 0.9991 - F1: 0.4491 - Loss: 0.0045\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 16:16:05\n",
      "Accuracy: 0.9811 - Precision: 0.8027 - Recall: 0.3500 - Specificity: 0.9991 - F1: 0.4475 - Loss: 0.0045\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 16:16:13\n",
      "Accuracy: 0.9810 - Precision: 0.8034 - Recall: 0.3487 - Specificity: 0.9991 - F1: 0.4458 - Loss: 0.0045\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 16:16:24\n",
      "Accuracy: 0.9810 - Precision: 0.8027 - Recall: 0.3475 - Specificity: 0.9991 - F1: 0.4442 - Loss: 0.0045\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 16:16:35\n",
      "Accuracy: 0.9810 - Precision: 0.8030 - Recall: 0.3462 - Specificity: 0.9991 - F1: 0.4427 - Loss: 0.0045\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 16:16:44\n",
      "Accuracy: 0.9810 - Precision: 0.8033 - Recall: 0.3450 - Specificity: 0.9991 - F1: 0.4411 - Loss: 0.0045\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 16:16:53\n",
      "Accuracy: 0.9809 - Precision: 0.8036 - Recall: 0.3438 - Specificity: 0.9991 - F1: 0.4397 - Loss: 0.0045\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 16:17:02\n",
      "Accuracy: 0.9809 - Precision: 0.8042 - Recall: 0.3426 - Specificity: 0.9991 - F1: 0.4382 - Loss: 0.0045\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 16:17:11\n",
      "Accuracy: 0.9809 - Precision: 0.8043 - Recall: 0.3415 - Specificity: 0.9992 - F1: 0.4368 - Loss: 0.0046\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 16:17:20\n",
      "Accuracy: 0.9808 - Precision: 0.8029 - Recall: 0.3402 - Specificity: 0.9992 - F1: 0.4352 - Loss: 0.0046\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 16:17:28\n",
      "Accuracy: 0.9808 - Precision: 0.8036 - Recall: 0.3390 - Specificity: 0.9992 - F1: 0.4337 - Loss: 0.0046\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 16:17:37\n",
      "Accuracy: 0.9808 - Precision: 0.8007 - Recall: 0.3378 - Specificity: 0.9992 - F1: 0.4321 - Loss: 0.0046\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 16:17:46\n",
      "Accuracy: 0.9808 - Precision: 0.8014 - Recall: 0.3366 - Specificity: 0.9992 - F1: 0.4305 - Loss: 0.0046\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 16:17:55\n",
      "Accuracy: 0.9808 - Precision: 0.8021 - Recall: 0.3354 - Specificity: 0.9992 - F1: 0.4290 - Loss: 0.0046\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 16:18:03\n",
      "Accuracy: 0.9808 - Precision: 0.8012 - Recall: 0.3343 - Specificity: 0.9992 - F1: 0.4277 - Loss: 0.0046\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 16:18:12\n",
      "Accuracy: 0.9808 - Precision: 0.7984 - Recall: 0.3331 - Specificity: 0.9992 - F1: 0.4262 - Loss: 0.0046\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 16:18:23\n",
      "Accuracy: 0.9807 - Precision: 0.7991 - Recall: 0.3320 - Specificity: 0.9992 - F1: 0.4247 - Loss: 0.0046\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 16:18:32\n",
      "Accuracy: 0.9808 - Precision: 0.7963 - Recall: 0.3308 - Specificity: 0.9992 - F1: 0.4232 - Loss: 0.0046\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 16:18:41\n",
      "Accuracy: 0.9808 - Precision: 0.7935 - Recall: 0.3296 - Specificity: 0.9992 - F1: 0.4218 - Loss: 0.0046\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 16:18:52\n",
      "Accuracy: 0.9808 - Precision: 0.7942 - Recall: 0.3285 - Specificity: 0.9992 - F1: 0.4203 - Loss: 0.0046\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 16:19:02\n",
      "Accuracy: 0.9808 - Precision: 0.7949 - Recall: 0.3274 - Specificity: 0.9992 - F1: 0.4189 - Loss: 0.0046\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 16:19:11\n",
      "Accuracy: 0.9807 - Precision: 0.7956 - Recall: 0.3264 - Specificity: 0.9992 - F1: 0.4177 - Loss: 0.0046\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 16:19:20\n",
      "Accuracy: 0.9807 - Precision: 0.7959 - Recall: 0.3253 - Specificity: 0.9992 - F1: 0.4163 - Loss: 0.0046\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 16:19:29\n",
      "Accuracy: 0.9807 - Precision: 0.7962 - Recall: 0.3242 - Specificity: 0.9992 - F1: 0.4150 - Loss: 0.0047\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 16:19:38\n",
      "Accuracy: 0.9806 - Precision: 0.7967 - Recall: 0.3232 - Specificity: 0.9992 - F1: 0.4139 - Loss: 0.0047\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 16:19:46\n",
      "Accuracy: 0.9806 - Precision: 0.7973 - Recall: 0.3222 - Specificity: 0.9992 - F1: 0.4125 - Loss: 0.0047\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 16:19:55\n",
      "Accuracy: 0.9806 - Precision: 0.7971 - Recall: 0.3216 - Specificity: 0.9992 - F1: 0.4120 - Loss: 0.0047\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 16:20:04\n",
      "Accuracy: 0.9806 - Precision: 0.7973 - Recall: 0.3214 - Specificity: 0.9992 - F1: 0.4119 - Loss: 0.0047\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 16:20:13\n",
      "Accuracy: 0.9806 - Precision: 0.7979 - Recall: 0.3206 - Specificity: 0.9992 - F1: 0.4111 - Loss: 0.0047\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 16:20:22\n",
      "Accuracy: 0.9805 - Precision: 0.7981 - Recall: 0.3198 - Specificity: 0.9992 - F1: 0.4103 - Loss: 0.0047\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 16:20:32\n",
      "Accuracy: 0.9806 - Precision: 0.7983 - Recall: 0.3193 - Specificity: 0.9992 - F1: 0.4098 - Loss: 0.0047\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 16:20:42\n",
      "Accuracy: 0.9805 - Precision: 0.7988 - Recall: 0.3186 - Specificity: 0.9992 - F1: 0.4092 - Loss: 0.0047\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 16:20:53\n",
      "Accuracy: 0.9805 - Precision: 0.7993 - Recall: 0.3178 - Specificity: 0.9992 - F1: 0.4082 - Loss: 0.0047\n",
      "\n",
      "Epoch 6/20\n",
      "Validation - Accuracy: 0.9801, Precision: 0.9202, Recall: 0.0808, Specificity: 0.9998, F1: 0.1475, Loss: 0.0050\n",
      "\n",
      "\n",
      "Epoch 7/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 16:29:50\n",
      "Accuracy: 0.9769 - Precision: 0.9471 - Recall: 0.1256 - Specificity: 0.9998 - F1: 0.2218 - Loss: 0.0063\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 16:29:59\n",
      "Accuracy: 0.9756 - Precision: 0.9522 - Recall: 0.1290 - Specificity: 0.9998 - F1: 0.2271 - Loss: 0.0063\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 16:30:08\n",
      "Accuracy: 0.9750 - Precision: 0.9619 - Recall: 0.1405 - Specificity: 0.9998 - F1: 0.2449 - Loss: 0.0060\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 16:30:17\n",
      "Accuracy: 0.9773 - Precision: 0.9677 - Recall: 0.1197 - Specificity: 0.9999 - F1: 0.2107 - Loss: 0.0055\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 16:30:26\n",
      "Accuracy: 0.9790 - Precision: 0.9424 - Recall: 0.1151 - Specificity: 0.9998 - F1: 0.2033 - Loss: 0.0052\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 16:30:37\n",
      "Accuracy: 0.9791 - Precision: 0.9512 - Recall: 0.1196 - Specificity: 0.9999 - F1: 0.2109 - Loss: 0.0050\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 16:30:46\n",
      "Accuracy: 0.9804 - Precision: 0.9511 - Recall: 0.1317 - Specificity: 0.9999 - F1: 0.2288 - Loss: 0.0047\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 16:30:55\n",
      "Accuracy: 0.9809 - Precision: 0.9153 - Recall: 0.1440 - Specificity: 0.9996 - F1: 0.2429 - Loss: 0.0046\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 16:31:03\n",
      "Accuracy: 0.9817 - Precision: 0.9217 - Recall: 0.1568 - Specificity: 0.9996 - F1: 0.2613 - Loss: 0.0043\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 16:31:12\n",
      "Accuracy: 0.9821 - Precision: 0.9284 - Recall: 0.1558 - Specificity: 0.9997 - F1: 0.2609 - Loss: 0.0043\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 16:31:21\n",
      "Accuracy: 0.9825 - Precision: 0.9150 - Recall: 0.1738 - Specificity: 0.9995 - F1: 0.2814 - Loss: 0.0042\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 16:31:31\n",
      "Accuracy: 0.9830 - Precision: 0.9173 - Recall: 0.1899 - Specificity: 0.9996 - F1: 0.3019 - Loss: 0.0041\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 16:31:39\n",
      "Accuracy: 0.9834 - Precision: 0.9145 - Recall: 0.2081 - Specificity: 0.9995 - F1: 0.3230 - Loss: 0.0040\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 16:31:48\n",
      "Accuracy: 0.9835 - Precision: 0.8916 - Recall: 0.2209 - Specificity: 0.9992 - F1: 0.3334 - Loss: 0.0040\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 16:31:57\n",
      "Accuracy: 0.9839 - Precision: 0.8948 - Recall: 0.2335 - Specificity: 0.9992 - F1: 0.3492 - Loss: 0.0040\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 16:32:06\n",
      "Accuracy: 0.9836 - Precision: 0.8975 - Recall: 0.2345 - Specificity: 0.9993 - F1: 0.3520 - Loss: 0.0041\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 16:32:14\n",
      "Accuracy: 0.9840 - Precision: 0.9020 - Recall: 0.2452 - Specificity: 0.9993 - F1: 0.3656 - Loss: 0.0040\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 16:32:23\n",
      "Accuracy: 0.9841 - Precision: 0.9050 - Recall: 0.2532 - Specificity: 0.9993 - F1: 0.3760 - Loss: 0.0039\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 16:32:33\n",
      "Accuracy: 0.9843 - Precision: 0.9053 - Recall: 0.2630 - Specificity: 0.9993 - F1: 0.3874 - Loss: 0.0039\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 16:32:43\n",
      "Accuracy: 0.9846 - Precision: 0.9034 - Recall: 0.2750 - Specificity: 0.9993 - F1: 0.3999 - Loss: 0.0038\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 16:32:51\n",
      "Accuracy: 0.9847 - Precision: 0.9006 - Recall: 0.2782 - Specificity: 0.9992 - F1: 0.4040 - Loss: 0.0038\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 16:33:00\n",
      "Accuracy: 0.9843 - Precision: 0.8807 - Recall: 0.2752 - Specificity: 0.9990 - F1: 0.3990 - Loss: 0.0040\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 16:33:09\n",
      "Accuracy: 0.9842 - Precision: 0.8851 - Recall: 0.2734 - Specificity: 0.9990 - F1: 0.3981 - Loss: 0.0039\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 16:33:17\n",
      "Accuracy: 0.9841 - Precision: 0.8892 - Recall: 0.2723 - Specificity: 0.9991 - F1: 0.3979 - Loss: 0.0039\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 16:33:27\n",
      "Accuracy: 0.9841 - Precision: 0.8913 - Recall: 0.2703 - Specificity: 0.9991 - F1: 0.3964 - Loss: 0.0039\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 16:33:36\n",
      "Accuracy: 0.9843 - Precision: 0.8940 - Recall: 0.2722 - Specificity: 0.9991 - F1: 0.3995 - Loss: 0.0039\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 16:33:46\n",
      "Accuracy: 0.9842 - Precision: 0.8972 - Recall: 0.2714 - Specificity: 0.9992 - F1: 0.3996 - Loss: 0.0038\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 16:33:55\n",
      "Accuracy: 0.9842 - Precision: 0.8989 - Recall: 0.2682 - Specificity: 0.9992 - F1: 0.3962 - Loss: 0.0038\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 16:34:05\n",
      "Accuracy: 0.9839 - Precision: 0.8986 - Recall: 0.2643 - Specificity: 0.9992 - F1: 0.3916 - Loss: 0.0039\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 16:34:14\n",
      "Accuracy: 0.9839 - Precision: 0.9009 - Recall: 0.2671 - Specificity: 0.9992 - F1: 0.3957 - Loss: 0.0039\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 16:34:24\n",
      "Accuracy: 0.9841 - Precision: 0.9016 - Recall: 0.2708 - Specificity: 0.9992 - F1: 0.4003 - Loss: 0.0038\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 16:34:35\n",
      "Accuracy: 0.9841 - Precision: 0.9024 - Recall: 0.2735 - Specificity: 0.9992 - F1: 0.4039 - Loss: 0.0038\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 16:34:47\n",
      "Accuracy: 0.9842 - Precision: 0.9032 - Recall: 0.2780 - Specificity: 0.9992 - F1: 0.4092 - Loss: 0.0038\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 16:34:57\n",
      "Accuracy: 0.9842 - Precision: 0.9049 - Recall: 0.2810 - Specificity: 0.9992 - F1: 0.4132 - Loss: 0.0038\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 16:35:05\n",
      "Accuracy: 0.9842 - Precision: 0.9058 - Recall: 0.2823 - Specificity: 0.9992 - F1: 0.4153 - Loss: 0.0038\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 16:35:13\n",
      "Accuracy: 0.9844 - Precision: 0.9056 - Recall: 0.2896 - Specificity: 0.9992 - F1: 0.4226 - Loss: 0.0037\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 16:35:21\n",
      "Accuracy: 0.9846 - Precision: 0.9063 - Recall: 0.2991 - Specificity: 0.9992 - F1: 0.4317 - Loss: 0.0037\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 16:35:30\n",
      "Accuracy: 0.9846 - Precision: 0.9050 - Recall: 0.3051 - Specificity: 0.9992 - F1: 0.4375 - Loss: 0.0037\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 16:35:38\n",
      "Accuracy: 0.9848 - Precision: 0.9056 - Recall: 0.3116 - Specificity: 0.9992 - F1: 0.4441 - Loss: 0.0037\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 16:35:47\n",
      "Accuracy: 0.9849 - Precision: 0.9063 - Recall: 0.3187 - Specificity: 0.9992 - F1: 0.4512 - Loss: 0.0037\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 16:35:56\n",
      "Accuracy: 0.9848 - Precision: 0.9062 - Recall: 0.3212 - Specificity: 0.9992 - F1: 0.4542 - Loss: 0.0037\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 16:36:08\n",
      "Accuracy: 0.9849 - Precision: 0.9068 - Recall: 0.3272 - Specificity: 0.9992 - F1: 0.4604 - Loss: 0.0037\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 16:36:19\n",
      "Accuracy: 0.9851 - Precision: 0.9069 - Recall: 0.3350 - Specificity: 0.9991 - F1: 0.4675 - Loss: 0.0036\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 16:36:28\n",
      "Accuracy: 0.9852 - Precision: 0.9062 - Recall: 0.3431 - Specificity: 0.9991 - F1: 0.4744 - Loss: 0.0036\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 16:36:37\n",
      "Accuracy: 0.9853 - Precision: 0.9010 - Recall: 0.3497 - Specificity: 0.9990 - F1: 0.4785 - Loss: 0.0036\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 16:36:47\n",
      "Accuracy: 0.9854 - Precision: 0.9026 - Recall: 0.3518 - Specificity: 0.9990 - F1: 0.4814 - Loss: 0.0036\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 16:36:56\n",
      "Accuracy: 0.9854 - Precision: 0.9039 - Recall: 0.3523 - Specificity: 0.9991 - F1: 0.4826 - Loss: 0.0036\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 16:37:06\n",
      "Accuracy: 0.9854 - Precision: 0.9054 - Recall: 0.3537 - Specificity: 0.9991 - F1: 0.4848 - Loss: 0.0036\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 16:37:16\n",
      "Accuracy: 0.9854 - Precision: 0.9059 - Recall: 0.3569 - Specificity: 0.9991 - F1: 0.4883 - Loss: 0.0036\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 16:37:25\n",
      "Accuracy: 0.9855 - Precision: 0.9070 - Recall: 0.3608 - Specificity: 0.9991 - F1: 0.4925 - Loss: 0.0036\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 16:37:34\n",
      "Accuracy: 0.9856 - Precision: 0.9067 - Recall: 0.3648 - Specificity: 0.9991 - F1: 0.4965 - Loss: 0.0035\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 16:37:43\n",
      "Accuracy: 0.9856 - Precision: 0.9056 - Recall: 0.3683 - Specificity: 0.9991 - F1: 0.4997 - Loss: 0.0035\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 16:37:53\n",
      "Accuracy: 0.9857 - Precision: 0.9064 - Recall: 0.3724 - Specificity: 0.9991 - F1: 0.5040 - Loss: 0.0035\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 16:38:01\n",
      "Accuracy: 0.9858 - Precision: 0.9076 - Recall: 0.3764 - Specificity: 0.9991 - F1: 0.5082 - Loss: 0.0035\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 16:38:10\n",
      "Accuracy: 0.9859 - Precision: 0.9084 - Recall: 0.3790 - Specificity: 0.9991 - F1: 0.5112 - Loss: 0.0035\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 16:38:19\n",
      "Accuracy: 0.9860 - Precision: 0.9083 - Recall: 0.3839 - Specificity: 0.9991 - F1: 0.5156 - Loss: 0.0034\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 16:38:28\n",
      "Accuracy: 0.9861 - Precision: 0.9080 - Recall: 0.3881 - Specificity: 0.9991 - F1: 0.5194 - Loss: 0.0034\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 16:38:36\n",
      "Accuracy: 0.9862 - Precision: 0.9073 - Recall: 0.3927 - Specificity: 0.9990 - F1: 0.5233 - Loss: 0.0034\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 16:38:45\n",
      "Accuracy: 0.9863 - Precision: 0.9081 - Recall: 0.3963 - Specificity: 0.9990 - F1: 0.5270 - Loss: 0.0034\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 16:38:54\n",
      "Accuracy: 0.9863 - Precision: 0.9064 - Recall: 0.3988 - Specificity: 0.9990 - F1: 0.5291 - Loss: 0.0034\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 16:39:03\n",
      "Accuracy: 0.9863 - Precision: 0.9054 - Recall: 0.4008 - Specificity: 0.9990 - F1: 0.5310 - Loss: 0.0034\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 16:39:12\n",
      "Accuracy: 0.9864 - Precision: 0.9059 - Recall: 0.4037 - Specificity: 0.9990 - F1: 0.5340 - Loss: 0.0034\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 16:39:21\n",
      "Accuracy: 0.9865 - Precision: 0.9069 - Recall: 0.4070 - Specificity: 0.9990 - F1: 0.5374 - Loss: 0.0033\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 16:39:30\n",
      "Accuracy: 0.9866 - Precision: 0.9074 - Recall: 0.4109 - Specificity: 0.9990 - F1: 0.5410 - Loss: 0.0033\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 16:39:41\n",
      "Accuracy: 0.9866 - Precision: 0.9077 - Recall: 0.4132 - Specificity: 0.9990 - F1: 0.5435 - Loss: 0.0033\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 16:39:50\n",
      "Accuracy: 0.9866 - Precision: 0.9072 - Recall: 0.4147 - Specificity: 0.9990 - F1: 0.5451 - Loss: 0.0033\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 16:39:59\n",
      "Accuracy: 0.9866 - Precision: 0.9068 - Recall: 0.4170 - Specificity: 0.9990 - F1: 0.5472 - Loss: 0.0033\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 16:40:08\n",
      "Accuracy: 0.9867 - Precision: 0.9068 - Recall: 0.4192 - Specificity: 0.9990 - F1: 0.5494 - Loss: 0.0033\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 16:40:16\n",
      "Accuracy: 0.9868 - Precision: 0.9074 - Recall: 0.4223 - Specificity: 0.9990 - F1: 0.5525 - Loss: 0.0033\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 16:40:25\n",
      "Accuracy: 0.9868 - Precision: 0.9078 - Recall: 0.4251 - Specificity: 0.9990 - F1: 0.5552 - Loss: 0.0033\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 16:40:35\n",
      "Accuracy: 0.9869 - Precision: 0.9064 - Recall: 0.4266 - Specificity: 0.9990 - F1: 0.5564 - Loss: 0.0033\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 16:40:44\n",
      "Accuracy: 0.9869 - Precision: 0.9052 - Recall: 0.4267 - Specificity: 0.9990 - F1: 0.5566 - Loss: 0.0033\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 16:40:53\n",
      "Accuracy: 0.9868 - Precision: 0.9062 - Recall: 0.4266 - Specificity: 0.9990 - F1: 0.5570 - Loss: 0.0033\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 16:41:01\n",
      "Accuracy: 0.9868 - Precision: 0.9070 - Recall: 0.4273 - Specificity: 0.9990 - F1: 0.5581 - Loss: 0.0033\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 16:41:10\n",
      "Accuracy: 0.9868 - Precision: 0.9068 - Recall: 0.4293 - Specificity: 0.9990 - F1: 0.5600 - Loss: 0.0033\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 16:41:19\n",
      "Accuracy: 0.9869 - Precision: 0.9063 - Recall: 0.4315 - Specificity: 0.9990 - F1: 0.5619 - Loss: 0.0033\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 16:41:28\n",
      "Accuracy: 0.9869 - Precision: 0.9056 - Recall: 0.4344 - Specificity: 0.9989 - F1: 0.5643 - Loss: 0.0033\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 16:41:37\n",
      "Accuracy: 0.9870 - Precision: 0.9064 - Recall: 0.4362 - Specificity: 0.9989 - F1: 0.5663 - Loss: 0.0033\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 16:41:46\n",
      "Accuracy: 0.9869 - Precision: 0.9068 - Recall: 0.4371 - Specificity: 0.9989 - F1: 0.5674 - Loss: 0.0033\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 16:41:54\n",
      "Accuracy: 0.9870 - Precision: 0.9076 - Recall: 0.4385 - Specificity: 0.9990 - F1: 0.5692 - Loss: 0.0033\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 16:42:03\n",
      "Accuracy: 0.9870 - Precision: 0.9081 - Recall: 0.4394 - Specificity: 0.9990 - F1: 0.5703 - Loss: 0.0032\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 16:42:11\n",
      "Accuracy: 0.9870 - Precision: 0.9070 - Recall: 0.4405 - Specificity: 0.9989 - F1: 0.5712 - Loss: 0.0032\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 16:42:20\n",
      "Accuracy: 0.9871 - Precision: 0.9070 - Recall: 0.4417 - Specificity: 0.9989 - F1: 0.5724 - Loss: 0.0032\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 16:42:28\n",
      "Accuracy: 0.9871 - Precision: 0.9067 - Recall: 0.4435 - Specificity: 0.9989 - F1: 0.5740 - Loss: 0.0032\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 16:42:37\n",
      "Accuracy: 0.9872 - Precision: 0.9067 - Recall: 0.4467 - Specificity: 0.9989 - F1: 0.5768 - Loss: 0.0032\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 16:42:46\n",
      "Accuracy: 0.9872 - Precision: 0.9058 - Recall: 0.4489 - Specificity: 0.9989 - F1: 0.5784 - Loss: 0.0032\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 16:42:55\n",
      "Accuracy: 0.9873 - Precision: 0.9063 - Recall: 0.4511 - Specificity: 0.9989 - F1: 0.5806 - Loss: 0.0032\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 16:43:04\n",
      "Accuracy: 0.9873 - Precision: 0.9061 - Recall: 0.4523 - Specificity: 0.9989 - F1: 0.5818 - Loss: 0.0032\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 16:43:13\n",
      "Accuracy: 0.9873 - Precision: 0.9069 - Recall: 0.4529 - Specificity: 0.9989 - F1: 0.5827 - Loss: 0.0032\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 16:43:21\n",
      "Accuracy: 0.9873 - Precision: 0.9075 - Recall: 0.4533 - Specificity: 0.9989 - F1: 0.5834 - Loss: 0.0032\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 16:43:30\n",
      "Accuracy: 0.9873 - Precision: 0.9079 - Recall: 0.4554 - Specificity: 0.9989 - F1: 0.5854 - Loss: 0.0032\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 16:43:39\n",
      "Accuracy: 0.9874 - Precision: 0.9066 - Recall: 0.4581 - Specificity: 0.9989 - F1: 0.5871 - Loss: 0.0032\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 16:43:48\n",
      "Accuracy: 0.9874 - Precision: 0.9064 - Recall: 0.4607 - Specificity: 0.9989 - F1: 0.5893 - Loss: 0.0032\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 16:43:59\n",
      "Accuracy: 0.9875 - Precision: 0.9066 - Recall: 0.4623 - Specificity: 0.9989 - F1: 0.5908 - Loss: 0.0032\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 16:44:07\n",
      "Accuracy: 0.9875 - Precision: 0.9055 - Recall: 0.4630 - Specificity: 0.9989 - F1: 0.5913 - Loss: 0.0032\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 16:44:15\n",
      "Accuracy: 0.9874 - Precision: 0.9053 - Recall: 0.4621 - Specificity: 0.9989 - F1: 0.5907 - Loss: 0.0032\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 16:44:24\n",
      "Accuracy: 0.9874 - Precision: 0.9062 - Recall: 0.4610 - Specificity: 0.9989 - F1: 0.5900 - Loss: 0.0032\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 16:44:32\n",
      "Accuracy: 0.9875 - Precision: 0.9063 - Recall: 0.4608 - Specificity: 0.9989 - F1: 0.5900 - Loss: 0.0032\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 16:44:40\n",
      "Accuracy: 0.9875 - Precision: 0.9061 - Recall: 0.4605 - Specificity: 0.9989 - F1: 0.5899 - Loss: 0.0031\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 16:44:48\n",
      "Accuracy: 0.9875 - Precision: 0.9061 - Recall: 0.4608 - Specificity: 0.9989 - F1: 0.5904 - Loss: 0.0031\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 16:44:56\n",
      "Accuracy: 0.9875 - Precision: 0.9053 - Recall: 0.4616 - Specificity: 0.9989 - F1: 0.5910 - Loss: 0.0031\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 16:45:05\n",
      "Accuracy: 0.9875 - Precision: 0.9030 - Recall: 0.4616 - Specificity: 0.9989 - F1: 0.5905 - Loss: 0.0031\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 16:45:13\n",
      "Accuracy: 0.9876 - Precision: 0.9023 - Recall: 0.4623 - Specificity: 0.9989 - F1: 0.5911 - Loss: 0.0031\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 16:45:21\n",
      "Accuracy: 0.9876 - Precision: 0.9019 - Recall: 0.4625 - Specificity: 0.9989 - F1: 0.5914 - Loss: 0.0031\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 16:45:29\n",
      "Accuracy: 0.9876 - Precision: 0.9010 - Recall: 0.4626 - Specificity: 0.9988 - F1: 0.5915 - Loss: 0.0031\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 16:45:37\n",
      "Accuracy: 0.9876 - Precision: 0.9013 - Recall: 0.4621 - Specificity: 0.9989 - F1: 0.5912 - Loss: 0.0031\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 16:45:45\n",
      "Accuracy: 0.9876 - Precision: 0.9012 - Recall: 0.4608 - Specificity: 0.9989 - F1: 0.5902 - Loss: 0.0031\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 16:45:53\n",
      "Accuracy: 0.9876 - Precision: 0.9002 - Recall: 0.4595 - Specificity: 0.9989 - F1: 0.5889 - Loss: 0.0031\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 16:46:02\n",
      "Accuracy: 0.9876 - Precision: 0.9007 - Recall: 0.4592 - Specificity: 0.9989 - F1: 0.5889 - Loss: 0.0031\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 16:46:10\n",
      "Accuracy: 0.9876 - Precision: 0.9011 - Recall: 0.4597 - Specificity: 0.9989 - F1: 0.5896 - Loss: 0.0031\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 16:46:18\n",
      "Accuracy: 0.9877 - Precision: 0.9005 - Recall: 0.4597 - Specificity: 0.9989 - F1: 0.5896 - Loss: 0.0031\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 16:46:26\n",
      "Accuracy: 0.9877 - Precision: 0.9005 - Recall: 0.4603 - Specificity: 0.9989 - F1: 0.5903 - Loss: 0.0031\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 16:46:35\n",
      "Accuracy: 0.9877 - Precision: 0.9001 - Recall: 0.4613 - Specificity: 0.9989 - F1: 0.5912 - Loss: 0.0031\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 16:46:43\n",
      "Accuracy: 0.9877 - Precision: 0.9005 - Recall: 0.4615 - Specificity: 0.9989 - F1: 0.5916 - Loss: 0.0031\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 16:46:52\n",
      "Accuracy: 0.9877 - Precision: 0.9012 - Recall: 0.4614 - Specificity: 0.9989 - F1: 0.5918 - Loss: 0.0031\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 16:47:01\n",
      "Accuracy: 0.9877 - Precision: 0.9012 - Recall: 0.4613 - Specificity: 0.9989 - F1: 0.5919 - Loss: 0.0030\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 16:47:10\n",
      "Accuracy: 0.9877 - Precision: 0.9014 - Recall: 0.4609 - Specificity: 0.9989 - F1: 0.5917 - Loss: 0.0030\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 16:47:18\n",
      "Accuracy: 0.9877 - Precision: 0.9019 - Recall: 0.4610 - Specificity: 0.9989 - F1: 0.5920 - Loss: 0.0030\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 16:47:28\n",
      "Accuracy: 0.9877 - Precision: 0.9012 - Recall: 0.4617 - Specificity: 0.9989 - F1: 0.5926 - Loss: 0.0030\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 16:47:36\n",
      "Accuracy: 0.9878 - Precision: 0.9000 - Recall: 0.4633 - Specificity: 0.9989 - F1: 0.5935 - Loss: 0.0030\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 16:47:45\n",
      "Accuracy: 0.9878 - Precision: 0.8995 - Recall: 0.4641 - Specificity: 0.9989 - F1: 0.5941 - Loss: 0.0030\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 16:47:53\n",
      "Accuracy: 0.9878 - Precision: 0.8996 - Recall: 0.4648 - Specificity: 0.9988 - F1: 0.5949 - Loss: 0.0030\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 16:48:01\n",
      "Accuracy: 0.9878 - Precision: 0.8999 - Recall: 0.4658 - Specificity: 0.9988 - F1: 0.5959 - Loss: 0.0030\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 16:48:09\n",
      "Accuracy: 0.9878 - Precision: 0.9003 - Recall: 0.4673 - Specificity: 0.9989 - F1: 0.5974 - Loss: 0.0030\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 16:48:18\n",
      "Accuracy: 0.9879 - Precision: 0.9001 - Recall: 0.4685 - Specificity: 0.9989 - F1: 0.5984 - Loss: 0.0030\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 16:48:26\n",
      "Accuracy: 0.9879 - Precision: 0.9004 - Recall: 0.4700 - Specificity: 0.9989 - F1: 0.5997 - Loss: 0.0030\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 16:48:34\n",
      "Accuracy: 0.9879 - Precision: 0.8996 - Recall: 0.4711 - Specificity: 0.9988 - F1: 0.6005 - Loss: 0.0030\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 16:48:43\n",
      "Accuracy: 0.9879 - Precision: 0.8993 - Recall: 0.4714 - Specificity: 0.9988 - F1: 0.6008 - Loss: 0.0030\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 16:48:51\n",
      "Accuracy: 0.9879 - Precision: 0.8999 - Recall: 0.4720 - Specificity: 0.9988 - F1: 0.6016 - Loss: 0.0030\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 16:49:01\n",
      "Accuracy: 0.9880 - Precision: 0.9001 - Recall: 0.4719 - Specificity: 0.9988 - F1: 0.6017 - Loss: 0.0030\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 16:49:10\n",
      "Accuracy: 0.9880 - Precision: 0.9005 - Recall: 0.4722 - Specificity: 0.9989 - F1: 0.6022 - Loss: 0.0030\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 16:49:18\n",
      "Accuracy: 0.9880 - Precision: 0.9004 - Recall: 0.4735 - Specificity: 0.9988 - F1: 0.6032 - Loss: 0.0030\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 16:49:26\n",
      "Accuracy: 0.9880 - Precision: 0.9006 - Recall: 0.4740 - Specificity: 0.9988 - F1: 0.6039 - Loss: 0.0030\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 16:49:34\n",
      "Accuracy: 0.9880 - Precision: 0.9005 - Recall: 0.4753 - Specificity: 0.9988 - F1: 0.6050 - Loss: 0.0030\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 16:49:42\n",
      "Accuracy: 0.9880 - Precision: 0.9006 - Recall: 0.4769 - Specificity: 0.9988 - F1: 0.6063 - Loss: 0.0030\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 16:49:51\n",
      "Accuracy: 0.9881 - Precision: 0.9001 - Recall: 0.4783 - Specificity: 0.9988 - F1: 0.6073 - Loss: 0.0030\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 16:49:59\n",
      "Accuracy: 0.9881 - Precision: 0.9005 - Recall: 0.4793 - Specificity: 0.9988 - F1: 0.6083 - Loss: 0.0030\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 16:50:07\n",
      "Accuracy: 0.9881 - Precision: 0.9007 - Recall: 0.4799 - Specificity: 0.9988 - F1: 0.6089 - Loss: 0.0030\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 16:50:16\n",
      "Accuracy: 0.9881 - Precision: 0.9012 - Recall: 0.4800 - Specificity: 0.9988 - F1: 0.6093 - Loss: 0.0030\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 16:50:24\n",
      "Accuracy: 0.9881 - Precision: 0.9017 - Recall: 0.4810 - Specificity: 0.9989 - F1: 0.6104 - Loss: 0.0030\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 16:50:31\n",
      "Accuracy: 0.9882 - Precision: 0.9019 - Recall: 0.4821 - Specificity: 0.9989 - F1: 0.6113 - Loss: 0.0030\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 16:50:40\n",
      "Accuracy: 0.9882 - Precision: 0.9022 - Recall: 0.4827 - Specificity: 0.9989 - F1: 0.6120 - Loss: 0.0030\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 16:50:48\n",
      "Accuracy: 0.9882 - Precision: 0.9018 - Recall: 0.4836 - Specificity: 0.9988 - F1: 0.6128 - Loss: 0.0030\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 16:50:57\n",
      "Accuracy: 0.9882 - Precision: 0.9013 - Recall: 0.4850 - Specificity: 0.9988 - F1: 0.6137 - Loss: 0.0030\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 16:51:06\n",
      "Accuracy: 0.9882 - Precision: 0.9014 - Recall: 0.4859 - Specificity: 0.9988 - F1: 0.6146 - Loss: 0.0030\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 16:51:14\n",
      "Accuracy: 0.9882 - Precision: 0.9011 - Recall: 0.4870 - Specificity: 0.9988 - F1: 0.6154 - Loss: 0.0030\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 16:51:22\n",
      "Accuracy: 0.9882 - Precision: 0.9014 - Recall: 0.4874 - Specificity: 0.9988 - F1: 0.6159 - Loss: 0.0030\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 16:51:30\n",
      "Accuracy: 0.9883 - Precision: 0.9018 - Recall: 0.4880 - Specificity: 0.9988 - F1: 0.6166 - Loss: 0.0030\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 16:51:39\n",
      "Accuracy: 0.9882 - Precision: 0.9003 - Recall: 0.4859 - Specificity: 0.9988 - F1: 0.6143 - Loss: 0.0030\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 16:51:47\n",
      "Accuracy: 0.9882 - Precision: 0.9004 - Recall: 0.4861 - Specificity: 0.9988 - F1: 0.6147 - Loss: 0.0030\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 16:51:55\n",
      "Accuracy: 0.9882 - Precision: 0.9004 - Recall: 0.4857 - Specificity: 0.9988 - F1: 0.6144 - Loss: 0.0030\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 16:52:04\n",
      "Accuracy: 0.9882 - Precision: 0.9002 - Recall: 0.4860 - Specificity: 0.9988 - F1: 0.6147 - Loss: 0.0030\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 16:52:12\n",
      "Accuracy: 0.9882 - Precision: 0.9006 - Recall: 0.4863 - Specificity: 0.9988 - F1: 0.6152 - Loss: 0.0030\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 16:52:20\n",
      "Accuracy: 0.9882 - Precision: 0.9010 - Recall: 0.4869 - Specificity: 0.9988 - F1: 0.6158 - Loss: 0.0030\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 16:52:28\n",
      "Accuracy: 0.9882 - Precision: 0.9013 - Recall: 0.4876 - Specificity: 0.9988 - F1: 0.6166 - Loss: 0.0030\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 16:52:37\n",
      "Accuracy: 0.9883 - Precision: 0.9016 - Recall: 0.4883 - Specificity: 0.9988 - F1: 0.6174 - Loss: 0.0029\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 16:52:45\n",
      "Accuracy: 0.9883 - Precision: 0.9018 - Recall: 0.4893 - Specificity: 0.9988 - F1: 0.6183 - Loss: 0.0029\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 16:52:54\n",
      "Accuracy: 0.9883 - Precision: 0.9013 - Recall: 0.4905 - Specificity: 0.9988 - F1: 0.6191 - Loss: 0.0029\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 16:53:04\n",
      "Accuracy: 0.9883 - Precision: 0.9018 - Recall: 0.4914 - Specificity: 0.9988 - F1: 0.6200 - Loss: 0.0029\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 16:53:12\n",
      "Accuracy: 0.9884 - Precision: 0.9020 - Recall: 0.4921 - Specificity: 0.9988 - F1: 0.6207 - Loss: 0.0029\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 16:53:20\n",
      "Accuracy: 0.9884 - Precision: 0.9022 - Recall: 0.4925 - Specificity: 0.9988 - F1: 0.6212 - Loss: 0.0029\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 16:53:28\n",
      "Accuracy: 0.9884 - Precision: 0.9022 - Recall: 0.4936 - Specificity: 0.9988 - F1: 0.6221 - Loss: 0.0029\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 16:53:37\n",
      "Accuracy: 0.9884 - Precision: 0.9014 - Recall: 0.4947 - Specificity: 0.9988 - F1: 0.6227 - Loss: 0.0029\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 16:53:45\n",
      "Accuracy: 0.9884 - Precision: 0.9013 - Recall: 0.4952 - Specificity: 0.9988 - F1: 0.6231 - Loss: 0.0029\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 16:53:53\n",
      "Accuracy: 0.9884 - Precision: 0.9017 - Recall: 0.4956 - Specificity: 0.9988 - F1: 0.6238 - Loss: 0.0029\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 16:54:01\n",
      "Accuracy: 0.9884 - Precision: 0.9015 - Recall: 0.4955 - Specificity: 0.9988 - F1: 0.6237 - Loss: 0.0029\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 16:54:09\n",
      "Accuracy: 0.9884 - Precision: 0.9020 - Recall: 0.4951 - Specificity: 0.9988 - F1: 0.6235 - Loss: 0.0029\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 16:54:17\n",
      "Accuracy: 0.9884 - Precision: 0.9025 - Recall: 0.4944 - Specificity: 0.9988 - F1: 0.6230 - Loss: 0.0029\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 16:54:25\n",
      "Accuracy: 0.9884 - Precision: 0.9025 - Recall: 0.4942 - Specificity: 0.9988 - F1: 0.6230 - Loss: 0.0029\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 16:54:34\n",
      "Accuracy: 0.9884 - Precision: 0.9025 - Recall: 0.4949 - Specificity: 0.9988 - F1: 0.6236 - Loss: 0.0029\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 16:54:42\n",
      "Accuracy: 0.9884 - Precision: 0.9023 - Recall: 0.4956 - Specificity: 0.9988 - F1: 0.6242 - Loss: 0.0029\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 16:54:50\n",
      "Accuracy: 0.9884 - Precision: 0.9022 - Recall: 0.4960 - Specificity: 0.9988 - F1: 0.6246 - Loss: 0.0029\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 16:55:00\n",
      "Accuracy: 0.9884 - Precision: 0.9022 - Recall: 0.4965 - Specificity: 0.9988 - F1: 0.6250 - Loss: 0.0029\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 16:55:08\n",
      "Accuracy: 0.9885 - Precision: 0.9026 - Recall: 0.4972 - Specificity: 0.9988 - F1: 0.6257 - Loss: 0.0029\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 16:55:16\n",
      "Accuracy: 0.9885 - Precision: 0.9023 - Recall: 0.4974 - Specificity: 0.9988 - F1: 0.6259 - Loss: 0.0029\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 16:55:25\n",
      "Accuracy: 0.9885 - Precision: 0.9026 - Recall: 0.4979 - Specificity: 0.9988 - F1: 0.6265 - Loss: 0.0029\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 16:55:33\n",
      "Accuracy: 0.9885 - Precision: 0.9027 - Recall: 0.4986 - Specificity: 0.9988 - F1: 0.6271 - Loss: 0.0029\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 16:55:41\n",
      "Accuracy: 0.9885 - Precision: 0.9029 - Recall: 0.4991 - Specificity: 0.9988 - F1: 0.6277 - Loss: 0.0029\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 16:55:49\n",
      "Accuracy: 0.9885 - Precision: 0.9024 - Recall: 0.4994 - Specificity: 0.9988 - F1: 0.6279 - Loss: 0.0029\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 16:55:58\n",
      "Accuracy: 0.9885 - Precision: 0.9028 - Recall: 0.4991 - Specificity: 0.9988 - F1: 0.6278 - Loss: 0.0029\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 16:56:06\n",
      "Accuracy: 0.9885 - Precision: 0.9032 - Recall: 0.4989 - Specificity: 0.9988 - F1: 0.6277 - Loss: 0.0029\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 16:56:14\n",
      "Accuracy: 0.9885 - Precision: 0.9037 - Recall: 0.4990 - Specificity: 0.9989 - F1: 0.6280 - Loss: 0.0029\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 16:56:22\n",
      "Accuracy: 0.9885 - Precision: 0.9038 - Recall: 0.4993 - Specificity: 0.9989 - F1: 0.6284 - Loss: 0.0029\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 16:56:30\n",
      "Accuracy: 0.9886 - Precision: 0.9035 - Recall: 0.4999 - Specificity: 0.9988 - F1: 0.6289 - Loss: 0.0029\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 16:56:38\n",
      "Accuracy: 0.9886 - Precision: 0.9033 - Recall: 0.5012 - Specificity: 0.9988 - F1: 0.6298 - Loss: 0.0029\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 16:56:47\n",
      "Accuracy: 0.9886 - Precision: 0.9028 - Recall: 0.5018 - Specificity: 0.9988 - F1: 0.6302 - Loss: 0.0029\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 16:56:56\n",
      "Accuracy: 0.9886 - Precision: 0.9030 - Recall: 0.5022 - Specificity: 0.9988 - F1: 0.6305 - Loss: 0.0029\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 16:57:05\n",
      "Accuracy: 0.9886 - Precision: 0.9030 - Recall: 0.5024 - Specificity: 0.9988 - F1: 0.6309 - Loss: 0.0029\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 16:57:13\n",
      "Accuracy: 0.9886 - Precision: 0.9030 - Recall: 0.5026 - Specificity: 0.9988 - F1: 0.6310 - Loss: 0.0029\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 16:57:21\n",
      "Accuracy: 0.9886 - Precision: 0.9034 - Recall: 0.5025 - Specificity: 0.9988 - F1: 0.6312 - Loss: 0.0029\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 16:57:30\n",
      "Accuracy: 0.9886 - Precision: 0.9038 - Recall: 0.5028 - Specificity: 0.9988 - F1: 0.6316 - Loss: 0.0029\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 16:57:38\n",
      "Accuracy: 0.9886 - Precision: 0.9039 - Recall: 0.5031 - Specificity: 0.9988 - F1: 0.6319 - Loss: 0.0029\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 16:57:46\n",
      "Accuracy: 0.9886 - Precision: 0.9030 - Recall: 0.5036 - Specificity: 0.9988 - F1: 0.6320 - Loss: 0.0029\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 16:57:55\n",
      "Accuracy: 0.9886 - Precision: 0.9032 - Recall: 0.5042 - Specificity: 0.9988 - F1: 0.6326 - Loss: 0.0029\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 16:58:03\n",
      "Accuracy: 0.9886 - Precision: 0.9034 - Recall: 0.5043 - Specificity: 0.9988 - F1: 0.6329 - Loss: 0.0029\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 16:58:12\n",
      "Accuracy: 0.9887 - Precision: 0.9035 - Recall: 0.5050 - Specificity: 0.9988 - F1: 0.6335 - Loss: 0.0029\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 16:58:20\n",
      "Accuracy: 0.9887 - Precision: 0.9033 - Recall: 0.5051 - Specificity: 0.9988 - F1: 0.6336 - Loss: 0.0029\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 16:58:28\n",
      "Accuracy: 0.9887 - Precision: 0.9032 - Recall: 0.5054 - Specificity: 0.9988 - F1: 0.6339 - Loss: 0.0029\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 16:58:37\n",
      "Accuracy: 0.9887 - Precision: 0.9034 - Recall: 0.5054 - Specificity: 0.9988 - F1: 0.6340 - Loss: 0.0029\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 16:58:44\n",
      "Accuracy: 0.9887 - Precision: 0.9038 - Recall: 0.5058 - Specificity: 0.9988 - F1: 0.6345 - Loss: 0.0029\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 16:58:53\n",
      "Accuracy: 0.9887 - Precision: 0.9039 - Recall: 0.5064 - Specificity: 0.9988 - F1: 0.6350 - Loss: 0.0028\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 16:59:02\n",
      "Accuracy: 0.9887 - Precision: 0.9041 - Recall: 0.5076 - Specificity: 0.9988 - F1: 0.6360 - Loss: 0.0028\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 16:59:11\n",
      "Accuracy: 0.9887 - Precision: 0.9040 - Recall: 0.5087 - Specificity: 0.9988 - F1: 0.6369 - Loss: 0.0028\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 16:59:19\n",
      "Accuracy: 0.9888 - Precision: 0.9034 - Recall: 0.5096 - Specificity: 0.9988 - F1: 0.6374 - Loss: 0.0028\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 16:59:27\n",
      "Accuracy: 0.9888 - Precision: 0.9034 - Recall: 0.5105 - Specificity: 0.9988 - F1: 0.6380 - Loss: 0.0028\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 16:59:35\n",
      "Accuracy: 0.9888 - Precision: 0.9037 - Recall: 0.5111 - Specificity: 0.9988 - F1: 0.6386 - Loss: 0.0028\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 16:59:43\n",
      "Accuracy: 0.9888 - Precision: 0.9033 - Recall: 0.5112 - Specificity: 0.9988 - F1: 0.6387 - Loss: 0.0028\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 16:59:52\n",
      "Accuracy: 0.9888 - Precision: 0.9035 - Recall: 0.5110 - Specificity: 0.9988 - F1: 0.6387 - Loss: 0.0028\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 17:00:00\n",
      "Accuracy: 0.9888 - Precision: 0.9039 - Recall: 0.5114 - Specificity: 0.9988 - F1: 0.6391 - Loss: 0.0028\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 17:00:08\n",
      "Accuracy: 0.9888 - Precision: 0.9035 - Recall: 0.5122 - Specificity: 0.9988 - F1: 0.6397 - Loss: 0.0028\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 17:00:16\n",
      "Accuracy: 0.9889 - Precision: 0.9035 - Recall: 0.5130 - Specificity: 0.9988 - F1: 0.6403 - Loss: 0.0028\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 17:00:24\n",
      "Accuracy: 0.9889 - Precision: 0.9032 - Recall: 0.5138 - Specificity: 0.9988 - F1: 0.6408 - Loss: 0.0028\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 17:00:32\n",
      "Accuracy: 0.9889 - Precision: 0.9029 - Recall: 0.5138 - Specificity: 0.9988 - F1: 0.6408 - Loss: 0.0028\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 17:00:41\n",
      "Accuracy: 0.9889 - Precision: 0.9025 - Recall: 0.5131 - Specificity: 0.9988 - F1: 0.6401 - Loss: 0.0028\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 17:00:49\n",
      "Accuracy: 0.9888 - Precision: 0.9020 - Recall: 0.5122 - Specificity: 0.9988 - F1: 0.6393 - Loss: 0.0028\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 17:00:59\n",
      "Accuracy: 0.9887 - Precision: 0.9016 - Recall: 0.5112 - Specificity: 0.9988 - F1: 0.6383 - Loss: 0.0028\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 17:01:07\n",
      "Accuracy: 0.9887 - Precision: 0.9017 - Recall: 0.5102 - Specificity: 0.9988 - F1: 0.6375 - Loss: 0.0028\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 17:01:16\n",
      "Accuracy: 0.9887 - Precision: 0.9017 - Recall: 0.5096 - Specificity: 0.9988 - F1: 0.6370 - Loss: 0.0028\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 17:01:24\n",
      "Accuracy: 0.9887 - Precision: 0.9016 - Recall: 0.5087 - Specificity: 0.9988 - F1: 0.6363 - Loss: 0.0029\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 17:01:32\n",
      "Accuracy: 0.9886 - Precision: 0.9014 - Recall: 0.5072 - Specificity: 0.9988 - F1: 0.6347 - Loss: 0.0029\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 17:01:41\n",
      "Accuracy: 0.9886 - Precision: 0.9018 - Recall: 0.5060 - Specificity: 0.9988 - F1: 0.6335 - Loss: 0.0029\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 17:01:49\n",
      "Accuracy: 0.9885 - Precision: 0.9018 - Recall: 0.5048 - Specificity: 0.9988 - F1: 0.6323 - Loss: 0.0029\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 17:01:57\n",
      "Accuracy: 0.9885 - Precision: 0.9016 - Recall: 0.5035 - Specificity: 0.9988 - F1: 0.6311 - Loss: 0.0029\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 17:02:05\n",
      "Accuracy: 0.9885 - Precision: 0.9018 - Recall: 0.5033 - Specificity: 0.9988 - F1: 0.6310 - Loss: 0.0029\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 17:02:13\n",
      "Accuracy: 0.9885 - Precision: 0.9019 - Recall: 0.5027 - Specificity: 0.9988 - F1: 0.6306 - Loss: 0.0029\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 17:02:21\n",
      "Accuracy: 0.9884 - Precision: 0.9022 - Recall: 0.5015 - Specificity: 0.9988 - F1: 0.6295 - Loss: 0.0029\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 17:02:30\n",
      "Accuracy: 0.9884 - Precision: 0.9023 - Recall: 0.5012 - Specificity: 0.9988 - F1: 0.6293 - Loss: 0.0029\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 17:02:38\n",
      "Accuracy: 0.9884 - Precision: 0.9023 - Recall: 0.5011 - Specificity: 0.9988 - F1: 0.6293 - Loss: 0.0029\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 17:02:46\n",
      "Accuracy: 0.9884 - Precision: 0.9021 - Recall: 0.5002 - Specificity: 0.9988 - F1: 0.6284 - Loss: 0.0029\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 17:02:55\n",
      "Accuracy: 0.9884 - Precision: 0.9020 - Recall: 0.4997 - Specificity: 0.9988 - F1: 0.6280 - Loss: 0.0029\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 17:03:05\n",
      "Accuracy: 0.9884 - Precision: 0.9020 - Recall: 0.4995 - Specificity: 0.9988 - F1: 0.6280 - Loss: 0.0029\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 17:03:13\n",
      "Accuracy: 0.9884 - Precision: 0.9019 - Recall: 0.4989 - Specificity: 0.9988 - F1: 0.6274 - Loss: 0.0029\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 17:03:21\n",
      "Accuracy: 0.9883 - Precision: 0.9018 - Recall: 0.4980 - Specificity: 0.9988 - F1: 0.6265 - Loss: 0.0029\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 17:03:29\n",
      "Accuracy: 0.9883 - Precision: 0.9018 - Recall: 0.4971 - Specificity: 0.9988 - F1: 0.6258 - Loss: 0.0029\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 17:03:38\n",
      "Accuracy: 0.9882 - Precision: 0.9018 - Recall: 0.4964 - Specificity: 0.9988 - F1: 0.6251 - Loss: 0.0030\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 17:03:46\n",
      "Accuracy: 0.9882 - Precision: 0.9017 - Recall: 0.4959 - Specificity: 0.9988 - F1: 0.6247 - Loss: 0.0030\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 17:03:54\n",
      "Accuracy: 0.9881 - Precision: 0.9018 - Recall: 0.4952 - Specificity: 0.9988 - F1: 0.6241 - Loss: 0.0030\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 17:04:02\n",
      "Accuracy: 0.9881 - Precision: 0.9020 - Recall: 0.4944 - Specificity: 0.9988 - F1: 0.6234 - Loss: 0.0030\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 17:04:11\n",
      "Accuracy: 0.9881 - Precision: 0.9021 - Recall: 0.4940 - Specificity: 0.9988 - F1: 0.6232 - Loss: 0.0030\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 17:04:19\n",
      "Accuracy: 0.9877 - Precision: 0.9005 - Recall: 0.4920 - Specificity: 0.9988 - F1: 0.6208 - Loss: 0.0032\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 17:04:27\n",
      "Accuracy: 0.9876 - Precision: 0.8993 - Recall: 0.4910 - Specificity: 0.9988 - F1: 0.6197 - Loss: 0.0033\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 17:04:35\n",
      "Accuracy: 0.9873 - Precision: 0.8988 - Recall: 0.4903 - Specificity: 0.9988 - F1: 0.6190 - Loss: 0.0033\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 17:04:44\n",
      "Accuracy: 0.9870 - Precision: 0.8986 - Recall: 0.4891 - Specificity: 0.9988 - F1: 0.6177 - Loss: 0.0034\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 17:04:52\n",
      "Accuracy: 0.9867 - Precision: 0.8987 - Recall: 0.4872 - Specificity: 0.9988 - F1: 0.6154 - Loss: 0.0035\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 17:05:02\n",
      "Accuracy: 0.9865 - Precision: 0.8990 - Recall: 0.4852 - Specificity: 0.9988 - F1: 0.6130 - Loss: 0.0035\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 17:05:10\n",
      "Accuracy: 0.9862 - Precision: 0.8994 - Recall: 0.4833 - Specificity: 0.9988 - F1: 0.6105 - Loss: 0.0036\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 17:05:18\n",
      "Accuracy: 0.9860 - Precision: 0.8983 - Recall: 0.4813 - Specificity: 0.9988 - F1: 0.6080 - Loss: 0.0036\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 17:05:27\n",
      "Accuracy: 0.9856 - Precision: 0.8987 - Recall: 0.4794 - Specificity: 0.9988 - F1: 0.6056 - Loss: 0.0037\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 17:05:35\n",
      "Accuracy: 0.9853 - Precision: 0.8977 - Recall: 0.4775 - Specificity: 0.9988 - F1: 0.6032 - Loss: 0.0038\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 17:05:43\n",
      "Accuracy: 0.9850 - Precision: 0.8976 - Recall: 0.4757 - Specificity: 0.9988 - F1: 0.6010 - Loss: 0.0038\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 17:05:51\n",
      "Accuracy: 0.9849 - Precision: 0.8953 - Recall: 0.4738 - Specificity: 0.9988 - F1: 0.5986 - Loss: 0.0039\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 17:05:59\n",
      "Accuracy: 0.9846 - Precision: 0.8917 - Recall: 0.4719 - Specificity: 0.9988 - F1: 0.5962 - Loss: 0.0039\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 17:06:07\n",
      "Accuracy: 0.9845 - Precision: 0.8921 - Recall: 0.4700 - Specificity: 0.9988 - F1: 0.5939 - Loss: 0.0040\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 17:06:16\n",
      "Accuracy: 0.9842 - Precision: 0.8886 - Recall: 0.4682 - Specificity: 0.9988 - F1: 0.5916 - Loss: 0.0040\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 17:06:24\n",
      "Accuracy: 0.9838 - Precision: 0.8851 - Recall: 0.4664 - Specificity: 0.9988 - F1: 0.5892 - Loss: 0.0041\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 17:06:32\n",
      "Accuracy: 0.9836 - Precision: 0.8856 - Recall: 0.4645 - Specificity: 0.9988 - F1: 0.5869 - Loss: 0.0042\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 17:06:40\n",
      "Accuracy: 0.9834 - Precision: 0.8848 - Recall: 0.4627 - Specificity: 0.9988 - F1: 0.5847 - Loss: 0.0042\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 17:06:49\n",
      "Accuracy: 0.9834 - Precision: 0.8814 - Recall: 0.4609 - Specificity: 0.9988 - F1: 0.5824 - Loss: 0.0043\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 17:06:58\n",
      "Accuracy: 0.9833 - Precision: 0.8780 - Recall: 0.4592 - Specificity: 0.9988 - F1: 0.5801 - Loss: 0.0043\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 17:07:07\n",
      "Accuracy: 0.9833 - Precision: 0.8785 - Recall: 0.4574 - Specificity: 0.9988 - F1: 0.5779 - Loss: 0.0043\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 17:07:16\n",
      "Accuracy: 0.9833 - Precision: 0.8751 - Recall: 0.4556 - Specificity: 0.9988 - F1: 0.5757 - Loss: 0.0043\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 17:07:24\n",
      "Accuracy: 0.9831 - Precision: 0.8717 - Recall: 0.4539 - Specificity: 0.9988 - F1: 0.5735 - Loss: 0.0044\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 17:07:32\n",
      "Accuracy: 0.9830 - Precision: 0.8684 - Recall: 0.4522 - Specificity: 0.9988 - F1: 0.5713 - Loss: 0.0044\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 17:07:41\n",
      "Accuracy: 0.9830 - Precision: 0.8651 - Recall: 0.4505 - Specificity: 0.9988 - F1: 0.5692 - Loss: 0.0044\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 17:07:49\n",
      "Accuracy: 0.9829 - Precision: 0.8619 - Recall: 0.4488 - Specificity: 0.9989 - F1: 0.5670 - Loss: 0.0045\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 17:07:57\n",
      "Accuracy: 0.9829 - Precision: 0.8586 - Recall: 0.4471 - Specificity: 0.9989 - F1: 0.5649 - Loss: 0.0045\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 17:08:05\n",
      "Accuracy: 0.9829 - Precision: 0.8554 - Recall: 0.4454 - Specificity: 0.9989 - F1: 0.5628 - Loss: 0.0045\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 17:08:13\n",
      "Accuracy: 0.9828 - Precision: 0.8522 - Recall: 0.4437 - Specificity: 0.9989 - F1: 0.5607 - Loss: 0.0045\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 17:08:22\n",
      "Accuracy: 0.9828 - Precision: 0.8491 - Recall: 0.4421 - Specificity: 0.9989 - F1: 0.5586 - Loss: 0.0045\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 17:08:30\n",
      "Accuracy: 0.9828 - Precision: 0.8459 - Recall: 0.4405 - Specificity: 0.9989 - F1: 0.5565 - Loss: 0.0047\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 17:08:38\n",
      "Accuracy: 0.9828 - Precision: 0.8428 - Recall: 0.4388 - Specificity: 0.9989 - F1: 0.5544 - Loss: 0.0047\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 17:08:47\n",
      "Accuracy: 0.9827 - Precision: 0.8397 - Recall: 0.4372 - Specificity: 0.9989 - F1: 0.5524 - Loss: 0.0047\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 17:08:57\n",
      "Accuracy: 0.9827 - Precision: 0.8366 - Recall: 0.4356 - Specificity: 0.9989 - F1: 0.5504 - Loss: 0.0047\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 17:09:08\n",
      "Accuracy: 0.9826 - Precision: 0.8336 - Recall: 0.4340 - Specificity: 0.9989 - F1: 0.5484 - Loss: 0.0047\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 17:09:17\n",
      "Accuracy: 0.9826 - Precision: 0.8305 - Recall: 0.4324 - Specificity: 0.9989 - F1: 0.5464 - Loss: 0.0048\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 17:09:26\n",
      "Accuracy: 0.9826 - Precision: 0.8275 - Recall: 0.4309 - Specificity: 0.9989 - F1: 0.5444 - Loss: 0.0048\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 17:09:34\n",
      "Accuracy: 0.9826 - Precision: 0.8245 - Recall: 0.4293 - Specificity: 0.9989 - F1: 0.5424 - Loss: 0.0048\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 17:09:42\n",
      "Accuracy: 0.9825 - Precision: 0.8216 - Recall: 0.4278 - Specificity: 0.9989 - F1: 0.5405 - Loss: 0.0048\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 17:09:51\n",
      "Accuracy: 0.9825 - Precision: 0.8186 - Recall: 0.4262 - Specificity: 0.9989 - F1: 0.5386 - Loss: 0.0048\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 17:09:58\n",
      "Accuracy: 0.9825 - Precision: 0.8157 - Recall: 0.4247 - Specificity: 0.9989 - F1: 0.5366 - Loss: 0.0048\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 17:10:07\n",
      "Accuracy: 0.9825 - Precision: 0.8128 - Recall: 0.4232 - Specificity: 0.9989 - F1: 0.5347 - Loss: 0.0048\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 17:10:15\n",
      "Accuracy: 0.9825 - Precision: 0.8099 - Recall: 0.4217 - Specificity: 0.9989 - F1: 0.5328 - Loss: 0.0048\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 17:10:23\n",
      "Accuracy: 0.9825 - Precision: 0.8071 - Recall: 0.4202 - Specificity: 0.9989 - F1: 0.5309 - Loss: 0.0048\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 17:10:32\n",
      "Accuracy: 0.9825 - Precision: 0.8042 - Recall: 0.4187 - Specificity: 0.9989 - F1: 0.5291 - Loss: 0.0049\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 17:10:40\n",
      "Accuracy: 0.9825 - Precision: 0.8014 - Recall: 0.4173 - Specificity: 0.9989 - F1: 0.5272 - Loss: 0.0049\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 17:10:48\n",
      "Accuracy: 0.9825 - Precision: 0.7986 - Recall: 0.4158 - Specificity: 0.9989 - F1: 0.5254 - Loss: 0.0049\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 17:10:57\n",
      "Accuracy: 0.9824 - Precision: 0.7958 - Recall: 0.4144 - Specificity: 0.9989 - F1: 0.5235 - Loss: 0.0049\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 17:11:06\n",
      "Accuracy: 0.9824 - Precision: 0.7930 - Recall: 0.4129 - Specificity: 0.9989 - F1: 0.5217 - Loss: 0.0049\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 17:11:14\n",
      "Accuracy: 0.9823 - Precision: 0.7903 - Recall: 0.4115 - Specificity: 0.9989 - F1: 0.5199 - Loss: 0.0049\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 17:11:22\n",
      "Accuracy: 0.9823 - Precision: 0.7876 - Recall: 0.4101 - Specificity: 0.9990 - F1: 0.5181 - Loss: 0.0049\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 17:11:30\n",
      "Accuracy: 0.9823 - Precision: 0.7849 - Recall: 0.4087 - Specificity: 0.9990 - F1: 0.5163 - Loss: 0.0049\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 17:11:39\n",
      "Accuracy: 0.9822 - Precision: 0.7822 - Recall: 0.4073 - Specificity: 0.9990 - F1: 0.5146 - Loss: 0.0049\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 17:11:47\n",
      "Accuracy: 0.9822 - Precision: 0.7795 - Recall: 0.4059 - Specificity: 0.9990 - F1: 0.5128 - Loss: 0.0049\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 17:11:55\n",
      "Accuracy: 0.9822 - Precision: 0.7769 - Recall: 0.4045 - Specificity: 0.9990 - F1: 0.5111 - Loss: 0.0049\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 17:12:04\n",
      "Accuracy: 0.9821 - Precision: 0.7742 - Recall: 0.4031 - Specificity: 0.9990 - F1: 0.5093 - Loss: 0.0049\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 17:12:12\n",
      "Accuracy: 0.9821 - Precision: 0.7716 - Recall: 0.4018 - Specificity: 0.9990 - F1: 0.5076 - Loss: 0.0049\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 17:12:21\n",
      "Accuracy: 0.9821 - Precision: 0.7690 - Recall: 0.4004 - Specificity: 0.9990 - F1: 0.5059 - Loss: 0.0049\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 17:12:32\n",
      "Accuracy: 0.9820 - Precision: 0.7664 - Recall: 0.3991 - Specificity: 0.9990 - F1: 0.5042 - Loss: 0.0049\n",
      "\n",
      "Epoch 7/20\n",
      "Validation - Accuracy: 0.9786, Precision: 0.0000, Recall: 0.0000, Specificity: 1.0000, F1: 0.0000, Loss: 0.0058\n",
      "\n",
      "\n",
      "Epoch 8/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 17:22:27\n",
      "Accuracy: 0.9738 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0065\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 17:22:36\n",
      "Accuracy: 0.9722 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0067\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 17:22:45\n",
      "Accuracy: 0.9711 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0065\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 17:22:53\n",
      "Accuracy: 0.9742 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0059\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 17:23:06\n",
      "Accuracy: 0.9762 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0055\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 17:23:16\n",
      "Accuracy: 0.9762 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0055\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 17:23:25\n",
      "Accuracy: 0.9775 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0051\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 17:23:35\n",
      "Accuracy: 0.9781 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0049\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 17:23:44\n",
      "Accuracy: 0.9788 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0047\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 17:23:53\n",
      "Accuracy: 0.9792 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0046\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 17:24:01\n",
      "Accuracy: 0.9795 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0045\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 17:24:09\n",
      "Accuracy: 0.9797 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0044\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 17:24:18\n",
      "Accuracy: 0.9798 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0043\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 17:24:27\n",
      "Accuracy: 0.9800 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0043\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 17:24:38\n",
      "Accuracy: 0.9802 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0042\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 17:24:47\n",
      "Accuracy: 0.9797 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0043\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 17:24:55\n",
      "Accuracy: 0.9800 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0042\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 17:25:03\n",
      "Accuracy: 0.9799 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0041\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 17:25:13\n",
      "Accuracy: 0.9799 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0041\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 17:25:22\n",
      "Accuracy: 0.9801 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0040\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 17:25:30\n",
      "Accuracy: 0.9801 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0040\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 17:25:38\n",
      "Accuracy: 0.9799 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0041\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 17:25:47\n",
      "Accuracy: 0.9798 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0041\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 17:25:55\n",
      "Accuracy: 0.9796 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0041\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 17:26:03\n",
      "Accuracy: 0.9796 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0041\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 17:26:11\n",
      "Accuracy: 0.9798 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0040\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 17:26:19\n",
      "Accuracy: 0.9798 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0040\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 17:26:27\n",
      "Accuracy: 0.9797 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0040\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 17:26:35\n",
      "Accuracy: 0.9794 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0041\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 17:26:43\n",
      "Accuracy: 0.9793 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0041\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 17:26:51\n",
      "Accuracy: 0.9795 - Precision: 0.0000 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0000 - Loss: 0.0040\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 17:26:59\n",
      "Accuracy: 0.9794 - Precision: 0.0250 - Recall: 0.0000 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0040\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 17:27:08\n",
      "Accuracy: 0.9795 - Precision: 0.0545 - Recall: 0.0001 - Specificity: 1.0000 - F1: 0.0001 - Loss: 0.0040\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 17:27:18\n",
      "Accuracy: 0.9793 - Precision: 0.0819 - Recall: 0.0003 - Specificity: 1.0000 - F1: 0.0007 - Loss: 0.0040\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 17:27:26\n",
      "Accuracy: 0.9793 - Precision: 0.1071 - Recall: 0.0011 - Specificity: 1.0000 - F1: 0.0021 - Loss: 0.0040\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 17:27:34\n",
      "Accuracy: 0.9794 - Precision: 0.1300 - Recall: 0.0033 - Specificity: 1.0000 - F1: 0.0062 - Loss: 0.0039\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 17:27:42\n",
      "Accuracy: 0.9794 - Precision: 0.1526 - Recall: 0.0085 - Specificity: 1.0000 - F1: 0.0148 - Loss: 0.0039\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 17:27:50\n",
      "Accuracy: 0.9795 - Precision: 0.1734 - Recall: 0.0134 - Specificity: 1.0000 - F1: 0.0229 - Loss: 0.0039\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 17:27:59\n",
      "Accuracy: 0.9796 - Precision: 0.1926 - Recall: 0.0220 - Specificity: 1.0000 - F1: 0.0353 - Loss: 0.0039\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 17:28:07\n",
      "Accuracy: 0.9798 - Precision: 0.2110 - Recall: 0.0325 - Specificity: 0.9999 - F1: 0.0494 - Loss: 0.0039\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 17:28:15\n",
      "Accuracy: 0.9798 - Precision: 0.2270 - Recall: 0.0404 - Specificity: 0.9999 - F1: 0.0605 - Loss: 0.0039\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 17:28:23\n",
      "Accuracy: 0.9800 - Precision: 0.2440 - Recall: 0.0502 - Specificity: 0.9999 - F1: 0.0736 - Loss: 0.0039\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 17:28:31\n",
      "Accuracy: 0.9802 - Precision: 0.2598 - Recall: 0.0609 - Specificity: 0.9999 - F1: 0.0872 - Loss: 0.0038\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 17:28:40\n",
      "Accuracy: 0.9804 - Precision: 0.2743 - Recall: 0.0723 - Specificity: 0.9999 - F1: 0.1009 - Loss: 0.0038\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 17:28:48\n",
      "Accuracy: 0.9806 - Precision: 0.2834 - Recall: 0.0824 - Specificity: 0.9998 - F1: 0.1119 - Loss: 0.0038\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 17:28:57\n",
      "Accuracy: 0.9807 - Precision: 0.2982 - Recall: 0.0874 - Specificity: 0.9998 - F1: 0.1197 - Loss: 0.0038\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 17:29:05\n",
      "Accuracy: 0.9807 - Precision: 0.3123 - Recall: 0.0908 - Specificity: 0.9998 - F1: 0.1256 - Loss: 0.0038\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 17:29:15\n",
      "Accuracy: 0.9807 - Precision: 0.3264 - Recall: 0.0938 - Specificity: 0.9998 - F1: 0.1308 - Loss: 0.0038\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 17:29:24\n",
      "Accuracy: 0.9808 - Precision: 0.3384 - Recall: 0.1003 - Specificity: 0.9998 - F1: 0.1397 - Loss: 0.0037\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 17:29:32\n",
      "Accuracy: 0.9809 - Precision: 0.3510 - Recall: 0.1078 - Specificity: 0.9998 - F1: 0.1497 - Loss: 0.0037\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 17:29:40\n",
      "Accuracy: 0.9811 - Precision: 0.3618 - Recall: 0.1166 - Specificity: 0.9997 - F1: 0.1603 - Loss: 0.0037\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 17:29:49\n",
      "Accuracy: 0.9812 - Precision: 0.3717 - Recall: 0.1248 - Specificity: 0.9997 - F1: 0.1701 - Loss: 0.0037\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 17:29:57\n",
      "Accuracy: 0.9814 - Precision: 0.3820 - Recall: 0.1339 - Specificity: 0.9997 - F1: 0.1807 - Loss: 0.0037\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 17:30:05\n",
      "Accuracy: 0.9816 - Precision: 0.3927 - Recall: 0.1419 - Specificity: 0.9997 - F1: 0.1905 - Loss: 0.0036\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 17:30:13\n",
      "Accuracy: 0.9817 - Precision: 0.4028 - Recall: 0.1481 - Specificity: 0.9997 - F1: 0.1986 - Loss: 0.0036\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 17:30:21\n",
      "Accuracy: 0.9819 - Precision: 0.4116 - Recall: 0.1572 - Specificity: 0.9997 - F1: 0.2087 - Loss: 0.0036\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 17:30:29\n",
      "Accuracy: 0.9821 - Precision: 0.4198 - Recall: 0.1656 - Specificity: 0.9996 - F1: 0.2179 - Loss: 0.0036\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 17:30:37\n",
      "Accuracy: 0.9823 - Precision: 0.4278 - Recall: 0.1738 - Specificity: 0.9996 - F1: 0.2270 - Loss: 0.0036\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 17:30:45\n",
      "Accuracy: 0.9824 - Precision: 0.4363 - Recall: 0.1811 - Specificity: 0.9996 - F1: 0.2356 - Loss: 0.0035\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 17:30:54\n",
      "Accuracy: 0.9825 - Precision: 0.4425 - Recall: 0.1869 - Specificity: 0.9996 - F1: 0.2423 - Loss: 0.0035\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 17:31:02\n",
      "Accuracy: 0.9825 - Precision: 0.4491 - Recall: 0.1905 - Specificity: 0.9996 - F1: 0.2473 - Loss: 0.0035\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 17:31:10\n",
      "Accuracy: 0.9827 - Precision: 0.4576 - Recall: 0.1940 - Specificity: 0.9996 - F1: 0.2526 - Loss: 0.0035\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 17:31:20\n",
      "Accuracy: 0.9828 - Precision: 0.4660 - Recall: 0.1986 - Specificity: 0.9996 - F1: 0.2589 - Loss: 0.0035\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 17:31:28\n",
      "Accuracy: 0.9829 - Precision: 0.4737 - Recall: 0.2037 - Specificity: 0.9996 - F1: 0.2655 - Loss: 0.0035\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 17:31:36\n",
      "Accuracy: 0.9829 - Precision: 0.4812 - Recall: 0.2080 - Specificity: 0.9996 - F1: 0.2713 - Loss: 0.0034\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 17:31:45\n",
      "Accuracy: 0.9830 - Precision: 0.4873 - Recall: 0.2117 - Specificity: 0.9995 - F1: 0.2762 - Loss: 0.0035\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 17:31:53\n",
      "Accuracy: 0.9830 - Precision: 0.4928 - Recall: 0.2168 - Specificity: 0.9995 - F1: 0.2821 - Loss: 0.0034\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 17:32:01\n",
      "Accuracy: 0.9831 - Precision: 0.4985 - Recall: 0.2219 - Specificity: 0.9995 - F1: 0.2881 - Loss: 0.0034\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 17:32:09\n",
      "Accuracy: 0.9832 - Precision: 0.5049 - Recall: 0.2276 - Specificity: 0.9995 - F1: 0.2947 - Loss: 0.0034\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 17:32:17\n",
      "Accuracy: 0.9834 - Precision: 0.5112 - Recall: 0.2331 - Specificity: 0.9995 - F1: 0.3011 - Loss: 0.0034\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 17:32:26\n",
      "Accuracy: 0.9835 - Precision: 0.5160 - Recall: 0.2363 - Specificity: 0.9995 - F1: 0.3053 - Loss: 0.0034\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 17:32:34\n",
      "Accuracy: 0.9835 - Precision: 0.5204 - Recall: 0.2393 - Specificity: 0.9995 - F1: 0.3092 - Loss: 0.0034\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 17:32:42\n",
      "Accuracy: 0.9835 - Precision: 0.5267 - Recall: 0.2411 - Specificity: 0.9995 - F1: 0.3123 - Loss: 0.0034\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 17:32:50\n",
      "Accuracy: 0.9835 - Precision: 0.5327 - Recall: 0.2439 - Specificity: 0.9995 - F1: 0.3164 - Loss: 0.0034\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 17:32:58\n",
      "Accuracy: 0.9836 - Precision: 0.5372 - Recall: 0.2483 - Specificity: 0.9995 - F1: 0.3214 - Loss: 0.0034\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 17:33:06\n",
      "Accuracy: 0.9837 - Precision: 0.5418 - Recall: 0.2534 - Specificity: 0.9994 - F1: 0.3269 - Loss: 0.0034\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 17:33:17\n",
      "Accuracy: 0.9838 - Precision: 0.5453 - Recall: 0.2592 - Specificity: 0.9994 - F1: 0.3324 - Loss: 0.0034\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 17:33:27\n",
      "Accuracy: 0.9838 - Precision: 0.5505 - Recall: 0.2639 - Specificity: 0.9994 - F1: 0.3378 - Loss: 0.0034\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 17:33:35\n",
      "Accuracy: 0.9839 - Precision: 0.5552 - Recall: 0.2670 - Specificity: 0.9994 - F1: 0.3419 - Loss: 0.0034\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 17:33:44\n",
      "Accuracy: 0.9839 - Precision: 0.5603 - Recall: 0.2695 - Specificity: 0.9994 - F1: 0.3455 - Loss: 0.0034\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 17:33:53\n",
      "Accuracy: 0.9840 - Precision: 0.5655 - Recall: 0.2711 - Specificity: 0.9994 - F1: 0.3482 - Loss: 0.0034\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 17:34:02\n",
      "Accuracy: 0.9840 - Precision: 0.5691 - Recall: 0.2728 - Specificity: 0.9994 - F1: 0.3507 - Loss: 0.0033\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 17:34:11\n",
      "Accuracy: 0.9841 - Precision: 0.5737 - Recall: 0.2746 - Specificity: 0.9994 - F1: 0.3536 - Loss: 0.0033\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 17:34:20\n",
      "Accuracy: 0.9841 - Precision: 0.5775 - Recall: 0.2771 - Specificity: 0.9994 - F1: 0.3568 - Loss: 0.0033\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 17:34:28\n",
      "Accuracy: 0.9842 - Precision: 0.5817 - Recall: 0.2819 - Specificity: 0.9994 - F1: 0.3619 - Loss: 0.0033\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 17:34:37\n",
      "Accuracy: 0.9843 - Precision: 0.5847 - Recall: 0.2856 - Specificity: 0.9994 - F1: 0.3659 - Loss: 0.0033\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 17:34:46\n",
      "Accuracy: 0.9844 - Precision: 0.5887 - Recall: 0.2898 - Specificity: 0.9994 - F1: 0.3705 - Loss: 0.0033\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 17:34:54\n",
      "Accuracy: 0.9844 - Precision: 0.5921 - Recall: 0.2929 - Specificity: 0.9993 - F1: 0.3740 - Loss: 0.0033\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 17:35:03\n",
      "Accuracy: 0.9845 - Precision: 0.5964 - Recall: 0.2952 - Specificity: 0.9993 - F1: 0.3773 - Loss: 0.0033\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 17:35:12\n",
      "Accuracy: 0.9845 - Precision: 0.6006 - Recall: 0.2969 - Specificity: 0.9994 - F1: 0.3799 - Loss: 0.0033\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 17:35:22\n",
      "Accuracy: 0.9845 - Precision: 0.6044 - Recall: 0.2999 - Specificity: 0.9994 - F1: 0.3836 - Loss: 0.0033\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 17:35:31\n",
      "Accuracy: 0.9846 - Precision: 0.6069 - Recall: 0.3037 - Specificity: 0.9993 - F1: 0.3874 - Loss: 0.0033\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 17:35:39\n",
      "Accuracy: 0.9847 - Precision: 0.6099 - Recall: 0.3077 - Specificity: 0.9993 - F1: 0.3914 - Loss: 0.0033\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 17:35:50\n",
      "Accuracy: 0.9848 - Precision: 0.6132 - Recall: 0.3110 - Specificity: 0.9993 - F1: 0.3951 - Loss: 0.0032\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 17:36:00\n",
      "Accuracy: 0.9848 - Precision: 0.6151 - Recall: 0.3137 - Specificity: 0.9993 - F1: 0.3979 - Loss: 0.0032\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 17:36:09\n",
      "Accuracy: 0.9848 - Precision: 0.6180 - Recall: 0.3147 - Specificity: 0.9993 - F1: 0.3996 - Loss: 0.0032\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 17:36:17\n",
      "Accuracy: 0.9848 - Precision: 0.6219 - Recall: 0.3152 - Specificity: 0.9993 - F1: 0.4010 - Loss: 0.0032\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 17:36:26\n",
      "Accuracy: 0.9849 - Precision: 0.6248 - Recall: 0.3161 - Specificity: 0.9993 - F1: 0.4026 - Loss: 0.0032\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 17:36:35\n",
      "Accuracy: 0.9849 - Precision: 0.6276 - Recall: 0.3168 - Specificity: 0.9993 - F1: 0.4040 - Loss: 0.0032\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 17:36:44\n",
      "Accuracy: 0.9849 - Precision: 0.6305 - Recall: 0.3182 - Specificity: 0.9993 - F1: 0.4061 - Loss: 0.0032\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 17:36:53\n",
      "Accuracy: 0.9850 - Precision: 0.6328 - Recall: 0.3201 - Specificity: 0.9993 - F1: 0.4084 - Loss: 0.0032\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 17:37:01\n",
      "Accuracy: 0.9850 - Precision: 0.6331 - Recall: 0.3212 - Specificity: 0.9993 - F1: 0.4095 - Loss: 0.0032\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 17:37:12\n",
      "Accuracy: 0.9851 - Precision: 0.6351 - Recall: 0.3233 - Specificity: 0.9993 - F1: 0.4119 - Loss: 0.0032\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 17:37:22\n",
      "Accuracy: 0.9851 - Precision: 0.6375 - Recall: 0.3248 - Specificity: 0.9992 - F1: 0.4139 - Loss: 0.0032\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 17:37:31\n",
      "Accuracy: 0.9852 - Precision: 0.6392 - Recall: 0.3267 - Specificity: 0.9992 - F1: 0.4160 - Loss: 0.0032\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 17:37:40\n",
      "Accuracy: 0.9852 - Precision: 0.6419 - Recall: 0.3281 - Specificity: 0.9992 - F1: 0.4181 - Loss: 0.0032\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 17:37:49\n",
      "Accuracy: 0.9852 - Precision: 0.6443 - Recall: 0.3286 - Specificity: 0.9992 - F1: 0.4192 - Loss: 0.0032\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 17:37:58\n",
      "Accuracy: 0.9853 - Precision: 0.6454 - Recall: 0.3288 - Specificity: 0.9992 - F1: 0.4197 - Loss: 0.0032\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 17:38:07\n",
      "Accuracy: 0.9853 - Precision: 0.6481 - Recall: 0.3300 - Specificity: 0.9992 - F1: 0.4216 - Loss: 0.0031\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 17:38:15\n",
      "Accuracy: 0.9854 - Precision: 0.6506 - Recall: 0.3319 - Specificity: 0.9992 - F1: 0.4239 - Loss: 0.0031\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 17:38:24\n",
      "Accuracy: 0.9854 - Precision: 0.6523 - Recall: 0.3332 - Specificity: 0.9992 - F1: 0.4255 - Loss: 0.0031\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 17:38:33\n",
      "Accuracy: 0.9854 - Precision: 0.6547 - Recall: 0.3348 - Specificity: 0.9992 - F1: 0.4277 - Loss: 0.0031\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 17:38:42\n",
      "Accuracy: 0.9855 - Precision: 0.6563 - Recall: 0.3370 - Specificity: 0.9992 - F1: 0.4299 - Loss: 0.0031\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 17:38:50\n",
      "Accuracy: 0.9855 - Precision: 0.6589 - Recall: 0.3384 - Specificity: 0.9992 - F1: 0.4319 - Loss: 0.0031\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 17:38:59\n",
      "Accuracy: 0.9855 - Precision: 0.6617 - Recall: 0.3391 - Specificity: 0.9992 - F1: 0.4332 - Loss: 0.0031\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 17:39:08\n",
      "Accuracy: 0.9856 - Precision: 0.6640 - Recall: 0.3400 - Specificity: 0.9992 - F1: 0.4346 - Loss: 0.0031\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 17:39:16\n",
      "Accuracy: 0.9856 - Precision: 0.6662 - Recall: 0.3406 - Specificity: 0.9992 - F1: 0.4359 - Loss: 0.0031\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 17:39:25\n",
      "Accuracy: 0.9856 - Precision: 0.6685 - Recall: 0.3418 - Specificity: 0.9992 - F1: 0.4376 - Loss: 0.0031\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 17:39:35\n",
      "Accuracy: 0.9856 - Precision: 0.6696 - Recall: 0.3441 - Specificity: 0.9992 - F1: 0.4397 - Loss: 0.0031\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 17:39:45\n",
      "Accuracy: 0.9857 - Precision: 0.6701 - Recall: 0.3469 - Specificity: 0.9992 - F1: 0.4419 - Loss: 0.0031\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 17:39:53\n",
      "Accuracy: 0.9857 - Precision: 0.6715 - Recall: 0.3490 - Specificity: 0.9992 - F1: 0.4440 - Loss: 0.0031\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 17:40:01\n",
      "Accuracy: 0.9858 - Precision: 0.6734 - Recall: 0.3507 - Specificity: 0.9992 - F1: 0.4460 - Loss: 0.0031\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 17:40:10\n",
      "Accuracy: 0.9858 - Precision: 0.6756 - Recall: 0.3524 - Specificity: 0.9992 - F1: 0.4481 - Loss: 0.0031\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 17:40:18\n",
      "Accuracy: 0.9858 - Precision: 0.6780 - Recall: 0.3543 - Specificity: 0.9992 - F1: 0.4504 - Loss: 0.0031\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 17:40:27\n",
      "Accuracy: 0.9859 - Precision: 0.6798 - Recall: 0.3559 - Specificity: 0.9992 - F1: 0.4523 - Loss: 0.0031\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 17:40:36\n",
      "Accuracy: 0.9859 - Precision: 0.6820 - Recall: 0.3579 - Specificity: 0.9992 - F1: 0.4546 - Loss: 0.0031\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 17:40:44\n",
      "Accuracy: 0.9859 - Precision: 0.6831 - Recall: 0.3596 - Specificity: 0.9992 - F1: 0.4564 - Loss: 0.0031\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 17:40:53\n",
      "Accuracy: 0.9860 - Precision: 0.6846 - Recall: 0.3607 - Specificity: 0.9991 - F1: 0.4578 - Loss: 0.0031\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 17:41:01\n",
      "Accuracy: 0.9860 - Precision: 0.6869 - Recall: 0.3621 - Specificity: 0.9992 - F1: 0.4596 - Loss: 0.0030\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 17:41:09\n",
      "Accuracy: 0.9860 - Precision: 0.6889 - Recall: 0.3629 - Specificity: 0.9992 - F1: 0.4609 - Loss: 0.0030\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 17:41:18\n",
      "Accuracy: 0.9860 - Precision: 0.6908 - Recall: 0.3640 - Specificity: 0.9992 - F1: 0.4624 - Loss: 0.0030\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 17:41:27\n",
      "Accuracy: 0.9861 - Precision: 0.6923 - Recall: 0.3662 - Specificity: 0.9991 - F1: 0.4646 - Loss: 0.0030\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 17:41:37\n",
      "Accuracy: 0.9861 - Precision: 0.6940 - Recall: 0.3676 - Specificity: 0.9991 - F1: 0.4663 - Loss: 0.0030\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 17:41:47\n",
      "Accuracy: 0.9861 - Precision: 0.6956 - Recall: 0.3696 - Specificity: 0.9991 - F1: 0.4684 - Loss: 0.0030\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 17:41:55\n",
      "Accuracy: 0.9862 - Precision: 0.6972 - Recall: 0.3718 - Specificity: 0.9991 - F1: 0.4706 - Loss: 0.0030\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 17:42:03\n",
      "Accuracy: 0.9862 - Precision: 0.6985 - Recall: 0.3740 - Specificity: 0.9991 - F1: 0.4727 - Loss: 0.0030\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 17:42:12\n",
      "Accuracy: 0.9862 - Precision: 0.7003 - Recall: 0.3757 - Specificity: 0.9991 - F1: 0.4747 - Loss: 0.0030\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 17:42:21\n",
      "Accuracy: 0.9863 - Precision: 0.7018 - Recall: 0.3772 - Specificity: 0.9991 - F1: 0.4764 - Loss: 0.0030\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 17:42:32\n",
      "Accuracy: 0.9863 - Precision: 0.7037 - Recall: 0.3784 - Specificity: 0.9991 - F1: 0.4779 - Loss: 0.0030\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 17:42:41\n",
      "Accuracy: 0.9863 - Precision: 0.7056 - Recall: 0.3802 - Specificity: 0.9991 - F1: 0.4800 - Loss: 0.0030\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 17:42:49\n",
      "Accuracy: 0.9864 - Precision: 0.7070 - Recall: 0.3822 - Specificity: 0.9991 - F1: 0.4821 - Loss: 0.0030\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 17:42:58\n",
      "Accuracy: 0.9864 - Precision: 0.7086 - Recall: 0.3835 - Specificity: 0.9991 - F1: 0.4836 - Loss: 0.0030\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 17:43:07\n",
      "Accuracy: 0.9864 - Precision: 0.7096 - Recall: 0.3852 - Specificity: 0.9991 - F1: 0.4853 - Loss: 0.0030\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 17:43:16\n",
      "Accuracy: 0.9865 - Precision: 0.7104 - Recall: 0.3873 - Specificity: 0.9991 - F1: 0.4871 - Loss: 0.0030\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 17:43:24\n",
      "Accuracy: 0.9865 - Precision: 0.7120 - Recall: 0.3887 - Specificity: 0.9991 - F1: 0.4888 - Loss: 0.0030\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 17:43:34\n",
      "Accuracy: 0.9865 - Precision: 0.7130 - Recall: 0.3904 - Specificity: 0.9991 - F1: 0.4904 - Loss: 0.0030\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 17:43:44\n",
      "Accuracy: 0.9865 - Precision: 0.7146 - Recall: 0.3914 - Specificity: 0.9991 - F1: 0.4918 - Loss: 0.0030\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 17:43:53\n",
      "Accuracy: 0.9866 - Precision: 0.7162 - Recall: 0.3925 - Specificity: 0.9991 - F1: 0.4932 - Loss: 0.0030\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 17:44:01\n",
      "Accuracy: 0.9865 - Precision: 0.7159 - Recall: 0.3911 - Specificity: 0.9991 - F1: 0.4918 - Loss: 0.0030\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 17:44:10\n",
      "Accuracy: 0.9866 - Precision: 0.7172 - Recall: 0.3916 - Specificity: 0.9991 - F1: 0.4927 - Loss: 0.0030\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 17:44:18\n",
      "Accuracy: 0.9865 - Precision: 0.7185 - Recall: 0.3914 - Specificity: 0.9991 - F1: 0.4928 - Loss: 0.0030\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 17:44:26\n",
      "Accuracy: 0.9865 - Precision: 0.7198 - Recall: 0.3920 - Specificity: 0.9991 - F1: 0.4937 - Loss: 0.0030\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 17:44:35\n",
      "Accuracy: 0.9866 - Precision: 0.7214 - Recall: 0.3929 - Specificity: 0.9991 - F1: 0.4949 - Loss: 0.0030\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 17:44:43\n",
      "Accuracy: 0.9866 - Precision: 0.7230 - Recall: 0.3942 - Specificity: 0.9991 - F1: 0.4965 - Loss: 0.0030\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 17:44:52\n",
      "Accuracy: 0.9866 - Precision: 0.7244 - Recall: 0.3957 - Specificity: 0.9991 - F1: 0.4981 - Loss: 0.0030\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 17:45:00\n",
      "Accuracy: 0.9866 - Precision: 0.7258 - Recall: 0.3971 - Specificity: 0.9991 - F1: 0.4998 - Loss: 0.0030\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 17:45:08\n",
      "Accuracy: 0.9867 - Precision: 0.7269 - Recall: 0.3990 - Specificity: 0.9991 - F1: 0.5015 - Loss: 0.0030\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 17:45:17\n",
      "Accuracy: 0.9867 - Precision: 0.7279 - Recall: 0.4005 - Specificity: 0.9991 - F1: 0.5031 - Loss: 0.0030\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 17:45:25\n",
      "Accuracy: 0.9867 - Precision: 0.7295 - Recall: 0.4017 - Specificity: 0.9991 - F1: 0.5045 - Loss: 0.0030\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 17:45:35\n",
      "Accuracy: 0.9868 - Precision: 0.7310 - Recall: 0.4025 - Specificity: 0.9991 - F1: 0.5057 - Loss: 0.0029\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 17:45:45\n",
      "Accuracy: 0.9868 - Precision: 0.7324 - Recall: 0.4032 - Specificity: 0.9991 - F1: 0.5066 - Loss: 0.0030\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 17:45:53\n",
      "Accuracy: 0.9868 - Precision: 0.7339 - Recall: 0.4043 - Specificity: 0.9991 - F1: 0.5080 - Loss: 0.0029\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 17:46:01\n",
      "Accuracy: 0.9868 - Precision: 0.7343 - Recall: 0.4057 - Specificity: 0.9991 - F1: 0.5093 - Loss: 0.0029\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 17:46:12\n",
      "Accuracy: 0.9869 - Precision: 0.7353 - Recall: 0.4069 - Specificity: 0.9991 - F1: 0.5105 - Loss: 0.0029\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 17:46:21\n",
      "Accuracy: 0.9869 - Precision: 0.7367 - Recall: 0.4081 - Specificity: 0.9991 - F1: 0.5119 - Loss: 0.0029\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 17:46:30\n",
      "Accuracy: 0.9869 - Precision: 0.7373 - Recall: 0.4087 - Specificity: 0.9991 - F1: 0.5127 - Loss: 0.0029\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 17:46:39\n",
      "Accuracy: 0.9869 - Precision: 0.7388 - Recall: 0.4089 - Specificity: 0.9991 - F1: 0.5133 - Loss: 0.0029\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 17:46:48\n",
      "Accuracy: 0.9869 - Precision: 0.7402 - Recall: 0.4088 - Specificity: 0.9991 - F1: 0.5136 - Loss: 0.0029\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 17:46:57\n",
      "Accuracy: 0.9869 - Precision: 0.7413 - Recall: 0.4092 - Specificity: 0.9991 - F1: 0.5142 - Loss: 0.0029\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 17:47:05\n",
      "Accuracy: 0.9869 - Precision: 0.7424 - Recall: 0.4104 - Specificity: 0.9991 - F1: 0.5155 - Loss: 0.0029\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 17:47:15\n",
      "Accuracy: 0.9870 - Precision: 0.7434 - Recall: 0.4114 - Specificity: 0.9991 - F1: 0.5167 - Loss: 0.0029\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 17:47:24\n",
      "Accuracy: 0.9870 - Precision: 0.7443 - Recall: 0.4124 - Specificity: 0.9991 - F1: 0.5178 - Loss: 0.0029\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 17:47:33\n",
      "Accuracy: 0.9870 - Precision: 0.7452 - Recall: 0.4133 - Specificity: 0.9991 - F1: 0.5189 - Loss: 0.0029\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 17:47:44\n",
      "Accuracy: 0.9870 - Precision: 0.7463 - Recall: 0.4146 - Specificity: 0.9991 - F1: 0.5202 - Loss: 0.0029\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 17:47:53\n",
      "Accuracy: 0.9870 - Precision: 0.7469 - Recall: 0.4154 - Specificity: 0.9991 - F1: 0.5211 - Loss: 0.0029\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 17:48:01\n",
      "Accuracy: 0.9871 - Precision: 0.7481 - Recall: 0.4165 - Specificity: 0.9991 - F1: 0.5224 - Loss: 0.0029\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 17:48:10\n",
      "Accuracy: 0.9871 - Precision: 0.7491 - Recall: 0.4176 - Specificity: 0.9991 - F1: 0.5236 - Loss: 0.0029\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 17:48:18\n",
      "Accuracy: 0.9871 - Precision: 0.7500 - Recall: 0.4186 - Specificity: 0.9991 - F1: 0.5247 - Loss: 0.0029\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 17:48:27\n",
      "Accuracy: 0.9871 - Precision: 0.7504 - Recall: 0.4193 - Specificity: 0.9991 - F1: 0.5254 - Loss: 0.0029\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 17:48:36\n",
      "Accuracy: 0.9871 - Precision: 0.7516 - Recall: 0.4197 - Specificity: 0.9991 - F1: 0.5261 - Loss: 0.0029\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 17:48:47\n",
      "Accuracy: 0.9871 - Precision: 0.7529 - Recall: 0.4196 - Specificity: 0.9991 - F1: 0.5264 - Loss: 0.0029\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 17:48:56\n",
      "Accuracy: 0.9871 - Precision: 0.7542 - Recall: 0.4200 - Specificity: 0.9991 - F1: 0.5270 - Loss: 0.0029\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 17:49:05\n",
      "Accuracy: 0.9872 - Precision: 0.7551 - Recall: 0.4205 - Specificity: 0.9991 - F1: 0.5278 - Loss: 0.0029\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 17:49:14\n",
      "Accuracy: 0.9872 - Precision: 0.7559 - Recall: 0.4213 - Specificity: 0.9991 - F1: 0.5287 - Loss: 0.0029\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 17:49:22\n",
      "Accuracy: 0.9872 - Precision: 0.7564 - Recall: 0.4229 - Specificity: 0.9991 - F1: 0.5301 - Loss: 0.0029\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 17:49:31\n",
      "Accuracy: 0.9872 - Precision: 0.7567 - Recall: 0.4241 - Specificity: 0.9991 - F1: 0.5311 - Loss: 0.0029\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 17:49:41\n",
      "Accuracy: 0.9872 - Precision: 0.7574 - Recall: 0.4254 - Specificity: 0.9991 - F1: 0.5323 - Loss: 0.0029\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 17:49:51\n",
      "Accuracy: 0.9872 - Precision: 0.7582 - Recall: 0.4265 - Specificity: 0.9991 - F1: 0.5334 - Loss: 0.0029\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 17:49:59\n",
      "Accuracy: 0.9873 - Precision: 0.7590 - Recall: 0.4273 - Specificity: 0.9991 - F1: 0.5344 - Loss: 0.0029\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 17:50:07\n",
      "Accuracy: 0.9873 - Precision: 0.7601 - Recall: 0.4279 - Specificity: 0.9991 - F1: 0.5352 - Loss: 0.0029\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 17:50:16\n",
      "Accuracy: 0.9873 - Precision: 0.7612 - Recall: 0.4283 - Specificity: 0.9991 - F1: 0.5359 - Loss: 0.0029\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 17:50:25\n",
      "Accuracy: 0.9873 - Precision: 0.7621 - Recall: 0.4288 - Specificity: 0.9991 - F1: 0.5366 - Loss: 0.0029\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 17:50:33\n",
      "Accuracy: 0.9873 - Precision: 0.7620 - Recall: 0.4298 - Specificity: 0.9991 - F1: 0.5373 - Loss: 0.0029\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 17:50:41\n",
      "Accuracy: 0.9873 - Precision: 0.7630 - Recall: 0.4307 - Specificity: 0.9991 - F1: 0.5384 - Loss: 0.0029\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 17:50:50\n",
      "Accuracy: 0.9874 - Precision: 0.7639 - Recall: 0.4313 - Specificity: 0.9991 - F1: 0.5391 - Loss: 0.0029\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 17:50:59\n",
      "Accuracy: 0.9874 - Precision: 0.7647 - Recall: 0.4325 - Specificity: 0.9991 - F1: 0.5403 - Loss: 0.0029\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 17:51:07\n",
      "Accuracy: 0.9874 - Precision: 0.7651 - Recall: 0.4333 - Specificity: 0.9991 - F1: 0.5411 - Loss: 0.0029\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 17:51:16\n",
      "Accuracy: 0.9874 - Precision: 0.7657 - Recall: 0.4340 - Specificity: 0.9991 - F1: 0.5419 - Loss: 0.0029\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 17:51:25\n",
      "Accuracy: 0.9874 - Precision: 0.7667 - Recall: 0.4344 - Specificity: 0.9991 - F1: 0.5425 - Loss: 0.0029\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 17:51:33\n",
      "Accuracy: 0.9874 - Precision: 0.7677 - Recall: 0.4349 - Specificity: 0.9991 - F1: 0.5432 - Loss: 0.0028\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 17:51:42\n",
      "Accuracy: 0.9874 - Precision: 0.7687 - Recall: 0.4356 - Specificity: 0.9991 - F1: 0.5441 - Loss: 0.0028\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 17:51:52\n",
      "Accuracy: 0.9875 - Precision: 0.7695 - Recall: 0.4371 - Specificity: 0.9991 - F1: 0.5455 - Loss: 0.0028\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 17:52:01\n",
      "Accuracy: 0.9875 - Precision: 0.7703 - Recall: 0.4384 - Specificity: 0.9991 - F1: 0.5467 - Loss: 0.0028\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 17:52:09\n",
      "Accuracy: 0.9875 - Precision: 0.7703 - Recall: 0.4397 - Specificity: 0.9990 - F1: 0.5477 - Loss: 0.0028\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 17:52:17\n",
      "Accuracy: 0.9876 - Precision: 0.7709 - Recall: 0.4409 - Specificity: 0.9990 - F1: 0.5488 - Loss: 0.0028\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 17:52:26\n",
      "Accuracy: 0.9876 - Precision: 0.7718 - Recall: 0.4418 - Specificity: 0.9990 - F1: 0.5499 - Loss: 0.0028\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 17:52:35\n",
      "Accuracy: 0.9876 - Precision: 0.7723 - Recall: 0.4424 - Specificity: 0.9990 - F1: 0.5505 - Loss: 0.0028\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 17:52:44\n",
      "Accuracy: 0.9876 - Precision: 0.7732 - Recall: 0.4427 - Specificity: 0.9990 - F1: 0.5510 - Loss: 0.0028\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 17:52:52\n",
      "Accuracy: 0.9876 - Precision: 0.7742 - Recall: 0.4432 - Specificity: 0.9991 - F1: 0.5517 - Loss: 0.0028\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 17:53:01\n",
      "Accuracy: 0.9877 - Precision: 0.7746 - Recall: 0.4440 - Specificity: 0.9990 - F1: 0.5525 - Loss: 0.0028\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 17:53:10\n",
      "Accuracy: 0.9877 - Precision: 0.7755 - Recall: 0.4449 - Specificity: 0.9991 - F1: 0.5535 - Loss: 0.0028\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 17:53:18\n",
      "Accuracy: 0.9877 - Precision: 0.7761 - Recall: 0.4460 - Specificity: 0.9990 - F1: 0.5546 - Loss: 0.0028\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 17:53:26\n",
      "Accuracy: 0.9877 - Precision: 0.7763 - Recall: 0.4465 - Specificity: 0.9990 - F1: 0.5551 - Loss: 0.0028\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 17:53:34\n",
      "Accuracy: 0.9877 - Precision: 0.7763 - Recall: 0.4462 - Specificity: 0.9990 - F1: 0.5548 - Loss: 0.0028\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 17:53:44\n",
      "Accuracy: 0.9877 - Precision: 0.7765 - Recall: 0.4460 - Specificity: 0.9990 - F1: 0.5548 - Loss: 0.0028\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 17:53:53\n",
      "Accuracy: 0.9876 - Precision: 0.7766 - Recall: 0.4453 - Specificity: 0.9990 - F1: 0.5543 - Loss: 0.0028\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 17:54:01\n",
      "Accuracy: 0.9876 - Precision: 0.7773 - Recall: 0.4446 - Specificity: 0.9990 - F1: 0.5537 - Loss: 0.0028\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 17:54:10\n",
      "Accuracy: 0.9876 - Precision: 0.7780 - Recall: 0.4440 - Specificity: 0.9990 - F1: 0.5533 - Loss: 0.0028\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 17:54:18\n",
      "Accuracy: 0.9875 - Precision: 0.7785 - Recall: 0.4434 - Specificity: 0.9990 - F1: 0.5529 - Loss: 0.0028\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 17:54:27\n",
      "Accuracy: 0.9875 - Precision: 0.7787 - Recall: 0.4425 - Specificity: 0.9990 - F1: 0.5521 - Loss: 0.0028\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 17:54:37\n",
      "Accuracy: 0.9875 - Precision: 0.7796 - Recall: 0.4421 - Specificity: 0.9990 - F1: 0.5519 - Loss: 0.0029\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 17:54:46\n",
      "Accuracy: 0.9874 - Precision: 0.7796 - Recall: 0.4413 - Specificity: 0.9990 - F1: 0.5513 - Loss: 0.0029\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 17:54:54\n",
      "Accuracy: 0.9874 - Precision: 0.7798 - Recall: 0.4404 - Specificity: 0.9990 - F1: 0.5504 - Loss: 0.0029\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 17:55:03\n",
      "Accuracy: 0.9874 - Precision: 0.7805 - Recall: 0.4400 - Specificity: 0.9990 - F1: 0.5502 - Loss: 0.0029\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 17:55:12\n",
      "Accuracy: 0.9874 - Precision: 0.7814 - Recall: 0.4393 - Specificity: 0.9990 - F1: 0.5497 - Loss: 0.0029\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 17:55:22\n",
      "Accuracy: 0.9874 - Precision: 0.7823 - Recall: 0.4382 - Specificity: 0.9990 - F1: 0.5488 - Loss: 0.0029\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 17:55:30\n",
      "Accuracy: 0.9873 - Precision: 0.7830 - Recall: 0.4381 - Specificity: 0.9990 - F1: 0.5489 - Loss: 0.0029\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 17:55:39\n",
      "Accuracy: 0.9874 - Precision: 0.7834 - Recall: 0.4385 - Specificity: 0.9990 - F1: 0.5494 - Loss: 0.0029\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 17:55:50\n",
      "Accuracy: 0.9873 - Precision: 0.7835 - Recall: 0.4382 - Specificity: 0.9990 - F1: 0.5492 - Loss: 0.0029\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 17:55:58\n",
      "Accuracy: 0.9873 - Precision: 0.7839 - Recall: 0.4383 - Specificity: 0.9990 - F1: 0.5494 - Loss: 0.0029\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 17:56:07\n",
      "Accuracy: 0.9874 - Precision: 0.7843 - Recall: 0.4385 - Specificity: 0.9990 - F1: 0.5498 - Loss: 0.0029\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 17:56:18\n",
      "Accuracy: 0.9873 - Precision: 0.7848 - Recall: 0.4381 - Specificity: 0.9990 - F1: 0.5496 - Loss: 0.0029\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 17:56:27\n",
      "Accuracy: 0.9873 - Precision: 0.7855 - Recall: 0.4372 - Specificity: 0.9990 - F1: 0.5488 - Loss: 0.0029\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 17:56:36\n",
      "Accuracy: 0.9872 - Precision: 0.7861 - Recall: 0.4366 - Specificity: 0.9990 - F1: 0.5483 - Loss: 0.0029\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 17:56:45\n",
      "Accuracy: 0.9871 - Precision: 0.7866 - Recall: 0.4361 - Specificity: 0.9990 - F1: 0.5480 - Loss: 0.0029\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 17:56:54\n",
      "Accuracy: 0.9871 - Precision: 0.7869 - Recall: 0.4360 - Specificity: 0.9990 - F1: 0.5481 - Loss: 0.0029\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 17:57:03\n",
      "Accuracy: 0.9871 - Precision: 0.7869 - Recall: 0.4360 - Specificity: 0.9990 - F1: 0.5481 - Loss: 0.0030\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 17:57:12\n",
      "Accuracy: 0.9871 - Precision: 0.7876 - Recall: 0.4352 - Specificity: 0.9990 - F1: 0.5475 - Loss: 0.0030\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 17:57:21\n",
      "Accuracy: 0.9870 - Precision: 0.7883 - Recall: 0.4348 - Specificity: 0.9990 - F1: 0.5473 - Loss: 0.0030\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 17:57:29\n",
      "Accuracy: 0.9867 - Precision: 0.7883 - Recall: 0.4331 - Specificity: 0.9990 - F1: 0.5452 - Loss: 0.0032\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 17:57:38\n",
      "Accuracy: 0.9865 - Precision: 0.7882 - Recall: 0.4318 - Specificity: 0.9990 - F1: 0.5438 - Loss: 0.0032\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 17:57:48\n",
      "Accuracy: 0.9863 - Precision: 0.7883 - Recall: 0.4314 - Specificity: 0.9990 - F1: 0.5435 - Loss: 0.0034\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 17:57:58\n",
      "Accuracy: 0.9860 - Precision: 0.7886 - Recall: 0.4306 - Specificity: 0.9990 - F1: 0.5428 - Loss: 0.0034\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 17:58:06\n",
      "Accuracy: 0.9858 - Precision: 0.7888 - Recall: 0.4296 - Specificity: 0.9990 - F1: 0.5418 - Loss: 0.0035\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 17:58:14\n",
      "Accuracy: 0.9856 - Precision: 0.7884 - Recall: 0.4283 - Specificity: 0.9989 - F1: 0.5404 - Loss: 0.0036\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 17:58:23\n",
      "Accuracy: 0.9853 - Precision: 0.7883 - Recall: 0.4266 - Specificity: 0.9989 - F1: 0.5383 - Loss: 0.0036\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 17:58:32\n",
      "Accuracy: 0.9851 - Precision: 0.7870 - Recall: 0.4249 - Specificity: 0.9989 - F1: 0.5361 - Loss: 0.0037\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 17:58:43\n",
      "Accuracy: 0.9847 - Precision: 0.7878 - Recall: 0.4232 - Specificity: 0.9990 - F1: 0.5340 - Loss: 0.0038\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 17:58:52\n",
      "Accuracy: 0.9844 - Precision: 0.7872 - Recall: 0.4219 - Specificity: 0.9989 - F1: 0.5325 - Loss: 0.0038\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 17:59:01\n",
      "Accuracy: 0.9842 - Precision: 0.7877 - Recall: 0.4203 - Specificity: 0.9989 - F1: 0.5307 - Loss: 0.0039\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 17:59:10\n",
      "Accuracy: 0.9841 - Precision: 0.7846 - Recall: 0.4186 - Specificity: 0.9989 - F1: 0.5285 - Loss: 0.0039\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 17:59:19\n",
      "Accuracy: 0.9838 - Precision: 0.7815 - Recall: 0.4170 - Specificity: 0.9989 - F1: 0.5264 - Loss: 0.0040\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 17:59:28\n",
      "Accuracy: 0.9836 - Precision: 0.7784 - Recall: 0.4153 - Specificity: 0.9990 - F1: 0.5244 - Loss: 0.0040\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 17:59:39\n",
      "Accuracy: 0.9833 - Precision: 0.7753 - Recall: 0.4137 - Specificity: 0.9990 - F1: 0.5223 - Loss: 0.0040\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 17:59:49\n",
      "Accuracy: 0.9829 - Precision: 0.7723 - Recall: 0.4121 - Specificity: 0.9990 - F1: 0.5202 - Loss: 0.0041\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 17:59:59\n",
      "Accuracy: 0.9827 - Precision: 0.7693 - Recall: 0.4105 - Specificity: 0.9990 - F1: 0.5182 - Loss: 0.0041\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 18:00:09\n",
      "Accuracy: 0.9826 - Precision: 0.7669 - Recall: 0.4089 - Specificity: 0.9990 - F1: 0.5162 - Loss: 0.0042\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 18:00:18\n",
      "Accuracy: 0.9825 - Precision: 0.7641 - Recall: 0.4073 - Specificity: 0.9990 - F1: 0.5142 - Loss: 0.0042\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 18:00:26\n",
      "Accuracy: 0.9825 - Precision: 0.7612 - Recall: 0.4057 - Specificity: 0.9990 - F1: 0.5122 - Loss: 0.0042\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 18:00:35\n",
      "Accuracy: 0.9824 - Precision: 0.7583 - Recall: 0.4042 - Specificity: 0.9990 - F1: 0.5103 - Loss: 0.0042\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 18:00:43\n",
      "Accuracy: 0.9824 - Precision: 0.7553 - Recall: 0.4026 - Specificity: 0.9990 - F1: 0.5083 - Loss: 0.0042\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 18:00:52\n",
      "Accuracy: 0.9823 - Precision: 0.7563 - Recall: 0.4011 - Specificity: 0.9990 - F1: 0.5064 - Loss: 0.0043\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 18:01:01\n",
      "Accuracy: 0.9822 - Precision: 0.7534 - Recall: 0.3995 - Specificity: 0.9990 - F1: 0.5044 - Loss: 0.0043\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 18:01:09\n",
      "Accuracy: 0.9822 - Precision: 0.7543 - Recall: 0.3980 - Specificity: 0.9990 - F1: 0.5025 - Loss: 0.0043\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 18:01:19\n",
      "Accuracy: 0.9821 - Precision: 0.7515 - Recall: 0.3965 - Specificity: 0.9990 - F1: 0.5006 - Loss: 0.0044\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 18:01:27\n",
      "Accuracy: 0.9821 - Precision: 0.7524 - Recall: 0.3950 - Specificity: 0.9990 - F1: 0.4987 - Loss: 0.0044\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 18:01:36\n",
      "Accuracy: 0.9821 - Precision: 0.7496 - Recall: 0.3936 - Specificity: 0.9990 - F1: 0.4969 - Loss: 0.0044\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 18:01:44\n",
      "Accuracy: 0.9820 - Precision: 0.7505 - Recall: 0.3921 - Specificity: 0.9990 - F1: 0.4950 - Loss: 0.0044\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 18:01:55\n",
      "Accuracy: 0.9820 - Precision: 0.7478 - Recall: 0.3906 - Specificity: 0.9990 - F1: 0.4932 - Loss: 0.0044\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 18:02:04\n",
      "Accuracy: 0.9820 - Precision: 0.7487 - Recall: 0.3892 - Specificity: 0.9990 - F1: 0.4914 - Loss: 0.0044\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 18:02:14\n",
      "Accuracy: 0.9819 - Precision: 0.7496 - Recall: 0.3877 - Specificity: 0.9990 - F1: 0.4895 - Loss: 0.0044\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 18:02:24\n",
      "Accuracy: 0.9819 - Precision: 0.7505 - Recall: 0.3863 - Specificity: 0.9990 - F1: 0.4877 - Loss: 0.0044\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 18:02:33\n",
      "Accuracy: 0.9819 - Precision: 0.7515 - Recall: 0.3849 - Specificity: 0.9990 - F1: 0.4860 - Loss: 0.0044\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 18:02:42\n",
      "Accuracy: 0.9818 - Precision: 0.7509 - Recall: 0.3835 - Specificity: 0.9990 - F1: 0.4842 - Loss: 0.0044\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 18:02:50\n",
      "Accuracy: 0.9818 - Precision: 0.7482 - Recall: 0.3821 - Specificity: 0.9990 - F1: 0.4824 - Loss: 0.0045\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 18:02:59\n",
      "Accuracy: 0.9818 - Precision: 0.7484 - Recall: 0.3807 - Specificity: 0.9990 - F1: 0.4807 - Loss: 0.0045\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 18:03:08\n",
      "Accuracy: 0.9818 - Precision: 0.7457 - Recall: 0.3794 - Specificity: 0.9990 - F1: 0.4790 - Loss: 0.0045\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 18:03:17\n",
      "Accuracy: 0.9817 - Precision: 0.7467 - Recall: 0.3780 - Specificity: 0.9990 - F1: 0.4772 - Loss: 0.0045\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 18:03:25\n",
      "Accuracy: 0.9817 - Precision: 0.7476 - Recall: 0.3766 - Specificity: 0.9990 - F1: 0.4755 - Loss: 0.0045\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 18:03:33\n",
      "Accuracy: 0.9817 - Precision: 0.7471 - Recall: 0.3753 - Specificity: 0.9991 - F1: 0.4738 - Loss: 0.0045\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 18:03:42\n",
      "Accuracy: 0.9817 - Precision: 0.7444 - Recall: 0.3740 - Specificity: 0.9991 - F1: 0.4722 - Loss: 0.0045\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 18:03:54\n",
      "Accuracy: 0.9817 - Precision: 0.7449 - Recall: 0.3726 - Specificity: 0.9991 - F1: 0.4705 - Loss: 0.0045\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 18:04:05\n",
      "Accuracy: 0.9817 - Precision: 0.7423 - Recall: 0.3713 - Specificity: 0.9991 - F1: 0.4688 - Loss: 0.0045\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 18:04:13\n",
      "Accuracy: 0.9817 - Precision: 0.7397 - Recall: 0.3700 - Specificity: 0.9991 - F1: 0.4672 - Loss: 0.0045\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 18:04:22\n",
      "Accuracy: 0.9817 - Precision: 0.7406 - Recall: 0.3687 - Specificity: 0.9991 - F1: 0.4656 - Loss: 0.0045\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 18:04:31\n",
      "Accuracy: 0.9817 - Precision: 0.7415 - Recall: 0.3674 - Specificity: 0.9991 - F1: 0.4639 - Loss: 0.0045\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 18:04:40\n",
      "Accuracy: 0.9816 - Precision: 0.7424 - Recall: 0.3662 - Specificity: 0.9991 - F1: 0.4623 - Loss: 0.0045\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 18:04:48\n",
      "Accuracy: 0.9816 - Precision: 0.7419 - Recall: 0.3649 - Specificity: 0.9991 - F1: 0.4607 - Loss: 0.0045\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 18:04:57\n",
      "Accuracy: 0.9816 - Precision: 0.7426 - Recall: 0.3636 - Specificity: 0.9991 - F1: 0.4592 - Loss: 0.0045\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 18:05:06\n",
      "Accuracy: 0.9816 - Precision: 0.7433 - Recall: 0.3624 - Specificity: 0.9991 - F1: 0.4576 - Loss: 0.0046\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 18:05:14\n",
      "Accuracy: 0.9815 - Precision: 0.7426 - Recall: 0.3612 - Specificity: 0.9991 - F1: 0.4560 - Loss: 0.0046\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 18:05:23\n",
      "Accuracy: 0.9815 - Precision: 0.7421 - Recall: 0.3600 - Specificity: 0.9991 - F1: 0.4546 - Loss: 0.0046\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 18:05:32\n",
      "Accuracy: 0.9815 - Precision: 0.7426 - Recall: 0.3589 - Specificity: 0.9991 - F1: 0.4533 - Loss: 0.0046\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 18:05:40\n",
      "Accuracy: 0.9814 - Precision: 0.7434 - Recall: 0.3577 - Specificity: 0.9991 - F1: 0.4518 - Loss: 0.0046\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 18:05:49\n",
      "Accuracy: 0.9814 - Precision: 0.7432 - Recall: 0.3565 - Specificity: 0.9991 - F1: 0.4503 - Loss: 0.0046\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 18:06:01\n",
      "Accuracy: 0.9814 - Precision: 0.7431 - Recall: 0.3555 - Specificity: 0.9991 - F1: 0.4492 - Loss: 0.0046\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 18:06:10\n",
      "Accuracy: 0.9814 - Precision: 0.7437 - Recall: 0.3545 - Specificity: 0.9991 - F1: 0.4480 - Loss: 0.0046\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 18:06:19\n",
      "Accuracy: 0.9813 - Precision: 0.7443 - Recall: 0.3534 - Specificity: 0.9991 - F1: 0.4468 - Loss: 0.0046\n",
      "\n",
      "Epoch 8/20\n",
      "Validation - Accuracy: 0.9796, Precision: 0.9005, Recall: 0.0547, Specificity: 0.9999, F1: 0.1023, Loss: 0.0050\n",
      "\n",
      "\n",
      "Epoch 9/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 18:14:28\n",
      "Accuracy: 0.9760 - Precision: 0.9081 - Recall: 0.0944 - Specificity: 0.9997 - F1: 0.1710 - Loss: 0.0062\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 18:14:36\n",
      "Accuracy: 0.9748 - Precision: 0.9113 - Recall: 0.1027 - Specificity: 0.9997 - F1: 0.1846 - Loss: 0.0065\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 18:14:45\n",
      "Accuracy: 0.9747 - Precision: 0.9256 - Recall: 0.1318 - Specificity: 0.9997 - F1: 0.2287 - Loss: 0.0061\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 18:14:55\n",
      "Accuracy: 0.9773 - Precision: 0.9294 - Recall: 0.1260 - Specificity: 0.9998 - F1: 0.2202 - Loss: 0.0054\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 18:15:05\n",
      "Accuracy: 0.9790 - Precision: 0.9141 - Recall: 0.1280 - Specificity: 0.9997 - F1: 0.2231 - Loss: 0.0051\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 18:15:14\n",
      "Accuracy: 0.9794 - Precision: 0.9184 - Recall: 0.1434 - Specificity: 0.9997 - F1: 0.2453 - Loss: 0.0050\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 18:15:24\n",
      "Accuracy: 0.9808 - Precision: 0.9091 - Recall: 0.1685 - Specificity: 0.9996 - F1: 0.2767 - Loss: 0.0046\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 18:15:35\n",
      "Accuracy: 0.9813 - Precision: 0.8705 - Recall: 0.1974 - Specificity: 0.9991 - F1: 0.3021 - Loss: 0.0046\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 18:15:45\n",
      "Accuracy: 0.9823 - Precision: 0.8739 - Recall: 0.2248 - Specificity: 0.9991 - F1: 0.3346 - Loss: 0.0043\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 18:15:55\n",
      "Accuracy: 0.9827 - Precision: 0.8807 - Recall: 0.2250 - Specificity: 0.9992 - F1: 0.3377 - Loss: 0.0042\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 18:16:13\n",
      "Accuracy: 0.9831 - Precision: 0.8710 - Recall: 0.2346 - Specificity: 0.9991 - F1: 0.3492 - Loss: 0.0041\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 18:16:45\n",
      "Accuracy: 0.9833 - Precision: 0.8807 - Recall: 0.2341 - Specificity: 0.9992 - F1: 0.3509 - Loss: 0.0040\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 18:16:53\n",
      "Accuracy: 0.9834 - Precision: 0.8840 - Recall: 0.2327 - Specificity: 0.9992 - F1: 0.3509 - Loss: 0.0039\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 18:17:02\n",
      "Accuracy: 0.9835 - Precision: 0.8695 - Recall: 0.2309 - Specificity: 0.9991 - F1: 0.3485 - Loss: 0.0040\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 18:17:12\n",
      "Accuracy: 0.9836 - Precision: 0.8774 - Recall: 0.2254 - Specificity: 0.9992 - F1: 0.3425 - Loss: 0.0039\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 18:17:21\n",
      "Accuracy: 0.9832 - Precision: 0.8824 - Recall: 0.2188 - Specificity: 0.9992 - F1: 0.3344 - Loss: 0.0040\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 18:17:31\n",
      "Accuracy: 0.9834 - Precision: 0.8888 - Recall: 0.2169 - Specificity: 0.9993 - F1: 0.3333 - Loss: 0.0039\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 18:17:40\n",
      "Accuracy: 0.9833 - Precision: 0.8935 - Recall: 0.2164 - Specificity: 0.9993 - F1: 0.3337 - Loss: 0.0039\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 18:17:49\n",
      "Accuracy: 0.9834 - Precision: 0.8963 - Recall: 0.2191 - Specificity: 0.9993 - F1: 0.3381 - Loss: 0.0038\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 18:18:00\n",
      "Accuracy: 0.9837 - Precision: 0.8984 - Recall: 0.2259 - Specificity: 0.9993 - F1: 0.3470 - Loss: 0.0037\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 18:18:10\n",
      "Accuracy: 0.9837 - Precision: 0.8981 - Recall: 0.2263 - Specificity: 0.9993 - F1: 0.3481 - Loss: 0.0037\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 18:18:18\n",
      "Accuracy: 0.9834 - Precision: 0.8781 - Recall: 0.2241 - Specificity: 0.9991 - F1: 0.3440 - Loss: 0.0039\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 18:18:26\n",
      "Accuracy: 0.9834 - Precision: 0.8822 - Recall: 0.2250 - Specificity: 0.9992 - F1: 0.3460 - Loss: 0.0039\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 18:18:34\n",
      "Accuracy: 0.9833 - Precision: 0.8841 - Recall: 0.2295 - Specificity: 0.9992 - F1: 0.3520 - Loss: 0.0039\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 18:18:43\n",
      "Accuracy: 0.9834 - Precision: 0.8867 - Recall: 0.2343 - Specificity: 0.9992 - F1: 0.3583 - Loss: 0.0038\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 18:18:51\n",
      "Accuracy: 0.9837 - Precision: 0.8873 - Recall: 0.2429 - Specificity: 0.9992 - F1: 0.3679 - Loss: 0.0038\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 18:18:59\n",
      "Accuracy: 0.9838 - Precision: 0.8898 - Recall: 0.2472 - Specificity: 0.9992 - F1: 0.3736 - Loss: 0.0037\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 18:19:08\n",
      "Accuracy: 0.9838 - Precision: 0.8923 - Recall: 0.2478 - Specificity: 0.9992 - F1: 0.3751 - Loss: 0.0037\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 18:19:16\n",
      "Accuracy: 0.9836 - Precision: 0.8921 - Recall: 0.2484 - Specificity: 0.9992 - F1: 0.3763 - Loss: 0.0038\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 18:19:25\n",
      "Accuracy: 0.9838 - Precision: 0.8937 - Recall: 0.2575 - Specificity: 0.9992 - F1: 0.3861 - Loss: 0.0038\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 18:19:33\n",
      "Accuracy: 0.9840 - Precision: 0.8929 - Recall: 0.2669 - Specificity: 0.9992 - F1: 0.3953 - Loss: 0.0037\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 18:19:41\n",
      "Accuracy: 0.9841 - Precision: 0.8928 - Recall: 0.2727 - Specificity: 0.9992 - F1: 0.4017 - Loss: 0.0037\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 18:19:49\n",
      "Accuracy: 0.9843 - Precision: 0.8935 - Recall: 0.2805 - Specificity: 0.9992 - F1: 0.4099 - Loss: 0.0037\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 18:19:58\n",
      "Accuracy: 0.9843 - Precision: 0.8953 - Recall: 0.2854 - Specificity: 0.9992 - F1: 0.4157 - Loss: 0.0037\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 18:20:07\n",
      "Accuracy: 0.9843 - Precision: 0.8971 - Recall: 0.2868 - Specificity: 0.9992 - F1: 0.4180 - Loss: 0.0037\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 18:20:15\n",
      "Accuracy: 0.9845 - Precision: 0.8974 - Recall: 0.2943 - Specificity: 0.9992 - F1: 0.4256 - Loss: 0.0036\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 18:20:23\n",
      "Accuracy: 0.9847 - Precision: 0.8972 - Recall: 0.3055 - Specificity: 0.9992 - F1: 0.4354 - Loss: 0.0036\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 18:20:32\n",
      "Accuracy: 0.9848 - Precision: 0.8951 - Recall: 0.3140 - Specificity: 0.9991 - F1: 0.4427 - Loss: 0.0036\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 18:20:40\n",
      "Accuracy: 0.9849 - Precision: 0.8950 - Recall: 0.3223 - Specificity: 0.9991 - F1: 0.4503 - Loss: 0.0036\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 18:20:48\n",
      "Accuracy: 0.9850 - Precision: 0.8953 - Recall: 0.3300 - Specificity: 0.9991 - F1: 0.4577 - Loss: 0.0036\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 18:20:57\n",
      "Accuracy: 0.9850 - Precision: 0.8963 - Recall: 0.3325 - Specificity: 0.9991 - F1: 0.4610 - Loss: 0.0036\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 18:21:05\n",
      "Accuracy: 0.9851 - Precision: 0.8979 - Recall: 0.3364 - Specificity: 0.9991 - F1: 0.4656 - Loss: 0.0036\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 18:21:13\n",
      "Accuracy: 0.9852 - Precision: 0.8987 - Recall: 0.3427 - Specificity: 0.9991 - F1: 0.4719 - Loss: 0.0035\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 18:21:21\n",
      "Accuracy: 0.9854 - Precision: 0.8984 - Recall: 0.3502 - Specificity: 0.9991 - F1: 0.4786 - Loss: 0.0035\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 18:21:30\n",
      "Accuracy: 0.9854 - Precision: 0.8925 - Recall: 0.3579 - Specificity: 0.9989 - F1: 0.4826 - Loss: 0.0035\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 18:21:38\n",
      "Accuracy: 0.9855 - Precision: 0.8942 - Recall: 0.3603 - Specificity: 0.9990 - F1: 0.4859 - Loss: 0.0035\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 18:21:46\n",
      "Accuracy: 0.9854 - Precision: 0.8956 - Recall: 0.3595 - Specificity: 0.9990 - F1: 0.4859 - Loss: 0.0035\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 18:21:54\n",
      "Accuracy: 0.9854 - Precision: 0.8975 - Recall: 0.3580 - Specificity: 0.9990 - F1: 0.4850 - Loss: 0.0035\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 18:22:04\n",
      "Accuracy: 0.9854 - Precision: 0.8985 - Recall: 0.3574 - Specificity: 0.9990 - F1: 0.4851 - Loss: 0.0035\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 18:22:13\n",
      "Accuracy: 0.9853 - Precision: 0.9005 - Recall: 0.3572 - Specificity: 0.9990 - F1: 0.4856 - Loss: 0.0035\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 18:22:21\n",
      "Accuracy: 0.9854 - Precision: 0.9014 - Recall: 0.3573 - Specificity: 0.9990 - F1: 0.4864 - Loss: 0.0035\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 18:22:29\n",
      "Accuracy: 0.9854 - Precision: 0.9015 - Recall: 0.3576 - Specificity: 0.9990 - F1: 0.4872 - Loss: 0.0035\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 18:22:37\n",
      "Accuracy: 0.9855 - Precision: 0.9023 - Recall: 0.3604 - Specificity: 0.9990 - F1: 0.4905 - Loss: 0.0034\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 18:22:46\n",
      "Accuracy: 0.9856 - Precision: 0.9035 - Recall: 0.3642 - Specificity: 0.9991 - F1: 0.4946 - Loss: 0.0034\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 18:22:54\n",
      "Accuracy: 0.9856 - Precision: 0.9044 - Recall: 0.3672 - Specificity: 0.9991 - F1: 0.4979 - Loss: 0.0034\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 18:23:02\n",
      "Accuracy: 0.9857 - Precision: 0.9044 - Recall: 0.3728 - Specificity: 0.9991 - F1: 0.5030 - Loss: 0.0034\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 18:23:10\n",
      "Accuracy: 0.9859 - Precision: 0.9043 - Recall: 0.3771 - Specificity: 0.9990 - F1: 0.5070 - Loss: 0.0034\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 18:23:18\n",
      "Accuracy: 0.9860 - Precision: 0.9042 - Recall: 0.3816 - Specificity: 0.9990 - F1: 0.5111 - Loss: 0.0033\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 18:23:26\n",
      "Accuracy: 0.9861 - Precision: 0.9047 - Recall: 0.3852 - Specificity: 0.9990 - F1: 0.5148 - Loss: 0.0033\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 18:23:35\n",
      "Accuracy: 0.9861 - Precision: 0.9025 - Recall: 0.3894 - Specificity: 0.9990 - F1: 0.5178 - Loss: 0.0033\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 18:23:43\n",
      "Accuracy: 0.9861 - Precision: 0.9008 - Recall: 0.3936 - Specificity: 0.9989 - F1: 0.5210 - Loss: 0.0033\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 18:23:51\n",
      "Accuracy: 0.9862 - Precision: 0.9004 - Recall: 0.3984 - Specificity: 0.9989 - F1: 0.5251 - Loss: 0.0033\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 18:24:03\n",
      "Accuracy: 0.9863 - Precision: 0.9010 - Recall: 0.4027 - Specificity: 0.9989 - F1: 0.5292 - Loss: 0.0033\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 18:24:14\n",
      "Accuracy: 0.9864 - Precision: 0.9014 - Recall: 0.4064 - Specificity: 0.9989 - F1: 0.5327 - Loss: 0.0033\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 18:24:23\n",
      "Accuracy: 0.9864 - Precision: 0.9022 - Recall: 0.4078 - Specificity: 0.9989 - F1: 0.5346 - Loss: 0.0032\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 18:24:32\n",
      "Accuracy: 0.9864 - Precision: 0.9023 - Recall: 0.4082 - Specificity: 0.9989 - F1: 0.5354 - Loss: 0.0033\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 18:24:42\n",
      "Accuracy: 0.9864 - Precision: 0.9022 - Recall: 0.4098 - Specificity: 0.9989 - F1: 0.5372 - Loss: 0.0033\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 18:24:51\n",
      "Accuracy: 0.9865 - Precision: 0.9024 - Recall: 0.4115 - Specificity: 0.9989 - F1: 0.5390 - Loss: 0.0032\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 18:24:59\n",
      "Accuracy: 0.9865 - Precision: 0.9028 - Recall: 0.4152 - Specificity: 0.9989 - F1: 0.5425 - Loss: 0.0032\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 18:25:08\n",
      "Accuracy: 0.9866 - Precision: 0.9027 - Recall: 0.4189 - Specificity: 0.9989 - F1: 0.5458 - Loss: 0.0032\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 18:25:19\n",
      "Accuracy: 0.9867 - Precision: 0.9010 - Recall: 0.4213 - Specificity: 0.9989 - F1: 0.5475 - Loss: 0.0032\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 18:25:27\n",
      "Accuracy: 0.9867 - Precision: 0.8997 - Recall: 0.4228 - Specificity: 0.9989 - F1: 0.5488 - Loss: 0.0032\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 18:25:36\n",
      "Accuracy: 0.9867 - Precision: 0.9007 - Recall: 0.4233 - Specificity: 0.9989 - F1: 0.5498 - Loss: 0.0032\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 18:25:44\n",
      "Accuracy: 0.9867 - Precision: 0.9016 - Recall: 0.4243 - Specificity: 0.9989 - F1: 0.5513 - Loss: 0.0032\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 18:25:52\n",
      "Accuracy: 0.9867 - Precision: 0.9013 - Recall: 0.4264 - Specificity: 0.9989 - F1: 0.5533 - Loss: 0.0032\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 18:26:02\n",
      "Accuracy: 0.9867 - Precision: 0.9011 - Recall: 0.4295 - Specificity: 0.9989 - F1: 0.5560 - Loss: 0.0032\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 18:26:11\n",
      "Accuracy: 0.9868 - Precision: 0.8997 - Recall: 0.4333 - Specificity: 0.9988 - F1: 0.5586 - Loss: 0.0032\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 18:26:19\n",
      "Accuracy: 0.9868 - Precision: 0.8999 - Recall: 0.4364 - Specificity: 0.9988 - F1: 0.5614 - Loss: 0.0032\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 18:26:27\n",
      "Accuracy: 0.9868 - Precision: 0.8997 - Recall: 0.4386 - Specificity: 0.9988 - F1: 0.5634 - Loss: 0.0032\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 18:26:35\n",
      "Accuracy: 0.9869 - Precision: 0.9003 - Recall: 0.4407 - Specificity: 0.9988 - F1: 0.5656 - Loss: 0.0032\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 18:26:43\n",
      "Accuracy: 0.9870 - Precision: 0.9009 - Recall: 0.4417 - Specificity: 0.9988 - F1: 0.5669 - Loss: 0.0032\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 18:26:51\n",
      "Accuracy: 0.9870 - Precision: 0.9005 - Recall: 0.4419 - Specificity: 0.9988 - F1: 0.5673 - Loss: 0.0032\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 18:26:59\n",
      "Accuracy: 0.9870 - Precision: 0.9012 - Recall: 0.4421 - Specificity: 0.9988 - F1: 0.5679 - Loss: 0.0032\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 18:27:07\n",
      "Accuracy: 0.9870 - Precision: 0.9013 - Recall: 0.4426 - Specificity: 0.9989 - F1: 0.5687 - Loss: 0.0032\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 18:27:15\n",
      "Accuracy: 0.9871 - Precision: 0.9020 - Recall: 0.4448 - Specificity: 0.9989 - F1: 0.5710 - Loss: 0.0031\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 18:27:23\n",
      "Accuracy: 0.9871 - Precision: 0.9016 - Recall: 0.4464 - Specificity: 0.9989 - F1: 0.5725 - Loss: 0.0031\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 18:27:31\n",
      "Accuracy: 0.9872 - Precision: 0.9021 - Recall: 0.4489 - Specificity: 0.9989 - F1: 0.5748 - Loss: 0.0031\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 18:27:39\n",
      "Accuracy: 0.9872 - Precision: 0.9016 - Recall: 0.4510 - Specificity: 0.9988 - F1: 0.5766 - Loss: 0.0031\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 18:27:47\n",
      "Accuracy: 0.9872 - Precision: 0.9022 - Recall: 0.4532 - Specificity: 0.9988 - F1: 0.5788 - Loss: 0.0031\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 18:27:55\n",
      "Accuracy: 0.9872 - Precision: 0.9027 - Recall: 0.4543 - Specificity: 0.9989 - F1: 0.5801 - Loss: 0.0031\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 18:28:05\n",
      "Accuracy: 0.9873 - Precision: 0.9032 - Recall: 0.4561 - Specificity: 0.9989 - F1: 0.5819 - Loss: 0.0031\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 18:28:13\n",
      "Accuracy: 0.9873 - Precision: 0.9024 - Recall: 0.4579 - Specificity: 0.9988 - F1: 0.5834 - Loss: 0.0031\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 18:28:21\n",
      "Accuracy: 0.9874 - Precision: 0.9025 - Recall: 0.4599 - Specificity: 0.9988 - F1: 0.5852 - Loss: 0.0031\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 18:28:29\n",
      "Accuracy: 0.9874 - Precision: 0.9027 - Recall: 0.4615 - Specificity: 0.9988 - F1: 0.5868 - Loss: 0.0031\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 18:28:37\n",
      "Accuracy: 0.9874 - Precision: 0.9015 - Recall: 0.4628 - Specificity: 0.9988 - F1: 0.5877 - Loss: 0.0031\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 18:28:46\n",
      "Accuracy: 0.9874 - Precision: 0.9014 - Recall: 0.4631 - Specificity: 0.9988 - F1: 0.5882 - Loss: 0.0031\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 18:28:54\n",
      "Accuracy: 0.9874 - Precision: 0.9023 - Recall: 0.4632 - Specificity: 0.9988 - F1: 0.5887 - Loss: 0.0031\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 18:29:02\n",
      "Accuracy: 0.9875 - Precision: 0.9025 - Recall: 0.4640 - Specificity: 0.9988 - F1: 0.5896 - Loss: 0.0031\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 18:29:10\n",
      "Accuracy: 0.9875 - Precision: 0.9022 - Recall: 0.4644 - Specificity: 0.9988 - F1: 0.5902 - Loss: 0.0031\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 18:29:18\n",
      "Accuracy: 0.9875 - Precision: 0.9021 - Recall: 0.4649 - Specificity: 0.9988 - F1: 0.5908 - Loss: 0.0030\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 18:29:27\n",
      "Accuracy: 0.9876 - Precision: 0.9020 - Recall: 0.4656 - Specificity: 0.9988 - F1: 0.5915 - Loss: 0.0030\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 18:29:35\n",
      "Accuracy: 0.9876 - Precision: 0.8999 - Recall: 0.4655 - Specificity: 0.9988 - F1: 0.5911 - Loss: 0.0030\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 18:29:43\n",
      "Accuracy: 0.9876 - Precision: 0.8994 - Recall: 0.4662 - Specificity: 0.9988 - F1: 0.5918 - Loss: 0.0030\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 18:29:51\n",
      "Accuracy: 0.9876 - Precision: 0.8990 - Recall: 0.4664 - Specificity: 0.9988 - F1: 0.5921 - Loss: 0.0030\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 18:30:00\n",
      "Accuracy: 0.9876 - Precision: 0.8983 - Recall: 0.4669 - Specificity: 0.9988 - F1: 0.5925 - Loss: 0.0030\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 18:30:09\n",
      "Accuracy: 0.9877 - Precision: 0.8986 - Recall: 0.4672 - Specificity: 0.9988 - F1: 0.5930 - Loss: 0.0030\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 18:30:17\n",
      "Accuracy: 0.9877 - Precision: 0.8985 - Recall: 0.4668 - Specificity: 0.9988 - F1: 0.5928 - Loss: 0.0030\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 18:30:26\n",
      "Accuracy: 0.9877 - Precision: 0.8976 - Recall: 0.4659 - Specificity: 0.9988 - F1: 0.5920 - Loss: 0.0030\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 18:30:34\n",
      "Accuracy: 0.9877 - Precision: 0.8980 - Recall: 0.4663 - Specificity: 0.9988 - F1: 0.5926 - Loss: 0.0030\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 18:30:42\n",
      "Accuracy: 0.9877 - Precision: 0.8983 - Recall: 0.4672 - Specificity: 0.9988 - F1: 0.5937 - Loss: 0.0030\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 18:30:50\n",
      "Accuracy: 0.9878 - Precision: 0.8977 - Recall: 0.4675 - Specificity: 0.9988 - F1: 0.5940 - Loss: 0.0030\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 18:30:59\n",
      "Accuracy: 0.9878 - Precision: 0.8977 - Recall: 0.4685 - Specificity: 0.9988 - F1: 0.5950 - Loss: 0.0030\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 18:31:07\n",
      "Accuracy: 0.9878 - Precision: 0.8972 - Recall: 0.4698 - Specificity: 0.9988 - F1: 0.5960 - Loss: 0.0030\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 18:31:15\n",
      "Accuracy: 0.9878 - Precision: 0.8978 - Recall: 0.4704 - Specificity: 0.9988 - F1: 0.5968 - Loss: 0.0030\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 18:31:23\n",
      "Accuracy: 0.9878 - Precision: 0.8985 - Recall: 0.4705 - Specificity: 0.9988 - F1: 0.5972 - Loss: 0.0030\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 18:31:31\n",
      "Accuracy: 0.9879 - Precision: 0.8986 - Recall: 0.4704 - Specificity: 0.9988 - F1: 0.5973 - Loss: 0.0029\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 18:31:39\n",
      "Accuracy: 0.9879 - Precision: 0.8989 - Recall: 0.4703 - Specificity: 0.9988 - F1: 0.5975 - Loss: 0.0030\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 18:31:48\n",
      "Accuracy: 0.9879 - Precision: 0.8993 - Recall: 0.4705 - Specificity: 0.9988 - F1: 0.5979 - Loss: 0.0029\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 18:31:56\n",
      "Accuracy: 0.9879 - Precision: 0.8986 - Recall: 0.4716 - Specificity: 0.9988 - F1: 0.5987 - Loss: 0.0029\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 18:32:05\n",
      "Accuracy: 0.9879 - Precision: 0.8973 - Recall: 0.4734 - Specificity: 0.9988 - F1: 0.5996 - Loss: 0.0029\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 18:32:14\n",
      "Accuracy: 0.9879 - Precision: 0.8967 - Recall: 0.4744 - Specificity: 0.9988 - F1: 0.6004 - Loss: 0.0029\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 18:32:22\n",
      "Accuracy: 0.9879 - Precision: 0.8967 - Recall: 0.4754 - Specificity: 0.9988 - F1: 0.6014 - Loss: 0.0029\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 18:32:30\n",
      "Accuracy: 0.9879 - Precision: 0.8970 - Recall: 0.4764 - Specificity: 0.9988 - F1: 0.6024 - Loss: 0.0029\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 18:32:38\n",
      "Accuracy: 0.9880 - Precision: 0.8974 - Recall: 0.4778 - Specificity: 0.9988 - F1: 0.6038 - Loss: 0.0029\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 18:32:46\n",
      "Accuracy: 0.9880 - Precision: 0.8974 - Recall: 0.4789 - Specificity: 0.9988 - F1: 0.6048 - Loss: 0.0029\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 18:32:54\n",
      "Accuracy: 0.9880 - Precision: 0.8977 - Recall: 0.4803 - Specificity: 0.9988 - F1: 0.6061 - Loss: 0.0029\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 18:33:03\n",
      "Accuracy: 0.9881 - Precision: 0.8972 - Recall: 0.4811 - Specificity: 0.9988 - F1: 0.6068 - Loss: 0.0029\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 18:33:11\n",
      "Accuracy: 0.9881 - Precision: 0.8971 - Recall: 0.4816 - Specificity: 0.9988 - F1: 0.6072 - Loss: 0.0029\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 18:33:19\n",
      "Accuracy: 0.9881 - Precision: 0.8976 - Recall: 0.4824 - Specificity: 0.9988 - F1: 0.6082 - Loss: 0.0029\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 18:33:27\n",
      "Accuracy: 0.9881 - Precision: 0.8980 - Recall: 0.4824 - Specificity: 0.9988 - F1: 0.6084 - Loss: 0.0029\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 18:33:35\n",
      "Accuracy: 0.9881 - Precision: 0.8982 - Recall: 0.4829 - Specificity: 0.9988 - F1: 0.6090 - Loss: 0.0029\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 18:33:43\n",
      "Accuracy: 0.9881 - Precision: 0.8980 - Recall: 0.4844 - Specificity: 0.9988 - F1: 0.6102 - Loss: 0.0029\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 18:33:51\n",
      "Accuracy: 0.9881 - Precision: 0.8982 - Recall: 0.4851 - Specificity: 0.9988 - F1: 0.6110 - Loss: 0.0029\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 18:33:59\n",
      "Accuracy: 0.9882 - Precision: 0.8982 - Recall: 0.4863 - Specificity: 0.9988 - F1: 0.6120 - Loss: 0.0029\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 18:34:09\n",
      "Accuracy: 0.9882 - Precision: 0.8983 - Recall: 0.4878 - Specificity: 0.9988 - F1: 0.6133 - Loss: 0.0029\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 18:34:17\n",
      "Accuracy: 0.9882 - Precision: 0.8980 - Recall: 0.4892 - Specificity: 0.9988 - F1: 0.6143 - Loss: 0.0029\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 18:34:25\n",
      "Accuracy: 0.9882 - Precision: 0.8984 - Recall: 0.4900 - Specificity: 0.9988 - F1: 0.6152 - Loss: 0.0029\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 18:34:33\n",
      "Accuracy: 0.9883 - Precision: 0.8985 - Recall: 0.4906 - Specificity: 0.9988 - F1: 0.6159 - Loss: 0.0029\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 18:34:41\n",
      "Accuracy: 0.9883 - Precision: 0.8991 - Recall: 0.4909 - Specificity: 0.9988 - F1: 0.6164 - Loss: 0.0029\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 18:34:49\n",
      "Accuracy: 0.9883 - Precision: 0.8996 - Recall: 0.4919 - Specificity: 0.9988 - F1: 0.6175 - Loss: 0.0029\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 18:34:57\n",
      "Accuracy: 0.9883 - Precision: 0.8999 - Recall: 0.4930 - Specificity: 0.9988 - F1: 0.6185 - Loss: 0.0029\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 18:35:05\n",
      "Accuracy: 0.9883 - Precision: 0.9002 - Recall: 0.4937 - Specificity: 0.9988 - F1: 0.6193 - Loss: 0.0029\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 18:35:13\n",
      "Accuracy: 0.9883 - Precision: 0.9000 - Recall: 0.4948 - Specificity: 0.9988 - F1: 0.6202 - Loss: 0.0029\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 18:35:21\n",
      "Accuracy: 0.9884 - Precision: 0.8994 - Recall: 0.4963 - Specificity: 0.9988 - F1: 0.6211 - Loss: 0.0029\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 18:35:29\n",
      "Accuracy: 0.9884 - Precision: 0.8996 - Recall: 0.4974 - Specificity: 0.9988 - F1: 0.6221 - Loss: 0.0029\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 18:35:37\n",
      "Accuracy: 0.9884 - Precision: 0.8993 - Recall: 0.4985 - Specificity: 0.9988 - F1: 0.6230 - Loss: 0.0029\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 18:35:45\n",
      "Accuracy: 0.9884 - Precision: 0.8996 - Recall: 0.4991 - Specificity: 0.9988 - F1: 0.6236 - Loss: 0.0029\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 18:35:52\n",
      "Accuracy: 0.9884 - Precision: 0.8999 - Recall: 0.4997 - Specificity: 0.9988 - F1: 0.6243 - Loss: 0.0029\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 18:36:01\n",
      "Accuracy: 0.9884 - Precision: 0.8988 - Recall: 0.4977 - Specificity: 0.9988 - F1: 0.6223 - Loss: 0.0029\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 18:36:11\n",
      "Accuracy: 0.9884 - Precision: 0.8990 - Recall: 0.4978 - Specificity: 0.9988 - F1: 0.6226 - Loss: 0.0029\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 18:36:18\n",
      "Accuracy: 0.9884 - Precision: 0.8990 - Recall: 0.4971 - Specificity: 0.9988 - F1: 0.6220 - Loss: 0.0029\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 18:36:26\n",
      "Accuracy: 0.9884 - Precision: 0.8991 - Recall: 0.4970 - Specificity: 0.9988 - F1: 0.6221 - Loss: 0.0029\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 18:36:34\n",
      "Accuracy: 0.9884 - Precision: 0.8996 - Recall: 0.4972 - Specificity: 0.9988 - F1: 0.6225 - Loss: 0.0029\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 18:36:42\n",
      "Accuracy: 0.9884 - Precision: 0.9000 - Recall: 0.4976 - Specificity: 0.9988 - F1: 0.6231 - Loss: 0.0029\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 18:36:50\n",
      "Accuracy: 0.9884 - Precision: 0.9003 - Recall: 0.4982 - Specificity: 0.9988 - F1: 0.6238 - Loss: 0.0029\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 18:36:58\n",
      "Accuracy: 0.9884 - Precision: 0.9006 - Recall: 0.4990 - Specificity: 0.9988 - F1: 0.6246 - Loss: 0.0029\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 18:37:06\n",
      "Accuracy: 0.9885 - Precision: 0.9007 - Recall: 0.5003 - Specificity: 0.9988 - F1: 0.6256 - Loss: 0.0028\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 18:37:14\n",
      "Accuracy: 0.9885 - Precision: 0.9004 - Recall: 0.5015 - Specificity: 0.9988 - F1: 0.6265 - Loss: 0.0028\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 18:37:22\n",
      "Accuracy: 0.9885 - Precision: 0.9008 - Recall: 0.5024 - Specificity: 0.9988 - F1: 0.6274 - Loss: 0.0028\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 18:37:30\n",
      "Accuracy: 0.9885 - Precision: 0.9011 - Recall: 0.5030 - Specificity: 0.9988 - F1: 0.6281 - Loss: 0.0028\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 18:37:38\n",
      "Accuracy: 0.9885 - Precision: 0.9014 - Recall: 0.5034 - Specificity: 0.9988 - F1: 0.6286 - Loss: 0.0028\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 18:37:46\n",
      "Accuracy: 0.9886 - Precision: 0.9017 - Recall: 0.5042 - Specificity: 0.9988 - F1: 0.6294 - Loss: 0.0028\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 18:37:54\n",
      "Accuracy: 0.9886 - Precision: 0.9012 - Recall: 0.5053 - Specificity: 0.9988 - F1: 0.6302 - Loss: 0.0028\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 18:38:03\n",
      "Accuracy: 0.9886 - Precision: 0.9011 - Recall: 0.5059 - Specificity: 0.9988 - F1: 0.6307 - Loss: 0.0028\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 18:38:13\n",
      "Accuracy: 0.9886 - Precision: 0.9014 - Recall: 0.5069 - Specificity: 0.9988 - F1: 0.6316 - Loss: 0.0028\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 18:38:21\n",
      "Accuracy: 0.9886 - Precision: 0.9010 - Recall: 0.5074 - Specificity: 0.9988 - F1: 0.6319 - Loss: 0.0028\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 18:38:29\n",
      "Accuracy: 0.9886 - Precision: 0.9014 - Recall: 0.5076 - Specificity: 0.9988 - F1: 0.6323 - Loss: 0.0028\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 18:38:37\n",
      "Accuracy: 0.9886 - Precision: 0.9019 - Recall: 0.5073 - Specificity: 0.9988 - F1: 0.6323 - Loss: 0.0028\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 18:38:45\n",
      "Accuracy: 0.9886 - Precision: 0.9020 - Recall: 0.5074 - Specificity: 0.9988 - F1: 0.6325 - Loss: 0.0028\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 18:38:53\n",
      "Accuracy: 0.9887 - Precision: 0.9021 - Recall: 0.5081 - Specificity: 0.9988 - F1: 0.6331 - Loss: 0.0028\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 18:39:01\n",
      "Accuracy: 0.9887 - Precision: 0.9021 - Recall: 0.5086 - Specificity: 0.9988 - F1: 0.6337 - Loss: 0.0028\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 18:39:09\n",
      "Accuracy: 0.9887 - Precision: 0.9021 - Recall: 0.5090 - Specificity: 0.9988 - F1: 0.6341 - Loss: 0.0028\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 18:39:17\n",
      "Accuracy: 0.9887 - Precision: 0.9022 - Recall: 0.5092 - Specificity: 0.9988 - F1: 0.6344 - Loss: 0.0028\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 18:39:25\n",
      "Accuracy: 0.9887 - Precision: 0.9025 - Recall: 0.5098 - Specificity: 0.9988 - F1: 0.6350 - Loss: 0.0028\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 18:39:33\n",
      "Accuracy: 0.9887 - Precision: 0.9023 - Recall: 0.5100 - Specificity: 0.9988 - F1: 0.6352 - Loss: 0.0028\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 18:39:41\n",
      "Accuracy: 0.9887 - Precision: 0.9026 - Recall: 0.5107 - Specificity: 0.9988 - F1: 0.6359 - Loss: 0.0028\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 18:39:49\n",
      "Accuracy: 0.9887 - Precision: 0.9027 - Recall: 0.5114 - Specificity: 0.9988 - F1: 0.6366 - Loss: 0.0028\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 18:39:57\n",
      "Accuracy: 0.9887 - Precision: 0.9028 - Recall: 0.5121 - Specificity: 0.9988 - F1: 0.6372 - Loss: 0.0028\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 18:40:06\n",
      "Accuracy: 0.9888 - Precision: 0.9022 - Recall: 0.5125 - Specificity: 0.9988 - F1: 0.6374 - Loss: 0.0028\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 18:40:15\n",
      "Accuracy: 0.9888 - Precision: 0.9026 - Recall: 0.5127 - Specificity: 0.9988 - F1: 0.6378 - Loss: 0.0028\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 18:40:23\n",
      "Accuracy: 0.9888 - Precision: 0.9030 - Recall: 0.5123 - Specificity: 0.9988 - F1: 0.6376 - Loss: 0.0028\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 18:40:31\n",
      "Accuracy: 0.9888 - Precision: 0.9035 - Recall: 0.5122 - Specificity: 0.9988 - F1: 0.6378 - Loss: 0.0028\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 18:40:40\n",
      "Accuracy: 0.9888 - Precision: 0.9035 - Recall: 0.5123 - Specificity: 0.9988 - F1: 0.6379 - Loss: 0.0028\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 18:40:48\n",
      "Accuracy: 0.9888 - Precision: 0.9035 - Recall: 0.5128 - Specificity: 0.9988 - F1: 0.6383 - Loss: 0.0028\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 18:40:56\n",
      "Accuracy: 0.9888 - Precision: 0.9033 - Recall: 0.5140 - Specificity: 0.9988 - F1: 0.6392 - Loss: 0.0028\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 18:41:04\n",
      "Accuracy: 0.9888 - Precision: 0.9028 - Recall: 0.5148 - Specificity: 0.9988 - F1: 0.6397 - Loss: 0.0028\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 18:41:12\n",
      "Accuracy: 0.9888 - Precision: 0.9027 - Recall: 0.5157 - Specificity: 0.9988 - F1: 0.6404 - Loss: 0.0028\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 18:41:21\n",
      "Accuracy: 0.9888 - Precision: 0.9026 - Recall: 0.5164 - Specificity: 0.9988 - F1: 0.6409 - Loss: 0.0028\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 18:41:29\n",
      "Accuracy: 0.9888 - Precision: 0.9026 - Recall: 0.5168 - Specificity: 0.9988 - F1: 0.6414 - Loss: 0.0028\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 18:41:36\n",
      "Accuracy: 0.9888 - Precision: 0.9030 - Recall: 0.5169 - Specificity: 0.9988 - F1: 0.6417 - Loss: 0.0028\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 18:41:44\n",
      "Accuracy: 0.9889 - Precision: 0.9034 - Recall: 0.5170 - Specificity: 0.9988 - F1: 0.6419 - Loss: 0.0028\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 18:41:53\n",
      "Accuracy: 0.9888 - Precision: 0.9035 - Recall: 0.5171 - Specificity: 0.9988 - F1: 0.6421 - Loss: 0.0028\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 18:42:01\n",
      "Accuracy: 0.9889 - Precision: 0.9027 - Recall: 0.5176 - Specificity: 0.9988 - F1: 0.6422 - Loss: 0.0028\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 18:42:11\n",
      "Accuracy: 0.9889 - Precision: 0.9029 - Recall: 0.5181 - Specificity: 0.9988 - F1: 0.6428 - Loss: 0.0028\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 18:42:19\n",
      "Accuracy: 0.9889 - Precision: 0.9031 - Recall: 0.5183 - Specificity: 0.9988 - F1: 0.6431 - Loss: 0.0028\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 18:42:27\n",
      "Accuracy: 0.9889 - Precision: 0.9031 - Recall: 0.5191 - Specificity: 0.9988 - F1: 0.6438 - Loss: 0.0027\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 18:42:35\n",
      "Accuracy: 0.9889 - Precision: 0.9028 - Recall: 0.5194 - Specificity: 0.9988 - F1: 0.6440 - Loss: 0.0027\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 18:42:43\n",
      "Accuracy: 0.9889 - Precision: 0.9027 - Recall: 0.5198 - Specificity: 0.9988 - F1: 0.6443 - Loss: 0.0027\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 18:42:51\n",
      "Accuracy: 0.9889 - Precision: 0.9029 - Recall: 0.5199 - Specificity: 0.9988 - F1: 0.6446 - Loss: 0.0027\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 18:42:59\n",
      "Accuracy: 0.9889 - Precision: 0.9033 - Recall: 0.5203 - Specificity: 0.9988 - F1: 0.6450 - Loss: 0.0027\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 18:43:07\n",
      "Accuracy: 0.9889 - Precision: 0.9035 - Recall: 0.5207 - Specificity: 0.9988 - F1: 0.6454 - Loss: 0.0027\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 18:43:15\n",
      "Accuracy: 0.9890 - Precision: 0.9037 - Recall: 0.5217 - Specificity: 0.9988 - F1: 0.6463 - Loss: 0.0027\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 18:43:23\n",
      "Accuracy: 0.9890 - Precision: 0.9039 - Recall: 0.5226 - Specificity: 0.9988 - F1: 0.6471 - Loss: 0.0027\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 18:43:31\n",
      "Accuracy: 0.9890 - Precision: 0.9033 - Recall: 0.5235 - Specificity: 0.9988 - F1: 0.6476 - Loss: 0.0027\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 18:43:39\n",
      "Accuracy: 0.9890 - Precision: 0.9032 - Recall: 0.5245 - Specificity: 0.9988 - F1: 0.6483 - Loss: 0.0027\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 18:43:47\n",
      "Accuracy: 0.9891 - Precision: 0.9034 - Recall: 0.5253 - Specificity: 0.9988 - F1: 0.6491 - Loss: 0.0027\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 18:43:55\n",
      "Accuracy: 0.9891 - Precision: 0.9033 - Recall: 0.5259 - Specificity: 0.9988 - F1: 0.6496 - Loss: 0.0027\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 18:44:03\n",
      "Accuracy: 0.9891 - Precision: 0.9035 - Recall: 0.5263 - Specificity: 0.9988 - F1: 0.6500 - Loss: 0.0027\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 18:44:13\n",
      "Accuracy: 0.9891 - Precision: 0.9038 - Recall: 0.5268 - Specificity: 0.9988 - F1: 0.6505 - Loss: 0.0027\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 18:44:21\n",
      "Accuracy: 0.9891 - Precision: 0.9036 - Recall: 0.5276 - Specificity: 0.9988 - F1: 0.6510 - Loss: 0.0027\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 18:44:29\n",
      "Accuracy: 0.9891 - Precision: 0.9038 - Recall: 0.5282 - Specificity: 0.9988 - F1: 0.6516 - Loss: 0.0027\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 18:44:37\n",
      "Accuracy: 0.9892 - Precision: 0.9039 - Recall: 0.5289 - Specificity: 0.9988 - F1: 0.6523 - Loss: 0.0027\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 18:44:45\n",
      "Accuracy: 0.9892 - Precision: 0.9037 - Recall: 0.5290 - Specificity: 0.9988 - F1: 0.6523 - Loss: 0.0027\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 18:44:53\n",
      "Accuracy: 0.9891 - Precision: 0.9035 - Recall: 0.5283 - Specificity: 0.9988 - F1: 0.6517 - Loss: 0.0027\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 18:45:01\n",
      "Accuracy: 0.9891 - Precision: 0.9030 - Recall: 0.5279 - Specificity: 0.9988 - F1: 0.6514 - Loss: 0.0027\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 18:45:09\n",
      "Accuracy: 0.9891 - Precision: 0.9028 - Recall: 0.5270 - Specificity: 0.9988 - F1: 0.6506 - Loss: 0.0027\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 18:45:17\n",
      "Accuracy: 0.9890 - Precision: 0.9028 - Recall: 0.5264 - Specificity: 0.9988 - F1: 0.6501 - Loss: 0.0027\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 18:45:25\n",
      "Accuracy: 0.9890 - Precision: 0.9029 - Recall: 0.5257 - Specificity: 0.9988 - F1: 0.6496 - Loss: 0.0027\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 18:45:33\n",
      "Accuracy: 0.9890 - Precision: 0.9028 - Recall: 0.5252 - Specificity: 0.9988 - F1: 0.6492 - Loss: 0.0027\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 18:45:41\n",
      "Accuracy: 0.9889 - Precision: 0.9025 - Recall: 0.5240 - Specificity: 0.9988 - F1: 0.6480 - Loss: 0.0027\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 18:45:49\n",
      "Accuracy: 0.9889 - Precision: 0.9025 - Recall: 0.5240 - Specificity: 0.9988 - F1: 0.6481 - Loss: 0.0027\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 18:45:57\n",
      "Accuracy: 0.9889 - Precision: 0.9017 - Recall: 0.5239 - Specificity: 0.9988 - F1: 0.6478 - Loss: 0.0028\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 18:46:06\n",
      "Accuracy: 0.9889 - Precision: 0.9012 - Recall: 0.5234 - Specificity: 0.9988 - F1: 0.6474 - Loss: 0.0028\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 18:46:16\n",
      "Accuracy: 0.9889 - Precision: 0.9014 - Recall: 0.5231 - Specificity: 0.9988 - F1: 0.6472 - Loss: 0.0028\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 18:46:24\n",
      "Accuracy: 0.9889 - Precision: 0.9018 - Recall: 0.5220 - Specificity: 0.9988 - F1: 0.6463 - Loss: 0.0028\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 18:46:32\n",
      "Accuracy: 0.9888 - Precision: 0.9021 - Recall: 0.5203 - Specificity: 0.9988 - F1: 0.6445 - Loss: 0.0028\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 18:46:40\n",
      "Accuracy: 0.9888 - Precision: 0.9023 - Recall: 0.5197 - Specificity: 0.9988 - F1: 0.6441 - Loss: 0.0028\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 18:46:49\n",
      "Accuracy: 0.9888 - Precision: 0.9024 - Recall: 0.5194 - Specificity: 0.9988 - F1: 0.6439 - Loss: 0.0028\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 18:46:56\n",
      "Accuracy: 0.9888 - Precision: 0.9020 - Recall: 0.5186 - Specificity: 0.9988 - F1: 0.6432 - Loss: 0.0028\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 18:47:04\n",
      "Accuracy: 0.9888 - Precision: 0.9017 - Recall: 0.5181 - Specificity: 0.9988 - F1: 0.6428 - Loss: 0.0028\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 18:47:12\n",
      "Accuracy: 0.9888 - Precision: 0.9016 - Recall: 0.5180 - Specificity: 0.9988 - F1: 0.6427 - Loss: 0.0028\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 18:47:20\n",
      "Accuracy: 0.9887 - Precision: 0.9015 - Recall: 0.5173 - Specificity: 0.9988 - F1: 0.6421 - Loss: 0.0028\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 18:47:28\n",
      "Accuracy: 0.9887 - Precision: 0.9016 - Recall: 0.5161 - Specificity: 0.9988 - F1: 0.6409 - Loss: 0.0028\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 18:47:36\n",
      "Accuracy: 0.9886 - Precision: 0.9018 - Recall: 0.5149 - Specificity: 0.9988 - F1: 0.6399 - Loss: 0.0028\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 18:47:44\n",
      "Accuracy: 0.9885 - Precision: 0.9019 - Recall: 0.5138 - Specificity: 0.9988 - F1: 0.6388 - Loss: 0.0028\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 18:47:52\n",
      "Accuracy: 0.9885 - Precision: 0.9020 - Recall: 0.5130 - Specificity: 0.9988 - F1: 0.6382 - Loss: 0.0029\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 18:48:00\n",
      "Accuracy: 0.9884 - Precision: 0.9018 - Recall: 0.5128 - Specificity: 0.9988 - F1: 0.6380 - Loss: 0.0029\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 18:48:09\n",
      "Accuracy: 0.9884 - Precision: 0.9018 - Recall: 0.5120 - Specificity: 0.9988 - F1: 0.6374 - Loss: 0.0029\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 18:48:18\n",
      "Accuracy: 0.9884 - Precision: 0.9018 - Recall: 0.5118 - Specificity: 0.9988 - F1: 0.6373 - Loss: 0.0029\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 18:48:26\n",
      "Accuracy: 0.9881 - Precision: 0.9016 - Recall: 0.5098 - Specificity: 0.9988 - F1: 0.6349 - Loss: 0.0030\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 18:48:34\n",
      "Accuracy: 0.9879 - Precision: 0.9016 - Recall: 0.5081 - Specificity: 0.9988 - F1: 0.6331 - Loss: 0.0031\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 18:48:42\n",
      "Accuracy: 0.9876 - Precision: 0.9015 - Recall: 0.5075 - Specificity: 0.9988 - F1: 0.6325 - Loss: 0.0032\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 18:48:50\n",
      "Accuracy: 0.9874 - Precision: 0.9008 - Recall: 0.5073 - Specificity: 0.9987 - F1: 0.6323 - Loss: 0.0032\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 18:48:59\n",
      "Accuracy: 0.9872 - Precision: 0.9005 - Recall: 0.5066 - Specificity: 0.9987 - F1: 0.6316 - Loss: 0.0033\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 18:49:07\n",
      "Accuracy: 0.9870 - Precision: 0.8997 - Recall: 0.5054 - Specificity: 0.9987 - F1: 0.6304 - Loss: 0.0033\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 18:49:15\n",
      "Accuracy: 0.9867 - Precision: 0.8994 - Recall: 0.5034 - Specificity: 0.9987 - F1: 0.6280 - Loss: 0.0034\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 18:49:22\n",
      "Accuracy: 0.9865 - Precision: 0.8992 - Recall: 0.5014 - Specificity: 0.9987 - F1: 0.6255 - Loss: 0.0035\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 18:49:30\n",
      "Accuracy: 0.9861 - Precision: 0.8996 - Recall: 0.4994 - Specificity: 0.9987 - F1: 0.6230 - Loss: 0.0036\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 18:49:38\n",
      "Accuracy: 0.9859 - Precision: 0.9000 - Recall: 0.4974 - Specificity: 0.9987 - F1: 0.6205 - Loss: 0.0036\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 18:49:46\n",
      "Accuracy: 0.9856 - Precision: 0.9004 - Recall: 0.4954 - Specificity: 0.9987 - F1: 0.6181 - Loss: 0.0037\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 18:49:55\n",
      "Accuracy: 0.9855 - Precision: 0.9004 - Recall: 0.4935 - Specificity: 0.9987 - F1: 0.6157 - Loss: 0.0037\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 18:50:03\n",
      "Accuracy: 0.9852 - Precision: 0.8998 - Recall: 0.4916 - Specificity: 0.9987 - F1: 0.6132 - Loss: 0.0038\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 18:50:12\n",
      "Accuracy: 0.9850 - Precision: 0.8993 - Recall: 0.4896 - Specificity: 0.9987 - F1: 0.6108 - Loss: 0.0038\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 18:50:21\n",
      "Accuracy: 0.9847 - Precision: 0.8985 - Recall: 0.4877 - Specificity: 0.9987 - F1: 0.6085 - Loss: 0.0039\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 18:50:29\n",
      "Accuracy: 0.9843 - Precision: 0.8989 - Recall: 0.4858 - Specificity: 0.9987 - F1: 0.6061 - Loss: 0.0039\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 18:50:36\n",
      "Accuracy: 0.9841 - Precision: 0.8988 - Recall: 0.4839 - Specificity: 0.9987 - F1: 0.6037 - Loss: 0.0040\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 18:50:44\n",
      "Accuracy: 0.9839 - Precision: 0.8987 - Recall: 0.4821 - Specificity: 0.9987 - F1: 0.6015 - Loss: 0.0040\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 18:50:53\n",
      "Accuracy: 0.9839 - Precision: 0.8979 - Recall: 0.4802 - Specificity: 0.9987 - F1: 0.5992 - Loss: 0.0041\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 18:51:00\n",
      "Accuracy: 0.9838 - Precision: 0.8974 - Recall: 0.4784 - Specificity: 0.9987 - F1: 0.5969 - Loss: 0.0041\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 18:51:08\n",
      "Accuracy: 0.9838 - Precision: 0.8974 - Recall: 0.4767 - Specificity: 0.9987 - F1: 0.5948 - Loss: 0.0041\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 18:51:16\n",
      "Accuracy: 0.9838 - Precision: 0.8976 - Recall: 0.4749 - Specificity: 0.9987 - F1: 0.5926 - Loss: 0.0041\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 18:51:24\n",
      "Accuracy: 0.9836 - Precision: 0.8978 - Recall: 0.4731 - Specificity: 0.9987 - F1: 0.5905 - Loss: 0.0042\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 18:51:32\n",
      "Accuracy: 0.9835 - Precision: 0.8976 - Recall: 0.4714 - Specificity: 0.9987 - F1: 0.5883 - Loss: 0.0042\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 18:51:40\n",
      "Accuracy: 0.9835 - Precision: 0.8979 - Recall: 0.4696 - Specificity: 0.9987 - F1: 0.5862 - Loss: 0.0042\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 18:51:48\n",
      "Accuracy: 0.9834 - Precision: 0.8970 - Recall: 0.4679 - Specificity: 0.9988 - F1: 0.5840 - Loss: 0.0043\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 18:51:56\n",
      "Accuracy: 0.9834 - Precision: 0.8972 - Recall: 0.4661 - Specificity: 0.9988 - F1: 0.5819 - Loss: 0.0043\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 18:52:04\n",
      "Accuracy: 0.9834 - Precision: 0.8974 - Recall: 0.4644 - Specificity: 0.9988 - F1: 0.5797 - Loss: 0.0043\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 18:52:13\n",
      "Accuracy: 0.9833 - Precision: 0.8972 - Recall: 0.4627 - Specificity: 0.9988 - F1: 0.5776 - Loss: 0.0043\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 18:52:22\n",
      "Accuracy: 0.9833 - Precision: 0.8958 - Recall: 0.4610 - Specificity: 0.9988 - F1: 0.5755 - Loss: 0.0043\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 18:52:30\n",
      "Accuracy: 0.9833 - Precision: 0.8961 - Recall: 0.4593 - Specificity: 0.9988 - F1: 0.5734 - Loss: 0.0043\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 18:52:37\n",
      "Accuracy: 0.9833 - Precision: 0.8959 - Recall: 0.4576 - Specificity: 0.9988 - F1: 0.5713 - Loss: 0.0043\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 18:52:45\n",
      "Accuracy: 0.9832 - Precision: 0.8960 - Recall: 0.4560 - Specificity: 0.9988 - F1: 0.5692 - Loss: 0.0043\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 18:52:53\n",
      "Accuracy: 0.9832 - Precision: 0.8962 - Recall: 0.4543 - Specificity: 0.9988 - F1: 0.5672 - Loss: 0.0043\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 18:53:01\n",
      "Accuracy: 0.9831 - Precision: 0.8962 - Recall: 0.4527 - Specificity: 0.9988 - F1: 0.5651 - Loss: 0.0044\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 18:53:09\n",
      "Accuracy: 0.9831 - Precision: 0.8946 - Recall: 0.4510 - Specificity: 0.9988 - F1: 0.5631 - Loss: 0.0044\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 18:53:17\n",
      "Accuracy: 0.9830 - Precision: 0.8950 - Recall: 0.4494 - Specificity: 0.9988 - F1: 0.5611 - Loss: 0.0044\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 18:53:25\n",
      "Accuracy: 0.9831 - Precision: 0.8925 - Recall: 0.4478 - Specificity: 0.9988 - F1: 0.5590 - Loss: 0.0044\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 18:53:33\n",
      "Accuracy: 0.9830 - Precision: 0.8929 - Recall: 0.4462 - Specificity: 0.9988 - F1: 0.5570 - Loss: 0.0044\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 18:53:41\n",
      "Accuracy: 0.9830 - Precision: 0.8932 - Recall: 0.4446 - Specificity: 0.9988 - F1: 0.5551 - Loss: 0.0044\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 18:53:49\n",
      "Accuracy: 0.9830 - Precision: 0.8918 - Recall: 0.4430 - Specificity: 0.9988 - F1: 0.5531 - Loss: 0.0044\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 18:53:57\n",
      "Accuracy: 0.9830 - Precision: 0.8886 - Recall: 0.4414 - Specificity: 0.9988 - F1: 0.5512 - Loss: 0.0044\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 18:54:05\n",
      "Accuracy: 0.9830 - Precision: 0.8890 - Recall: 0.4399 - Specificity: 0.9988 - F1: 0.5493 - Loss: 0.0044\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 18:54:14\n",
      "Accuracy: 0.9830 - Precision: 0.8859 - Recall: 0.4383 - Specificity: 0.9988 - F1: 0.5473 - Loss: 0.0044\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 18:54:23\n",
      "Accuracy: 0.9830 - Precision: 0.8863 - Recall: 0.4368 - Specificity: 0.9988 - F1: 0.5454 - Loss: 0.0044\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 18:54:31\n",
      "Accuracy: 0.9830 - Precision: 0.8867 - Recall: 0.4353 - Specificity: 0.9988 - F1: 0.5435 - Loss: 0.0044\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 18:54:39\n",
      "Accuracy: 0.9829 - Precision: 0.8867 - Recall: 0.4338 - Specificity: 0.9988 - F1: 0.5416 - Loss: 0.0044\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 18:54:47\n",
      "Accuracy: 0.9828 - Precision: 0.8871 - Recall: 0.4323 - Specificity: 0.9988 - F1: 0.5398 - Loss: 0.0045\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 18:54:55\n",
      "Accuracy: 0.9828 - Precision: 0.8875 - Recall: 0.4308 - Specificity: 0.9988 - F1: 0.5379 - Loss: 0.0045\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 18:55:03\n",
      "Accuracy: 0.9828 - Precision: 0.8878 - Recall: 0.4293 - Specificity: 0.9989 - F1: 0.5361 - Loss: 0.0045\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 18:55:12\n",
      "Accuracy: 0.9828 - Precision: 0.8877 - Recall: 0.4278 - Specificity: 0.9989 - F1: 0.5343 - Loss: 0.0045\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 18:55:19\n",
      "Accuracy: 0.9828 - Precision: 0.8878 - Recall: 0.4264 - Specificity: 0.9989 - F1: 0.5325 - Loss: 0.0045\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 18:55:28\n",
      "Accuracy: 0.9827 - Precision: 0.8875 - Recall: 0.4250 - Specificity: 0.9989 - F1: 0.5308 - Loss: 0.0045\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 18:55:36\n",
      "Accuracy: 0.9827 - Precision: 0.8876 - Recall: 0.4238 - Specificity: 0.9989 - F1: 0.5295 - Loss: 0.0045\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 18:55:44\n",
      "Accuracy: 0.9827 - Precision: 0.8880 - Recall: 0.4226 - Specificity: 0.9989 - F1: 0.5280 - Loss: 0.0045\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 18:55:52\n",
      "Accuracy: 0.9826 - Precision: 0.8879 - Recall: 0.4215 - Specificity: 0.9989 - F1: 0.5268 - Loss: 0.0045\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 18:56:00\n",
      "Accuracy: 0.9826 - Precision: 0.8878 - Recall: 0.4208 - Specificity: 0.9989 - F1: 0.5263 - Loss: 0.0045\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 18:56:08\n",
      "Accuracy: 0.9826 - Precision: 0.8879 - Recall: 0.4200 - Specificity: 0.9989 - F1: 0.5254 - Loss: 0.0045\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 18:56:18\n",
      "Accuracy: 0.9825 - Precision: 0.8880 - Recall: 0.4188 - Specificity: 0.9989 - F1: 0.5241 - Loss: 0.0045\n",
      "\n",
      "Epoch 9/20\n",
      "Validation - Accuracy: 0.9809, Precision: 0.9102, Recall: 0.1214, Specificity: 0.9997, F1: 0.2119, Loss: 0.0052\n",
      "\n",
      "\n",
      "Epoch 10/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 19:03:54\n",
      "Accuracy: 0.9773 - Precision: 0.9304 - Recall: 0.1475 - Specificity: 0.9997 - F1: 0.2547 - Loss: 0.0059\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 19:04:02\n",
      "Accuracy: 0.9764 - Precision: 0.9016 - Recall: 0.1716 - Specificity: 0.9994 - F1: 0.2872 - Loss: 0.0060\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 19:04:10\n",
      "Accuracy: 0.9770 - Precision: 0.9165 - Recall: 0.2180 - Specificity: 0.9994 - F1: 0.3475 - Loss: 0.0056\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 19:04:20\n",
      "Accuracy: 0.9797 - Precision: 0.9022 - Recall: 0.2426 - Specificity: 0.9993 - F1: 0.3762 - Loss: 0.0051\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 19:04:28\n",
      "Accuracy: 0.9812 - Precision: 0.8570 - Recall: 0.2746 - Specificity: 0.9989 - F1: 0.4019 - Loss: 0.0050\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 19:04:36\n",
      "Accuracy: 0.9811 - Precision: 0.8786 - Recall: 0.2582 - Specificity: 0.9990 - F1: 0.3847 - Loss: 0.0049\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 19:04:44\n",
      "Accuracy: 0.9821 - Precision: 0.8924 - Recall: 0.2459 - Specificity: 0.9992 - F1: 0.3716 - Loss: 0.0046\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 19:04:52\n",
      "Accuracy: 0.9823 - Precision: 0.8681 - Recall: 0.2301 - Specificity: 0.9992 - F1: 0.3506 - Loss: 0.0044\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 19:05:00\n",
      "Accuracy: 0.9827 - Precision: 0.8814 - Recall: 0.2182 - Specificity: 0.9992 - F1: 0.3360 - Loss: 0.0042\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 19:05:08\n",
      "Accuracy: 0.9828 - Precision: 0.8898 - Recall: 0.2022 - Specificity: 0.9993 - F1: 0.3134 - Loss: 0.0041\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 19:05:17\n",
      "Accuracy: 0.9829 - Precision: 0.8837 - Recall: 0.1960 - Specificity: 0.9993 - F1: 0.3058 - Loss: 0.0041\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 19:05:24\n",
      "Accuracy: 0.9830 - Precision: 0.8926 - Recall: 0.1900 - Specificity: 0.9994 - F1: 0.2987 - Loss: 0.0040\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 19:05:32\n",
      "Accuracy: 0.9832 - Precision: 0.8956 - Recall: 0.1930 - Specificity: 0.9994 - F1: 0.3040 - Loss: 0.0039\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 19:05:41\n",
      "Accuracy: 0.9833 - Precision: 0.8753 - Recall: 0.1957 - Specificity: 0.9993 - F1: 0.3063 - Loss: 0.0039\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 19:05:48\n",
      "Accuracy: 0.9835 - Precision: 0.8796 - Recall: 0.2029 - Specificity: 0.9993 - F1: 0.3164 - Loss: 0.0038\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 19:05:56\n",
      "Accuracy: 0.9833 - Precision: 0.8804 - Recall: 0.2063 - Specificity: 0.9993 - F1: 0.3216 - Loss: 0.0039\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 19:06:05\n",
      "Accuracy: 0.9837 - Precision: 0.8834 - Recall: 0.2198 - Specificity: 0.9993 - F1: 0.3376 - Loss: 0.0038\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 19:06:13\n",
      "Accuracy: 0.9838 - Precision: 0.8873 - Recall: 0.2297 - Specificity: 0.9993 - F1: 0.3500 - Loss: 0.0038\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 19:06:23\n",
      "Accuracy: 0.9841 - Precision: 0.8864 - Recall: 0.2417 - Specificity: 0.9993 - F1: 0.3632 - Loss: 0.0037\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 19:06:31\n",
      "Accuracy: 0.9844 - Precision: 0.8871 - Recall: 0.2556 - Specificity: 0.9993 - F1: 0.3780 - Loss: 0.0037\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 19:06:39\n",
      "Accuracy: 0.9845 - Precision: 0.8860 - Recall: 0.2623 - Specificity: 0.9992 - F1: 0.3859 - Loss: 0.0037\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 19:06:47\n",
      "Accuracy: 0.9842 - Precision: 0.8704 - Recall: 0.2616 - Specificity: 0.9990 - F1: 0.3838 - Loss: 0.0038\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 19:06:55\n",
      "Accuracy: 0.9841 - Precision: 0.8754 - Recall: 0.2577 - Specificity: 0.9991 - F1: 0.3798 - Loss: 0.0038\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 19:07:03\n",
      "Accuracy: 0.9839 - Precision: 0.8791 - Recall: 0.2545 - Specificity: 0.9991 - F1: 0.3767 - Loss: 0.0038\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 19:07:11\n",
      "Accuracy: 0.9838 - Precision: 0.8828 - Recall: 0.2493 - Specificity: 0.9991 - F1: 0.3705 - Loss: 0.0038\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 19:07:19\n",
      "Accuracy: 0.9839 - Precision: 0.8852 - Recall: 0.2453 - Specificity: 0.9992 - F1: 0.3659 - Loss: 0.0037\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 19:07:27\n",
      "Accuracy: 0.9838 - Precision: 0.8888 - Recall: 0.2403 - Specificity: 0.9992 - F1: 0.3597 - Loss: 0.0037\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 19:07:35\n",
      "Accuracy: 0.9837 - Precision: 0.8924 - Recall: 0.2345 - Specificity: 0.9992 - F1: 0.3520 - Loss: 0.0037\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 19:07:43\n",
      "Accuracy: 0.9834 - Precision: 0.8927 - Recall: 0.2298 - Specificity: 0.9992 - F1: 0.3459 - Loss: 0.0038\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 19:07:51\n",
      "Accuracy: 0.9833 - Precision: 0.8955 - Recall: 0.2299 - Specificity: 0.9993 - F1: 0.3470 - Loss: 0.0037\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 19:08:00\n",
      "Accuracy: 0.9835 - Precision: 0.8973 - Recall: 0.2326 - Specificity: 0.9993 - F1: 0.3510 - Loss: 0.0037\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 19:08:08\n",
      "Accuracy: 0.9835 - Precision: 0.8991 - Recall: 0.2334 - Specificity: 0.9993 - F1: 0.3527 - Loss: 0.0037\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 19:08:17\n",
      "Accuracy: 0.9836 - Precision: 0.9003 - Recall: 0.2397 - Specificity: 0.9993 - F1: 0.3602 - Loss: 0.0037\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 19:08:26\n",
      "Accuracy: 0.9836 - Precision: 0.9018 - Recall: 0.2436 - Specificity: 0.9993 - F1: 0.3654 - Loss: 0.0037\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 19:08:34\n",
      "Accuracy: 0.9837 - Precision: 0.9028 - Recall: 0.2492 - Specificity: 0.9993 - F1: 0.3720 - Loss: 0.0036\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 19:08:42\n",
      "Accuracy: 0.9839 - Precision: 0.9008 - Recall: 0.2598 - Specificity: 0.9993 - F1: 0.3816 - Loss: 0.0036\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 19:08:50\n",
      "Accuracy: 0.9841 - Precision: 0.9007 - Recall: 0.2716 - Specificity: 0.9992 - F1: 0.3925 - Loss: 0.0036\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 19:08:58\n",
      "Accuracy: 0.9842 - Precision: 0.8993 - Recall: 0.2804 - Specificity: 0.9992 - F1: 0.4007 - Loss: 0.0036\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 19:09:06\n",
      "Accuracy: 0.9844 - Precision: 0.8996 - Recall: 0.2880 - Specificity: 0.9992 - F1: 0.4086 - Loss: 0.0035\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 19:09:14\n",
      "Accuracy: 0.9845 - Precision: 0.9009 - Recall: 0.2952 - Specificity: 0.9992 - F1: 0.4163 - Loss: 0.0035\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 19:09:22\n",
      "Accuracy: 0.9844 - Precision: 0.9012 - Recall: 0.2979 - Specificity: 0.9992 - F1: 0.4199 - Loss: 0.0036\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 19:09:31\n",
      "Accuracy: 0.9845 - Precision: 0.9028 - Recall: 0.3036 - Specificity: 0.9992 - F1: 0.4263 - Loss: 0.0035\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 19:09:39\n",
      "Accuracy: 0.9847 - Precision: 0.9037 - Recall: 0.3100 - Specificity: 0.9992 - F1: 0.4331 - Loss: 0.0035\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 19:09:47\n",
      "Accuracy: 0.9848 - Precision: 0.9041 - Recall: 0.3176 - Specificity: 0.9992 - F1: 0.4405 - Loss: 0.0035\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 19:09:55\n",
      "Accuracy: 0.9850 - Precision: 0.8990 - Recall: 0.3260 - Specificity: 0.9991 - F1: 0.4459 - Loss: 0.0035\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 19:10:03\n",
      "Accuracy: 0.9850 - Precision: 0.9001 - Recall: 0.3305 - Specificity: 0.9991 - F1: 0.4511 - Loss: 0.0035\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 19:10:11\n",
      "Accuracy: 0.9850 - Precision: 0.9010 - Recall: 0.3324 - Specificity: 0.9991 - F1: 0.4538 - Loss: 0.0035\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 19:10:20\n",
      "Accuracy: 0.9850 - Precision: 0.9028 - Recall: 0.3335 - Specificity: 0.9991 - F1: 0.4559 - Loss: 0.0035\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 19:10:29\n",
      "Accuracy: 0.9851 - Precision: 0.9039 - Recall: 0.3350 - Specificity: 0.9991 - F1: 0.4583 - Loss: 0.0034\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 19:10:37\n",
      "Accuracy: 0.9851 - Precision: 0.9057 - Recall: 0.3364 - Specificity: 0.9991 - F1: 0.4606 - Loss: 0.0034\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 19:10:45\n",
      "Accuracy: 0.9851 - Precision: 0.9069 - Recall: 0.3382 - Specificity: 0.9991 - F1: 0.4632 - Loss: 0.0034\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 19:10:53\n",
      "Accuracy: 0.9851 - Precision: 0.9067 - Recall: 0.3394 - Specificity: 0.9991 - F1: 0.4650 - Loss: 0.0034\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 19:11:01\n",
      "Accuracy: 0.9852 - Precision: 0.9074 - Recall: 0.3430 - Specificity: 0.9991 - F1: 0.4690 - Loss: 0.0034\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 19:11:10\n",
      "Accuracy: 0.9854 - Precision: 0.9084 - Recall: 0.3483 - Specificity: 0.9991 - F1: 0.4744 - Loss: 0.0033\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 19:11:18\n",
      "Accuracy: 0.9855 - Precision: 0.9087 - Recall: 0.3530 - Specificity: 0.9991 - F1: 0.4791 - Loss: 0.0033\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 19:11:26\n",
      "Accuracy: 0.9856 - Precision: 0.9079 - Recall: 0.3598 - Specificity: 0.9991 - F1: 0.4847 - Loss: 0.0033\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 19:11:34\n",
      "Accuracy: 0.9857 - Precision: 0.9075 - Recall: 0.3651 - Specificity: 0.9991 - F1: 0.4895 - Loss: 0.0033\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 19:11:42\n",
      "Accuracy: 0.9858 - Precision: 0.9073 - Recall: 0.3705 - Specificity: 0.9991 - F1: 0.4944 - Loss: 0.0033\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 19:11:50\n",
      "Accuracy: 0.9859 - Precision: 0.9082 - Recall: 0.3743 - Specificity: 0.9991 - F1: 0.4985 - Loss: 0.0032\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 19:11:58\n",
      "Accuracy: 0.9860 - Precision: 0.9069 - Recall: 0.3775 - Specificity: 0.9991 - F1: 0.5013 - Loss: 0.0032\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 19:12:06\n",
      "Accuracy: 0.9860 - Precision: 0.9062 - Recall: 0.3794 - Specificity: 0.9991 - F1: 0.5034 - Loss: 0.0032\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 19:12:15\n",
      "Accuracy: 0.9861 - Precision: 0.9070 - Recall: 0.3828 - Specificity: 0.9991 - F1: 0.5071 - Loss: 0.0032\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 19:12:25\n",
      "Accuracy: 0.9862 - Precision: 0.9078 - Recall: 0.3873 - Specificity: 0.9991 - F1: 0.5115 - Loss: 0.0032\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 19:12:33\n",
      "Accuracy: 0.9863 - Precision: 0.9078 - Recall: 0.3925 - Specificity: 0.9991 - F1: 0.5161 - Loss: 0.0032\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 19:12:41\n",
      "Accuracy: 0.9864 - Precision: 0.9077 - Recall: 0.3967 - Specificity: 0.9991 - F1: 0.5199 - Loss: 0.0032\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 19:12:49\n",
      "Accuracy: 0.9864 - Precision: 0.9071 - Recall: 0.3994 - Specificity: 0.9990 - F1: 0.5225 - Loss: 0.0032\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 19:12:57\n",
      "Accuracy: 0.9864 - Precision: 0.9066 - Recall: 0.4025 - Specificity: 0.9990 - F1: 0.5254 - Loss: 0.0032\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 19:13:05\n",
      "Accuracy: 0.9865 - Precision: 0.9065 - Recall: 0.4045 - Specificity: 0.9990 - F1: 0.5276 - Loss: 0.0032\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 19:13:13\n",
      "Accuracy: 0.9865 - Precision: 0.9073 - Recall: 0.4075 - Specificity: 0.9990 - F1: 0.5308 - Loss: 0.0032\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 19:13:21\n",
      "Accuracy: 0.9866 - Precision: 0.9079 - Recall: 0.4104 - Specificity: 0.9990 - F1: 0.5338 - Loss: 0.0031\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 19:13:29\n",
      "Accuracy: 0.9867 - Precision: 0.9069 - Recall: 0.4123 - Specificity: 0.9990 - F1: 0.5356 - Loss: 0.0031\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 19:13:37\n",
      "Accuracy: 0.9867 - Precision: 0.9059 - Recall: 0.4135 - Specificity: 0.9990 - F1: 0.5368 - Loss: 0.0031\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 19:13:45\n",
      "Accuracy: 0.9866 - Precision: 0.9069 - Recall: 0.4141 - Specificity: 0.9990 - F1: 0.5380 - Loss: 0.0031\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 19:13:53\n",
      "Accuracy: 0.9866 - Precision: 0.9079 - Recall: 0.4146 - Specificity: 0.9990 - F1: 0.5391 - Loss: 0.0031\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 19:14:02\n",
      "Accuracy: 0.9866 - Precision: 0.9082 - Recall: 0.4158 - Specificity: 0.9990 - F1: 0.5406 - Loss: 0.0031\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 19:14:10\n",
      "Accuracy: 0.9867 - Precision: 0.9088 - Recall: 0.4175 - Specificity: 0.9990 - F1: 0.5426 - Loss: 0.0031\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 19:14:18\n",
      "Accuracy: 0.9867 - Precision: 0.9085 - Recall: 0.4203 - Specificity: 0.9990 - F1: 0.5452 - Loss: 0.0031\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 19:14:28\n",
      "Accuracy: 0.9868 - Precision: 0.9090 - Recall: 0.4232 - Specificity: 0.9990 - F1: 0.5480 - Loss: 0.0031\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 19:14:36\n",
      "Accuracy: 0.9868 - Precision: 0.9085 - Recall: 0.4262 - Specificity: 0.9990 - F1: 0.5506 - Loss: 0.0031\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 19:14:43\n",
      "Accuracy: 0.9869 - Precision: 0.9087 - Recall: 0.4295 - Specificity: 0.9990 - F1: 0.5536 - Loss: 0.0031\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 19:14:51\n",
      "Accuracy: 0.9870 - Precision: 0.9087 - Recall: 0.4325 - Specificity: 0.9990 - F1: 0.5563 - Loss: 0.0031\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 19:14:59\n",
      "Accuracy: 0.9870 - Precision: 0.9080 - Recall: 0.4340 - Specificity: 0.9990 - F1: 0.5578 - Loss: 0.0031\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 19:15:07\n",
      "Accuracy: 0.9870 - Precision: 0.9083 - Recall: 0.4353 - Specificity: 0.9990 - F1: 0.5592 - Loss: 0.0031\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 19:15:15\n",
      "Accuracy: 0.9871 - Precision: 0.9083 - Recall: 0.4362 - Specificity: 0.9990 - F1: 0.5604 - Loss: 0.0031\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 19:15:23\n",
      "Accuracy: 0.9871 - Precision: 0.9090 - Recall: 0.4383 - Specificity: 0.9990 - F1: 0.5627 - Loss: 0.0030\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 19:15:31\n",
      "Accuracy: 0.9871 - Precision: 0.9089 - Recall: 0.4394 - Specificity: 0.9990 - F1: 0.5639 - Loss: 0.0030\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 19:15:39\n",
      "Accuracy: 0.9872 - Precision: 0.9094 - Recall: 0.4416 - Specificity: 0.9990 - F1: 0.5662 - Loss: 0.0030\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 19:15:48\n",
      "Accuracy: 0.9872 - Precision: 0.9092 - Recall: 0.4436 - Specificity: 0.9990 - F1: 0.5680 - Loss: 0.0030\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 19:15:57\n",
      "Accuracy: 0.9873 - Precision: 0.9098 - Recall: 0.4458 - Specificity: 0.9990 - F1: 0.5702 - Loss: 0.0030\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 19:16:06\n",
      "Accuracy: 0.9873 - Precision: 0.9102 - Recall: 0.4478 - Specificity: 0.9990 - F1: 0.5722 - Loss: 0.0030\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 19:16:14\n",
      "Accuracy: 0.9873 - Precision: 0.9103 - Recall: 0.4505 - Specificity: 0.9990 - F1: 0.5747 - Loss: 0.0030\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 19:16:23\n",
      "Accuracy: 0.9874 - Precision: 0.9094 - Recall: 0.4532 - Specificity: 0.9990 - F1: 0.5766 - Loss: 0.0030\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 19:16:32\n",
      "Accuracy: 0.9874 - Precision: 0.9093 - Recall: 0.4555 - Specificity: 0.9990 - F1: 0.5787 - Loss: 0.0030\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 19:16:40\n",
      "Accuracy: 0.9875 - Precision: 0.9096 - Recall: 0.4572 - Specificity: 0.9990 - F1: 0.5804 - Loss: 0.0030\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 19:16:48\n",
      "Accuracy: 0.9875 - Precision: 0.9083 - Recall: 0.4585 - Specificity: 0.9989 - F1: 0.5814 - Loss: 0.0030\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 19:16:56\n",
      "Accuracy: 0.9875 - Precision: 0.9084 - Recall: 0.4585 - Specificity: 0.9989 - F1: 0.5817 - Loss: 0.0030\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 19:17:04\n",
      "Accuracy: 0.9875 - Precision: 0.9092 - Recall: 0.4580 - Specificity: 0.9989 - F1: 0.5817 - Loss: 0.0030\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 19:17:12\n",
      "Accuracy: 0.9875 - Precision: 0.9095 - Recall: 0.4584 - Specificity: 0.9990 - F1: 0.5823 - Loss: 0.0030\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 19:17:20\n",
      "Accuracy: 0.9875 - Precision: 0.9093 - Recall: 0.4583 - Specificity: 0.9990 - F1: 0.5825 - Loss: 0.0030\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 19:17:28\n",
      "Accuracy: 0.9876 - Precision: 0.9092 - Recall: 0.4588 - Specificity: 0.9990 - F1: 0.5832 - Loss: 0.0029\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 19:17:36\n",
      "Accuracy: 0.9876 - Precision: 0.9091 - Recall: 0.4594 - Specificity: 0.9990 - F1: 0.5839 - Loss: 0.0029\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 19:17:44\n",
      "Accuracy: 0.9876 - Precision: 0.9069 - Recall: 0.4591 - Specificity: 0.9989 - F1: 0.5833 - Loss: 0.0029\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 19:17:52\n",
      "Accuracy: 0.9877 - Precision: 0.9066 - Recall: 0.4598 - Specificity: 0.9989 - F1: 0.5841 - Loss: 0.0029\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 19:18:00\n",
      "Accuracy: 0.9876 - Precision: 0.9064 - Recall: 0.4601 - Specificity: 0.9989 - F1: 0.5846 - Loss: 0.0029\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 19:18:08\n",
      "Accuracy: 0.9877 - Precision: 0.9056 - Recall: 0.4608 - Specificity: 0.9989 - F1: 0.5851 - Loss: 0.0029\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 19:18:16\n",
      "Accuracy: 0.9877 - Precision: 0.9059 - Recall: 0.4611 - Specificity: 0.9989 - F1: 0.5857 - Loss: 0.0029\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 19:18:25\n",
      "Accuracy: 0.9877 - Precision: 0.9058 - Recall: 0.4604 - Specificity: 0.9989 - F1: 0.5854 - Loss: 0.0029\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 19:18:34\n",
      "Accuracy: 0.9877 - Precision: 0.9049 - Recall: 0.4593 - Specificity: 0.9989 - F1: 0.5843 - Loss: 0.0029\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 19:18:42\n",
      "Accuracy: 0.9877 - Precision: 0.9054 - Recall: 0.4591 - Specificity: 0.9989 - F1: 0.5845 - Loss: 0.0029\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 19:18:50\n",
      "Accuracy: 0.9878 - Precision: 0.9058 - Recall: 0.4600 - Specificity: 0.9989 - F1: 0.5855 - Loss: 0.0029\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 19:18:58\n",
      "Accuracy: 0.9878 - Precision: 0.9054 - Recall: 0.4601 - Specificity: 0.9989 - F1: 0.5858 - Loss: 0.0029\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 19:19:06\n",
      "Accuracy: 0.9878 - Precision: 0.9052 - Recall: 0.4610 - Specificity: 0.9989 - F1: 0.5866 - Loss: 0.0029\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 19:19:14\n",
      "Accuracy: 0.9878 - Precision: 0.9046 - Recall: 0.4624 - Specificity: 0.9989 - F1: 0.5878 - Loss: 0.0029\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 19:19:22\n",
      "Accuracy: 0.9879 - Precision: 0.9050 - Recall: 0.4635 - Specificity: 0.9989 - F1: 0.5889 - Loss: 0.0029\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 19:19:30\n",
      "Accuracy: 0.9879 - Precision: 0.9054 - Recall: 0.4641 - Specificity: 0.9989 - F1: 0.5899 - Loss: 0.0029\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 19:19:38\n",
      "Accuracy: 0.9879 - Precision: 0.9054 - Recall: 0.4648 - Specificity: 0.9989 - F1: 0.5906 - Loss: 0.0029\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 19:19:46\n",
      "Accuracy: 0.9879 - Precision: 0.9056 - Recall: 0.4652 - Specificity: 0.9989 - F1: 0.5912 - Loss: 0.0029\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 19:19:55\n",
      "Accuracy: 0.9879 - Precision: 0.9058 - Recall: 0.4659 - Specificity: 0.9989 - F1: 0.5921 - Loss: 0.0029\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 19:20:02\n",
      "Accuracy: 0.9879 - Precision: 0.9052 - Recall: 0.4670 - Specificity: 0.9989 - F1: 0.5929 - Loss: 0.0029\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 19:20:10\n",
      "Accuracy: 0.9880 - Precision: 0.9040 - Recall: 0.4685 - Specificity: 0.9989 - F1: 0.5938 - Loss: 0.0028\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 19:20:19\n",
      "Accuracy: 0.9880 - Precision: 0.9037 - Recall: 0.4692 - Specificity: 0.9989 - F1: 0.5945 - Loss: 0.0028\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 19:20:28\n",
      "Accuracy: 0.9880 - Precision: 0.9039 - Recall: 0.4700 - Specificity: 0.9989 - F1: 0.5954 - Loss: 0.0028\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 19:20:36\n",
      "Accuracy: 0.9880 - Precision: 0.9044 - Recall: 0.4708 - Specificity: 0.9989 - F1: 0.5963 - Loss: 0.0028\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 19:20:44\n",
      "Accuracy: 0.9880 - Precision: 0.9047 - Recall: 0.4723 - Specificity: 0.9989 - F1: 0.5978 - Loss: 0.0028\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 19:20:52\n",
      "Accuracy: 0.9881 - Precision: 0.9045 - Recall: 0.4737 - Specificity: 0.9989 - F1: 0.5990 - Loss: 0.0028\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 19:21:00\n",
      "Accuracy: 0.9881 - Precision: 0.9047 - Recall: 0.4755 - Specificity: 0.9989 - F1: 0.6006 - Loss: 0.0028\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 19:21:08\n",
      "Accuracy: 0.9881 - Precision: 0.9038 - Recall: 0.4769 - Specificity: 0.9989 - F1: 0.6015 - Loss: 0.0028\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 19:21:16\n",
      "Accuracy: 0.9881 - Precision: 0.9036 - Recall: 0.4776 - Specificity: 0.9989 - F1: 0.6021 - Loss: 0.0028\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 19:21:24\n",
      "Accuracy: 0.9882 - Precision: 0.9042 - Recall: 0.4784 - Specificity: 0.9989 - F1: 0.6031 - Loss: 0.0028\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 19:21:32\n",
      "Accuracy: 0.9882 - Precision: 0.9046 - Recall: 0.4785 - Specificity: 0.9989 - F1: 0.6035 - Loss: 0.0028\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 19:21:40\n",
      "Accuracy: 0.9882 - Precision: 0.9049 - Recall: 0.4785 - Specificity: 0.9989 - F1: 0.6037 - Loss: 0.0028\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 19:21:48\n",
      "Accuracy: 0.9882 - Precision: 0.9050 - Recall: 0.4789 - Specificity: 0.9989 - F1: 0.6042 - Loss: 0.0028\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 19:21:56\n",
      "Accuracy: 0.9882 - Precision: 0.9053 - Recall: 0.4792 - Specificity: 0.9989 - F1: 0.6047 - Loss: 0.0028\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 19:22:04\n",
      "Accuracy: 0.9882 - Precision: 0.9056 - Recall: 0.4804 - Specificity: 0.9989 - F1: 0.6059 - Loss: 0.0028\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 19:22:12\n",
      "Accuracy: 0.9882 - Precision: 0.9057 - Recall: 0.4819 - Specificity: 0.9989 - F1: 0.6072 - Loss: 0.0028\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 19:22:21\n",
      "Accuracy: 0.9883 - Precision: 0.9050 - Recall: 0.4838 - Specificity: 0.9989 - F1: 0.6085 - Loss: 0.0028\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 19:22:30\n",
      "Accuracy: 0.9883 - Precision: 0.9052 - Recall: 0.4851 - Specificity: 0.9989 - F1: 0.6097 - Loss: 0.0028\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 19:22:38\n",
      "Accuracy: 0.9883 - Precision: 0.9051 - Recall: 0.4863 - Specificity: 0.9989 - F1: 0.6107 - Loss: 0.0028\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 19:22:46\n",
      "Accuracy: 0.9883 - Precision: 0.9055 - Recall: 0.4868 - Specificity: 0.9989 - F1: 0.6114 - Loss: 0.0028\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 19:22:54\n",
      "Accuracy: 0.9883 - Precision: 0.9061 - Recall: 0.4878 - Specificity: 0.9989 - F1: 0.6125 - Loss: 0.0028\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 19:23:02\n",
      "Accuracy: 0.9884 - Precision: 0.9064 - Recall: 0.4885 - Specificity: 0.9989 - F1: 0.6133 - Loss: 0.0028\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 19:23:10\n",
      "Accuracy: 0.9884 - Precision: 0.9069 - Recall: 0.4884 - Specificity: 0.9989 - F1: 0.6134 - Loss: 0.0028\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 19:23:18\n",
      "Accuracy: 0.9884 - Precision: 0.9069 - Recall: 0.4885 - Specificity: 0.9989 - F1: 0.6137 - Loss: 0.0028\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 19:23:26\n",
      "Accuracy: 0.9884 - Precision: 0.9068 - Recall: 0.4891 - Specificity: 0.9989 - F1: 0.6143 - Loss: 0.0028\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 19:23:34\n",
      "Accuracy: 0.9884 - Precision: 0.9071 - Recall: 0.4899 - Specificity: 0.9989 - F1: 0.6152 - Loss: 0.0028\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 19:23:42\n",
      "Accuracy: 0.9884 - Precision: 0.9067 - Recall: 0.4913 - Specificity: 0.9989 - F1: 0.6162 - Loss: 0.0028\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 19:23:50\n",
      "Accuracy: 0.9884 - Precision: 0.9068 - Recall: 0.4924 - Specificity: 0.9989 - F1: 0.6172 - Loss: 0.0028\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 19:23:58\n",
      "Accuracy: 0.9885 - Precision: 0.9067 - Recall: 0.4940 - Specificity: 0.9989 - F1: 0.6184 - Loss: 0.0028\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 19:24:06\n",
      "Accuracy: 0.9884 - Precision: 0.9050 - Recall: 0.4925 - Specificity: 0.9989 - F1: 0.6169 - Loss: 0.0028\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 19:24:14\n",
      "Accuracy: 0.9885 - Precision: 0.9051 - Recall: 0.4930 - Specificity: 0.9989 - F1: 0.6175 - Loss: 0.0028\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 19:24:23\n",
      "Accuracy: 0.9884 - Precision: 0.9052 - Recall: 0.4925 - Specificity: 0.9989 - F1: 0.6172 - Loss: 0.0028\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 19:24:32\n",
      "Accuracy: 0.9884 - Precision: 0.9053 - Recall: 0.4922 - Specificity: 0.9989 - F1: 0.6171 - Loss: 0.0028\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 19:24:40\n",
      "Accuracy: 0.9884 - Precision: 0.9058 - Recall: 0.4920 - Specificity: 0.9989 - F1: 0.6172 - Loss: 0.0028\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 19:24:48\n",
      "Accuracy: 0.9884 - Precision: 0.9063 - Recall: 0.4920 - Specificity: 0.9989 - F1: 0.6174 - Loss: 0.0028\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 19:24:56\n",
      "Accuracy: 0.9884 - Precision: 0.9068 - Recall: 0.4921 - Specificity: 0.9989 - F1: 0.6177 - Loss: 0.0028\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 19:25:04\n",
      "Accuracy: 0.9884 - Precision: 0.9072 - Recall: 0.4925 - Specificity: 0.9989 - F1: 0.6183 - Loss: 0.0028\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 19:25:12\n",
      "Accuracy: 0.9884 - Precision: 0.9073 - Recall: 0.4937 - Specificity: 0.9989 - F1: 0.6194 - Loss: 0.0028\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 19:25:21\n",
      "Accuracy: 0.9885 - Precision: 0.9071 - Recall: 0.4951 - Specificity: 0.9989 - F1: 0.6204 - Loss: 0.0028\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 19:25:29\n",
      "Accuracy: 0.9885 - Precision: 0.9074 - Recall: 0.4963 - Specificity: 0.9989 - F1: 0.6215 - Loss: 0.0028\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 19:25:37\n",
      "Accuracy: 0.9885 - Precision: 0.9074 - Recall: 0.4974 - Specificity: 0.9989 - F1: 0.6224 - Loss: 0.0028\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 19:25:45\n",
      "Accuracy: 0.9886 - Precision: 0.9076 - Recall: 0.4979 - Specificity: 0.9989 - F1: 0.6230 - Loss: 0.0028\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 19:25:53\n",
      "Accuracy: 0.9886 - Precision: 0.9078 - Recall: 0.4988 - Specificity: 0.9989 - F1: 0.6240 - Loss: 0.0028\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 19:26:01\n",
      "Accuracy: 0.9886 - Precision: 0.9074 - Recall: 0.4997 - Specificity: 0.9989 - F1: 0.6246 - Loss: 0.0028\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 19:26:09\n",
      "Accuracy: 0.9886 - Precision: 0.9076 - Recall: 0.5001 - Specificity: 0.9989 - F1: 0.6251 - Loss: 0.0027\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 19:26:18\n",
      "Accuracy: 0.9886 - Precision: 0.9079 - Recall: 0.5006 - Specificity: 0.9989 - F1: 0.6257 - Loss: 0.0027\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 19:26:27\n",
      "Accuracy: 0.9886 - Precision: 0.9077 - Recall: 0.5008 - Specificity: 0.9989 - F1: 0.6259 - Loss: 0.0027\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 19:26:36\n",
      "Accuracy: 0.9886 - Precision: 0.9082 - Recall: 0.5008 - Specificity: 0.9989 - F1: 0.6261 - Loss: 0.0027\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 19:26:44\n",
      "Accuracy: 0.9886 - Precision: 0.9086 - Recall: 0.5006 - Specificity: 0.9989 - F1: 0.6262 - Loss: 0.0027\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 19:26:52\n",
      "Accuracy: 0.9886 - Precision: 0.9088 - Recall: 0.5008 - Specificity: 0.9989 - F1: 0.6265 - Loss: 0.0027\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 19:27:00\n",
      "Accuracy: 0.9887 - Precision: 0.9088 - Recall: 0.5015 - Specificity: 0.9989 - F1: 0.6272 - Loss: 0.0027\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 19:27:08\n",
      "Accuracy: 0.9887 - Precision: 0.9089 - Recall: 0.5021 - Specificity: 0.9989 - F1: 0.6277 - Loss: 0.0027\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 19:27:16\n",
      "Accuracy: 0.9887 - Precision: 0.9088 - Recall: 0.5027 - Specificity: 0.9989 - F1: 0.6283 - Loss: 0.0027\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 19:27:24\n",
      "Accuracy: 0.9887 - Precision: 0.9088 - Recall: 0.5033 - Specificity: 0.9989 - F1: 0.6289 - Loss: 0.0027\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 19:27:31\n",
      "Accuracy: 0.9887 - Precision: 0.9090 - Recall: 0.5040 - Specificity: 0.9989 - F1: 0.6296 - Loss: 0.0027\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 19:27:39\n",
      "Accuracy: 0.9887 - Precision: 0.9087 - Recall: 0.5045 - Specificity: 0.9989 - F1: 0.6300 - Loss: 0.0027\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 19:27:47\n",
      "Accuracy: 0.9887 - Precision: 0.9090 - Recall: 0.5054 - Specificity: 0.9989 - F1: 0.6308 - Loss: 0.0027\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 19:27:55\n",
      "Accuracy: 0.9887 - Precision: 0.9091 - Recall: 0.5062 - Specificity: 0.9989 - F1: 0.6316 - Loss: 0.0027\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 19:28:03\n",
      "Accuracy: 0.9888 - Precision: 0.9091 - Recall: 0.5068 - Specificity: 0.9989 - F1: 0.6322 - Loss: 0.0027\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 19:28:12\n",
      "Accuracy: 0.9888 - Precision: 0.9088 - Recall: 0.5073 - Specificity: 0.9989 - F1: 0.6325 - Loss: 0.0027\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 19:28:20\n",
      "Accuracy: 0.9888 - Precision: 0.9092 - Recall: 0.5074 - Specificity: 0.9989 - F1: 0.6328 - Loss: 0.0027\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 19:28:29\n",
      "Accuracy: 0.9888 - Precision: 0.9096 - Recall: 0.5070 - Specificity: 0.9989 - F1: 0.6327 - Loss: 0.0027\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 19:28:37\n",
      "Accuracy: 0.9888 - Precision: 0.9100 - Recall: 0.5068 - Specificity: 0.9989 - F1: 0.6327 - Loss: 0.0027\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 19:28:46\n",
      "Accuracy: 0.9888 - Precision: 0.9103 - Recall: 0.5066 - Specificity: 0.9989 - F1: 0.6327 - Loss: 0.0027\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 19:28:53\n",
      "Accuracy: 0.9888 - Precision: 0.9103 - Recall: 0.5067 - Specificity: 0.9989 - F1: 0.6329 - Loss: 0.0027\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 19:29:02\n",
      "Accuracy: 0.9888 - Precision: 0.9103 - Recall: 0.5077 - Specificity: 0.9989 - F1: 0.6337 - Loss: 0.0027\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 19:29:10\n",
      "Accuracy: 0.9888 - Precision: 0.9100 - Recall: 0.5082 - Specificity: 0.9989 - F1: 0.6341 - Loss: 0.0027\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 19:29:18\n",
      "Accuracy: 0.9888 - Precision: 0.9100 - Recall: 0.5090 - Specificity: 0.9989 - F1: 0.6348 - Loss: 0.0027\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 19:29:26\n",
      "Accuracy: 0.9888 - Precision: 0.9099 - Recall: 0.5101 - Specificity: 0.9989 - F1: 0.6356 - Loss: 0.0027\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 19:29:33\n",
      "Accuracy: 0.9889 - Precision: 0.9098 - Recall: 0.5112 - Specificity: 0.9989 - F1: 0.6365 - Loss: 0.0027\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 19:29:41\n",
      "Accuracy: 0.9889 - Precision: 0.9100 - Recall: 0.5119 - Specificity: 0.9989 - F1: 0.6372 - Loss: 0.0027\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 19:29:49\n",
      "Accuracy: 0.9889 - Precision: 0.9103 - Recall: 0.5123 - Specificity: 0.9989 - F1: 0.6377 - Loss: 0.0027\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 19:29:57\n",
      "Accuracy: 0.9889 - Precision: 0.9104 - Recall: 0.5125 - Specificity: 0.9989 - F1: 0.6380 - Loss: 0.0027\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 19:30:05\n",
      "Accuracy: 0.9889 - Precision: 0.9097 - Recall: 0.5130 - Specificity: 0.9989 - F1: 0.6382 - Loss: 0.0027\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 19:30:13\n",
      "Accuracy: 0.9889 - Precision: 0.9100 - Recall: 0.5133 - Specificity: 0.9989 - F1: 0.6386 - Loss: 0.0027\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 19:30:21\n",
      "Accuracy: 0.9889 - Precision: 0.9104 - Recall: 0.5132 - Specificity: 0.9989 - F1: 0.6387 - Loss: 0.0027\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 19:30:30\n",
      "Accuracy: 0.9889 - Precision: 0.9106 - Recall: 0.5138 - Specificity: 0.9989 - F1: 0.6393 - Loss: 0.0027\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 19:30:39\n",
      "Accuracy: 0.9889 - Precision: 0.9104 - Recall: 0.5139 - Specificity: 0.9989 - F1: 0.6394 - Loss: 0.0027\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 19:30:47\n",
      "Accuracy: 0.9889 - Precision: 0.9105 - Recall: 0.5143 - Specificity: 0.9989 - F1: 0.6399 - Loss: 0.0027\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 19:30:55\n",
      "Accuracy: 0.9890 - Precision: 0.9107 - Recall: 0.5149 - Specificity: 0.9989 - F1: 0.6404 - Loss: 0.0027\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 19:31:02\n",
      "Accuracy: 0.9890 - Precision: 0.9109 - Recall: 0.5156 - Specificity: 0.9989 - F1: 0.6411 - Loss: 0.0027\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 19:31:10\n",
      "Accuracy: 0.9890 - Precision: 0.9110 - Recall: 0.5164 - Specificity: 0.9989 - F1: 0.6419 - Loss: 0.0027\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 19:31:18\n",
      "Accuracy: 0.9890 - Precision: 0.9110 - Recall: 0.5177 - Specificity: 0.9989 - F1: 0.6428 - Loss: 0.0027\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 19:31:26\n",
      "Accuracy: 0.9891 - Precision: 0.9111 - Recall: 0.5189 - Specificity: 0.9989 - F1: 0.6438 - Loss: 0.0026\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 19:31:34\n",
      "Accuracy: 0.9891 - Precision: 0.9107 - Recall: 0.5198 - Specificity: 0.9989 - F1: 0.6443 - Loss: 0.0026\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 19:31:42\n",
      "Accuracy: 0.9891 - Precision: 0.9106 - Recall: 0.5206 - Specificity: 0.9989 - F1: 0.6450 - Loss: 0.0026\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 19:31:50\n",
      "Accuracy: 0.9891 - Precision: 0.9109 - Recall: 0.5212 - Specificity: 0.9989 - F1: 0.6456 - Loss: 0.0026\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 19:31:58\n",
      "Accuracy: 0.9891 - Precision: 0.9108 - Recall: 0.5216 - Specificity: 0.9989 - F1: 0.6459 - Loss: 0.0026\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 19:32:06\n",
      "Accuracy: 0.9891 - Precision: 0.9110 - Recall: 0.5220 - Specificity: 0.9989 - F1: 0.6464 - Loss: 0.0026\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 19:32:14\n",
      "Accuracy: 0.9892 - Precision: 0.9113 - Recall: 0.5224 - Specificity: 0.9989 - F1: 0.6469 - Loss: 0.0026\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 19:32:22\n",
      "Accuracy: 0.9892 - Precision: 0.9112 - Recall: 0.5230 - Specificity: 0.9989 - F1: 0.6474 - Loss: 0.0026\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 19:32:31\n",
      "Accuracy: 0.9892 - Precision: 0.9114 - Recall: 0.5236 - Specificity: 0.9989 - F1: 0.6480 - Loss: 0.0026\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 19:32:39\n",
      "Accuracy: 0.9892 - Precision: 0.9115 - Recall: 0.5244 - Specificity: 0.9989 - F1: 0.6487 - Loss: 0.0026\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 19:32:47\n",
      "Accuracy: 0.9892 - Precision: 0.9112 - Recall: 0.5247 - Specificity: 0.9989 - F1: 0.6489 - Loss: 0.0026\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 19:32:55\n",
      "Accuracy: 0.9892 - Precision: 0.9108 - Recall: 0.5241 - Specificity: 0.9989 - F1: 0.6484 - Loss: 0.0026\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 19:33:03\n",
      "Accuracy: 0.9891 - Precision: 0.9103 - Recall: 0.5238 - Specificity: 0.9989 - F1: 0.6480 - Loss: 0.0026\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 19:33:11\n",
      "Accuracy: 0.9891 - Precision: 0.9099 - Recall: 0.5230 - Specificity: 0.9989 - F1: 0.6474 - Loss: 0.0026\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 19:33:19\n",
      "Accuracy: 0.9891 - Precision: 0.9100 - Recall: 0.5224 - Specificity: 0.9989 - F1: 0.6470 - Loss: 0.0026\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 19:33:27\n",
      "Accuracy: 0.9891 - Precision: 0.9101 - Recall: 0.5220 - Specificity: 0.9989 - F1: 0.6467 - Loss: 0.0026\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 19:33:34\n",
      "Accuracy: 0.9890 - Precision: 0.9103 - Recall: 0.5211 - Specificity: 0.9989 - F1: 0.6459 - Loss: 0.0026\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 19:33:42\n",
      "Accuracy: 0.9890 - Precision: 0.9099 - Recall: 0.5196 - Specificity: 0.9989 - F1: 0.6445 - Loss: 0.0027\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 19:33:50\n",
      "Accuracy: 0.9890 - Precision: 0.9102 - Recall: 0.5192 - Specificity: 0.9989 - F1: 0.6443 - Loss: 0.0027\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 19:33:59\n",
      "Accuracy: 0.9889 - Precision: 0.9099 - Recall: 0.5182 - Specificity: 0.9989 - F1: 0.6434 - Loss: 0.0027\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 19:34:06\n",
      "Accuracy: 0.9889 - Precision: 0.9097 - Recall: 0.5176 - Specificity: 0.9989 - F1: 0.6428 - Loss: 0.0027\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 19:34:14\n",
      "Accuracy: 0.9889 - Precision: 0.9099 - Recall: 0.5173 - Specificity: 0.9989 - F1: 0.6427 - Loss: 0.0027\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 19:34:23\n",
      "Accuracy: 0.9889 - Precision: 0.9101 - Recall: 0.5164 - Specificity: 0.9989 - F1: 0.6420 - Loss: 0.0027\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 19:34:32\n",
      "Accuracy: 0.9888 - Precision: 0.9104 - Recall: 0.5151 - Specificity: 0.9989 - F1: 0.6407 - Loss: 0.0027\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 19:34:41\n",
      "Accuracy: 0.9888 - Precision: 0.9106 - Recall: 0.5144 - Specificity: 0.9989 - F1: 0.6401 - Loss: 0.0027\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 19:34:49\n",
      "Accuracy: 0.9888 - Precision: 0.9108 - Recall: 0.5141 - Specificity: 0.9989 - F1: 0.6400 - Loss: 0.0027\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 19:34:57\n",
      "Accuracy: 0.9888 - Precision: 0.9110 - Recall: 0.5133 - Specificity: 0.9989 - F1: 0.6393 - Loss: 0.0027\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 19:35:05\n",
      "Accuracy: 0.9888 - Precision: 0.9108 - Recall: 0.5130 - Specificity: 0.9989 - F1: 0.6391 - Loss: 0.0027\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 19:35:13\n",
      "Accuracy: 0.9888 - Precision: 0.9105 - Recall: 0.5132 - Specificity: 0.9989 - F1: 0.6392 - Loss: 0.0027\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 19:35:20\n",
      "Accuracy: 0.9888 - Precision: 0.9099 - Recall: 0.5132 - Specificity: 0.9989 - F1: 0.6392 - Loss: 0.0027\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 19:35:28\n",
      "Accuracy: 0.9887 - Precision: 0.9095 - Recall: 0.5126 - Specificity: 0.9989 - F1: 0.6386 - Loss: 0.0027\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 19:35:36\n",
      "Accuracy: 0.9887 - Precision: 0.9096 - Recall: 0.5120 - Specificity: 0.9989 - F1: 0.6381 - Loss: 0.0027\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 19:35:44\n",
      "Accuracy: 0.9886 - Precision: 0.9097 - Recall: 0.5109 - Specificity: 0.9989 - F1: 0.6372 - Loss: 0.0027\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 19:35:52\n",
      "Accuracy: 0.9886 - Precision: 0.9099 - Recall: 0.5101 - Specificity: 0.9989 - F1: 0.6365 - Loss: 0.0028\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 19:36:00\n",
      "Accuracy: 0.9885 - Precision: 0.9101 - Recall: 0.5092 - Specificity: 0.9989 - F1: 0.6357 - Loss: 0.0028\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 19:36:08\n",
      "Accuracy: 0.9885 - Precision: 0.9103 - Recall: 0.5081 - Specificity: 0.9989 - F1: 0.6348 - Loss: 0.0028\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 19:36:16\n",
      "Accuracy: 0.9885 - Precision: 0.9105 - Recall: 0.5077 - Specificity: 0.9989 - F1: 0.6344 - Loss: 0.0028\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 19:36:24\n",
      "Accuracy: 0.9881 - Precision: 0.9100 - Recall: 0.5058 - Specificity: 0.9989 - F1: 0.6322 - Loss: 0.0029\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 19:36:33\n",
      "Accuracy: 0.9880 - Precision: 0.9099 - Recall: 0.5042 - Specificity: 0.9989 - F1: 0.6305 - Loss: 0.0030\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 19:36:42\n",
      "Accuracy: 0.9877 - Precision: 0.9098 - Recall: 0.5032 - Specificity: 0.9989 - F1: 0.6296 - Loss: 0.0030\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 19:36:50\n",
      "Accuracy: 0.9875 - Precision: 0.9094 - Recall: 0.5027 - Specificity: 0.9989 - F1: 0.6292 - Loss: 0.0031\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 19:36:57\n",
      "Accuracy: 0.9873 - Precision: 0.9087 - Recall: 0.5023 - Specificity: 0.9988 - F1: 0.6287 - Loss: 0.0032\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 19:37:05\n",
      "Accuracy: 0.9871 - Precision: 0.9080 - Recall: 0.5013 - Specificity: 0.9988 - F1: 0.6277 - Loss: 0.0032\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 19:37:13\n",
      "Accuracy: 0.9868 - Precision: 0.9077 - Recall: 0.4994 - Specificity: 0.9988 - F1: 0.6254 - Loss: 0.0033\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 19:37:22\n",
      "Accuracy: 0.9866 - Precision: 0.9073 - Recall: 0.4974 - Specificity: 0.9988 - F1: 0.6230 - Loss: 0.0033\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 19:37:29\n",
      "Accuracy: 0.9862 - Precision: 0.9077 - Recall: 0.4954 - Specificity: 0.9988 - F1: 0.6205 - Loss: 0.0034\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 19:37:37\n",
      "Accuracy: 0.9859 - Precision: 0.9081 - Recall: 0.4935 - Specificity: 0.9988 - F1: 0.6180 - Loss: 0.0034\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 19:37:45\n",
      "Accuracy: 0.9856 - Precision: 0.9084 - Recall: 0.4915 - Specificity: 0.9988 - F1: 0.6155 - Loss: 0.0035\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 19:37:53\n",
      "Accuracy: 0.9855 - Precision: 0.9083 - Recall: 0.4895 - Specificity: 0.9988 - F1: 0.6131 - Loss: 0.0035\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 19:38:01\n",
      "Accuracy: 0.9852 - Precision: 0.9084 - Recall: 0.4876 - Specificity: 0.9988 - F1: 0.6107 - Loss: 0.0036\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 19:38:09\n",
      "Accuracy: 0.9850 - Precision: 0.9082 - Recall: 0.4857 - Specificity: 0.9988 - F1: 0.6083 - Loss: 0.0036\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 19:38:17\n",
      "Accuracy: 0.9847 - Precision: 0.9079 - Recall: 0.4838 - Specificity: 0.9988 - F1: 0.6059 - Loss: 0.0037\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 19:38:24\n",
      "Accuracy: 0.9844 - Precision: 0.9083 - Recall: 0.4819 - Specificity: 0.9988 - F1: 0.6036 - Loss: 0.0037\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 19:38:34\n",
      "Accuracy: 0.9841 - Precision: 0.9087 - Recall: 0.4800 - Specificity: 0.9988 - F1: 0.6012 - Loss: 0.0038\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 19:38:42\n",
      "Accuracy: 0.9840 - Precision: 0.9090 - Recall: 0.4782 - Specificity: 0.9988 - F1: 0.5989 - Loss: 0.0038\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 19:38:50\n",
      "Accuracy: 0.9839 - Precision: 0.9093 - Recall: 0.4763 - Specificity: 0.9989 - F1: 0.5966 - Loss: 0.0039\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 19:38:58\n",
      "Accuracy: 0.9839 - Precision: 0.9097 - Recall: 0.4745 - Specificity: 0.9989 - F1: 0.5943 - Loss: 0.0039\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 19:39:07\n",
      "Accuracy: 0.9839 - Precision: 0.9099 - Recall: 0.4727 - Specificity: 0.9989 - F1: 0.5922 - Loss: 0.0039\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 19:39:15\n",
      "Accuracy: 0.9838 - Precision: 0.9103 - Recall: 0.4709 - Specificity: 0.9989 - F1: 0.5899 - Loss: 0.0039\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 19:39:23\n",
      "Accuracy: 0.9837 - Precision: 0.9105 - Recall: 0.4692 - Specificity: 0.9989 - F1: 0.5878 - Loss: 0.0040\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 19:39:31\n",
      "Accuracy: 0.9836 - Precision: 0.9105 - Recall: 0.4675 - Specificity: 0.9989 - F1: 0.5856 - Loss: 0.0040\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 19:39:39\n",
      "Accuracy: 0.9836 - Precision: 0.9106 - Recall: 0.4657 - Specificity: 0.9989 - F1: 0.5835 - Loss: 0.0040\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 19:39:46\n",
      "Accuracy: 0.9835 - Precision: 0.9092 - Recall: 0.4640 - Specificity: 0.9989 - F1: 0.5814 - Loss: 0.0040\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 19:39:54\n",
      "Accuracy: 0.9835 - Precision: 0.9092 - Recall: 0.4623 - Specificity: 0.9989 - F1: 0.5793 - Loss: 0.0041\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 19:40:02\n",
      "Accuracy: 0.9834 - Precision: 0.9094 - Recall: 0.4606 - Specificity: 0.9989 - F1: 0.5772 - Loss: 0.0041\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 19:40:10\n",
      "Accuracy: 0.9834 - Precision: 0.9095 - Recall: 0.4589 - Specificity: 0.9989 - F1: 0.5751 - Loss: 0.0041\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 19:40:18\n",
      "Accuracy: 0.9834 - Precision: 0.9073 - Recall: 0.4572 - Specificity: 0.9989 - F1: 0.5729 - Loss: 0.0041\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 19:40:26\n",
      "Accuracy: 0.9833 - Precision: 0.9070 - Recall: 0.4555 - Specificity: 0.9989 - F1: 0.5709 - Loss: 0.0041\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 19:40:35\n",
      "Accuracy: 0.9833 - Precision: 0.9073 - Recall: 0.4539 - Specificity: 0.9989 - F1: 0.5688 - Loss: 0.0041\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 19:40:44\n",
      "Accuracy: 0.9832 - Precision: 0.9075 - Recall: 0.4522 - Specificity: 0.9989 - F1: 0.5668 - Loss: 0.0041\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 19:40:51\n",
      "Accuracy: 0.9832 - Precision: 0.9074 - Recall: 0.4506 - Specificity: 0.9989 - F1: 0.5647 - Loss: 0.0041\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 19:40:59\n",
      "Accuracy: 0.9832 - Precision: 0.9066 - Recall: 0.4490 - Specificity: 0.9989 - F1: 0.5627 - Loss: 0.0041\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 19:41:07\n",
      "Accuracy: 0.9831 - Precision: 0.9043 - Recall: 0.4474 - Specificity: 0.9989 - F1: 0.5607 - Loss: 0.0042\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 19:41:15\n",
      "Accuracy: 0.9831 - Precision: 0.9043 - Recall: 0.4458 - Specificity: 0.9989 - F1: 0.5587 - Loss: 0.0042\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 19:41:23\n",
      "Accuracy: 0.9831 - Precision: 0.9013 - Recall: 0.4442 - Specificity: 0.9989 - F1: 0.5567 - Loss: 0.0042\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 19:41:31\n",
      "Accuracy: 0.9831 - Precision: 0.8981 - Recall: 0.4426 - Specificity: 0.9989 - F1: 0.5547 - Loss: 0.0042\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 19:41:39\n",
      "Accuracy: 0.9831 - Precision: 0.8984 - Recall: 0.4410 - Specificity: 0.9989 - F1: 0.5527 - Loss: 0.0042\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 19:41:46\n",
      "Accuracy: 0.9830 - Precision: 0.8972 - Recall: 0.4394 - Specificity: 0.9989 - F1: 0.5508 - Loss: 0.0042\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 19:41:54\n",
      "Accuracy: 0.9830 - Precision: 0.8940 - Recall: 0.4379 - Specificity: 0.9989 - F1: 0.5488 - Loss: 0.0042\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 19:42:02\n",
      "Accuracy: 0.9830 - Precision: 0.8931 - Recall: 0.4363 - Specificity: 0.9989 - F1: 0.5469 - Loss: 0.0042\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 19:42:10\n",
      "Accuracy: 0.9830 - Precision: 0.8899 - Recall: 0.4348 - Specificity: 0.9989 - F1: 0.5450 - Loss: 0.0042\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 19:42:18\n",
      "Accuracy: 0.9830 - Precision: 0.8868 - Recall: 0.4333 - Specificity: 0.9990 - F1: 0.5431 - Loss: 0.0042\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 19:42:26\n",
      "Accuracy: 0.9830 - Precision: 0.8865 - Recall: 0.4318 - Specificity: 0.9990 - F1: 0.5412 - Loss: 0.0042\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 19:42:35\n",
      "Accuracy: 0.9830 - Precision: 0.8868 - Recall: 0.4303 - Specificity: 0.9990 - F1: 0.5394 - Loss: 0.0042\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 19:42:44\n",
      "Accuracy: 0.9829 - Precision: 0.8871 - Recall: 0.4288 - Specificity: 0.9990 - F1: 0.5375 - Loss: 0.0042\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 19:42:51\n",
      "Accuracy: 0.9829 - Precision: 0.8875 - Recall: 0.4273 - Specificity: 0.9990 - F1: 0.5357 - Loss: 0.0043\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 19:42:59\n",
      "Accuracy: 0.9828 - Precision: 0.8878 - Recall: 0.4258 - Specificity: 0.9990 - F1: 0.5338 - Loss: 0.0043\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 19:43:07\n",
      "Accuracy: 0.9828 - Precision: 0.8874 - Recall: 0.4244 - Specificity: 0.9990 - F1: 0.5321 - Loss: 0.0043\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 19:43:15\n",
      "Accuracy: 0.9828 - Precision: 0.8874 - Recall: 0.4230 - Specificity: 0.9990 - F1: 0.5303 - Loss: 0.0043\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 19:43:23\n",
      "Accuracy: 0.9828 - Precision: 0.8871 - Recall: 0.4216 - Specificity: 0.9990 - F1: 0.5287 - Loss: 0.0043\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 19:43:31\n",
      "Accuracy: 0.9827 - Precision: 0.8869 - Recall: 0.4205 - Specificity: 0.9990 - F1: 0.5274 - Loss: 0.0043\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 19:43:39\n",
      "Accuracy: 0.9827 - Precision: 0.8870 - Recall: 0.4192 - Specificity: 0.9990 - F1: 0.5259 - Loss: 0.0043\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 19:43:46\n",
      "Accuracy: 0.9827 - Precision: 0.8866 - Recall: 0.4181 - Specificity: 0.9990 - F1: 0.5246 - Loss: 0.0043\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 19:43:54\n",
      "Accuracy: 0.9827 - Precision: 0.8862 - Recall: 0.4172 - Specificity: 0.9990 - F1: 0.5237 - Loss: 0.0043\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 19:44:02\n",
      "Accuracy: 0.9826 - Precision: 0.8863 - Recall: 0.4163 - Specificity: 0.9990 - F1: 0.5228 - Loss: 0.0043\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 19:44:10\n",
      "Accuracy: 0.9826 - Precision: 0.8864 - Recall: 0.4151 - Specificity: 0.9990 - F1: 0.5215 - Loss: 0.0043\n",
      "\n",
      "Epoch 10/20\n",
      "Validation - Accuracy: 0.9801, Precision: 0.9217, Recall: 0.0795, Specificity: 0.9999, F1: 0.1454, Loss: 0.0049\n",
      "\n",
      "\n",
      "Epoch 11/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 19:51:20\n",
      "Accuracy: 0.9763 - Precision: 0.9470 - Recall: 0.1025 - Specificity: 0.9998 - F1: 0.1850 - Loss: 0.0057\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 19:51:28\n",
      "Accuracy: 0.9752 - Precision: 0.9627 - Recall: 0.1115 - Specificity: 0.9999 - F1: 0.1998 - Loss: 0.0058\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 19:51:36\n",
      "Accuracy: 0.9747 - Precision: 0.9698 - Recall: 0.1261 - Specificity: 0.9999 - F1: 0.2226 - Loss: 0.0055\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 19:51:43\n",
      "Accuracy: 0.9774 - Precision: 0.9699 - Recall: 0.1276 - Specificity: 0.9999 - F1: 0.2251 - Loss: 0.0050\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 19:51:51\n",
      "Accuracy: 0.9792 - Precision: 0.9601 - Recall: 0.1372 - Specificity: 0.9999 - F1: 0.2390 - Loss: 0.0047\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 19:51:59\n",
      "Accuracy: 0.9797 - Precision: 0.9641 - Recall: 0.1543 - Specificity: 0.9999 - F1: 0.2634 - Loss: 0.0045\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 19:52:07\n",
      "Accuracy: 0.9811 - Precision: 0.9561 - Recall: 0.1776 - Specificity: 0.9998 - F1: 0.2930 - Loss: 0.0042\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 19:52:15\n",
      "Accuracy: 0.9817 - Precision: 0.9195 - Recall: 0.2055 - Specificity: 0.9994 - F1: 0.3188 - Loss: 0.0042\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 19:52:23\n",
      "Accuracy: 0.9827 - Precision: 0.9228 - Recall: 0.2302 - Specificity: 0.9994 - F1: 0.3489 - Loss: 0.0039\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 19:52:31\n",
      "Accuracy: 0.9831 - Precision: 0.9281 - Recall: 0.2284 - Specificity: 0.9995 - F1: 0.3489 - Loss: 0.0038\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 19:52:41\n",
      "Accuracy: 0.9834 - Precision: 0.9182 - Recall: 0.2354 - Specificity: 0.9994 - F1: 0.3577 - Loss: 0.0038\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 19:52:48\n",
      "Accuracy: 0.9837 - Precision: 0.9246 - Recall: 0.2404 - Specificity: 0.9995 - F1: 0.3659 - Loss: 0.0037\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 19:52:56\n",
      "Accuracy: 0.9839 - Precision: 0.9261 - Recall: 0.2440 - Specificity: 0.9995 - F1: 0.3715 - Loss: 0.0036\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 19:53:04\n",
      "Accuracy: 0.9840 - Precision: 0.9107 - Recall: 0.2423 - Specificity: 0.9994 - F1: 0.3690 - Loss: 0.0036\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 19:53:12\n",
      "Accuracy: 0.9842 - Precision: 0.9146 - Recall: 0.2482 - Specificity: 0.9994 - F1: 0.3773 - Loss: 0.0035\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 19:53:20\n",
      "Accuracy: 0.9840 - Precision: 0.9177 - Recall: 0.2481 - Specificity: 0.9994 - F1: 0.3782 - Loss: 0.0036\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 19:53:27\n",
      "Accuracy: 0.9844 - Precision: 0.9209 - Recall: 0.2604 - Specificity: 0.9995 - F1: 0.3926 - Loss: 0.0035\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 19:53:35\n",
      "Accuracy: 0.9845 - Precision: 0.9230 - Recall: 0.2682 - Specificity: 0.9995 - F1: 0.4022 - Loss: 0.0035\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 19:53:43\n",
      "Accuracy: 0.9848 - Precision: 0.9244 - Recall: 0.2795 - Specificity: 0.9995 - F1: 0.4148 - Loss: 0.0035\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 19:53:51\n",
      "Accuracy: 0.9851 - Precision: 0.9232 - Recall: 0.2933 - Specificity: 0.9994 - F1: 0.4283 - Loss: 0.0034\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 19:53:59\n",
      "Accuracy: 0.9852 - Precision: 0.9182 - Recall: 0.2989 - Specificity: 0.9994 - F1: 0.4340 - Loss: 0.0034\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 19:54:07\n",
      "Accuracy: 0.9848 - Precision: 0.9010 - Recall: 0.2975 - Specificity: 0.9992 - F1: 0.4305 - Loss: 0.0035\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 19:54:15\n",
      "Accuracy: 0.9848 - Precision: 0.9046 - Recall: 0.2987 - Specificity: 0.9992 - F1: 0.4330 - Loss: 0.0035\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 19:54:23\n",
      "Accuracy: 0.9847 - Precision: 0.9071 - Recall: 0.3000 - Specificity: 0.9992 - F1: 0.4355 - Loss: 0.0035\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 19:54:31\n",
      "Accuracy: 0.9848 - Precision: 0.9100 - Recall: 0.3016 - Specificity: 0.9992 - F1: 0.4383 - Loss: 0.0035\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 19:54:40\n",
      "Accuracy: 0.9850 - Precision: 0.9120 - Recall: 0.3065 - Specificity: 0.9993 - F1: 0.4442 - Loss: 0.0034\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 19:54:49\n",
      "Accuracy: 0.9851 - Precision: 0.9144 - Recall: 0.3082 - Specificity: 0.9993 - F1: 0.4470 - Loss: 0.0034\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 19:54:57\n",
      "Accuracy: 0.9850 - Precision: 0.9158 - Recall: 0.3069 - Specificity: 0.9993 - F1: 0.4461 - Loss: 0.0034\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 19:55:05\n",
      "Accuracy: 0.9848 - Precision: 0.9156 - Recall: 0.3067 - Specificity: 0.9993 - F1: 0.4463 - Loss: 0.0035\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 19:55:14\n",
      "Accuracy: 0.9849 - Precision: 0.9166 - Recall: 0.3143 - Specificity: 0.9993 - F1: 0.4542 - Loss: 0.0035\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 19:55:22\n",
      "Accuracy: 0.9852 - Precision: 0.9157 - Recall: 0.3233 - Specificity: 0.9993 - F1: 0.4625 - Loss: 0.0034\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 19:55:30\n",
      "Accuracy: 0.9852 - Precision: 0.9154 - Recall: 0.3268 - Specificity: 0.9993 - F1: 0.4664 - Loss: 0.0034\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 19:55:38\n",
      "Accuracy: 0.9854 - Precision: 0.9158 - Recall: 0.3350 - Specificity: 0.9993 - F1: 0.4744 - Loss: 0.0034\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 19:55:46\n",
      "Accuracy: 0.9854 - Precision: 0.9174 - Recall: 0.3377 - Specificity: 0.9993 - F1: 0.4778 - Loss: 0.0034\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 19:55:54\n",
      "Accuracy: 0.9855 - Precision: 0.9179 - Recall: 0.3412 - Specificity: 0.9993 - F1: 0.4818 - Loss: 0.0034\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 19:56:02\n",
      "Accuracy: 0.9856 - Precision: 0.9178 - Recall: 0.3493 - Specificity: 0.9993 - F1: 0.4892 - Loss: 0.0033\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 19:56:10\n",
      "Accuracy: 0.9858 - Precision: 0.9175 - Recall: 0.3589 - Specificity: 0.9992 - F1: 0.4974 - Loss: 0.0033\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 19:56:18\n",
      "Accuracy: 0.9859 - Precision: 0.9157 - Recall: 0.3654 - Specificity: 0.9992 - F1: 0.5029 - Loss: 0.0033\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 19:56:26\n",
      "Accuracy: 0.9860 - Precision: 0.9160 - Recall: 0.3722 - Specificity: 0.9992 - F1: 0.5092 - Loss: 0.0033\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 19:56:34\n",
      "Accuracy: 0.9861 - Precision: 0.9161 - Recall: 0.3790 - Specificity: 0.9992 - F1: 0.5155 - Loss: 0.0033\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 19:56:44\n",
      "Accuracy: 0.9860 - Precision: 0.9161 - Recall: 0.3811 - Specificity: 0.9992 - F1: 0.5179 - Loss: 0.0033\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 19:56:51\n",
      "Accuracy: 0.9861 - Precision: 0.9170 - Recall: 0.3862 - Specificity: 0.9992 - F1: 0.5231 - Loss: 0.0033\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 19:56:59\n",
      "Accuracy: 0.9863 - Precision: 0.9176 - Recall: 0.3915 - Specificity: 0.9992 - F1: 0.5283 - Loss: 0.0032\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 19:57:07\n",
      "Accuracy: 0.9864 - Precision: 0.9177 - Recall: 0.3975 - Specificity: 0.9992 - F1: 0.5336 - Loss: 0.0032\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 19:57:15\n",
      "Accuracy: 0.9865 - Precision: 0.9128 - Recall: 0.4035 - Specificity: 0.9991 - F1: 0.5369 - Loss: 0.0032\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 19:57:23\n",
      "Accuracy: 0.9865 - Precision: 0.9139 - Recall: 0.4059 - Specificity: 0.9991 - F1: 0.5398 - Loss: 0.0032\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 19:57:31\n",
      "Accuracy: 0.9865 - Precision: 0.9146 - Recall: 0.4063 - Specificity: 0.9991 - F1: 0.5408 - Loss: 0.0032\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 19:57:39\n",
      "Accuracy: 0.9864 - Precision: 0.9160 - Recall: 0.4057 - Specificity: 0.9991 - F1: 0.5409 - Loss: 0.0032\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 19:57:47\n",
      "Accuracy: 0.9865 - Precision: 0.9168 - Recall: 0.4055 - Specificity: 0.9991 - F1: 0.5412 - Loss: 0.0032\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 19:57:55\n",
      "Accuracy: 0.9864 - Precision: 0.9183 - Recall: 0.4052 - Specificity: 0.9991 - F1: 0.5417 - Loss: 0.0032\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 19:58:02\n",
      "Accuracy: 0.9864 - Precision: 0.9188 - Recall: 0.4049 - Specificity: 0.9991 - F1: 0.5419 - Loss: 0.0032\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 19:58:10\n",
      "Accuracy: 0.9864 - Precision: 0.9187 - Recall: 0.4046 - Specificity: 0.9991 - F1: 0.5419 - Loss: 0.0032\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 19:58:18\n",
      "Accuracy: 0.9865 - Precision: 0.9194 - Recall: 0.4062 - Specificity: 0.9991 - F1: 0.5439 - Loss: 0.0032\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 19:58:26\n",
      "Accuracy: 0.9866 - Precision: 0.9201 - Recall: 0.4092 - Specificity: 0.9992 - F1: 0.5470 - Loss: 0.0031\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 19:58:35\n",
      "Accuracy: 0.9866 - Precision: 0.9205 - Recall: 0.4120 - Specificity: 0.9992 - F1: 0.5499 - Loss: 0.0031\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 19:58:44\n",
      "Accuracy: 0.9867 - Precision: 0.9200 - Recall: 0.4169 - Specificity: 0.9991 - F1: 0.5540 - Loss: 0.0031\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 19:58:52\n",
      "Accuracy: 0.9868 - Precision: 0.9196 - Recall: 0.4207 - Specificity: 0.9991 - F1: 0.5572 - Loss: 0.0031\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 19:59:00\n",
      "Accuracy: 0.9869 - Precision: 0.9191 - Recall: 0.4251 - Specificity: 0.9991 - F1: 0.5609 - Loss: 0.0031\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 19:59:08\n",
      "Accuracy: 0.9870 - Precision: 0.9196 - Recall: 0.4290 - Specificity: 0.9991 - F1: 0.5645 - Loss: 0.0031\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 19:59:16\n",
      "Accuracy: 0.9871 - Precision: 0.9181 - Recall: 0.4318 - Specificity: 0.9991 - F1: 0.5667 - Loss: 0.0031\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 19:59:24\n",
      "Accuracy: 0.9871 - Precision: 0.9174 - Recall: 0.4344 - Specificity: 0.9991 - F1: 0.5690 - Loss: 0.0031\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 19:59:32\n",
      "Accuracy: 0.9872 - Precision: 0.9179 - Recall: 0.4379 - Specificity: 0.9991 - F1: 0.5722 - Loss: 0.0030\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 19:59:40\n",
      "Accuracy: 0.9873 - Precision: 0.9185 - Recall: 0.4414 - Specificity: 0.9991 - F1: 0.5755 - Loss: 0.0030\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 19:59:48\n",
      "Accuracy: 0.9874 - Precision: 0.9184 - Recall: 0.4455 - Specificity: 0.9991 - F1: 0.5789 - Loss: 0.0030\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 19:59:56\n",
      "Accuracy: 0.9874 - Precision: 0.9185 - Recall: 0.4484 - Specificity: 0.9991 - F1: 0.5816 - Loss: 0.0030\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 20:00:04\n",
      "Accuracy: 0.9874 - Precision: 0.9179 - Recall: 0.4503 - Specificity: 0.9991 - F1: 0.5833 - Loss: 0.0030\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 20:00:11\n",
      "Accuracy: 0.9874 - Precision: 0.9172 - Recall: 0.4525 - Specificity: 0.9990 - F1: 0.5852 - Loss: 0.0030\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 20:00:19\n",
      "Accuracy: 0.9875 - Precision: 0.9168 - Recall: 0.4547 - Specificity: 0.9990 - F1: 0.5872 - Loss: 0.0030\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 20:00:27\n",
      "Accuracy: 0.9875 - Precision: 0.9169 - Recall: 0.4583 - Specificity: 0.9990 - F1: 0.5902 - Loss: 0.0030\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 20:00:36\n",
      "Accuracy: 0.9876 - Precision: 0.9170 - Recall: 0.4618 - Specificity: 0.9990 - F1: 0.5932 - Loss: 0.0030\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 20:00:45\n",
      "Accuracy: 0.9877 - Precision: 0.9156 - Recall: 0.4645 - Specificity: 0.9990 - F1: 0.5951 - Loss: 0.0030\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 20:00:53\n",
      "Accuracy: 0.9877 - Precision: 0.9142 - Recall: 0.4664 - Specificity: 0.9990 - F1: 0.5964 - Loss: 0.0030\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 20:01:01\n",
      "Accuracy: 0.9877 - Precision: 0.9149 - Recall: 0.4676 - Specificity: 0.9990 - F1: 0.5978 - Loss: 0.0030\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 20:01:10\n",
      "Accuracy: 0.9877 - Precision: 0.9156 - Recall: 0.4678 - Specificity: 0.9990 - F1: 0.5986 - Loss: 0.0030\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 20:01:18\n",
      "Accuracy: 0.9877 - Precision: 0.9157 - Recall: 0.4681 - Specificity: 0.9990 - F1: 0.5991 - Loss: 0.0030\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 20:01:26\n",
      "Accuracy: 0.9877 - Precision: 0.9165 - Recall: 0.4686 - Specificity: 0.9990 - F1: 0.5999 - Loss: 0.0030\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 20:01:33\n",
      "Accuracy: 0.9877 - Precision: 0.9164 - Recall: 0.4698 - Specificity: 0.9990 - F1: 0.6012 - Loss: 0.0029\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 20:01:41\n",
      "Accuracy: 0.9877 - Precision: 0.9172 - Recall: 0.4711 - Specificity: 0.9990 - F1: 0.6027 - Loss: 0.0029\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 20:01:49\n",
      "Accuracy: 0.9877 - Precision: 0.9172 - Recall: 0.4728 - Specificity: 0.9990 - F1: 0.6043 - Loss: 0.0029\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 20:01:57\n",
      "Accuracy: 0.9878 - Precision: 0.9176 - Recall: 0.4752 - Specificity: 0.9990 - F1: 0.6065 - Loss: 0.0029\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 20:02:05\n",
      "Accuracy: 0.9878 - Precision: 0.9171 - Recall: 0.4777 - Specificity: 0.9990 - F1: 0.6085 - Loss: 0.0029\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 20:02:14\n",
      "Accuracy: 0.9879 - Precision: 0.9157 - Recall: 0.4792 - Specificity: 0.9990 - F1: 0.6094 - Loss: 0.0029\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 20:02:22\n",
      "Accuracy: 0.9879 - Precision: 0.9154 - Recall: 0.4808 - Specificity: 0.9990 - F1: 0.6109 - Loss: 0.0029\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 20:02:30\n",
      "Accuracy: 0.9879 - Precision: 0.9150 - Recall: 0.4820 - Specificity: 0.9990 - F1: 0.6119 - Loss: 0.0029\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 20:02:39\n",
      "Accuracy: 0.9880 - Precision: 0.9155 - Recall: 0.4842 - Specificity: 0.9990 - F1: 0.6140 - Loss: 0.0029\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 20:02:48\n",
      "Accuracy: 0.9880 - Precision: 0.9153 - Recall: 0.4845 - Specificity: 0.9990 - F1: 0.6144 - Loss: 0.0029\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 20:02:56\n",
      "Accuracy: 0.9880 - Precision: 0.9160 - Recall: 0.4860 - Specificity: 0.9990 - F1: 0.6160 - Loss: 0.0029\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 20:03:04\n",
      "Accuracy: 0.9881 - Precision: 0.9160 - Recall: 0.4871 - Specificity: 0.9990 - F1: 0.6171 - Loss: 0.0029\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 20:03:12\n",
      "Accuracy: 0.9881 - Precision: 0.9166 - Recall: 0.4879 - Specificity: 0.9990 - F1: 0.6181 - Loss: 0.0029\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 20:03:20\n",
      "Accuracy: 0.9881 - Precision: 0.9171 - Recall: 0.4887 - Specificity: 0.9990 - F1: 0.6191 - Loss: 0.0029\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 20:03:28\n",
      "Accuracy: 0.9881 - Precision: 0.9173 - Recall: 0.4907 - Specificity: 0.9990 - F1: 0.6209 - Loss: 0.0029\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 20:03:36\n",
      "Accuracy: 0.9882 - Precision: 0.9164 - Recall: 0.4933 - Specificity: 0.9990 - F1: 0.6226 - Loss: 0.0029\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 20:03:44\n",
      "Accuracy: 0.9882 - Precision: 0.9159 - Recall: 0.4957 - Specificity: 0.9990 - F1: 0.6244 - Loss: 0.0029\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 20:03:52\n",
      "Accuracy: 0.9883 - Precision: 0.9158 - Recall: 0.4978 - Specificity: 0.9989 - F1: 0.6261 - Loss: 0.0028\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 20:04:00\n",
      "Accuracy: 0.9883 - Precision: 0.9143 - Recall: 0.4996 - Specificity: 0.9989 - F1: 0.6271 - Loss: 0.0029\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 20:04:08\n",
      "Accuracy: 0.9883 - Precision: 0.9141 - Recall: 0.5003 - Specificity: 0.9989 - F1: 0.6277 - Loss: 0.0028\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 20:04:16\n",
      "Accuracy: 0.9883 - Precision: 0.9148 - Recall: 0.5003 - Specificity: 0.9989 - F1: 0.6281 - Loss: 0.0028\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 20:04:24\n",
      "Accuracy: 0.9883 - Precision: 0.9147 - Recall: 0.5006 - Specificity: 0.9989 - F1: 0.6286 - Loss: 0.0028\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 20:04:32\n",
      "Accuracy: 0.9883 - Precision: 0.9145 - Recall: 0.4998 - Specificity: 0.9989 - F1: 0.6280 - Loss: 0.0028\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 20:04:41\n",
      "Accuracy: 0.9883 - Precision: 0.9143 - Recall: 0.4995 - Specificity: 0.9989 - F1: 0.6278 - Loss: 0.0028\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 20:04:50\n",
      "Accuracy: 0.9883 - Precision: 0.9139 - Recall: 0.4982 - Specificity: 0.9989 - F1: 0.6268 - Loss: 0.0028\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 20:04:58\n",
      "Accuracy: 0.9883 - Precision: 0.9117 - Recall: 0.4965 - Specificity: 0.9989 - F1: 0.6250 - Loss: 0.0028\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 20:05:06\n",
      "Accuracy: 0.9884 - Precision: 0.9114 - Recall: 0.4964 - Specificity: 0.9989 - F1: 0.6250 - Loss: 0.0028\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 20:05:14\n",
      "Accuracy: 0.9883 - Precision: 0.9113 - Recall: 0.4959 - Specificity: 0.9989 - F1: 0.6247 - Loss: 0.0028\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 20:05:22\n",
      "Accuracy: 0.9883 - Precision: 0.9104 - Recall: 0.4962 - Specificity: 0.9989 - F1: 0.6248 - Loss: 0.0028\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 20:05:30\n",
      "Accuracy: 0.9884 - Precision: 0.9104 - Recall: 0.4967 - Specificity: 0.9989 - F1: 0.6254 - Loss: 0.0028\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 20:05:38\n",
      "Accuracy: 0.9884 - Precision: 0.9101 - Recall: 0.4966 - Specificity: 0.9989 - F1: 0.6254 - Loss: 0.0028\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 20:05:46\n",
      "Accuracy: 0.9884 - Precision: 0.9092 - Recall: 0.4962 - Specificity: 0.9989 - F1: 0.6250 - Loss: 0.0028\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 20:05:54\n",
      "Accuracy: 0.9884 - Precision: 0.9094 - Recall: 0.4969 - Specificity: 0.9989 - F1: 0.6258 - Loss: 0.0028\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 20:06:02\n",
      "Accuracy: 0.9885 - Precision: 0.9096 - Recall: 0.4981 - Specificity: 0.9989 - F1: 0.6269 - Loss: 0.0028\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 20:06:10\n",
      "Accuracy: 0.9885 - Precision: 0.9090 - Recall: 0.4984 - Specificity: 0.9989 - F1: 0.6271 - Loss: 0.0028\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 20:06:18\n",
      "Accuracy: 0.9885 - Precision: 0.9089 - Recall: 0.4986 - Specificity: 0.9989 - F1: 0.6274 - Loss: 0.0028\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 20:06:26\n",
      "Accuracy: 0.9885 - Precision: 0.9087 - Recall: 0.4995 - Specificity: 0.9989 - F1: 0.6282 - Loss: 0.0028\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 20:06:34\n",
      "Accuracy: 0.9885 - Precision: 0.9092 - Recall: 0.4998 - Specificity: 0.9989 - F1: 0.6287 - Loss: 0.0028\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 20:06:43\n",
      "Accuracy: 0.9886 - Precision: 0.9097 - Recall: 0.5000 - Specificity: 0.9989 - F1: 0.6291 - Loss: 0.0027\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 20:06:52\n",
      "Accuracy: 0.9886 - Precision: 0.9095 - Recall: 0.5002 - Specificity: 0.9989 - F1: 0.6294 - Loss: 0.0027\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 20:07:00\n",
      "Accuracy: 0.9886 - Precision: 0.9095 - Recall: 0.5004 - Specificity: 0.9989 - F1: 0.6297 - Loss: 0.0027\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 20:07:08\n",
      "Accuracy: 0.9886 - Precision: 0.9098 - Recall: 0.5010 - Specificity: 0.9989 - F1: 0.6304 - Loss: 0.0027\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 20:07:16\n",
      "Accuracy: 0.9886 - Precision: 0.9091 - Recall: 0.5021 - Specificity: 0.9989 - F1: 0.6311 - Loss: 0.0027\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 20:07:26\n",
      "Accuracy: 0.9886 - Precision: 0.9078 - Recall: 0.5032 - Specificity: 0.9989 - F1: 0.6317 - Loss: 0.0027\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 20:07:35\n",
      "Accuracy: 0.9886 - Precision: 0.9076 - Recall: 0.5037 - Specificity: 0.9989 - F1: 0.6321 - Loss: 0.0027\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 20:07:43\n",
      "Accuracy: 0.9886 - Precision: 0.9079 - Recall: 0.5040 - Specificity: 0.9989 - F1: 0.6326 - Loss: 0.0027\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 20:07:51\n",
      "Accuracy: 0.9886 - Precision: 0.9084 - Recall: 0.5045 - Specificity: 0.9989 - F1: 0.6332 - Loss: 0.0027\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 20:07:59\n",
      "Accuracy: 0.9887 - Precision: 0.9089 - Recall: 0.5056 - Specificity: 0.9989 - F1: 0.6343 - Loss: 0.0027\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 20:08:07\n",
      "Accuracy: 0.9887 - Precision: 0.9090 - Recall: 0.5065 - Specificity: 0.9989 - F1: 0.6352 - Loss: 0.0027\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 20:08:15\n",
      "Accuracy: 0.9887 - Precision: 0.9093 - Recall: 0.5077 - Specificity: 0.9989 - F1: 0.6363 - Loss: 0.0027\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 20:08:24\n",
      "Accuracy: 0.9887 - Precision: 0.9086 - Recall: 0.5087 - Specificity: 0.9989 - F1: 0.6369 - Loss: 0.0027\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 20:08:32\n",
      "Accuracy: 0.9888 - Precision: 0.9085 - Recall: 0.5094 - Specificity: 0.9989 - F1: 0.6376 - Loss: 0.0027\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 20:08:41\n",
      "Accuracy: 0.9888 - Precision: 0.9089 - Recall: 0.5106 - Specificity: 0.9989 - F1: 0.6386 - Loss: 0.0027\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 20:08:51\n",
      "Accuracy: 0.9888 - Precision: 0.9091 - Recall: 0.5108 - Specificity: 0.9989 - F1: 0.6390 - Loss: 0.0027\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 20:08:59\n",
      "Accuracy: 0.9888 - Precision: 0.9094 - Recall: 0.5111 - Specificity: 0.9989 - F1: 0.6394 - Loss: 0.0027\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 20:09:08\n",
      "Accuracy: 0.9888 - Precision: 0.9093 - Recall: 0.5120 - Specificity: 0.9989 - F1: 0.6402 - Loss: 0.0027\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 20:09:16\n",
      "Accuracy: 0.9888 - Precision: 0.9095 - Recall: 0.5120 - Specificity: 0.9989 - F1: 0.6404 - Loss: 0.0027\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 20:09:24\n",
      "Accuracy: 0.9888 - Precision: 0.9097 - Recall: 0.5128 - Specificity: 0.9989 - F1: 0.6412 - Loss: 0.0027\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 20:09:33\n",
      "Accuracy: 0.9888 - Precision: 0.9100 - Recall: 0.5137 - Specificity: 0.9989 - F1: 0.6421 - Loss: 0.0027\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 20:09:41\n",
      "Accuracy: 0.9889 - Precision: 0.9097 - Recall: 0.5151 - Specificity: 0.9989 - F1: 0.6430 - Loss: 0.0027\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 20:09:49\n",
      "Accuracy: 0.9889 - Precision: 0.9099 - Recall: 0.5162 - Specificity: 0.9989 - F1: 0.6440 - Loss: 0.0027\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 20:09:57\n",
      "Accuracy: 0.9889 - Precision: 0.9098 - Recall: 0.5174 - Specificity: 0.9989 - F1: 0.6450 - Loss: 0.0027\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 20:10:06\n",
      "Accuracy: 0.9889 - Precision: 0.9101 - Recall: 0.5181 - Specificity: 0.9989 - F1: 0.6457 - Loss: 0.0027\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 20:10:14\n",
      "Accuracy: 0.9890 - Precision: 0.9104 - Recall: 0.5196 - Specificity: 0.9989 - F1: 0.6470 - Loss: 0.0027\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 20:10:22\n",
      "Accuracy: 0.9890 - Precision: 0.9104 - Recall: 0.5207 - Specificity: 0.9989 - F1: 0.6479 - Loss: 0.0027\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 20:10:30\n",
      "Accuracy: 0.9890 - Precision: 0.9106 - Recall: 0.5211 - Specificity: 0.9989 - F1: 0.6484 - Loss: 0.0027\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 20:10:39\n",
      "Accuracy: 0.9890 - Precision: 0.9104 - Recall: 0.5216 - Specificity: 0.9989 - F1: 0.6488 - Loss: 0.0027\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 20:10:49\n",
      "Accuracy: 0.9890 - Precision: 0.9103 - Recall: 0.5223 - Specificity: 0.9989 - F1: 0.6494 - Loss: 0.0027\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 20:10:57\n",
      "Accuracy: 0.9890 - Precision: 0.9108 - Recall: 0.5227 - Specificity: 0.9989 - F1: 0.6499 - Loss: 0.0027\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 20:11:06\n",
      "Accuracy: 0.9890 - Precision: 0.9109 - Recall: 0.5234 - Specificity: 0.9989 - F1: 0.6506 - Loss: 0.0027\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 20:11:14\n",
      "Accuracy: 0.9890 - Precision: 0.9111 - Recall: 0.5239 - Specificity: 0.9989 - F1: 0.6511 - Loss: 0.0027\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 20:11:23\n",
      "Accuracy: 0.9891 - Precision: 0.9113 - Recall: 0.5249 - Specificity: 0.9989 - F1: 0.6521 - Loss: 0.0027\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 20:11:31\n",
      "Accuracy: 0.9891 - Precision: 0.9103 - Recall: 0.5233 - Specificity: 0.9989 - F1: 0.6504 - Loss: 0.0027\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 20:11:40\n",
      "Accuracy: 0.9891 - Precision: 0.9103 - Recall: 0.5238 - Specificity: 0.9989 - F1: 0.6510 - Loss: 0.0027\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 20:11:49\n",
      "Accuracy: 0.9890 - Precision: 0.9100 - Recall: 0.5237 - Specificity: 0.9989 - F1: 0.6509 - Loss: 0.0027\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 20:11:57\n",
      "Accuracy: 0.9890 - Precision: 0.9099 - Recall: 0.5240 - Specificity: 0.9989 - F1: 0.6511 - Loss: 0.0027\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 20:12:06\n",
      "Accuracy: 0.9891 - Precision: 0.9102 - Recall: 0.5245 - Specificity: 0.9989 - F1: 0.6517 - Loss: 0.0027\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 20:12:14\n",
      "Accuracy: 0.9891 - Precision: 0.9106 - Recall: 0.5249 - Specificity: 0.9989 - F1: 0.6523 - Loss: 0.0027\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 20:12:23\n",
      "Accuracy: 0.9891 - Precision: 0.9109 - Recall: 0.5253 - Specificity: 0.9989 - F1: 0.6527 - Loss: 0.0027\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 20:12:32\n",
      "Accuracy: 0.9891 - Precision: 0.9112 - Recall: 0.5256 - Specificity: 0.9989 - F1: 0.6532 - Loss: 0.0027\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 20:12:41\n",
      "Accuracy: 0.9891 - Precision: 0.9113 - Recall: 0.5264 - Specificity: 0.9989 - F1: 0.6538 - Loss: 0.0027\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 20:12:51\n",
      "Accuracy: 0.9891 - Precision: 0.9115 - Recall: 0.5275 - Specificity: 0.9989 - F1: 0.6548 - Loss: 0.0026\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 20:13:00\n",
      "Accuracy: 0.9891 - Precision: 0.9118 - Recall: 0.5284 - Specificity: 0.9989 - F1: 0.6556 - Loss: 0.0026\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 20:13:09\n",
      "Accuracy: 0.9892 - Precision: 0.9119 - Recall: 0.5292 - Specificity: 0.9989 - F1: 0.6563 - Loss: 0.0026\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 20:13:18\n",
      "Accuracy: 0.9892 - Precision: 0.9121 - Recall: 0.5298 - Specificity: 0.9989 - F1: 0.6569 - Loss: 0.0026\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 20:13:26\n",
      "Accuracy: 0.9892 - Precision: 0.9121 - Recall: 0.5307 - Specificity: 0.9989 - F1: 0.6577 - Loss: 0.0026\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 20:13:35\n",
      "Accuracy: 0.9892 - Precision: 0.9115 - Recall: 0.5316 - Specificity: 0.9989 - F1: 0.6582 - Loss: 0.0026\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 20:13:43\n",
      "Accuracy: 0.9892 - Precision: 0.9117 - Recall: 0.5321 - Specificity: 0.9989 - F1: 0.6587 - Loss: 0.0026\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 20:13:53\n",
      "Accuracy: 0.9893 - Precision: 0.9120 - Recall: 0.5327 - Specificity: 0.9989 - F1: 0.6593 - Loss: 0.0026\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 20:14:01\n",
      "Accuracy: 0.9893 - Precision: 0.9118 - Recall: 0.5328 - Specificity: 0.9989 - F1: 0.6594 - Loss: 0.0026\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 20:14:09\n",
      "Accuracy: 0.9893 - Precision: 0.9122 - Recall: 0.5328 - Specificity: 0.9989 - F1: 0.6596 - Loss: 0.0026\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 20:14:17\n",
      "Accuracy: 0.9892 - Precision: 0.9126 - Recall: 0.5323 - Specificity: 0.9989 - F1: 0.6594 - Loss: 0.0026\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 20:14:26\n",
      "Accuracy: 0.9893 - Precision: 0.9128 - Recall: 0.5322 - Specificity: 0.9989 - F1: 0.6594 - Loss: 0.0026\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 20:14:35\n",
      "Accuracy: 0.9893 - Precision: 0.9130 - Recall: 0.5326 - Specificity: 0.9989 - F1: 0.6598 - Loss: 0.0026\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 20:14:44\n",
      "Accuracy: 0.9893 - Precision: 0.9131 - Recall: 0.5329 - Specificity: 0.9989 - F1: 0.6602 - Loss: 0.0026\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 20:14:53\n",
      "Accuracy: 0.9893 - Precision: 0.9130 - Recall: 0.5334 - Specificity: 0.9989 - F1: 0.6606 - Loss: 0.0026\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 20:15:01\n",
      "Accuracy: 0.9893 - Precision: 0.9129 - Recall: 0.5339 - Specificity: 0.9989 - F1: 0.6611 - Loss: 0.0026\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 20:15:09\n",
      "Accuracy: 0.9893 - Precision: 0.9130 - Recall: 0.5347 - Specificity: 0.9989 - F1: 0.6617 - Loss: 0.0026\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 20:15:17\n",
      "Accuracy: 0.9893 - Precision: 0.9126 - Recall: 0.5353 - Specificity: 0.9989 - F1: 0.6621 - Loss: 0.0026\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 20:15:25\n",
      "Accuracy: 0.9893 - Precision: 0.9129 - Recall: 0.5363 - Specificity: 0.9989 - F1: 0.6630 - Loss: 0.0026\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 20:15:33\n",
      "Accuracy: 0.9894 - Precision: 0.9129 - Recall: 0.5371 - Specificity: 0.9989 - F1: 0.6636 - Loss: 0.0026\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 20:15:41\n",
      "Accuracy: 0.9894 - Precision: 0.9129 - Recall: 0.5378 - Specificity: 0.9989 - F1: 0.6642 - Loss: 0.0026\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 20:15:49\n",
      "Accuracy: 0.9894 - Precision: 0.9126 - Recall: 0.5383 - Specificity: 0.9989 - F1: 0.6645 - Loss: 0.0026\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 20:15:57\n",
      "Accuracy: 0.9894 - Precision: 0.9129 - Recall: 0.5385 - Specificity: 0.9989 - F1: 0.6648 - Loss: 0.0026\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 20:16:05\n",
      "Accuracy: 0.9894 - Precision: 0.9132 - Recall: 0.5382 - Specificity: 0.9989 - F1: 0.6648 - Loss: 0.0026\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 20:16:13\n",
      "Accuracy: 0.9894 - Precision: 0.9136 - Recall: 0.5379 - Specificity: 0.9989 - F1: 0.6647 - Loss: 0.0026\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 20:16:21\n",
      "Accuracy: 0.9894 - Precision: 0.9138 - Recall: 0.5377 - Specificity: 0.9989 - F1: 0.6646 - Loss: 0.0026\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 20:16:29\n",
      "Accuracy: 0.9894 - Precision: 0.9139 - Recall: 0.5378 - Specificity: 0.9989 - F1: 0.6648 - Loss: 0.0026\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 20:16:36\n",
      "Accuracy: 0.9894 - Precision: 0.9139 - Recall: 0.5386 - Specificity: 0.9989 - F1: 0.6654 - Loss: 0.0026\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 20:16:45\n",
      "Accuracy: 0.9894 - Precision: 0.9136 - Recall: 0.5390 - Specificity: 0.9989 - F1: 0.6657 - Loss: 0.0026\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 20:16:54\n",
      "Accuracy: 0.9894 - Precision: 0.9136 - Recall: 0.5396 - Specificity: 0.9989 - F1: 0.6662 - Loss: 0.0026\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 20:17:02\n",
      "Accuracy: 0.9894 - Precision: 0.9135 - Recall: 0.5406 - Specificity: 0.9989 - F1: 0.6669 - Loss: 0.0026\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 20:17:10\n",
      "Accuracy: 0.9894 - Precision: 0.9134 - Recall: 0.5415 - Specificity: 0.9989 - F1: 0.6676 - Loss: 0.0026\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 20:17:18\n",
      "Accuracy: 0.9895 - Precision: 0.9135 - Recall: 0.5422 - Specificity: 0.9989 - F1: 0.6682 - Loss: 0.0026\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 20:17:26\n",
      "Accuracy: 0.9895 - Precision: 0.9138 - Recall: 0.5426 - Specificity: 0.9989 - F1: 0.6687 - Loss: 0.0026\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 20:17:35\n",
      "Accuracy: 0.9895 - Precision: 0.9139 - Recall: 0.5429 - Specificity: 0.9989 - F1: 0.6689 - Loss: 0.0026\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 20:17:44\n",
      "Accuracy: 0.9895 - Precision: 0.9133 - Recall: 0.5433 - Specificity: 0.9989 - F1: 0.6691 - Loss: 0.0026\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 20:17:53\n",
      "Accuracy: 0.9895 - Precision: 0.9136 - Recall: 0.5436 - Specificity: 0.9989 - F1: 0.6695 - Loss: 0.0026\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 20:18:01\n",
      "Accuracy: 0.9895 - Precision: 0.9140 - Recall: 0.5434 - Specificity: 0.9989 - F1: 0.6695 - Loss: 0.0026\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 20:18:09\n",
      "Accuracy: 0.9895 - Precision: 0.9141 - Recall: 0.5438 - Specificity: 0.9989 - F1: 0.6699 - Loss: 0.0026\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 20:18:20\n",
      "Accuracy: 0.9895 - Precision: 0.9139 - Recall: 0.5438 - Specificity: 0.9989 - F1: 0.6699 - Loss: 0.0026\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 20:18:29\n",
      "Accuracy: 0.9895 - Precision: 0.9140 - Recall: 0.5440 - Specificity: 0.9989 - F1: 0.6701 - Loss: 0.0026\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 20:18:38\n",
      "Accuracy: 0.9895 - Precision: 0.9142 - Recall: 0.5442 - Specificity: 0.9989 - F1: 0.6704 - Loss: 0.0026\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 20:18:48\n",
      "Accuracy: 0.9895 - Precision: 0.9145 - Recall: 0.5448 - Specificity: 0.9989 - F1: 0.6710 - Loss: 0.0025\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 20:18:58\n",
      "Accuracy: 0.9896 - Precision: 0.9146 - Recall: 0.5455 - Specificity: 0.9989 - F1: 0.6716 - Loss: 0.0025\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 20:19:06\n",
      "Accuracy: 0.9896 - Precision: 0.9145 - Recall: 0.5466 - Specificity: 0.9989 - F1: 0.6724 - Loss: 0.0025\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 20:19:15\n",
      "Accuracy: 0.9896 - Precision: 0.9146 - Recall: 0.5477 - Specificity: 0.9989 - F1: 0.6732 - Loss: 0.0025\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 20:19:23\n",
      "Accuracy: 0.9896 - Precision: 0.9139 - Recall: 0.5486 - Specificity: 0.9989 - F1: 0.6736 - Loss: 0.0025\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 20:19:31\n",
      "Accuracy: 0.9897 - Precision: 0.9139 - Recall: 0.5495 - Specificity: 0.9989 - F1: 0.6743 - Loss: 0.0025\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 20:19:39\n",
      "Accuracy: 0.9897 - Precision: 0.9142 - Recall: 0.5500 - Specificity: 0.9989 - F1: 0.6748 - Loss: 0.0025\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 20:19:48\n",
      "Accuracy: 0.9897 - Precision: 0.9141 - Recall: 0.5503 - Specificity: 0.9989 - F1: 0.6751 - Loss: 0.0025\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 20:19:56\n",
      "Accuracy: 0.9897 - Precision: 0.9142 - Recall: 0.5508 - Specificity: 0.9989 - F1: 0.6755 - Loss: 0.0025\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 20:20:05\n",
      "Accuracy: 0.9897 - Precision: 0.9145 - Recall: 0.5515 - Specificity: 0.9989 - F1: 0.6761 - Loss: 0.0025\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 20:20:13\n",
      "Accuracy: 0.9897 - Precision: 0.9143 - Recall: 0.5520 - Specificity: 0.9989 - F1: 0.6765 - Loss: 0.0025\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 20:20:21\n",
      "Accuracy: 0.9897 - Precision: 0.9145 - Recall: 0.5523 - Specificity: 0.9989 - F1: 0.6769 - Loss: 0.0025\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 20:20:29\n",
      "Accuracy: 0.9898 - Precision: 0.9147 - Recall: 0.5529 - Specificity: 0.9989 - F1: 0.6774 - Loss: 0.0025\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 20:20:37\n",
      "Accuracy: 0.9898 - Precision: 0.9146 - Recall: 0.5530 - Specificity: 0.9989 - F1: 0.6775 - Loss: 0.0025\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 20:20:46\n",
      "Accuracy: 0.9897 - Precision: 0.9144 - Recall: 0.5522 - Specificity: 0.9989 - F1: 0.6768 - Loss: 0.0025\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 20:20:55\n",
      "Accuracy: 0.9897 - Precision: 0.9139 - Recall: 0.5517 - Specificity: 0.9989 - F1: 0.6764 - Loss: 0.0025\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 20:21:03\n",
      "Accuracy: 0.9897 - Precision: 0.9135 - Recall: 0.5509 - Specificity: 0.9989 - F1: 0.6756 - Loss: 0.0025\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 20:21:11\n",
      "Accuracy: 0.9896 - Precision: 0.9135 - Recall: 0.5503 - Specificity: 0.9989 - F1: 0.6752 - Loss: 0.0025\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 20:21:19\n",
      "Accuracy: 0.9896 - Precision: 0.9136 - Recall: 0.5499 - Specificity: 0.9989 - F1: 0.6750 - Loss: 0.0025\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 20:21:27\n",
      "Accuracy: 0.9896 - Precision: 0.9136 - Recall: 0.5490 - Specificity: 0.9989 - F1: 0.6742 - Loss: 0.0025\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 20:21:35\n",
      "Accuracy: 0.9895 - Precision: 0.9132 - Recall: 0.5476 - Specificity: 0.9989 - F1: 0.6728 - Loss: 0.0025\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 20:21:43\n",
      "Accuracy: 0.9895 - Precision: 0.9134 - Recall: 0.5473 - Specificity: 0.9989 - F1: 0.6727 - Loss: 0.0026\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 20:21:51\n",
      "Accuracy: 0.9895 - Precision: 0.9133 - Recall: 0.5462 - Specificity: 0.9989 - F1: 0.6717 - Loss: 0.0026\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 20:21:59\n",
      "Accuracy: 0.9895 - Precision: 0.9131 - Recall: 0.5457 - Specificity: 0.9989 - F1: 0.6712 - Loss: 0.0026\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 20:22:07\n",
      "Accuracy: 0.9895 - Precision: 0.9132 - Recall: 0.5457 - Specificity: 0.9989 - F1: 0.6713 - Loss: 0.0026\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 20:22:15\n",
      "Accuracy: 0.9895 - Precision: 0.9134 - Recall: 0.5449 - Specificity: 0.9989 - F1: 0.6707 - Loss: 0.0026\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 20:22:23\n",
      "Accuracy: 0.9894 - Precision: 0.9136 - Recall: 0.5438 - Specificity: 0.9989 - F1: 0.6697 - Loss: 0.0026\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 20:22:31\n",
      "Accuracy: 0.9894 - Precision: 0.9138 - Recall: 0.5430 - Specificity: 0.9989 - F1: 0.6691 - Loss: 0.0026\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 20:22:39\n",
      "Accuracy: 0.9894 - Precision: 0.9140 - Recall: 0.5425 - Specificity: 0.9989 - F1: 0.6687 - Loss: 0.0026\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 20:22:49\n",
      "Accuracy: 0.9894 - Precision: 0.9143 - Recall: 0.5412 - Specificity: 0.9989 - F1: 0.6676 - Loss: 0.0026\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 20:22:58\n",
      "Accuracy: 0.9894 - Precision: 0.9143 - Recall: 0.5406 - Specificity: 0.9989 - F1: 0.6671 - Loss: 0.0026\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 20:23:06\n",
      "Accuracy: 0.9894 - Precision: 0.9142 - Recall: 0.5404 - Specificity: 0.9989 - F1: 0.6670 - Loss: 0.0026\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 20:23:14\n",
      "Accuracy: 0.9893 - Precision: 0.9139 - Recall: 0.5402 - Specificity: 0.9989 - F1: 0.6667 - Loss: 0.0026\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 20:23:22\n",
      "Accuracy: 0.9893 - Precision: 0.9134 - Recall: 0.5396 - Specificity: 0.9989 - F1: 0.6662 - Loss: 0.0026\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 20:23:30\n",
      "Accuracy: 0.9892 - Precision: 0.9133 - Recall: 0.5391 - Specificity: 0.9989 - F1: 0.6658 - Loss: 0.0026\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 20:23:38\n",
      "Accuracy: 0.9892 - Precision: 0.9132 - Recall: 0.5383 - Specificity: 0.9989 - F1: 0.6651 - Loss: 0.0026\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 20:23:46\n",
      "Accuracy: 0.9891 - Precision: 0.9132 - Recall: 0.5376 - Specificity: 0.9989 - F1: 0.6645 - Loss: 0.0026\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 20:23:55\n",
      "Accuracy: 0.9891 - Precision: 0.9133 - Recall: 0.5367 - Specificity: 0.9989 - F1: 0.6638 - Loss: 0.0026\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 20:24:03\n",
      "Accuracy: 0.9891 - Precision: 0.9135 - Recall: 0.5357 - Specificity: 0.9989 - F1: 0.6629 - Loss: 0.0026\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 20:24:11\n",
      "Accuracy: 0.9890 - Precision: 0.9138 - Recall: 0.5352 - Specificity: 0.9989 - F1: 0.6625 - Loss: 0.0027\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 20:24:19\n",
      "Accuracy: 0.9887 - Precision: 0.9131 - Recall: 0.5331 - Specificity: 0.9989 - F1: 0.6600 - Loss: 0.0029\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 20:24:27\n",
      "Accuracy: 0.9885 - Precision: 0.9129 - Recall: 0.5312 - Specificity: 0.9989 - F1: 0.6580 - Loss: 0.0029\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 20:24:35\n",
      "Accuracy: 0.9882 - Precision: 0.9129 - Recall: 0.5297 - Specificity: 0.9989 - F1: 0.6563 - Loss: 0.0029\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 20:24:44\n",
      "Accuracy: 0.9880 - Precision: 0.9127 - Recall: 0.5286 - Specificity: 0.9989 - F1: 0.6554 - Loss: 0.0030\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 20:24:54\n",
      "Accuracy: 0.9878 - Precision: 0.9123 - Recall: 0.5281 - Specificity: 0.9989 - F1: 0.6549 - Loss: 0.0031\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 20:25:02\n",
      "Accuracy: 0.9876 - Precision: 0.9115 - Recall: 0.5278 - Specificity: 0.9988 - F1: 0.6544 - Loss: 0.0032\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 20:25:10\n",
      "Accuracy: 0.9873 - Precision: 0.9110 - Recall: 0.5262 - Specificity: 0.9988 - F1: 0.6528 - Loss: 0.0032\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 20:25:18\n",
      "Accuracy: 0.9871 - Precision: 0.9104 - Recall: 0.5243 - Specificity: 0.9988 - F1: 0.6506 - Loss: 0.0033\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 20:25:26\n",
      "Accuracy: 0.9868 - Precision: 0.9107 - Recall: 0.5223 - Specificity: 0.9988 - F1: 0.6482 - Loss: 0.0033\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 20:25:34\n",
      "Accuracy: 0.9865 - Precision: 0.9107 - Recall: 0.5203 - Specificity: 0.9988 - F1: 0.6457 - Loss: 0.0034\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 20:25:42\n",
      "Accuracy: 0.9862 - Precision: 0.9109 - Recall: 0.5183 - Specificity: 0.9988 - F1: 0.6433 - Loss: 0.0034\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 20:25:50\n",
      "Accuracy: 0.9861 - Precision: 0.9095 - Recall: 0.5164 - Specificity: 0.9988 - F1: 0.6410 - Loss: 0.0035\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 20:25:58\n",
      "Accuracy: 0.9858 - Precision: 0.9091 - Recall: 0.5144 - Specificity: 0.9988 - F1: 0.6386 - Loss: 0.0035\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 20:26:07\n",
      "Accuracy: 0.9856 - Precision: 0.9085 - Recall: 0.5124 - Specificity: 0.9988 - F1: 0.6361 - Loss: 0.0036\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 20:26:14\n",
      "Accuracy: 0.9853 - Precision: 0.9088 - Recall: 0.5104 - Specificity: 0.9988 - F1: 0.6336 - Loss: 0.0036\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 20:26:22\n",
      "Accuracy: 0.9849 - Precision: 0.9091 - Recall: 0.5084 - Specificity: 0.9988 - F1: 0.6312 - Loss: 0.0037\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 20:26:31\n",
      "Accuracy: 0.9847 - Precision: 0.9095 - Recall: 0.5064 - Specificity: 0.9988 - F1: 0.6288 - Loss: 0.0037\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 20:26:39\n",
      "Accuracy: 0.9845 - Precision: 0.9097 - Recall: 0.5046 - Specificity: 0.9988 - F1: 0.6265 - Loss: 0.0037\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 20:26:48\n",
      "Accuracy: 0.9845 - Precision: 0.9094 - Recall: 0.5026 - Specificity: 0.9988 - F1: 0.6241 - Loss: 0.0038\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 20:26:57\n",
      "Accuracy: 0.9844 - Precision: 0.9097 - Recall: 0.5007 - Specificity: 0.9988 - F1: 0.6218 - Loss: 0.0038\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 20:27:05\n",
      "Accuracy: 0.9844 - Precision: 0.9101 - Recall: 0.4990 - Specificity: 0.9988 - F1: 0.6198 - Loss: 0.0038\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 20:27:13\n",
      "Accuracy: 0.9844 - Precision: 0.9104 - Recall: 0.4972 - Specificity: 0.9988 - F1: 0.6175 - Loss: 0.0038\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 20:27:21\n",
      "Accuracy: 0.9842 - Precision: 0.9107 - Recall: 0.4953 - Specificity: 0.9989 - F1: 0.6153 - Loss: 0.0039\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 20:27:29\n",
      "Accuracy: 0.9842 - Precision: 0.9105 - Recall: 0.4935 - Specificity: 0.9989 - F1: 0.6131 - Loss: 0.0039\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 20:27:37\n",
      "Accuracy: 0.9841 - Precision: 0.9107 - Recall: 0.4917 - Specificity: 0.9989 - F1: 0.6109 - Loss: 0.0039\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 20:27:46\n",
      "Accuracy: 0.9840 - Precision: 0.9100 - Recall: 0.4899 - Specificity: 0.9989 - F1: 0.6087 - Loss: 0.0040\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 20:27:54\n",
      "Accuracy: 0.9840 - Precision: 0.9102 - Recall: 0.4881 - Specificity: 0.9989 - F1: 0.6066 - Loss: 0.0040\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 20:28:02\n",
      "Accuracy: 0.9840 - Precision: 0.9104 - Recall: 0.4864 - Specificity: 0.9989 - F1: 0.6045 - Loss: 0.0040\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 20:28:10\n",
      "Accuracy: 0.9839 - Precision: 0.9106 - Recall: 0.4847 - Specificity: 0.9989 - F1: 0.6025 - Loss: 0.0040\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 20:28:18\n",
      "Accuracy: 0.9839 - Precision: 0.9093 - Recall: 0.4831 - Specificity: 0.9989 - F1: 0.6005 - Loss: 0.0040\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 20:28:26\n",
      "Accuracy: 0.9839 - Precision: 0.9095 - Recall: 0.4814 - Specificity: 0.9989 - F1: 0.5985 - Loss: 0.0040\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 20:28:34\n",
      "Accuracy: 0.9839 - Precision: 0.9098 - Recall: 0.4798 - Specificity: 0.9989 - F1: 0.5966 - Loss: 0.0040\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 20:28:43\n",
      "Accuracy: 0.9838 - Precision: 0.9099 - Recall: 0.4782 - Specificity: 0.9989 - F1: 0.5947 - Loss: 0.0041\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 20:28:53\n",
      "Accuracy: 0.9838 - Precision: 0.9094 - Recall: 0.4766 - Specificity: 0.9989 - F1: 0.5929 - Loss: 0.0041\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 20:29:01\n",
      "Accuracy: 0.9837 - Precision: 0.9090 - Recall: 0.4751 - Specificity: 0.9989 - F1: 0.5911 - Loss: 0.0041\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 20:29:09\n",
      "Accuracy: 0.9837 - Precision: 0.9072 - Recall: 0.4734 - Specificity: 0.9989 - F1: 0.5890 - Loss: 0.0041\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 20:29:17\n",
      "Accuracy: 0.9836 - Precision: 0.9073 - Recall: 0.4717 - Specificity: 0.9989 - F1: 0.5870 - Loss: 0.0041\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 20:29:25\n",
      "Accuracy: 0.9837 - Precision: 0.9043 - Recall: 0.4700 - Specificity: 0.9989 - F1: 0.5849 - Loss: 0.0041\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 20:29:34\n",
      "Accuracy: 0.9836 - Precision: 0.9045 - Recall: 0.4683 - Specificity: 0.9989 - F1: 0.5828 - Loss: 0.0041\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 20:29:41\n",
      "Accuracy: 0.9836 - Precision: 0.9048 - Recall: 0.4667 - Specificity: 0.9989 - F1: 0.5809 - Loss: 0.0041\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 20:29:49\n",
      "Accuracy: 0.9836 - Precision: 0.9035 - Recall: 0.4652 - Specificity: 0.9989 - F1: 0.5791 - Loss: 0.0041\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 20:29:58\n",
      "Accuracy: 0.9836 - Precision: 0.9021 - Recall: 0.4636 - Specificity: 0.9989 - F1: 0.5771 - Loss: 0.0041\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 20:30:06\n",
      "Accuracy: 0.9835 - Precision: 0.9020 - Recall: 0.4620 - Specificity: 0.9989 - F1: 0.5751 - Loss: 0.0041\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 20:30:14\n",
      "Accuracy: 0.9836 - Precision: 0.9000 - Recall: 0.4604 - Specificity: 0.9989 - F1: 0.5731 - Loss: 0.0041\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 20:30:22\n",
      "Accuracy: 0.9835 - Precision: 0.9002 - Recall: 0.4588 - Specificity: 0.9989 - F1: 0.5711 - Loss: 0.0042\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 20:30:30\n",
      "Accuracy: 0.9835 - Precision: 0.8990 - Recall: 0.4572 - Specificity: 0.9989 - F1: 0.5692 - Loss: 0.0042\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 20:30:38\n",
      "Accuracy: 0.9835 - Precision: 0.8990 - Recall: 0.4556 - Specificity: 0.9989 - F1: 0.5673 - Loss: 0.0042\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 20:30:47\n",
      "Accuracy: 0.9834 - Precision: 0.8992 - Recall: 0.4541 - Specificity: 0.9989 - F1: 0.5654 - Loss: 0.0042\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 20:30:56\n",
      "Accuracy: 0.9834 - Precision: 0.8992 - Recall: 0.4526 - Specificity: 0.9989 - F1: 0.5635 - Loss: 0.0042\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 20:31:05\n",
      "Accuracy: 0.9834 - Precision: 0.8992 - Recall: 0.4510 - Specificity: 0.9989 - F1: 0.5616 - Loss: 0.0042\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 20:31:13\n",
      "Accuracy: 0.9834 - Precision: 0.8985 - Recall: 0.4496 - Specificity: 0.9990 - F1: 0.5600 - Loss: 0.0042\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 20:31:21\n",
      "Accuracy: 0.9833 - Precision: 0.8980 - Recall: 0.4482 - Specificity: 0.9990 - F1: 0.5583 - Loss: 0.0042\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 20:31:29\n",
      "Accuracy: 0.9833 - Precision: 0.8978 - Recall: 0.4470 - Specificity: 0.9990 - F1: 0.5570 - Loss: 0.0042\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 20:31:38\n",
      "Accuracy: 0.9833 - Precision: 0.8977 - Recall: 0.4461 - Specificity: 0.9990 - F1: 0.5560 - Loss: 0.0042\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 20:31:46\n",
      "Accuracy: 0.9832 - Precision: 0.8979 - Recall: 0.4448 - Specificity: 0.9990 - F1: 0.5546 - Loss: 0.0042\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 20:31:54\n",
      "Accuracy: 0.9832 - Precision: 0.8976 - Recall: 0.4436 - Specificity: 0.9990 - F1: 0.5532 - Loss: 0.0042\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 20:32:02\n",
      "Accuracy: 0.9832 - Precision: 0.8974 - Recall: 0.4426 - Specificity: 0.9990 - F1: 0.5522 - Loss: 0.0042\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 20:32:10\n",
      "Accuracy: 0.9832 - Precision: 0.8975 - Recall: 0.4416 - Specificity: 0.9990 - F1: 0.5512 - Loss: 0.0042\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 20:32:18\n",
      "Accuracy: 0.9831 - Precision: 0.8976 - Recall: 0.4403 - Specificity: 0.9990 - F1: 0.5497 - Loss: 0.0042\n",
      "\n",
      "Epoch 11/20\n",
      "Validation - Accuracy: 0.9800, Precision: 0.8808, Recall: 0.0788, Specificity: 0.9998, F1: 0.1437, Loss: 0.0051\n",
      "\n",
      "\n",
      "Epoch 12/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 20:40:14\n",
      "Accuracy: 0.9762 - Precision: 0.9648 - Recall: 0.0957 - Specificity: 0.9999 - F1: 0.1741 - Loss: 0.0062\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 20:40:23\n",
      "Accuracy: 0.9751 - Precision: 0.9749 - Recall: 0.1073 - Specificity: 0.9999 - F1: 0.1932 - Loss: 0.0063\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 20:40:31\n",
      "Accuracy: 0.9746 - Precision: 0.9783 - Recall: 0.1215 - Specificity: 0.9999 - F1: 0.2155 - Loss: 0.0058\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 20:40:40\n",
      "Accuracy: 0.9774 - Precision: 0.9792 - Recall: 0.1286 - Specificity: 0.9999 - F1: 0.2267 - Loss: 0.0052\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 20:40:49\n",
      "Accuracy: 0.9792 - Precision: 0.9514 - Recall: 0.1398 - Specificity: 0.9998 - F1: 0.2418 - Loss: 0.0048\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 20:40:59\n",
      "Accuracy: 0.9797 - Precision: 0.9550 - Recall: 0.1576 - Specificity: 0.9998 - F1: 0.2671 - Loss: 0.0047\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 20:41:07\n",
      "Accuracy: 0.9812 - Precision: 0.9480 - Recall: 0.1859 - Specificity: 0.9998 - F1: 0.3019 - Loss: 0.0044\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 20:41:16\n",
      "Accuracy: 0.9819 - Precision: 0.9209 - Recall: 0.2153 - Specificity: 0.9995 - F1: 0.3310 - Loss: 0.0043\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 20:41:24\n",
      "Accuracy: 0.9830 - Precision: 0.9260 - Recall: 0.2464 - Specificity: 0.9995 - F1: 0.3670 - Loss: 0.0040\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 20:41:33\n",
      "Accuracy: 0.9835 - Precision: 0.9296 - Recall: 0.2524 - Specificity: 0.9995 - F1: 0.3768 - Loss: 0.0039\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 20:41:42\n",
      "Accuracy: 0.9839 - Precision: 0.9181 - Recall: 0.2673 - Specificity: 0.9994 - F1: 0.3924 - Loss: 0.0039\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 20:41:50\n",
      "Accuracy: 0.9844 - Precision: 0.9224 - Recall: 0.2835 - Specificity: 0.9994 - F1: 0.4118 - Loss: 0.0037\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 20:41:59\n",
      "Accuracy: 0.9848 - Precision: 0.9235 - Recall: 0.2979 - Specificity: 0.9994 - F1: 0.4283 - Loss: 0.0037\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 20:42:08\n",
      "Accuracy: 0.9849 - Precision: 0.9047 - Recall: 0.2997 - Specificity: 0.9993 - F1: 0.4288 - Loss: 0.0037\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 20:42:18\n",
      "Accuracy: 0.9852 - Precision: 0.9081 - Recall: 0.3130 - Specificity: 0.9993 - F1: 0.4438 - Loss: 0.0036\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 20:42:27\n",
      "Accuracy: 0.9850 - Precision: 0.9112 - Recall: 0.3132 - Specificity: 0.9993 - F1: 0.4459 - Loss: 0.0037\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 20:42:36\n",
      "Accuracy: 0.9854 - Precision: 0.9141 - Recall: 0.3275 - Specificity: 0.9993 - F1: 0.4610 - Loss: 0.0036\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 20:42:45\n",
      "Accuracy: 0.9856 - Precision: 0.9165 - Recall: 0.3356 - Specificity: 0.9993 - F1: 0.4707 - Loss: 0.0036\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 20:42:53\n",
      "Accuracy: 0.9858 - Precision: 0.9169 - Recall: 0.3454 - Specificity: 0.9993 - F1: 0.4810 - Loss: 0.0035\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 20:43:02\n",
      "Accuracy: 0.9861 - Precision: 0.9147 - Recall: 0.3587 - Specificity: 0.9993 - F1: 0.4929 - Loss: 0.0034\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 20:43:11\n",
      "Accuracy: 0.9862 - Precision: 0.9118 - Recall: 0.3630 - Specificity: 0.9992 - F1: 0.4974 - Loss: 0.0034\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 20:43:20\n",
      "Accuracy: 0.9858 - Precision: 0.8943 - Recall: 0.3598 - Specificity: 0.9990 - F1: 0.4919 - Loss: 0.0036\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 20:43:28\n",
      "Accuracy: 0.9858 - Precision: 0.8980 - Recall: 0.3598 - Specificity: 0.9990 - F1: 0.4934 - Loss: 0.0036\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 20:43:37\n",
      "Accuracy: 0.9857 - Precision: 0.9006 - Recall: 0.3599 - Specificity: 0.9990 - F1: 0.4947 - Loss: 0.0036\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 20:43:45\n",
      "Accuracy: 0.9857 - Precision: 0.9027 - Recall: 0.3600 - Specificity: 0.9991 - F1: 0.4960 - Loss: 0.0035\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 20:43:54\n",
      "Accuracy: 0.9859 - Precision: 0.9042 - Recall: 0.3634 - Specificity: 0.9991 - F1: 0.5003 - Loss: 0.0035\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 20:44:03\n",
      "Accuracy: 0.9859 - Precision: 0.9070 - Recall: 0.3641 - Specificity: 0.9991 - F1: 0.5022 - Loss: 0.0035\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 20:44:11\n",
      "Accuracy: 0.9859 - Precision: 0.9089 - Recall: 0.3607 - Specificity: 0.9991 - F1: 0.4992 - Loss: 0.0035\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 20:44:20\n",
      "Accuracy: 0.9856 - Precision: 0.9085 - Recall: 0.3576 - Specificity: 0.9991 - F1: 0.4963 - Loss: 0.0035\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 20:44:28\n",
      "Accuracy: 0.9857 - Precision: 0.9103 - Recall: 0.3622 - Specificity: 0.9991 - F1: 0.5016 - Loss: 0.0035\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 20:44:37\n",
      "Accuracy: 0.9858 - Precision: 0.9108 - Recall: 0.3665 - Specificity: 0.9992 - F1: 0.5062 - Loss: 0.0034\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 20:44:45\n",
      "Accuracy: 0.9858 - Precision: 0.9104 - Recall: 0.3666 - Specificity: 0.9992 - F1: 0.5067 - Loss: 0.0034\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 20:44:54\n",
      "Accuracy: 0.9859 - Precision: 0.9115 - Recall: 0.3687 - Specificity: 0.9992 - F1: 0.5095 - Loss: 0.0034\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 20:45:02\n",
      "Accuracy: 0.9858 - Precision: 0.9132 - Recall: 0.3683 - Specificity: 0.9992 - F1: 0.5098 - Loss: 0.0034\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 20:45:11\n",
      "Accuracy: 0.9858 - Precision: 0.9145 - Recall: 0.3677 - Specificity: 0.9992 - F1: 0.5098 - Loss: 0.0034\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 20:45:21\n",
      "Accuracy: 0.9860 - Precision: 0.9145 - Recall: 0.3726 - Specificity: 0.9992 - F1: 0.5146 - Loss: 0.0034\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 20:45:30\n",
      "Accuracy: 0.9861 - Precision: 0.9150 - Recall: 0.3799 - Specificity: 0.9992 - F1: 0.5213 - Loss: 0.0034\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 20:45:38\n",
      "Accuracy: 0.9861 - Precision: 0.9143 - Recall: 0.3840 - Specificity: 0.9992 - F1: 0.5251 - Loss: 0.0033\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 20:45:47\n",
      "Accuracy: 0.9863 - Precision: 0.9152 - Recall: 0.3900 - Specificity: 0.9992 - F1: 0.5308 - Loss: 0.0033\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 20:45:56\n",
      "Accuracy: 0.9864 - Precision: 0.9158 - Recall: 0.3962 - Specificity: 0.9992 - F1: 0.5366 - Loss: 0.0033\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 20:46:05\n",
      "Accuracy: 0.9863 - Precision: 0.9155 - Recall: 0.3971 - Specificity: 0.9991 - F1: 0.5378 - Loss: 0.0033\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 20:46:13\n",
      "Accuracy: 0.9864 - Precision: 0.9164 - Recall: 0.4016 - Specificity: 0.9992 - F1: 0.5423 - Loss: 0.0033\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 20:46:22\n",
      "Accuracy: 0.9865 - Precision: 0.9168 - Recall: 0.4066 - Specificity: 0.9991 - F1: 0.5470 - Loss: 0.0033\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 20:46:31\n",
      "Accuracy: 0.9866 - Precision: 0.9175 - Recall: 0.4121 - Specificity: 0.9992 - F1: 0.5520 - Loss: 0.0033\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 20:46:39\n",
      "Accuracy: 0.9867 - Precision: 0.9126 - Recall: 0.4180 - Specificity: 0.9991 - F1: 0.5550 - Loss: 0.0033\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 20:46:47\n",
      "Accuracy: 0.9868 - Precision: 0.9131 - Recall: 0.4221 - Specificity: 0.9991 - F1: 0.5589 - Loss: 0.0032\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 20:46:55\n",
      "Accuracy: 0.9868 - Precision: 0.9130 - Recall: 0.4256 - Specificity: 0.9991 - F1: 0.5622 - Loss: 0.0032\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 20:47:04\n",
      "Accuracy: 0.9869 - Precision: 0.9135 - Recall: 0.4299 - Specificity: 0.9991 - F1: 0.5662 - Loss: 0.0032\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 20:47:12\n",
      "Accuracy: 0.9870 - Precision: 0.9128 - Recall: 0.4349 - Specificity: 0.9990 - F1: 0.5703 - Loss: 0.0032\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 20:47:23\n",
      "Accuracy: 0.9870 - Precision: 0.9137 - Recall: 0.4397 - Specificity: 0.9990 - F1: 0.5747 - Loss: 0.0032\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 20:47:32\n",
      "Accuracy: 0.9871 - Precision: 0.9134 - Recall: 0.4443 - Specificity: 0.9990 - F1: 0.5785 - Loss: 0.0032\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 20:47:40\n",
      "Accuracy: 0.9872 - Precision: 0.9125 - Recall: 0.4477 - Specificity: 0.9990 - F1: 0.5813 - Loss: 0.0032\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 20:47:49\n",
      "Accuracy: 0.9873 - Precision: 0.9130 - Recall: 0.4522 - Specificity: 0.9990 - F1: 0.5853 - Loss: 0.0031\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 20:47:57\n",
      "Accuracy: 0.9874 - Precision: 0.9136 - Recall: 0.4566 - Specificity: 0.9990 - F1: 0.5892 - Loss: 0.0031\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 20:48:06\n",
      "Accuracy: 0.9874 - Precision: 0.9138 - Recall: 0.4592 - Specificity: 0.9990 - F1: 0.5917 - Loss: 0.0031\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 20:48:15\n",
      "Accuracy: 0.9876 - Precision: 0.9134 - Recall: 0.4645 - Specificity: 0.9990 - F1: 0.5958 - Loss: 0.0031\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 20:48:23\n",
      "Accuracy: 0.9876 - Precision: 0.9130 - Recall: 0.4678 - Specificity: 0.9990 - F1: 0.5986 - Loss: 0.0031\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 20:48:32\n",
      "Accuracy: 0.9877 - Precision: 0.9126 - Recall: 0.4715 - Specificity: 0.9990 - F1: 0.6016 - Loss: 0.0031\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 20:48:40\n",
      "Accuracy: 0.9878 - Precision: 0.9133 - Recall: 0.4747 - Specificity: 0.9990 - F1: 0.6046 - Loss: 0.0030\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 20:48:49\n",
      "Accuracy: 0.9878 - Precision: 0.9120 - Recall: 0.4768 - Specificity: 0.9990 - F1: 0.6062 - Loss: 0.0030\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 20:48:57\n",
      "Accuracy: 0.9879 - Precision: 0.9114 - Recall: 0.4784 - Specificity: 0.9989 - F1: 0.6076 - Loss: 0.0030\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 20:49:06\n",
      "Accuracy: 0.9879 - Precision: 0.9122 - Recall: 0.4802 - Specificity: 0.9990 - F1: 0.6096 - Loss: 0.0030\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 20:49:14\n",
      "Accuracy: 0.9880 - Precision: 0.9132 - Recall: 0.4824 - Specificity: 0.9990 - F1: 0.6120 - Loss: 0.0030\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 20:49:25\n",
      "Accuracy: 0.9880 - Precision: 0.9137 - Recall: 0.4846 - Specificity: 0.9990 - F1: 0.6141 - Loss: 0.0030\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 20:49:33\n",
      "Accuracy: 0.9881 - Precision: 0.9141 - Recall: 0.4856 - Specificity: 0.9990 - F1: 0.6153 - Loss: 0.0030\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 20:49:42\n",
      "Accuracy: 0.9880 - Precision: 0.9140 - Recall: 0.4855 - Specificity: 0.9990 - F1: 0.6155 - Loss: 0.0030\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 20:49:51\n",
      "Accuracy: 0.9880 - Precision: 0.9135 - Recall: 0.4864 - Specificity: 0.9990 - F1: 0.6164 - Loss: 0.0030\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 20:49:59\n",
      "Accuracy: 0.9880 - Precision: 0.9135 - Recall: 0.4873 - Specificity: 0.9990 - F1: 0.6174 - Loss: 0.0030\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 20:50:08\n",
      "Accuracy: 0.9881 - Precision: 0.9139 - Recall: 0.4902 - Specificity: 0.9990 - F1: 0.6200 - Loss: 0.0030\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 20:50:16\n",
      "Accuracy: 0.9882 - Precision: 0.9141 - Recall: 0.4930 - Specificity: 0.9990 - F1: 0.6224 - Loss: 0.0029\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 20:50:25\n",
      "Accuracy: 0.9882 - Precision: 0.9127 - Recall: 0.4950 - Specificity: 0.9989 - F1: 0.6236 - Loss: 0.0029\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 20:50:34\n",
      "Accuracy: 0.9882 - Precision: 0.9111 - Recall: 0.4964 - Specificity: 0.9989 - F1: 0.6245 - Loss: 0.0029\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 20:50:42\n",
      "Accuracy: 0.9882 - Precision: 0.9118 - Recall: 0.4976 - Specificity: 0.9989 - F1: 0.6258 - Loss: 0.0029\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 20:50:50\n",
      "Accuracy: 0.9882 - Precision: 0.9126 - Recall: 0.4979 - Specificity: 0.9989 - F1: 0.6266 - Loss: 0.0029\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 20:51:03\n",
      "Accuracy: 0.9882 - Precision: 0.9128 - Recall: 0.4986 - Specificity: 0.9989 - F1: 0.6274 - Loss: 0.0029\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 20:51:12\n",
      "Accuracy: 0.9882 - Precision: 0.9136 - Recall: 0.4991 - Specificity: 0.9989 - F1: 0.6282 - Loss: 0.0029\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 20:51:21\n",
      "Accuracy: 0.9882 - Precision: 0.9135 - Recall: 0.5004 - Specificity: 0.9989 - F1: 0.6294 - Loss: 0.0029\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 20:51:32\n",
      "Accuracy: 0.9883 - Precision: 0.9142 - Recall: 0.5017 - Specificity: 0.9989 - F1: 0.6309 - Loss: 0.0029\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 20:51:42\n",
      "Accuracy: 0.9883 - Precision: 0.9142 - Recall: 0.5032 - Specificity: 0.9989 - F1: 0.6323 - Loss: 0.0029\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 20:51:53\n",
      "Accuracy: 0.9883 - Precision: 0.9146 - Recall: 0.5053 - Specificity: 0.9989 - F1: 0.6342 - Loss: 0.0029\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 20:52:03\n",
      "Accuracy: 0.9884 - Precision: 0.9143 - Recall: 0.5078 - Specificity: 0.9989 - F1: 0.6361 - Loss: 0.0029\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 20:52:12\n",
      "Accuracy: 0.9884 - Precision: 0.9131 - Recall: 0.5090 - Specificity: 0.9989 - F1: 0.6368 - Loss: 0.0029\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 20:52:23\n",
      "Accuracy: 0.9884 - Precision: 0.9129 - Recall: 0.5103 - Specificity: 0.9989 - F1: 0.6380 - Loss: 0.0029\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 20:52:41\n",
      "Accuracy: 0.9885 - Precision: 0.9124 - Recall: 0.5114 - Specificity: 0.9989 - F1: 0.6388 - Loss: 0.0029\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 20:52:52\n",
      "Accuracy: 0.9885 - Precision: 0.9130 - Recall: 0.5130 - Specificity: 0.9989 - F1: 0.6405 - Loss: 0.0029\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 20:53:02\n",
      "Accuracy: 0.9885 - Precision: 0.9128 - Recall: 0.5132 - Specificity: 0.9989 - F1: 0.6407 - Loss: 0.0029\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 20:53:11\n",
      "Accuracy: 0.9885 - Precision: 0.9136 - Recall: 0.5142 - Specificity: 0.9989 - F1: 0.6419 - Loss: 0.0029\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 20:53:20\n",
      "Accuracy: 0.9886 - Precision: 0.9137 - Recall: 0.5150 - Specificity: 0.9989 - F1: 0.6428 - Loss: 0.0029\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 20:53:29\n",
      "Accuracy: 0.9886 - Precision: 0.9143 - Recall: 0.5161 - Specificity: 0.9989 - F1: 0.6440 - Loss: 0.0028\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 20:53:40\n",
      "Accuracy: 0.9886 - Precision: 0.9147 - Recall: 0.5170 - Specificity: 0.9989 - F1: 0.6450 - Loss: 0.0028\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 20:53:50\n",
      "Accuracy: 0.9886 - Precision: 0.9150 - Recall: 0.5190 - Specificity: 0.9989 - F1: 0.6467 - Loss: 0.0028\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 20:54:00\n",
      "Accuracy: 0.9887 - Precision: 0.9141 - Recall: 0.5211 - Specificity: 0.9989 - F1: 0.6480 - Loss: 0.0028\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 20:54:08\n",
      "Accuracy: 0.9887 - Precision: 0.9138 - Recall: 0.5230 - Specificity: 0.9989 - F1: 0.6495 - Loss: 0.0028\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 20:54:18\n",
      "Accuracy: 0.9888 - Precision: 0.9138 - Recall: 0.5247 - Specificity: 0.9989 - F1: 0.6509 - Loss: 0.0028\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 20:54:30\n",
      "Accuracy: 0.9888 - Precision: 0.9128 - Recall: 0.5264 - Specificity: 0.9989 - F1: 0.6518 - Loss: 0.0028\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 20:54:39\n",
      "Accuracy: 0.9888 - Precision: 0.9127 - Recall: 0.5271 - Specificity: 0.9989 - F1: 0.6525 - Loss: 0.0028\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 20:54:48\n",
      "Accuracy: 0.9888 - Precision: 0.9134 - Recall: 0.5278 - Specificity: 0.9989 - F1: 0.6534 - Loss: 0.0028\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 20:54:56\n",
      "Accuracy: 0.9888 - Precision: 0.9134 - Recall: 0.5287 - Specificity: 0.9989 - F1: 0.6543 - Loss: 0.0028\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 20:55:05\n",
      "Accuracy: 0.9888 - Precision: 0.9133 - Recall: 0.5287 - Specificity: 0.9989 - F1: 0.6544 - Loss: 0.0028\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 20:55:16\n",
      "Accuracy: 0.9889 - Precision: 0.9133 - Recall: 0.5290 - Specificity: 0.9989 - F1: 0.6548 - Loss: 0.0028\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 20:55:25\n",
      "Accuracy: 0.9889 - Precision: 0.9130 - Recall: 0.5288 - Specificity: 0.9989 - F1: 0.6547 - Loss: 0.0028\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 20:55:39\n",
      "Accuracy: 0.9889 - Precision: 0.9108 - Recall: 0.5278 - Specificity: 0.9989 - F1: 0.6534 - Loss: 0.0028\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 20:55:49\n",
      "Accuracy: 0.9889 - Precision: 0.9104 - Recall: 0.5285 - Specificity: 0.9989 - F1: 0.6540 - Loss: 0.0028\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 20:56:04\n",
      "Accuracy: 0.9889 - Precision: 0.9103 - Recall: 0.5289 - Specificity: 0.9989 - F1: 0.6544 - Loss: 0.0028\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 20:56:15\n",
      "Accuracy: 0.9889 - Precision: 0.9093 - Recall: 0.5297 - Specificity: 0.9988 - F1: 0.6548 - Loss: 0.0028\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 20:56:25\n",
      "Accuracy: 0.9890 - Precision: 0.9095 - Recall: 0.5305 - Specificity: 0.9988 - F1: 0.6556 - Loss: 0.0027\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 20:56:34\n",
      "Accuracy: 0.9890 - Precision: 0.9090 - Recall: 0.5305 - Specificity: 0.9988 - F1: 0.6556 - Loss: 0.0027\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 20:56:43\n",
      "Accuracy: 0.9890 - Precision: 0.9082 - Recall: 0.5296 - Specificity: 0.9988 - F1: 0.6548 - Loss: 0.0027\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 20:56:51\n",
      "Accuracy: 0.9890 - Precision: 0.9085 - Recall: 0.5299 - Specificity: 0.9988 - F1: 0.6552 - Loss: 0.0027\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 20:57:03\n",
      "Accuracy: 0.9891 - Precision: 0.9088 - Recall: 0.5307 - Specificity: 0.9988 - F1: 0.6561 - Loss: 0.0027\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 20:57:13\n",
      "Accuracy: 0.9891 - Precision: 0.9086 - Recall: 0.5308 - Specificity: 0.9988 - F1: 0.6562 - Loss: 0.0027\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 20:57:26\n",
      "Accuracy: 0.9891 - Precision: 0.9085 - Recall: 0.5311 - Specificity: 0.9988 - F1: 0.6566 - Loss: 0.0027\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 20:57:36\n",
      "Accuracy: 0.9891 - Precision: 0.9082 - Recall: 0.5321 - Specificity: 0.9988 - F1: 0.6573 - Loss: 0.0027\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 20:57:45\n",
      "Accuracy: 0.9891 - Precision: 0.9085 - Recall: 0.5326 - Specificity: 0.9988 - F1: 0.6580 - Loss: 0.0027\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 20:57:55\n",
      "Accuracy: 0.9891 - Precision: 0.9090 - Recall: 0.5330 - Specificity: 0.9989 - F1: 0.6585 - Loss: 0.0027\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 20:58:04\n",
      "Accuracy: 0.9892 - Precision: 0.9086 - Recall: 0.5333 - Specificity: 0.9988 - F1: 0.6587 - Loss: 0.0027\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 20:58:14\n",
      "Accuracy: 0.9892 - Precision: 0.9088 - Recall: 0.5334 - Specificity: 0.9988 - F1: 0.6589 - Loss: 0.0027\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 20:58:24\n",
      "Accuracy: 0.9892 - Precision: 0.9090 - Recall: 0.5338 - Specificity: 0.9989 - F1: 0.6594 - Loss: 0.0027\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 20:58:33\n",
      "Accuracy: 0.9892 - Precision: 0.9084 - Recall: 0.5346 - Specificity: 0.9988 - F1: 0.6599 - Loss: 0.0027\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 20:58:42\n",
      "Accuracy: 0.9892 - Precision: 0.9073 - Recall: 0.5356 - Specificity: 0.9988 - F1: 0.6603 - Loss: 0.0027\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 20:58:51\n",
      "Accuracy: 0.9892 - Precision: 0.9070 - Recall: 0.5359 - Specificity: 0.9988 - F1: 0.6606 - Loss: 0.0027\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 20:59:01\n",
      "Accuracy: 0.9892 - Precision: 0.9072 - Recall: 0.5361 - Specificity: 0.9988 - F1: 0.6609 - Loss: 0.0027\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 20:59:10\n",
      "Accuracy: 0.9892 - Precision: 0.9075 - Recall: 0.5364 - Specificity: 0.9988 - F1: 0.6614 - Loss: 0.0027\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 20:59:18\n",
      "Accuracy: 0.9892 - Precision: 0.9080 - Recall: 0.5374 - Specificity: 0.9988 - F1: 0.6624 - Loss: 0.0027\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 20:59:27\n",
      "Accuracy: 0.9893 - Precision: 0.9080 - Recall: 0.5383 - Specificity: 0.9988 - F1: 0.6631 - Loss: 0.0027\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 20:59:36\n",
      "Accuracy: 0.9893 - Precision: 0.9083 - Recall: 0.5396 - Specificity: 0.9988 - F1: 0.6642 - Loss: 0.0027\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 20:59:45\n",
      "Accuracy: 0.9893 - Precision: 0.9074 - Recall: 0.5405 - Specificity: 0.9988 - F1: 0.6646 - Loss: 0.0027\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 20:59:54\n",
      "Accuracy: 0.9893 - Precision: 0.9069 - Recall: 0.5410 - Specificity: 0.9988 - F1: 0.6650 - Loss: 0.0027\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 21:00:03\n",
      "Accuracy: 0.9893 - Precision: 0.9074 - Recall: 0.5417 - Specificity: 0.9988 - F1: 0.6657 - Loss: 0.0027\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 21:00:12\n",
      "Accuracy: 0.9893 - Precision: 0.9078 - Recall: 0.5416 - Specificity: 0.9988 - F1: 0.6658 - Loss: 0.0027\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 21:00:21\n",
      "Accuracy: 0.9893 - Precision: 0.9081 - Recall: 0.5414 - Specificity: 0.9988 - F1: 0.6659 - Loss: 0.0027\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 21:00:30\n",
      "Accuracy: 0.9893 - Precision: 0.9082 - Recall: 0.5421 - Specificity: 0.9988 - F1: 0.6665 - Loss: 0.0027\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 21:00:39\n",
      "Accuracy: 0.9893 - Precision: 0.9085 - Recall: 0.5421 - Specificity: 0.9988 - F1: 0.6667 - Loss: 0.0027\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 21:00:48\n",
      "Accuracy: 0.9893 - Precision: 0.9086 - Recall: 0.5428 - Specificity: 0.9988 - F1: 0.6673 - Loss: 0.0027\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 21:00:57\n",
      "Accuracy: 0.9894 - Precision: 0.9089 - Recall: 0.5438 - Specificity: 0.9988 - F1: 0.6682 - Loss: 0.0027\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 21:01:07\n",
      "Accuracy: 0.9894 - Precision: 0.9087 - Recall: 0.5448 - Specificity: 0.9988 - F1: 0.6690 - Loss: 0.0026\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 21:01:16\n",
      "Accuracy: 0.9894 - Precision: 0.9090 - Recall: 0.5457 - Specificity: 0.9988 - F1: 0.6698 - Loss: 0.0026\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 21:01:25\n",
      "Accuracy: 0.9894 - Precision: 0.9090 - Recall: 0.5465 - Specificity: 0.9988 - F1: 0.6705 - Loss: 0.0026\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 21:01:34\n",
      "Accuracy: 0.9894 - Precision: 0.9092 - Recall: 0.5470 - Specificity: 0.9988 - F1: 0.6710 - Loss: 0.0026\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 21:01:46\n",
      "Accuracy: 0.9895 - Precision: 0.9096 - Recall: 0.5482 - Specificity: 0.9988 - F1: 0.6721 - Loss: 0.0026\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 21:01:55\n",
      "Accuracy: 0.9895 - Precision: 0.9099 - Recall: 0.5492 - Specificity: 0.9988 - F1: 0.6729 - Loss: 0.0026\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 21:02:04\n",
      "Accuracy: 0.9895 - Precision: 0.9101 - Recall: 0.5496 - Specificity: 0.9988 - F1: 0.6734 - Loss: 0.0026\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 21:02:14\n",
      "Accuracy: 0.9895 - Precision: 0.9100 - Recall: 0.5502 - Specificity: 0.9988 - F1: 0.6739 - Loss: 0.0026\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 21:02:23\n",
      "Accuracy: 0.9895 - Precision: 0.9099 - Recall: 0.5510 - Specificity: 0.9988 - F1: 0.6745 - Loss: 0.0026\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 21:02:33\n",
      "Accuracy: 0.9895 - Precision: 0.9102 - Recall: 0.5514 - Specificity: 0.9988 - F1: 0.6750 - Loss: 0.0026\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 21:02:42\n",
      "Accuracy: 0.9895 - Precision: 0.9103 - Recall: 0.5520 - Specificity: 0.9988 - F1: 0.6755 - Loss: 0.0026\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 21:02:52\n",
      "Accuracy: 0.9895 - Precision: 0.9106 - Recall: 0.5522 - Specificity: 0.9988 - F1: 0.6758 - Loss: 0.0026\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 21:03:02\n",
      "Accuracy: 0.9896 - Precision: 0.9109 - Recall: 0.5528 - Specificity: 0.9989 - F1: 0.6765 - Loss: 0.0026\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 21:03:12\n",
      "Accuracy: 0.9895 - Precision: 0.9100 - Recall: 0.5509 - Specificity: 0.9989 - F1: 0.6746 - Loss: 0.0026\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 21:03:22\n",
      "Accuracy: 0.9896 - Precision: 0.9101 - Recall: 0.5512 - Specificity: 0.9989 - F1: 0.6750 - Loss: 0.0026\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 21:03:32\n",
      "Accuracy: 0.9895 - Precision: 0.9098 - Recall: 0.5510 - Specificity: 0.9988 - F1: 0.6748 - Loss: 0.0026\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 21:03:41\n",
      "Accuracy: 0.9895 - Precision: 0.9097 - Recall: 0.5513 - Specificity: 0.9988 - F1: 0.6751 - Loss: 0.0026\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 21:03:51\n",
      "Accuracy: 0.9895 - Precision: 0.9099 - Recall: 0.5517 - Specificity: 0.9988 - F1: 0.6755 - Loss: 0.0026\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 21:04:00\n",
      "Accuracy: 0.9896 - Precision: 0.9103 - Recall: 0.5521 - Specificity: 0.9988 - F1: 0.6760 - Loss: 0.0026\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 21:04:09\n",
      "Accuracy: 0.9896 - Precision: 0.9107 - Recall: 0.5525 - Specificity: 0.9989 - F1: 0.6765 - Loss: 0.0026\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 21:04:19\n",
      "Accuracy: 0.9896 - Precision: 0.9109 - Recall: 0.5527 - Specificity: 0.9989 - F1: 0.6768 - Loss: 0.0026\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 21:04:29\n",
      "Accuracy: 0.9896 - Precision: 0.9111 - Recall: 0.5533 - Specificity: 0.9989 - F1: 0.6773 - Loss: 0.0026\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 21:04:39\n",
      "Accuracy: 0.9896 - Precision: 0.9111 - Recall: 0.5541 - Specificity: 0.9989 - F1: 0.6780 - Loss: 0.0026\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 21:04:50\n",
      "Accuracy: 0.9896 - Precision: 0.9115 - Recall: 0.5546 - Specificity: 0.9989 - F1: 0.6785 - Loss: 0.0026\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 21:04:59\n",
      "Accuracy: 0.9897 - Precision: 0.9118 - Recall: 0.5550 - Specificity: 0.9989 - F1: 0.6790 - Loss: 0.0026\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 21:05:12\n",
      "Accuracy: 0.9897 - Precision: 0.9120 - Recall: 0.5552 - Specificity: 0.9989 - F1: 0.6793 - Loss: 0.0026\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 21:05:20\n",
      "Accuracy: 0.9897 - Precision: 0.9123 - Recall: 0.5559 - Specificity: 0.9989 - F1: 0.6799 - Loss: 0.0026\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 21:05:29\n",
      "Accuracy: 0.9897 - Precision: 0.9118 - Recall: 0.5566 - Specificity: 0.9989 - F1: 0.6803 - Loss: 0.0026\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 21:05:38\n",
      "Accuracy: 0.9897 - Precision: 0.9118 - Recall: 0.5570 - Specificity: 0.9989 - F1: 0.6807 - Loss: 0.0026\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 21:05:46\n",
      "Accuracy: 0.9897 - Precision: 0.9120 - Recall: 0.5576 - Specificity: 0.9989 - F1: 0.6813 - Loss: 0.0026\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 21:05:55\n",
      "Accuracy: 0.9897 - Precision: 0.9118 - Recall: 0.5579 - Specificity: 0.9989 - F1: 0.6815 - Loss: 0.0026\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 21:06:03\n",
      "Accuracy: 0.9897 - Precision: 0.9122 - Recall: 0.5579 - Specificity: 0.9989 - F1: 0.6817 - Loss: 0.0026\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 21:06:12\n",
      "Accuracy: 0.9897 - Precision: 0.9126 - Recall: 0.5576 - Specificity: 0.9989 - F1: 0.6816 - Loss: 0.0026\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 21:06:21\n",
      "Accuracy: 0.9897 - Precision: 0.9127 - Recall: 0.5577 - Specificity: 0.9989 - F1: 0.6817 - Loss: 0.0026\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 21:06:31\n",
      "Accuracy: 0.9897 - Precision: 0.9126 - Recall: 0.5584 - Specificity: 0.9989 - F1: 0.6823 - Loss: 0.0026\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 21:06:46\n",
      "Accuracy: 0.9898 - Precision: 0.9127 - Recall: 0.5588 - Specificity: 0.9989 - F1: 0.6827 - Loss: 0.0026\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 21:06:57\n",
      "Accuracy: 0.9898 - Precision: 0.9126 - Recall: 0.5592 - Specificity: 0.9989 - F1: 0.6830 - Loss: 0.0026\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 21:07:08\n",
      "Accuracy: 0.9898 - Precision: 0.9126 - Recall: 0.5594 - Specificity: 0.9989 - F1: 0.6832 - Loss: 0.0026\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 21:07:22\n",
      "Accuracy: 0.9898 - Precision: 0.9128 - Recall: 0.5599 - Specificity: 0.9989 - F1: 0.6837 - Loss: 0.0026\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 21:07:34\n",
      "Accuracy: 0.9898 - Precision: 0.9125 - Recall: 0.5601 - Specificity: 0.9989 - F1: 0.6838 - Loss: 0.0026\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 21:07:46\n",
      "Accuracy: 0.9898 - Precision: 0.9128 - Recall: 0.5608 - Specificity: 0.9989 - F1: 0.6844 - Loss: 0.0026\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 21:07:56\n",
      "Accuracy: 0.9898 - Precision: 0.9128 - Recall: 0.5615 - Specificity: 0.9989 - F1: 0.6850 - Loss: 0.0026\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 21:08:08\n",
      "Accuracy: 0.9898 - Precision: 0.9128 - Recall: 0.5620 - Specificity: 0.9989 - F1: 0.6855 - Loss: 0.0026\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 21:08:18\n",
      "Accuracy: 0.9898 - Precision: 0.9124 - Recall: 0.5623 - Specificity: 0.9989 - F1: 0.6856 - Loss: 0.0026\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 21:08:27\n",
      "Accuracy: 0.9898 - Precision: 0.9127 - Recall: 0.5624 - Specificity: 0.9989 - F1: 0.6858 - Loss: 0.0026\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 21:08:37\n",
      "Accuracy: 0.9898 - Precision: 0.9129 - Recall: 0.5622 - Specificity: 0.9989 - F1: 0.6858 - Loss: 0.0026\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 21:08:46\n",
      "Accuracy: 0.9898 - Precision: 0.9133 - Recall: 0.5621 - Specificity: 0.9989 - F1: 0.6858 - Loss: 0.0025\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 21:08:56\n",
      "Accuracy: 0.9898 - Precision: 0.9135 - Recall: 0.5617 - Specificity: 0.9989 - F1: 0.6856 - Loss: 0.0025\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 21:09:05\n",
      "Accuracy: 0.9898 - Precision: 0.9137 - Recall: 0.5615 - Specificity: 0.9989 - F1: 0.6856 - Loss: 0.0025\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 21:09:14\n",
      "Accuracy: 0.9898 - Precision: 0.9137 - Recall: 0.5619 - Specificity: 0.9989 - F1: 0.6859 - Loss: 0.0025\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 21:09:23\n",
      "Accuracy: 0.9898 - Precision: 0.9137 - Recall: 0.5621 - Specificity: 0.9989 - F1: 0.6861 - Loss: 0.0025\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 21:09:31\n",
      "Accuracy: 0.9898 - Precision: 0.9137 - Recall: 0.5624 - Specificity: 0.9989 - F1: 0.6864 - Loss: 0.0025\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 21:09:39\n",
      "Accuracy: 0.9899 - Precision: 0.9136 - Recall: 0.5631 - Specificity: 0.9989 - F1: 0.6869 - Loss: 0.0025\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 21:09:48\n",
      "Accuracy: 0.9899 - Precision: 0.9134 - Recall: 0.5641 - Specificity: 0.9989 - F1: 0.6876 - Loss: 0.0025\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 21:09:56\n",
      "Accuracy: 0.9899 - Precision: 0.9135 - Recall: 0.5648 - Specificity: 0.9989 - F1: 0.6882 - Loss: 0.0025\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 21:10:04\n",
      "Accuracy: 0.9899 - Precision: 0.9137 - Recall: 0.5653 - Specificity: 0.9989 - F1: 0.6887 - Loss: 0.0025\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 21:10:12\n",
      "Accuracy: 0.9899 - Precision: 0.9138 - Recall: 0.5658 - Specificity: 0.9989 - F1: 0.6891 - Loss: 0.0025\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 21:10:20\n",
      "Accuracy: 0.9899 - Precision: 0.9132 - Recall: 0.5662 - Specificity: 0.9989 - F1: 0.6892 - Loss: 0.0025\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 21:10:29\n",
      "Accuracy: 0.9899 - Precision: 0.9134 - Recall: 0.5667 - Specificity: 0.9989 - F1: 0.6897 - Loss: 0.0025\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 21:10:37\n",
      "Accuracy: 0.9899 - Precision: 0.9138 - Recall: 0.5665 - Specificity: 0.9989 - F1: 0.6897 - Loss: 0.0025\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 21:10:49\n",
      "Accuracy: 0.9900 - Precision: 0.9140 - Recall: 0.5669 - Specificity: 0.9989 - F1: 0.6901 - Loss: 0.0025\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 21:10:57\n",
      "Accuracy: 0.9900 - Precision: 0.9138 - Recall: 0.5668 - Specificity: 0.9989 - F1: 0.6900 - Loss: 0.0025\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 21:11:06\n",
      "Accuracy: 0.9900 - Precision: 0.9140 - Recall: 0.5668 - Specificity: 0.9989 - F1: 0.6901 - Loss: 0.0025\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 21:11:14\n",
      "Accuracy: 0.9899 - Precision: 0.9143 - Recall: 0.5668 - Specificity: 0.9989 - F1: 0.6902 - Loss: 0.0025\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 21:11:22\n",
      "Accuracy: 0.9900 - Precision: 0.9146 - Recall: 0.5672 - Specificity: 0.9989 - F1: 0.6907 - Loss: 0.0025\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 21:11:30\n",
      "Accuracy: 0.9900 - Precision: 0.9147 - Recall: 0.5679 - Specificity: 0.9989 - F1: 0.6912 - Loss: 0.0025\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 21:11:38\n",
      "Accuracy: 0.9900 - Precision: 0.9147 - Recall: 0.5689 - Specificity: 0.9989 - F1: 0.6920 - Loss: 0.0025\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 21:11:46\n",
      "Accuracy: 0.9900 - Precision: 0.9146 - Recall: 0.5700 - Specificity: 0.9989 - F1: 0.6927 - Loss: 0.0025\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 21:11:55\n",
      "Accuracy: 0.9900 - Precision: 0.9142 - Recall: 0.5708 - Specificity: 0.9989 - F1: 0.6931 - Loss: 0.0025\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 21:12:03\n",
      "Accuracy: 0.9901 - Precision: 0.9140 - Recall: 0.5716 - Specificity: 0.9989 - F1: 0.6937 - Loss: 0.0025\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 21:12:11\n",
      "Accuracy: 0.9901 - Precision: 0.9142 - Recall: 0.5721 - Specificity: 0.9989 - F1: 0.6941 - Loss: 0.0025\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 21:12:20\n",
      "Accuracy: 0.9901 - Precision: 0.9141 - Recall: 0.5723 - Specificity: 0.9989 - F1: 0.6942 - Loss: 0.0025\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 21:12:28\n",
      "Accuracy: 0.9901 - Precision: 0.9143 - Recall: 0.5724 - Specificity: 0.9989 - F1: 0.6944 - Loss: 0.0025\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 21:12:36\n",
      "Accuracy: 0.9901 - Precision: 0.9146 - Recall: 0.5726 - Specificity: 0.9989 - F1: 0.6948 - Loss: 0.0025\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 21:12:44\n",
      "Accuracy: 0.9901 - Precision: 0.9145 - Recall: 0.5732 - Specificity: 0.9989 - F1: 0.6952 - Loss: 0.0025\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 21:12:52\n",
      "Accuracy: 0.9901 - Precision: 0.9147 - Recall: 0.5736 - Specificity: 0.9989 - F1: 0.6956 - Loss: 0.0025\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 21:13:01\n",
      "Accuracy: 0.9902 - Precision: 0.9148 - Recall: 0.5741 - Specificity: 0.9989 - F1: 0.6960 - Loss: 0.0025\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 21:13:09\n",
      "Accuracy: 0.9902 - Precision: 0.9146 - Recall: 0.5742 - Specificity: 0.9989 - F1: 0.6961 - Loss: 0.0025\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 21:13:17\n",
      "Accuracy: 0.9901 - Precision: 0.9145 - Recall: 0.5734 - Specificity: 0.9989 - F1: 0.6954 - Loss: 0.0025\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 21:13:25\n",
      "Accuracy: 0.9901 - Precision: 0.9140 - Recall: 0.5727 - Specificity: 0.9989 - F1: 0.6947 - Loss: 0.0025\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 21:13:33\n",
      "Accuracy: 0.9900 - Precision: 0.9138 - Recall: 0.5716 - Specificity: 0.9989 - F1: 0.6938 - Loss: 0.0025\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 21:13:42\n",
      "Accuracy: 0.9900 - Precision: 0.9139 - Recall: 0.5710 - Specificity: 0.9989 - F1: 0.6934 - Loss: 0.0025\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 21:13:50\n",
      "Accuracy: 0.9900 - Precision: 0.9140 - Recall: 0.5707 - Specificity: 0.9989 - F1: 0.6932 - Loss: 0.0025\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 21:13:59\n",
      "Accuracy: 0.9900 - Precision: 0.9141 - Recall: 0.5699 - Specificity: 0.9989 - F1: 0.6925 - Loss: 0.0025\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 21:14:10\n",
      "Accuracy: 0.9899 - Precision: 0.9137 - Recall: 0.5685 - Specificity: 0.9989 - F1: 0.6912 - Loss: 0.0025\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 21:14:23\n",
      "Accuracy: 0.9899 - Precision: 0.9138 - Recall: 0.5683 - Specificity: 0.9989 - F1: 0.6911 - Loss: 0.0025\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 21:14:31\n",
      "Accuracy: 0.9899 - Precision: 0.9136 - Recall: 0.5673 - Specificity: 0.9989 - F1: 0.6903 - Loss: 0.0025\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 21:14:40\n",
      "Accuracy: 0.9899 - Precision: 0.9135 - Recall: 0.5668 - Specificity: 0.9989 - F1: 0.6898 - Loss: 0.0025\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 21:14:48\n",
      "Accuracy: 0.9899 - Precision: 0.9135 - Recall: 0.5668 - Specificity: 0.9989 - F1: 0.6899 - Loss: 0.0025\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 21:14:57\n",
      "Accuracy: 0.9899 - Precision: 0.9136 - Recall: 0.5662 - Specificity: 0.9989 - F1: 0.6894 - Loss: 0.0025\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 21:15:07\n",
      "Accuracy: 0.9898 - Precision: 0.9138 - Recall: 0.5649 - Specificity: 0.9989 - F1: 0.6883 - Loss: 0.0025\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 21:15:18\n",
      "Accuracy: 0.9898 - Precision: 0.9140 - Recall: 0.5641 - Specificity: 0.9989 - F1: 0.6877 - Loss: 0.0025\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 21:15:27\n",
      "Accuracy: 0.9898 - Precision: 0.9142 - Recall: 0.5635 - Specificity: 0.9989 - F1: 0.6873 - Loss: 0.0025\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 21:15:36\n",
      "Accuracy: 0.9898 - Precision: 0.9145 - Recall: 0.5623 - Specificity: 0.9989 - F1: 0.6862 - Loss: 0.0025\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 21:15:45\n",
      "Accuracy: 0.9897 - Precision: 0.9145 - Recall: 0.5615 - Specificity: 0.9989 - F1: 0.6855 - Loss: 0.0025\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 21:15:53\n",
      "Accuracy: 0.9898 - Precision: 0.9145 - Recall: 0.5612 - Specificity: 0.9989 - F1: 0.6853 - Loss: 0.0025\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 21:16:02\n",
      "Accuracy: 0.9897 - Precision: 0.9143 - Recall: 0.5607 - Specificity: 0.9989 - F1: 0.6849 - Loss: 0.0025\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 21:16:12\n",
      "Accuracy: 0.9897 - Precision: 0.9140 - Recall: 0.5600 - Specificity: 0.9989 - F1: 0.6843 - Loss: 0.0026\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 21:16:21\n",
      "Accuracy: 0.9896 - Precision: 0.9138 - Recall: 0.5594 - Specificity: 0.9989 - F1: 0.6838 - Loss: 0.0026\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 21:16:31\n",
      "Accuracy: 0.9895 - Precision: 0.9137 - Recall: 0.5586 - Specificity: 0.9989 - F1: 0.6831 - Loss: 0.0026\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 21:16:39\n",
      "Accuracy: 0.9895 - Precision: 0.9138 - Recall: 0.5578 - Specificity: 0.9989 - F1: 0.6825 - Loss: 0.0026\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 21:16:48\n",
      "Accuracy: 0.9895 - Precision: 0.9138 - Recall: 0.5571 - Specificity: 0.9989 - F1: 0.6819 - Loss: 0.0026\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 21:16:56\n",
      "Accuracy: 0.9894 - Precision: 0.9140 - Recall: 0.5562 - Specificity: 0.9989 - F1: 0.6811 - Loss: 0.0026\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 21:17:05\n",
      "Accuracy: 0.9894 - Precision: 0.9141 - Recall: 0.5558 - Specificity: 0.9989 - F1: 0.6809 - Loss: 0.0026\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 21:17:13\n",
      "Accuracy: 0.9891 - Precision: 0.9136 - Recall: 0.5539 - Specificity: 0.9989 - F1: 0.6787 - Loss: 0.0027\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 21:17:22\n",
      "Accuracy: 0.9889 - Precision: 0.9134 - Recall: 0.5524 - Specificity: 0.9989 - F1: 0.6772 - Loss: 0.0028\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 21:17:30\n",
      "Accuracy: 0.9887 - Precision: 0.9134 - Recall: 0.5512 - Specificity: 0.9989 - F1: 0.6762 - Loss: 0.0028\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 21:17:39\n",
      "Accuracy: 0.9885 - Precision: 0.9131 - Recall: 0.5507 - Specificity: 0.9988 - F1: 0.6757 - Loss: 0.0029\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 21:17:48\n",
      "Accuracy: 0.9883 - Precision: 0.9123 - Recall: 0.5508 - Specificity: 0.9988 - F1: 0.6755 - Loss: 0.0029\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 21:17:57\n",
      "Accuracy: 0.9881 - Precision: 0.9115 - Recall: 0.5503 - Specificity: 0.9987 - F1: 0.6750 - Loss: 0.0030\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 21:18:06\n",
      "Accuracy: 0.9878 - Precision: 0.9110 - Recall: 0.5483 - Specificity: 0.9987 - F1: 0.6727 - Loss: 0.0031\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 21:18:14\n",
      "Accuracy: 0.9876 - Precision: 0.9105 - Recall: 0.5462 - Specificity: 0.9987 - F1: 0.6702 - Loss: 0.0031\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 21:18:23\n",
      "Accuracy: 0.9872 - Precision: 0.9107 - Recall: 0.5441 - Specificity: 0.9987 - F1: 0.6676 - Loss: 0.0032\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 21:18:32\n",
      "Accuracy: 0.9869 - Precision: 0.9109 - Recall: 0.5419 - Specificity: 0.9987 - F1: 0.6649 - Loss: 0.0032\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 21:18:40\n",
      "Accuracy: 0.9866 - Precision: 0.9113 - Recall: 0.5397 - Specificity: 0.9987 - F1: 0.6623 - Loss: 0.0033\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 21:18:49\n",
      "Accuracy: 0.9865 - Precision: 0.9110 - Recall: 0.5376 - Specificity: 0.9987 - F1: 0.6597 - Loss: 0.0033\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 21:18:58\n",
      "Accuracy: 0.9862 - Precision: 0.9109 - Recall: 0.5355 - Specificity: 0.9987 - F1: 0.6571 - Loss: 0.0034\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 21:19:06\n",
      "Accuracy: 0.9861 - Precision: 0.9089 - Recall: 0.5334 - Specificity: 0.9987 - F1: 0.6545 - Loss: 0.0034\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 21:19:15\n",
      "Accuracy: 0.9858 - Precision: 0.9087 - Recall: 0.5313 - Specificity: 0.9987 - F1: 0.6519 - Loss: 0.0034\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 21:19:23\n",
      "Accuracy: 0.9854 - Precision: 0.9086 - Recall: 0.5292 - Specificity: 0.9987 - F1: 0.6494 - Loss: 0.0035\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 21:19:32\n",
      "Accuracy: 0.9851 - Precision: 0.9079 - Recall: 0.5272 - Specificity: 0.9987 - F1: 0.6469 - Loss: 0.0035\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 21:19:41\n",
      "Accuracy: 0.9850 - Precision: 0.9065 - Recall: 0.5252 - Specificity: 0.9988 - F1: 0.6445 - Loss: 0.0036\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 21:19:50\n",
      "Accuracy: 0.9849 - Precision: 0.9047 - Recall: 0.5232 - Specificity: 0.9988 - F1: 0.6421 - Loss: 0.0036\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 21:19:58\n",
      "Accuracy: 0.9849 - Precision: 0.9035 - Recall: 0.5212 - Specificity: 0.9988 - F1: 0.6396 - Loss: 0.0036\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 21:20:07\n",
      "Accuracy: 0.9848 - Precision: 0.9031 - Recall: 0.5192 - Specificity: 0.9988 - F1: 0.6373 - Loss: 0.0037\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 21:20:15\n",
      "Accuracy: 0.9848 - Precision: 0.9033 - Recall: 0.5173 - Specificity: 0.9988 - F1: 0.6349 - Loss: 0.0037\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 21:20:23\n",
      "Accuracy: 0.9847 - Precision: 0.9036 - Recall: 0.5153 - Specificity: 0.9988 - F1: 0.6325 - Loss: 0.0037\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 21:20:32\n",
      "Accuracy: 0.9846 - Precision: 0.9031 - Recall: 0.5134 - Specificity: 0.9988 - F1: 0.6302 - Loss: 0.0038\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 21:20:41\n",
      "Accuracy: 0.9845 - Precision: 0.9031 - Recall: 0.5114 - Specificity: 0.9988 - F1: 0.6278 - Loss: 0.0038\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 21:20:49\n",
      "Accuracy: 0.9845 - Precision: 0.9017 - Recall: 0.5095 - Specificity: 0.9988 - F1: 0.6254 - Loss: 0.0038\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 21:20:58\n",
      "Accuracy: 0.9844 - Precision: 0.9019 - Recall: 0.5076 - Specificity: 0.9988 - F1: 0.6231 - Loss: 0.0038\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 21:21:07\n",
      "Accuracy: 0.9844 - Precision: 0.9022 - Recall: 0.5057 - Specificity: 0.9988 - F1: 0.6208 - Loss: 0.0038\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 21:21:16\n",
      "Accuracy: 0.9843 - Precision: 0.9026 - Recall: 0.5038 - Specificity: 0.9988 - F1: 0.6185 - Loss: 0.0038\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 21:21:24\n",
      "Accuracy: 0.9843 - Precision: 0.9005 - Recall: 0.5019 - Specificity: 0.9988 - F1: 0.6162 - Loss: 0.0039\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 21:21:33\n",
      "Accuracy: 0.9843 - Precision: 0.9008 - Recall: 0.5001 - Specificity: 0.9988 - F1: 0.6139 - Loss: 0.0039\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 21:21:42\n",
      "Accuracy: 0.9842 - Precision: 0.9012 - Recall: 0.4982 - Specificity: 0.9988 - F1: 0.6116 - Loss: 0.0039\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 21:21:51\n",
      "Accuracy: 0.9842 - Precision: 0.9008 - Recall: 0.4964 - Specificity: 0.9988 - F1: 0.6094 - Loss: 0.0039\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 21:21:59\n",
      "Accuracy: 0.9841 - Precision: 0.9011 - Recall: 0.4946 - Specificity: 0.9988 - F1: 0.6072 - Loss: 0.0039\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 21:22:08\n",
      "Accuracy: 0.9841 - Precision: 0.9009 - Recall: 0.4928 - Specificity: 0.9988 - F1: 0.6050 - Loss: 0.0039\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 21:22:16\n",
      "Accuracy: 0.9841 - Precision: 0.8976 - Recall: 0.4910 - Specificity: 0.9988 - F1: 0.6028 - Loss: 0.0039\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 21:22:25\n",
      "Accuracy: 0.9840 - Precision: 0.8980 - Recall: 0.4892 - Specificity: 0.9988 - F1: 0.6006 - Loss: 0.0039\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 21:22:34\n",
      "Accuracy: 0.9840 - Precision: 0.8983 - Recall: 0.4875 - Specificity: 0.9988 - F1: 0.5984 - Loss: 0.0039\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 21:22:43\n",
      "Accuracy: 0.9840 - Precision: 0.8951 - Recall: 0.4857 - Specificity: 0.9988 - F1: 0.5963 - Loss: 0.0039\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 21:22:52\n",
      "Accuracy: 0.9840 - Precision: 0.8955 - Recall: 0.4840 - Specificity: 0.9988 - F1: 0.5941 - Loss: 0.0039\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 21:23:01\n",
      "Accuracy: 0.9840 - Precision: 0.8937 - Recall: 0.4823 - Specificity: 0.9989 - F1: 0.5920 - Loss: 0.0040\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 21:23:09\n",
      "Accuracy: 0.9839 - Precision: 0.8905 - Recall: 0.4805 - Specificity: 0.9989 - F1: 0.5899 - Loss: 0.0040\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 21:23:19\n",
      "Accuracy: 0.9839 - Precision: 0.8898 - Recall: 0.4788 - Specificity: 0.9989 - F1: 0.5878 - Loss: 0.0040\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 21:23:28\n",
      "Accuracy: 0.9839 - Precision: 0.8867 - Recall: 0.4771 - Specificity: 0.9989 - F1: 0.5857 - Loss: 0.0040\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 21:23:37\n",
      "Accuracy: 0.9839 - Precision: 0.8836 - Recall: 0.4755 - Specificity: 0.9989 - F1: 0.5837 - Loss: 0.0040\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 21:23:47\n",
      "Accuracy: 0.9839 - Precision: 0.8829 - Recall: 0.4738 - Specificity: 0.9989 - F1: 0.5816 - Loss: 0.0040\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 21:23:59\n",
      "Accuracy: 0.9839 - Precision: 0.8833 - Recall: 0.4722 - Specificity: 0.9989 - F1: 0.5796 - Loss: 0.0040\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 21:24:08\n",
      "Accuracy: 0.9838 - Precision: 0.8837 - Recall: 0.4705 - Specificity: 0.9989 - F1: 0.5776 - Loss: 0.0040\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 21:24:17\n",
      "Accuracy: 0.9838 - Precision: 0.8841 - Recall: 0.4689 - Specificity: 0.9989 - F1: 0.5756 - Loss: 0.0040\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 21:24:25\n",
      "Accuracy: 0.9837 - Precision: 0.8845 - Recall: 0.4673 - Specificity: 0.9989 - F1: 0.5736 - Loss: 0.0040\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 21:24:34\n",
      "Accuracy: 0.9837 - Precision: 0.8845 - Recall: 0.4657 - Specificity: 0.9989 - F1: 0.5717 - Loss: 0.0040\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 21:24:43\n",
      "Accuracy: 0.9837 - Precision: 0.8841 - Recall: 0.4641 - Specificity: 0.9989 - F1: 0.5697 - Loss: 0.0040\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 21:24:52\n",
      "Accuracy: 0.9836 - Precision: 0.8838 - Recall: 0.4625 - Specificity: 0.9989 - F1: 0.5678 - Loss: 0.0040\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 21:25:00\n",
      "Accuracy: 0.9836 - Precision: 0.8839 - Recall: 0.4610 - Specificity: 0.9989 - F1: 0.5659 - Loss: 0.0040\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 21:25:08\n",
      "Accuracy: 0.9836 - Precision: 0.8842 - Recall: 0.4594 - Specificity: 0.9989 - F1: 0.5641 - Loss: 0.0040\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 21:25:16\n",
      "Accuracy: 0.9835 - Precision: 0.8836 - Recall: 0.4579 - Specificity: 0.9989 - F1: 0.5622 - Loss: 0.0040\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 21:25:25\n",
      "Accuracy: 0.9835 - Precision: 0.8835 - Recall: 0.4564 - Specificity: 0.9989 - F1: 0.5604 - Loss: 0.0040\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 21:25:36\n",
      "Accuracy: 0.9835 - Precision: 0.8839 - Recall: 0.4549 - Specificity: 0.9989 - F1: 0.5586 - Loss: 0.0040\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 21:25:46\n",
      "Accuracy: 0.9834 - Precision: 0.8840 - Recall: 0.4534 - Specificity: 0.9989 - F1: 0.5567 - Loss: 0.0041\n",
      "\n",
      "Epoch 12/20\n",
      "Validation - Accuracy: 0.9789, Precision: 0.9269, Recall: 0.0153, Specificity: 1.0000, F1: 0.0301, Loss: 0.0047\n",
      "\n",
      "\n",
      "Epoch 13/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 21:33:46\n",
      "Accuracy: 0.9743 - Precision: 0.9836 - Recall: 0.0196 - Specificity: 1.0000 - F1: 0.0385 - Loss: 0.0054\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 21:33:55\n",
      "Accuracy: 0.9728 - Precision: 0.9801 - Recall: 0.0220 - Specificity: 1.0000 - F1: 0.0429 - Loss: 0.0057\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 21:34:04\n",
      "Accuracy: 0.9719 - Precision: 0.9800 - Recall: 0.0276 - Specificity: 1.0000 - F1: 0.0536 - Loss: 0.0054\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 21:34:13\n",
      "Accuracy: 0.9749 - Precision: 0.9794 - Recall: 0.0270 - Specificity: 1.0000 - F1: 0.0524 - Loss: 0.0049\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 21:34:22\n",
      "Accuracy: 0.9768 - Precision: 0.9770 - Recall: 0.0277 - Specificity: 1.0000 - F1: 0.0537 - Loss: 0.0046\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 21:34:32\n",
      "Accuracy: 0.9769 - Precision: 0.9809 - Recall: 0.0308 - Specificity: 1.0000 - F1: 0.0595 - Loss: 0.0044\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 21:34:42\n",
      "Accuracy: 0.9783 - Precision: 0.9817 - Recall: 0.0373 - Specificity: 1.0000 - F1: 0.0714 - Loss: 0.0041\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 21:34:51\n",
      "Accuracy: 0.9789 - Precision: 0.9509 - Recall: 0.0391 - Specificity: 0.9999 - F1: 0.0744 - Loss: 0.0040\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 21:35:01\n",
      "Accuracy: 0.9797 - Precision: 0.9551 - Recall: 0.0457 - Specificity: 1.0000 - F1: 0.0860 - Loss: 0.0038\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 21:35:14\n",
      "Accuracy: 0.9801 - Precision: 0.9569 - Recall: 0.0464 - Specificity: 1.0000 - F1: 0.0876 - Loss: 0.0037\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 21:35:25\n",
      "Accuracy: 0.9804 - Precision: 0.9420 - Recall: 0.0529 - Specificity: 0.9999 - F1: 0.0982 - Loss: 0.0037\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 21:35:39\n",
      "Accuracy: 0.9807 - Precision: 0.9465 - Recall: 0.0567 - Specificity: 0.9999 - F1: 0.1050 - Loss: 0.0036\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 21:35:54\n",
      "Accuracy: 0.9809 - Precision: 0.9453 - Recall: 0.0620 - Specificity: 0.9999 - F1: 0.1139 - Loss: 0.0035\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 21:36:10\n",
      "Accuracy: 0.9811 - Precision: 0.9281 - Recall: 0.0657 - Specificity: 0.9999 - F1: 0.1198 - Loss: 0.0035\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 21:36:25\n",
      "Accuracy: 0.9814 - Precision: 0.9327 - Recall: 0.0725 - Specificity: 0.9999 - F1: 0.1309 - Loss: 0.0034\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 21:36:34\n",
      "Accuracy: 0.9811 - Precision: 0.9349 - Recall: 0.0771 - Specificity: 0.9999 - F1: 0.1386 - Loss: 0.0035\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 21:36:43\n",
      "Accuracy: 0.9815 - Precision: 0.9374 - Recall: 0.0869 - Specificity: 0.9999 - F1: 0.1535 - Loss: 0.0034\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 21:36:52\n",
      "Accuracy: 0.9816 - Precision: 0.9401 - Recall: 0.0961 - Specificity: 0.9999 - F1: 0.1672 - Loss: 0.0034\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 21:37:01\n",
      "Accuracy: 0.9818 - Precision: 0.9397 - Recall: 0.1065 - Specificity: 0.9999 - F1: 0.1819 - Loss: 0.0033\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 21:37:10\n",
      "Accuracy: 0.9822 - Precision: 0.9354 - Recall: 0.1206 - Specificity: 0.9998 - F1: 0.1995 - Loss: 0.0033\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 21:37:19\n",
      "Accuracy: 0.9823 - Precision: 0.9303 - Recall: 0.1282 - Specificity: 0.9998 - F1: 0.2100 - Loss: 0.0033\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 21:37:29\n",
      "Accuracy: 0.9821 - Precision: 0.9150 - Recall: 0.1311 - Specificity: 0.9996 - F1: 0.2137 - Loss: 0.0034\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 21:37:38\n",
      "Accuracy: 0.9822 - Precision: 0.9182 - Recall: 0.1375 - Specificity: 0.9996 - F1: 0.2233 - Loss: 0.0033\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 21:37:48\n",
      "Accuracy: 0.9822 - Precision: 0.9201 - Recall: 0.1449 - Specificity: 0.9996 - F1: 0.2337 - Loss: 0.0034\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 21:37:56\n",
      "Accuracy: 0.9823 - Precision: 0.9212 - Recall: 0.1523 - Specificity: 0.9996 - F1: 0.2440 - Loss: 0.0033\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 21:38:05\n",
      "Accuracy: 0.9827 - Precision: 0.9229 - Recall: 0.1631 - Specificity: 0.9996 - F1: 0.2576 - Loss: 0.0033\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 21:38:13\n",
      "Accuracy: 0.9828 - Precision: 0.9245 - Recall: 0.1704 - Specificity: 0.9996 - F1: 0.2674 - Loss: 0.0033\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 21:38:22\n",
      "Accuracy: 0.9828 - Precision: 0.9253 - Recall: 0.1738 - Specificity: 0.9996 - F1: 0.2727 - Loss: 0.0032\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 21:38:30\n",
      "Accuracy: 0.9827 - Precision: 0.9241 - Recall: 0.1781 - Specificity: 0.9996 - F1: 0.2787 - Loss: 0.0033\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 21:38:38\n",
      "Accuracy: 0.9829 - Precision: 0.9251 - Recall: 0.1899 - Specificity: 0.9996 - F1: 0.2922 - Loss: 0.0033\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 21:38:46\n",
      "Accuracy: 0.9832 - Precision: 0.9229 - Recall: 0.2023 - Specificity: 0.9996 - F1: 0.3050 - Loss: 0.0032\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 21:38:55\n",
      "Accuracy: 0.9833 - Precision: 0.9215 - Recall: 0.2097 - Specificity: 0.9995 - F1: 0.3137 - Loss: 0.0033\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 21:39:03\n",
      "Accuracy: 0.9835 - Precision: 0.9216 - Recall: 0.2191 - Specificity: 0.9995 - F1: 0.3244 - Loss: 0.0032\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 21:39:12\n",
      "Accuracy: 0.9835 - Precision: 0.9228 - Recall: 0.2265 - Specificity: 0.9995 - F1: 0.3335 - Loss: 0.0032\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 21:39:21\n",
      "Accuracy: 0.9836 - Precision: 0.9236 - Recall: 0.2312 - Specificity: 0.9995 - F1: 0.3397 - Loss: 0.0032\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 21:39:29\n",
      "Accuracy: 0.9838 - Precision: 0.9240 - Recall: 0.2392 - Specificity: 0.9995 - F1: 0.3489 - Loss: 0.0032\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 21:39:39\n",
      "Accuracy: 0.9840 - Precision: 0.9247 - Recall: 0.2488 - Specificity: 0.9995 - F1: 0.3592 - Loss: 0.0032\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 21:39:48\n",
      "Accuracy: 0.9841 - Precision: 0.9245 - Recall: 0.2560 - Specificity: 0.9995 - F1: 0.3673 - Loss: 0.0031\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 21:39:57\n",
      "Accuracy: 0.9842 - Precision: 0.9249 - Recall: 0.2648 - Specificity: 0.9995 - F1: 0.3766 - Loss: 0.0031\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 21:40:05\n",
      "Accuracy: 0.9844 - Precision: 0.9248 - Recall: 0.2742 - Specificity: 0.9995 - F1: 0.3861 - Loss: 0.0031\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 21:40:13\n",
      "Accuracy: 0.9844 - Precision: 0.9244 - Recall: 0.2795 - Specificity: 0.9995 - F1: 0.3922 - Loss: 0.0031\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 21:40:22\n",
      "Accuracy: 0.9845 - Precision: 0.9250 - Recall: 0.2878 - Specificity: 0.9994 - F1: 0.4009 - Loss: 0.0031\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 21:40:31\n",
      "Accuracy: 0.9847 - Precision: 0.9251 - Recall: 0.2956 - Specificity: 0.9994 - F1: 0.4089 - Loss: 0.0031\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 21:40:39\n",
      "Accuracy: 0.9849 - Precision: 0.9249 - Recall: 0.3044 - Specificity: 0.9994 - F1: 0.4174 - Loss: 0.0031\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 21:40:48\n",
      "Accuracy: 0.9850 - Precision: 0.9200 - Recall: 0.3135 - Specificity: 0.9993 - F1: 0.4239 - Loss: 0.0031\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 21:40:57\n",
      "Accuracy: 0.9851 - Precision: 0.9206 - Recall: 0.3195 - Specificity: 0.9993 - F1: 0.4304 - Loss: 0.0031\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 21:41:06\n",
      "Accuracy: 0.9852 - Precision: 0.9207 - Recall: 0.3242 - Specificity: 0.9993 - F1: 0.4358 - Loss: 0.0031\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 21:41:14\n",
      "Accuracy: 0.9852 - Precision: 0.9213 - Recall: 0.3292 - Specificity: 0.9993 - F1: 0.4415 - Loss: 0.0030\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 21:41:23\n",
      "Accuracy: 0.9853 - Precision: 0.9213 - Recall: 0.3346 - Specificity: 0.9993 - F1: 0.4472 - Loss: 0.0030\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 21:41:31\n",
      "Accuracy: 0.9854 - Precision: 0.9225 - Recall: 0.3403 - Specificity: 0.9993 - F1: 0.4535 - Loss: 0.0030\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 21:41:41\n",
      "Accuracy: 0.9855 - Precision: 0.9227 - Recall: 0.3459 - Specificity: 0.9993 - F1: 0.4592 - Loss: 0.0030\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 21:41:50\n",
      "Accuracy: 0.9856 - Precision: 0.9223 - Recall: 0.3501 - Specificity: 0.9993 - F1: 0.4638 - Loss: 0.0030\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 21:42:00\n",
      "Accuracy: 0.9858 - Precision: 0.9226 - Recall: 0.3555 - Specificity: 0.9993 - F1: 0.4694 - Loss: 0.0030\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 21:42:14\n",
      "Accuracy: 0.9859 - Precision: 0.9232 - Recall: 0.3615 - Specificity: 0.9993 - F1: 0.4754 - Loss: 0.0030\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 21:42:24\n",
      "Accuracy: 0.9860 - Precision: 0.9235 - Recall: 0.3665 - Specificity: 0.9993 - F1: 0.4805 - Loss: 0.0029\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 21:42:34\n",
      "Accuracy: 0.9861 - Precision: 0.9232 - Recall: 0.3730 - Specificity: 0.9993 - F1: 0.4864 - Loss: 0.0029\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 21:42:43\n",
      "Accuracy: 0.9862 - Precision: 0.9228 - Recall: 0.3779 - Specificity: 0.9993 - F1: 0.4912 - Loss: 0.0029\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 21:42:52\n",
      "Accuracy: 0.9863 - Precision: 0.9227 - Recall: 0.3833 - Specificity: 0.9993 - F1: 0.4963 - Loss: 0.0029\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 21:43:00\n",
      "Accuracy: 0.9865 - Precision: 0.9232 - Recall: 0.3882 - Specificity: 0.9993 - F1: 0.5012 - Loss: 0.0029\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 21:43:09\n",
      "Accuracy: 0.9865 - Precision: 0.9217 - Recall: 0.3920 - Specificity: 0.9992 - F1: 0.5047 - Loss: 0.0029\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 21:43:18\n",
      "Accuracy: 0.9866 - Precision: 0.9211 - Recall: 0.3958 - Specificity: 0.9992 - F1: 0.5083 - Loss: 0.0029\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 21:43:27\n",
      "Accuracy: 0.9867 - Precision: 0.9216 - Recall: 0.4000 - Specificity: 0.9992 - F1: 0.5127 - Loss: 0.0028\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 21:43:36\n",
      "Accuracy: 0.9868 - Precision: 0.9223 - Recall: 0.4043 - Specificity: 0.9992 - F1: 0.5171 - Loss: 0.0028\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 21:43:46\n",
      "Accuracy: 0.9869 - Precision: 0.9223 - Recall: 0.4089 - Specificity: 0.9992 - F1: 0.5215 - Loss: 0.0028\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 21:43:55\n",
      "Accuracy: 0.9869 - Precision: 0.9224 - Recall: 0.4127 - Specificity: 0.9992 - F1: 0.5253 - Loss: 0.0028\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 21:44:03\n",
      "Accuracy: 0.9869 - Precision: 0.9222 - Recall: 0.4151 - Specificity: 0.9992 - F1: 0.5279 - Loss: 0.0028\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 21:44:12\n",
      "Accuracy: 0.9869 - Precision: 0.9216 - Recall: 0.4169 - Specificity: 0.9992 - F1: 0.5300 - Loss: 0.0028\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 21:44:20\n",
      "Accuracy: 0.9870 - Precision: 0.9218 - Recall: 0.4194 - Specificity: 0.9992 - F1: 0.5328 - Loss: 0.0028\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 21:44:30\n",
      "Accuracy: 0.9871 - Precision: 0.9221 - Recall: 0.4236 - Specificity: 0.9992 - F1: 0.5368 - Loss: 0.0028\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 21:44:38\n",
      "Accuracy: 0.9872 - Precision: 0.9220 - Recall: 0.4275 - Specificity: 0.9992 - F1: 0.5405 - Loss: 0.0028\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 21:44:46\n",
      "Accuracy: 0.9872 - Precision: 0.9204 - Recall: 0.4309 - Specificity: 0.9992 - F1: 0.5432 - Loss: 0.0028\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 21:44:58\n",
      "Accuracy: 0.9873 - Precision: 0.9190 - Recall: 0.4340 - Specificity: 0.9991 - F1: 0.5457 - Loss: 0.0028\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 21:45:07\n",
      "Accuracy: 0.9873 - Precision: 0.9194 - Recall: 0.4364 - Specificity: 0.9991 - F1: 0.5484 - Loss: 0.0028\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 21:45:15\n",
      "Accuracy: 0.9873 - Precision: 0.9201 - Recall: 0.4377 - Specificity: 0.9991 - F1: 0.5503 - Loss: 0.0028\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 21:45:24\n",
      "Accuracy: 0.9873 - Precision: 0.9204 - Recall: 0.4390 - Specificity: 0.9991 - F1: 0.5521 - Loss: 0.0028\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 21:45:34\n",
      "Accuracy: 0.9873 - Precision: 0.9211 - Recall: 0.4402 - Specificity: 0.9991 - F1: 0.5538 - Loss: 0.0028\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 21:45:43\n",
      "Accuracy: 0.9874 - Precision: 0.9212 - Recall: 0.4419 - Specificity: 0.9991 - F1: 0.5558 - Loss: 0.0028\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 21:45:53\n",
      "Accuracy: 0.9874 - Precision: 0.9219 - Recall: 0.4435 - Specificity: 0.9991 - F1: 0.5579 - Loss: 0.0028\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 21:46:02\n",
      "Accuracy: 0.9874 - Precision: 0.9221 - Recall: 0.4451 - Specificity: 0.9991 - F1: 0.5598 - Loss: 0.0028\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 21:46:11\n",
      "Accuracy: 0.9875 - Precision: 0.9226 - Recall: 0.4476 - Specificity: 0.9991 - F1: 0.5625 - Loss: 0.0028\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 21:46:19\n",
      "Accuracy: 0.9875 - Precision: 0.9225 - Recall: 0.4508 - Specificity: 0.9991 - F1: 0.5654 - Loss: 0.0027\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 21:46:28\n",
      "Accuracy: 0.9876 - Precision: 0.9213 - Recall: 0.4529 - Specificity: 0.9991 - F1: 0.5671 - Loss: 0.0027\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 21:46:36\n",
      "Accuracy: 0.9876 - Precision: 0.9212 - Recall: 0.4553 - Specificity: 0.9991 - F1: 0.5695 - Loss: 0.0027\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 21:46:45\n",
      "Accuracy: 0.9877 - Precision: 0.9205 - Recall: 0.4574 - Specificity: 0.9991 - F1: 0.5714 - Loss: 0.0027\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 21:46:54\n",
      "Accuracy: 0.9877 - Precision: 0.9209 - Recall: 0.4606 - Specificity: 0.9991 - F1: 0.5744 - Loss: 0.0027\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 21:47:03\n",
      "Accuracy: 0.9878 - Precision: 0.9206 - Recall: 0.4625 - Specificity: 0.9991 - F1: 0.5762 - Loss: 0.0027\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 21:47:11\n",
      "Accuracy: 0.9878 - Precision: 0.9209 - Recall: 0.4643 - Specificity: 0.9991 - F1: 0.5782 - Loss: 0.0027\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 21:47:20\n",
      "Accuracy: 0.9878 - Precision: 0.9211 - Recall: 0.4653 - Specificity: 0.9991 - F1: 0.5796 - Loss: 0.0027\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 21:47:29\n",
      "Accuracy: 0.9878 - Precision: 0.9218 - Recall: 0.4661 - Specificity: 0.9991 - F1: 0.5809 - Loss: 0.0027\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 21:47:38\n",
      "Accuracy: 0.9878 - Precision: 0.9224 - Recall: 0.4669 - Specificity: 0.9991 - F1: 0.5821 - Loss: 0.0027\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 21:47:47\n",
      "Accuracy: 0.9879 - Precision: 0.9228 - Recall: 0.4691 - Specificity: 0.9991 - F1: 0.5843 - Loss: 0.0027\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 21:47:58\n",
      "Accuracy: 0.9879 - Precision: 0.9220 - Recall: 0.4720 - Specificity: 0.9991 - F1: 0.5865 - Loss: 0.0027\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 21:48:08\n",
      "Accuracy: 0.9880 - Precision: 0.9215 - Recall: 0.4747 - Specificity: 0.9991 - F1: 0.5887 - Loss: 0.0027\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 21:48:17\n",
      "Accuracy: 0.9880 - Precision: 0.9214 - Recall: 0.4770 - Specificity: 0.9991 - F1: 0.5909 - Loss: 0.0027\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 21:48:26\n",
      "Accuracy: 0.9880 - Precision: 0.9200 - Recall: 0.4791 - Specificity: 0.9990 - F1: 0.5923 - Loss: 0.0027\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 21:48:35\n",
      "Accuracy: 0.9881 - Precision: 0.9198 - Recall: 0.4808 - Specificity: 0.9990 - F1: 0.5940 - Loss: 0.0027\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 21:48:44\n",
      "Accuracy: 0.9881 - Precision: 0.9203 - Recall: 0.4822 - Specificity: 0.9990 - F1: 0.5956 - Loss: 0.0027\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 21:48:52\n",
      "Accuracy: 0.9882 - Precision: 0.9204 - Recall: 0.4836 - Specificity: 0.9990 - F1: 0.5971 - Loss: 0.0027\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 21:49:01\n",
      "Accuracy: 0.9882 - Precision: 0.9201 - Recall: 0.4839 - Specificity: 0.9990 - F1: 0.5977 - Loss: 0.0027\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 21:49:10\n",
      "Accuracy: 0.9882 - Precision: 0.9201 - Recall: 0.4846 - Specificity: 0.9990 - F1: 0.5986 - Loss: 0.0027\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 21:49:19\n",
      "Accuracy: 0.9882 - Precision: 0.9197 - Recall: 0.4840 - Specificity: 0.9990 - F1: 0.5983 - Loss: 0.0026\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 21:49:27\n",
      "Accuracy: 0.9882 - Precision: 0.9178 - Recall: 0.4829 - Specificity: 0.9990 - F1: 0.5973 - Loss: 0.0026\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 21:49:35\n",
      "Accuracy: 0.9883 - Precision: 0.9174 - Recall: 0.4832 - Specificity: 0.9990 - F1: 0.5978 - Loss: 0.0026\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 21:49:44\n",
      "Accuracy: 0.9883 - Precision: 0.9174 - Recall: 0.4830 - Specificity: 0.9990 - F1: 0.5979 - Loss: 0.0026\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 21:49:53\n",
      "Accuracy: 0.9883 - Precision: 0.9165 - Recall: 0.4835 - Specificity: 0.9990 - F1: 0.5984 - Loss: 0.0026\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 21:50:03\n",
      "Accuracy: 0.9883 - Precision: 0.9167 - Recall: 0.4845 - Specificity: 0.9990 - F1: 0.5996 - Loss: 0.0026\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 21:50:12\n",
      "Accuracy: 0.9883 - Precision: 0.9164 - Recall: 0.4846 - Specificity: 0.9990 - F1: 0.5999 - Loss: 0.0026\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 21:50:21\n",
      "Accuracy: 0.9883 - Precision: 0.9154 - Recall: 0.4843 - Specificity: 0.9990 - F1: 0.5998 - Loss: 0.0026\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 21:50:29\n",
      "Accuracy: 0.9884 - Precision: 0.9155 - Recall: 0.4856 - Specificity: 0.9990 - F1: 0.6011 - Loss: 0.0026\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 21:50:37\n",
      "Accuracy: 0.9884 - Precision: 0.9154 - Recall: 0.4872 - Specificity: 0.9990 - F1: 0.6026 - Loss: 0.0026\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 21:50:46\n",
      "Accuracy: 0.9884 - Precision: 0.9151 - Recall: 0.4879 - Specificity: 0.9990 - F1: 0.6033 - Loss: 0.0026\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 21:50:55\n",
      "Accuracy: 0.9885 - Precision: 0.9146 - Recall: 0.4889 - Specificity: 0.9990 - F1: 0.6043 - Loss: 0.0026\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 21:51:04\n",
      "Accuracy: 0.9885 - Precision: 0.9142 - Recall: 0.4904 - Specificity: 0.9990 - F1: 0.6055 - Loss: 0.0026\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 21:51:15\n",
      "Accuracy: 0.9885 - Precision: 0.9144 - Recall: 0.4912 - Specificity: 0.9990 - F1: 0.6066 - Loss: 0.0026\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 21:51:25\n",
      "Accuracy: 0.9885 - Precision: 0.9149 - Recall: 0.4915 - Specificity: 0.9990 - F1: 0.6072 - Loss: 0.0026\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 21:51:33\n",
      "Accuracy: 0.9885 - Precision: 0.9145 - Recall: 0.4916 - Specificity: 0.9990 - F1: 0.6074 - Loss: 0.0026\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 21:51:42\n",
      "Accuracy: 0.9885 - Precision: 0.9147 - Recall: 0.4918 - Specificity: 0.9990 - F1: 0.6080 - Loss: 0.0026\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 21:51:50\n",
      "Accuracy: 0.9886 - Precision: 0.9149 - Recall: 0.4924 - Specificity: 0.9990 - F1: 0.6088 - Loss: 0.0026\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 21:51:59\n",
      "Accuracy: 0.9886 - Precision: 0.9142 - Recall: 0.4934 - Specificity: 0.9990 - F1: 0.6096 - Loss: 0.0026\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 21:52:09\n",
      "Accuracy: 0.9886 - Precision: 0.9133 - Recall: 0.4945 - Specificity: 0.9990 - F1: 0.6104 - Loss: 0.0026\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 21:52:18\n",
      "Accuracy: 0.9886 - Precision: 0.9131 - Recall: 0.4950 - Specificity: 0.9990 - F1: 0.6110 - Loss: 0.0026\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 21:52:26\n",
      "Accuracy: 0.9886 - Precision: 0.9133 - Recall: 0.4954 - Specificity: 0.9990 - F1: 0.6116 - Loss: 0.0026\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 21:52:35\n",
      "Accuracy: 0.9886 - Precision: 0.9138 - Recall: 0.4960 - Specificity: 0.9990 - F1: 0.6125 - Loss: 0.0026\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 21:52:43\n",
      "Accuracy: 0.9886 - Precision: 0.9143 - Recall: 0.4973 - Specificity: 0.9990 - F1: 0.6139 - Loss: 0.0026\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 21:52:52\n",
      "Accuracy: 0.9887 - Precision: 0.9143 - Recall: 0.4984 - Specificity: 0.9990 - F1: 0.6150 - Loss: 0.0026\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 21:53:00\n",
      "Accuracy: 0.9887 - Precision: 0.9145 - Recall: 0.5001 - Specificity: 0.9990 - F1: 0.6165 - Loss: 0.0026\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 21:53:09\n",
      "Accuracy: 0.9887 - Precision: 0.9138 - Recall: 0.5013 - Specificity: 0.9990 - F1: 0.6174 - Loss: 0.0026\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 21:53:17\n",
      "Accuracy: 0.9887 - Precision: 0.9137 - Recall: 0.5022 - Specificity: 0.9990 - F1: 0.6183 - Loss: 0.0026\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 21:53:26\n",
      "Accuracy: 0.9888 - Precision: 0.9140 - Recall: 0.5035 - Specificity: 0.9990 - F1: 0.6196 - Loss: 0.0026\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 21:53:34\n",
      "Accuracy: 0.9888 - Precision: 0.9141 - Recall: 0.5044 - Specificity: 0.9990 - F1: 0.6206 - Loss: 0.0026\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 21:53:43\n",
      "Accuracy: 0.9888 - Precision: 0.9144 - Recall: 0.5050 - Specificity: 0.9990 - F1: 0.6213 - Loss: 0.0026\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 21:53:51\n",
      "Accuracy: 0.9888 - Precision: 0.9143 - Recall: 0.5062 - Specificity: 0.9990 - F1: 0.6224 - Loss: 0.0026\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 21:54:01\n",
      "Accuracy: 0.9888 - Precision: 0.9146 - Recall: 0.5064 - Specificity: 0.9990 - F1: 0.6229 - Loss: 0.0026\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 21:54:10\n",
      "Accuracy: 0.9888 - Precision: 0.9150 - Recall: 0.5073 - Specificity: 0.9990 - F1: 0.6239 - Loss: 0.0026\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 21:54:18\n",
      "Accuracy: 0.9889 - Precision: 0.9152 - Recall: 0.5082 - Specificity: 0.9990 - F1: 0.6249 - Loss: 0.0026\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 21:54:27\n",
      "Accuracy: 0.9889 - Precision: 0.9151 - Recall: 0.5095 - Specificity: 0.9990 - F1: 0.6260 - Loss: 0.0025\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 21:54:36\n",
      "Accuracy: 0.9889 - Precision: 0.9153 - Recall: 0.5107 - Specificity: 0.9990 - F1: 0.6272 - Loss: 0.0025\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 21:54:44\n",
      "Accuracy: 0.9889 - Precision: 0.9152 - Recall: 0.5120 - Specificity: 0.9990 - F1: 0.6283 - Loss: 0.0025\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 21:54:54\n",
      "Accuracy: 0.9890 - Precision: 0.9154 - Recall: 0.5131 - Specificity: 0.9990 - F1: 0.6294 - Loss: 0.0025\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 21:55:04\n",
      "Accuracy: 0.9890 - Precision: 0.9157 - Recall: 0.5148 - Specificity: 0.9990 - F1: 0.6309 - Loss: 0.0025\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 21:55:13\n",
      "Accuracy: 0.9890 - Precision: 0.9157 - Recall: 0.5161 - Specificity: 0.9990 - F1: 0.6320 - Loss: 0.0025\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 21:55:22\n",
      "Accuracy: 0.9890 - Precision: 0.9159 - Recall: 0.5167 - Specificity: 0.9990 - F1: 0.6328 - Loss: 0.0025\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 21:55:30\n",
      "Accuracy: 0.9890 - Precision: 0.9157 - Recall: 0.5175 - Specificity: 0.9990 - F1: 0.6335 - Loss: 0.0025\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 21:55:39\n",
      "Accuracy: 0.9891 - Precision: 0.9157 - Recall: 0.5185 - Specificity: 0.9990 - F1: 0.6344 - Loss: 0.0025\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 21:55:47\n",
      "Accuracy: 0.9891 - Precision: 0.9161 - Recall: 0.5188 - Specificity: 0.9990 - F1: 0.6350 - Loss: 0.0025\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 21:55:56\n",
      "Accuracy: 0.9891 - Precision: 0.9163 - Recall: 0.5196 - Specificity: 0.9990 - F1: 0.6359 - Loss: 0.0025\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 21:56:05\n",
      "Accuracy: 0.9891 - Precision: 0.9167 - Recall: 0.5200 - Specificity: 0.9990 - F1: 0.6364 - Loss: 0.0025\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 21:56:15\n",
      "Accuracy: 0.9891 - Precision: 0.9169 - Recall: 0.5207 - Specificity: 0.9990 - F1: 0.6373 - Loss: 0.0025\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 21:56:24\n",
      "Accuracy: 0.9891 - Precision: 0.9165 - Recall: 0.5190 - Specificity: 0.9990 - F1: 0.6357 - Loss: 0.0025\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 21:56:32\n",
      "Accuracy: 0.9891 - Precision: 0.9167 - Recall: 0.5196 - Specificity: 0.9990 - F1: 0.6364 - Loss: 0.0025\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 21:56:40\n",
      "Accuracy: 0.9891 - Precision: 0.9167 - Recall: 0.5196 - Specificity: 0.9990 - F1: 0.6366 - Loss: 0.0025\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 21:56:49\n",
      "Accuracy: 0.9891 - Precision: 0.9165 - Recall: 0.5203 - Specificity: 0.9990 - F1: 0.6372 - Loss: 0.0025\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 21:56:57\n",
      "Accuracy: 0.9891 - Precision: 0.9166 - Recall: 0.5211 - Specificity: 0.9990 - F1: 0.6380 - Loss: 0.0025\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 21:57:06\n",
      "Accuracy: 0.9891 - Precision: 0.9169 - Recall: 0.5218 - Specificity: 0.9990 - F1: 0.6388 - Loss: 0.0025\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 21:57:15\n",
      "Accuracy: 0.9892 - Precision: 0.9171 - Recall: 0.5226 - Specificity: 0.9990 - F1: 0.6396 - Loss: 0.0025\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 21:57:24\n",
      "Accuracy: 0.9892 - Precision: 0.9174 - Recall: 0.5231 - Specificity: 0.9990 - F1: 0.6403 - Loss: 0.0025\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 21:57:32\n",
      "Accuracy: 0.9892 - Precision: 0.9175 - Recall: 0.5241 - Specificity: 0.9990 - F1: 0.6412 - Loss: 0.0025\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 21:57:41\n",
      "Accuracy: 0.9892 - Precision: 0.9176 - Recall: 0.5252 - Specificity: 0.9990 - F1: 0.6422 - Loss: 0.0025\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 21:57:50\n",
      "Accuracy: 0.9892 - Precision: 0.9179 - Recall: 0.5261 - Specificity: 0.9990 - F1: 0.6432 - Loss: 0.0025\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 21:57:59\n",
      "Accuracy: 0.9893 - Precision: 0.9181 - Recall: 0.5269 - Specificity: 0.9990 - F1: 0.6440 - Loss: 0.0025\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 21:58:09\n",
      "Accuracy: 0.9893 - Precision: 0.9182 - Recall: 0.5275 - Specificity: 0.9990 - F1: 0.6446 - Loss: 0.0025\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 21:58:18\n",
      "Accuracy: 0.9893 - Precision: 0.9183 - Recall: 0.5285 - Specificity: 0.9990 - F1: 0.6455 - Loss: 0.0025\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 21:58:28\n",
      "Accuracy: 0.9893 - Precision: 0.9178 - Recall: 0.5295 - Specificity: 0.9990 - F1: 0.6463 - Loss: 0.0025\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 21:58:38\n",
      "Accuracy: 0.9893 - Precision: 0.9179 - Recall: 0.5303 - Specificity: 0.9990 - F1: 0.6470 - Loss: 0.0025\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 21:58:47\n",
      "Accuracy: 0.9894 - Precision: 0.9181 - Recall: 0.5313 - Specificity: 0.9990 - F1: 0.6480 - Loss: 0.0025\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 21:58:56\n",
      "Accuracy: 0.9894 - Precision: 0.9180 - Recall: 0.5320 - Specificity: 0.9990 - F1: 0.6486 - Loss: 0.0025\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 21:59:04\n",
      "Accuracy: 0.9894 - Precision: 0.9183 - Recall: 0.5325 - Specificity: 0.9990 - F1: 0.6492 - Loss: 0.0025\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 21:59:13\n",
      "Accuracy: 0.9894 - Precision: 0.9186 - Recall: 0.5327 - Specificity: 0.9990 - F1: 0.6496 - Loss: 0.0025\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 21:59:21\n",
      "Accuracy: 0.9894 - Precision: 0.9188 - Recall: 0.5333 - Specificity: 0.9990 - F1: 0.6502 - Loss: 0.0025\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 21:59:30\n",
      "Accuracy: 0.9894 - Precision: 0.9191 - Recall: 0.5339 - Specificity: 0.9990 - F1: 0.6510 - Loss: 0.0025\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 21:59:39\n",
      "Accuracy: 0.9894 - Precision: 0.9194 - Recall: 0.5343 - Specificity: 0.9990 - F1: 0.6515 - Loss: 0.0025\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 21:59:48\n",
      "Accuracy: 0.9894 - Precision: 0.9193 - Recall: 0.5347 - Specificity: 0.9990 - F1: 0.6519 - Loss: 0.0025\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 21:59:58\n",
      "Accuracy: 0.9894 - Precision: 0.9192 - Recall: 0.5353 - Specificity: 0.9990 - F1: 0.6525 - Loss: 0.0025\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 22:00:08\n",
      "Accuracy: 0.9895 - Precision: 0.9192 - Recall: 0.5360 - Specificity: 0.9990 - F1: 0.6531 - Loss: 0.0025\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 22:00:18\n",
      "Accuracy: 0.9895 - Precision: 0.9188 - Recall: 0.5368 - Specificity: 0.9990 - F1: 0.6536 - Loss: 0.0025\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 22:00:26\n",
      "Accuracy: 0.9895 - Precision: 0.9189 - Recall: 0.5378 - Specificity: 0.9990 - F1: 0.6546 - Loss: 0.0025\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 22:00:35\n",
      "Accuracy: 0.9895 - Precision: 0.9189 - Recall: 0.5387 - Specificity: 0.9990 - F1: 0.6553 - Loss: 0.0025\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 22:00:46\n",
      "Accuracy: 0.9895 - Precision: 0.9189 - Recall: 0.5394 - Specificity: 0.9990 - F1: 0.6560 - Loss: 0.0025\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 22:00:55\n",
      "Accuracy: 0.9895 - Precision: 0.9185 - Recall: 0.5399 - Specificity: 0.9990 - F1: 0.6563 - Loss: 0.0025\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 22:01:04\n",
      "Accuracy: 0.9895 - Precision: 0.9188 - Recall: 0.5401 - Specificity: 0.9990 - F1: 0.6567 - Loss: 0.0025\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 22:01:12\n",
      "Accuracy: 0.9895 - Precision: 0.9191 - Recall: 0.5399 - Specificity: 0.9990 - F1: 0.6568 - Loss: 0.0025\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 22:01:21\n",
      "Accuracy: 0.9895 - Precision: 0.9195 - Recall: 0.5397 - Specificity: 0.9990 - F1: 0.6568 - Loss: 0.0024\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 22:01:30\n",
      "Accuracy: 0.9895 - Precision: 0.9197 - Recall: 0.5394 - Specificity: 0.9990 - F1: 0.6568 - Loss: 0.0024\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 22:01:38\n",
      "Accuracy: 0.9895 - Precision: 0.9199 - Recall: 0.5391 - Specificity: 0.9990 - F1: 0.6567 - Loss: 0.0024\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 22:01:47\n",
      "Accuracy: 0.9896 - Precision: 0.9198 - Recall: 0.5394 - Specificity: 0.9990 - F1: 0.6571 - Loss: 0.0024\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 22:01:55\n",
      "Accuracy: 0.9896 - Precision: 0.9198 - Recall: 0.5397 - Specificity: 0.9990 - F1: 0.6574 - Loss: 0.0024\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 22:02:04\n",
      "Accuracy: 0.9896 - Precision: 0.9199 - Recall: 0.5400 - Specificity: 0.9990 - F1: 0.6578 - Loss: 0.0024\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 22:02:13\n",
      "Accuracy: 0.9896 - Precision: 0.9199 - Recall: 0.5408 - Specificity: 0.9990 - F1: 0.6584 - Loss: 0.0024\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 22:02:22\n",
      "Accuracy: 0.9896 - Precision: 0.9198 - Recall: 0.5417 - Specificity: 0.9990 - F1: 0.6592 - Loss: 0.0024\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 22:02:30\n",
      "Accuracy: 0.9896 - Precision: 0.9198 - Recall: 0.5425 - Specificity: 0.9990 - F1: 0.6599 - Loss: 0.0024\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 22:02:39\n",
      "Accuracy: 0.9896 - Precision: 0.9199 - Recall: 0.5433 - Specificity: 0.9990 - F1: 0.6606 - Loss: 0.0024\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 22:02:48\n",
      "Accuracy: 0.9896 - Precision: 0.9199 - Recall: 0.5440 - Specificity: 0.9990 - F1: 0.6613 - Loss: 0.0024\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 22:02:57\n",
      "Accuracy: 0.9896 - Precision: 0.9192 - Recall: 0.5447 - Specificity: 0.9990 - F1: 0.6616 - Loss: 0.0024\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 22:03:05\n",
      "Accuracy: 0.9897 - Precision: 0.9193 - Recall: 0.5453 - Specificity: 0.9990 - F1: 0.6621 - Loss: 0.0024\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 22:03:14\n",
      "Accuracy: 0.9897 - Precision: 0.9197 - Recall: 0.5454 - Specificity: 0.9990 - F1: 0.6624 - Loss: 0.0024\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 22:03:23\n",
      "Accuracy: 0.9897 - Precision: 0.9198 - Recall: 0.5460 - Specificity: 0.9990 - F1: 0.6630 - Loss: 0.0024\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 22:03:31\n",
      "Accuracy: 0.9897 - Precision: 0.9197 - Recall: 0.5461 - Specificity: 0.9990 - F1: 0.6632 - Loss: 0.0024\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 22:03:40\n",
      "Accuracy: 0.9897 - Precision: 0.9199 - Recall: 0.5461 - Specificity: 0.9990 - F1: 0.6634 - Loss: 0.0024\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 22:03:48\n",
      "Accuracy: 0.9897 - Precision: 0.9201 - Recall: 0.5463 - Specificity: 0.9990 - F1: 0.6637 - Loss: 0.0024\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 22:03:57\n",
      "Accuracy: 0.9897 - Precision: 0.9204 - Recall: 0.5469 - Specificity: 0.9990 - F1: 0.6643 - Loss: 0.0024\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 22:04:06\n",
      "Accuracy: 0.9897 - Precision: 0.9205 - Recall: 0.5474 - Specificity: 0.9990 - F1: 0.6649 - Loss: 0.0024\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 22:04:16\n",
      "Accuracy: 0.9898 - Precision: 0.9206 - Recall: 0.5486 - Specificity: 0.9990 - F1: 0.6658 - Loss: 0.0024\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 22:04:24\n",
      "Accuracy: 0.9898 - Precision: 0.9206 - Recall: 0.5497 - Specificity: 0.9990 - F1: 0.6667 - Loss: 0.0024\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 22:04:33\n",
      "Accuracy: 0.9898 - Precision: 0.9200 - Recall: 0.5508 - Specificity: 0.9990 - F1: 0.6672 - Loss: 0.0024\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 22:04:41\n",
      "Accuracy: 0.9898 - Precision: 0.9198 - Recall: 0.5519 - Specificity: 0.9990 - F1: 0.6680 - Loss: 0.0024\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 22:04:50\n",
      "Accuracy: 0.9898 - Precision: 0.9199 - Recall: 0.5528 - Specificity: 0.9990 - F1: 0.6688 - Loss: 0.0024\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 22:04:58\n",
      "Accuracy: 0.9899 - Precision: 0.9195 - Recall: 0.5536 - Specificity: 0.9990 - F1: 0.6693 - Loss: 0.0024\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 22:05:07\n",
      "Accuracy: 0.9899 - Precision: 0.9195 - Recall: 0.5545 - Specificity: 0.9990 - F1: 0.6700 - Loss: 0.0024\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 22:05:16\n",
      "Accuracy: 0.9899 - Precision: 0.9198 - Recall: 0.5550 - Specificity: 0.9990 - F1: 0.6706 - Loss: 0.0024\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 22:05:25\n",
      "Accuracy: 0.9899 - Precision: 0.9197 - Recall: 0.5554 - Specificity: 0.9990 - F1: 0.6709 - Loss: 0.0024\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 22:05:34\n",
      "Accuracy: 0.9899 - Precision: 0.9200 - Recall: 0.5553 - Specificity: 0.9990 - F1: 0.6711 - Loss: 0.0024\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 22:05:42\n",
      "Accuracy: 0.9899 - Precision: 0.9202 - Recall: 0.5556 - Specificity: 0.9990 - F1: 0.6715 - Loss: 0.0024\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 22:05:51\n",
      "Accuracy: 0.9899 - Precision: 0.9203 - Recall: 0.5553 - Specificity: 0.9990 - F1: 0.6714 - Loss: 0.0024\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 22:06:00\n",
      "Accuracy: 0.9899 - Precision: 0.9202 - Recall: 0.5544 - Specificity: 0.9990 - F1: 0.6706 - Loss: 0.0024\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 22:06:10\n",
      "Accuracy: 0.9899 - Precision: 0.9199 - Recall: 0.5539 - Specificity: 0.9990 - F1: 0.6703 - Loss: 0.0024\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 22:06:20\n",
      "Accuracy: 0.9898 - Precision: 0.9195 - Recall: 0.5534 - Specificity: 0.9990 - F1: 0.6699 - Loss: 0.0024\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 22:06:30\n",
      "Accuracy: 0.9898 - Precision: 0.9194 - Recall: 0.5533 - Specificity: 0.9990 - F1: 0.6698 - Loss: 0.0024\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 22:06:39\n",
      "Accuracy: 0.9898 - Precision: 0.9194 - Recall: 0.5533 - Specificity: 0.9990 - F1: 0.6699 - Loss: 0.0024\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 22:06:49\n",
      "Accuracy: 0.9898 - Precision: 0.9192 - Recall: 0.5529 - Specificity: 0.9990 - F1: 0.6696 - Loss: 0.0024\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 22:06:59\n",
      "Accuracy: 0.9897 - Precision: 0.9188 - Recall: 0.5520 - Specificity: 0.9990 - F1: 0.6688 - Loss: 0.0024\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 22:07:08\n",
      "Accuracy: 0.9897 - Precision: 0.9188 - Recall: 0.5521 - Specificity: 0.9990 - F1: 0.6690 - Loss: 0.0024\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 22:07:17\n",
      "Accuracy: 0.9897 - Precision: 0.9188 - Recall: 0.5514 - Specificity: 0.9990 - F1: 0.6685 - Loss: 0.0024\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 22:07:25\n",
      "Accuracy: 0.9897 - Precision: 0.9186 - Recall: 0.5509 - Specificity: 0.9990 - F1: 0.6682 - Loss: 0.0024\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 22:07:34\n",
      "Accuracy: 0.9897 - Precision: 0.9187 - Recall: 0.5510 - Specificity: 0.9990 - F1: 0.6683 - Loss: 0.0024\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 22:07:42\n",
      "Accuracy: 0.9897 - Precision: 0.9188 - Recall: 0.5503 - Specificity: 0.9990 - F1: 0.6679 - Loss: 0.0024\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 22:07:51\n",
      "Accuracy: 0.9896 - Precision: 0.9190 - Recall: 0.5494 - Specificity: 0.9990 - F1: 0.6671 - Loss: 0.0024\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 22:08:00\n",
      "Accuracy: 0.9896 - Precision: 0.9192 - Recall: 0.5487 - Specificity: 0.9990 - F1: 0.6666 - Loss: 0.0024\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 22:08:09\n",
      "Accuracy: 0.9896 - Precision: 0.9194 - Recall: 0.5483 - Specificity: 0.9990 - F1: 0.6665 - Loss: 0.0024\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 22:08:20\n",
      "Accuracy: 0.9896 - Precision: 0.9196 - Recall: 0.5473 - Specificity: 0.9990 - F1: 0.6657 - Loss: 0.0025\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 22:08:29\n",
      "Accuracy: 0.9896 - Precision: 0.9197 - Recall: 0.5466 - Specificity: 0.9990 - F1: 0.6651 - Loss: 0.0025\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 22:08:37\n",
      "Accuracy: 0.9896 - Precision: 0.9197 - Recall: 0.5464 - Specificity: 0.9990 - F1: 0.6651 - Loss: 0.0025\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 22:08:45\n",
      "Accuracy: 0.9896 - Precision: 0.9194 - Recall: 0.5458 - Specificity: 0.9990 - F1: 0.6646 - Loss: 0.0025\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 22:08:53\n",
      "Accuracy: 0.9895 - Precision: 0.9191 - Recall: 0.5453 - Specificity: 0.9990 - F1: 0.6641 - Loss: 0.0025\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 22:09:01\n",
      "Accuracy: 0.9895 - Precision: 0.9190 - Recall: 0.5449 - Specificity: 0.9990 - F1: 0.6638 - Loss: 0.0025\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 22:09:09\n",
      "Accuracy: 0.9894 - Precision: 0.9189 - Recall: 0.5441 - Specificity: 0.9990 - F1: 0.6633 - Loss: 0.0025\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 22:09:18\n",
      "Accuracy: 0.9894 - Precision: 0.9188 - Recall: 0.5436 - Specificity: 0.9990 - F1: 0.6629 - Loss: 0.0025\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 22:09:27\n",
      "Accuracy: 0.9893 - Precision: 0.9188 - Recall: 0.5433 - Specificity: 0.9990 - F1: 0.6627 - Loss: 0.0025\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 22:09:38\n",
      "Accuracy: 0.9893 - Precision: 0.9188 - Recall: 0.5426 - Specificity: 0.9990 - F1: 0.6622 - Loss: 0.0025\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 22:09:46\n",
      "Accuracy: 0.9893 - Precision: 0.9189 - Recall: 0.5424 - Specificity: 0.9990 - F1: 0.6621 - Loss: 0.0025\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 22:09:55\n",
      "Accuracy: 0.9889 - Precision: 0.9187 - Recall: 0.5403 - Specificity: 0.9990 - F1: 0.6597 - Loss: 0.0027\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 22:10:04\n",
      "Accuracy: 0.9888 - Precision: 0.9186 - Recall: 0.5386 - Specificity: 0.9990 - F1: 0.6579 - Loss: 0.0027\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 22:10:13\n",
      "Accuracy: 0.9885 - Precision: 0.9186 - Recall: 0.5374 - Specificity: 0.9990 - F1: 0.6568 - Loss: 0.0028\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 22:10:24\n",
      "Accuracy: 0.9883 - Precision: 0.9184 - Recall: 0.5365 - Specificity: 0.9989 - F1: 0.6560 - Loss: 0.0028\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 22:10:32\n",
      "Accuracy: 0.9881 - Precision: 0.9178 - Recall: 0.5361 - Specificity: 0.9989 - F1: 0.6556 - Loss: 0.0029\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 22:10:41\n",
      "Accuracy: 0.9879 - Precision: 0.9168 - Recall: 0.5361 - Specificity: 0.9988 - F1: 0.6553 - Loss: 0.0030\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 22:10:50\n",
      "Accuracy: 0.9877 - Precision: 0.9163 - Recall: 0.5352 - Specificity: 0.9988 - F1: 0.6545 - Loss: 0.0030\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 22:10:58\n",
      "Accuracy: 0.9875 - Precision: 0.9153 - Recall: 0.5339 - Specificity: 0.9988 - F1: 0.6532 - Loss: 0.0031\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 22:11:07\n",
      "Accuracy: 0.9872 - Precision: 0.9154 - Recall: 0.5322 - Specificity: 0.9988 - F1: 0.6513 - Loss: 0.0031\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 22:11:15\n",
      "Accuracy: 0.9869 - Precision: 0.9150 - Recall: 0.5303 - Specificity: 0.9988 - F1: 0.6492 - Loss: 0.0032\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 22:11:23\n",
      "Accuracy: 0.9866 - Precision: 0.9153 - Recall: 0.5285 - Specificity: 0.9988 - F1: 0.6472 - Loss: 0.0033\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 22:11:31\n",
      "Accuracy: 0.9865 - Precision: 0.9146 - Recall: 0.5267 - Specificity: 0.9988 - F1: 0.6452 - Loss: 0.0033\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 22:11:40\n",
      "Accuracy: 0.9862 - Precision: 0.9136 - Recall: 0.5248 - Specificity: 0.9988 - F1: 0.6429 - Loss: 0.0033\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 22:11:49\n",
      "Accuracy: 0.9861 - Precision: 0.9126 - Recall: 0.5229 - Specificity: 0.9988 - F1: 0.6407 - Loss: 0.0034\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 22:11:58\n",
      "Accuracy: 0.9858 - Precision: 0.9121 - Recall: 0.5210 - Specificity: 0.9988 - F1: 0.6385 - Loss: 0.0034\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 22:12:06\n",
      "Accuracy: 0.9854 - Precision: 0.9116 - Recall: 0.5191 - Specificity: 0.9988 - F1: 0.6363 - Loss: 0.0035\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 22:12:17\n",
      "Accuracy: 0.9852 - Precision: 0.9116 - Recall: 0.5173 - Specificity: 0.9988 - F1: 0.6342 - Loss: 0.0035\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 22:12:27\n",
      "Accuracy: 0.9850 - Precision: 0.9104 - Recall: 0.5158 - Specificity: 0.9988 - F1: 0.6326 - Loss: 0.0035\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 22:12:36\n",
      "Accuracy: 0.9849 - Precision: 0.9084 - Recall: 0.5139 - Specificity: 0.9988 - F1: 0.6304 - Loss: 0.0036\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 22:12:44\n",
      "Accuracy: 0.9849 - Precision: 0.9085 - Recall: 0.5122 - Specificity: 0.9988 - F1: 0.6284 - Loss: 0.0036\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 22:12:51\n",
      "Accuracy: 0.9849 - Precision: 0.9086 - Recall: 0.5107 - Specificity: 0.9988 - F1: 0.6269 - Loss: 0.0036\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 22:13:00\n",
      "Accuracy: 0.9849 - Precision: 0.9084 - Recall: 0.5091 - Specificity: 0.9988 - F1: 0.6252 - Loss: 0.0036\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 22:13:08\n",
      "Accuracy: 0.9848 - Precision: 0.9087 - Recall: 0.5079 - Specificity: 0.9988 - F1: 0.6240 - Loss: 0.0037\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 22:13:16\n",
      "Accuracy: 0.9847 - Precision: 0.9083 - Recall: 0.5063 - Specificity: 0.9988 - F1: 0.6223 - Loss: 0.0037\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 22:13:24\n",
      "Accuracy: 0.9846 - Precision: 0.9085 - Recall: 0.5047 - Specificity: 0.9988 - F1: 0.6205 - Loss: 0.0037\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 22:13:32\n",
      "Accuracy: 0.9846 - Precision: 0.9075 - Recall: 0.5029 - Specificity: 0.9988 - F1: 0.6183 - Loss: 0.0037\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 22:13:41\n",
      "Accuracy: 0.9845 - Precision: 0.9078 - Recall: 0.5010 - Specificity: 0.9988 - F1: 0.6160 - Loss: 0.0038\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 22:13:49\n",
      "Accuracy: 0.9845 - Precision: 0.9081 - Recall: 0.4992 - Specificity: 0.9988 - F1: 0.6138 - Loss: 0.0038\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 22:13:57\n",
      "Accuracy: 0.9844 - Precision: 0.9081 - Recall: 0.4976 - Specificity: 0.9988 - F1: 0.6120 - Loss: 0.0038\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 22:14:05\n",
      "Accuracy: 0.9844 - Precision: 0.9069 - Recall: 0.4963 - Specificity: 0.9988 - F1: 0.6106 - Loss: 0.0038\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 22:14:13\n",
      "Accuracy: 0.9844 - Precision: 0.9068 - Recall: 0.4950 - Specificity: 0.9988 - F1: 0.6092 - Loss: 0.0038\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 22:14:21\n",
      "Accuracy: 0.9844 - Precision: 0.9069 - Recall: 0.4934 - Specificity: 0.9988 - F1: 0.6075 - Loss: 0.0038\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 22:14:32\n",
      "Accuracy: 0.9843 - Precision: 0.9070 - Recall: 0.4918 - Specificity: 0.9988 - F1: 0.6057 - Loss: 0.0038\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 22:14:40\n",
      "Accuracy: 0.9843 - Precision: 0.9073 - Recall: 0.4902 - Specificity: 0.9988 - F1: 0.6038 - Loss: 0.0038\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 22:14:48\n",
      "Accuracy: 0.9843 - Precision: 0.9075 - Recall: 0.4886 - Specificity: 0.9988 - F1: 0.6019 - Loss: 0.0038\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 22:14:57\n",
      "Accuracy: 0.9842 - Precision: 0.9057 - Recall: 0.4869 - Specificity: 0.9988 - F1: 0.5998 - Loss: 0.0039\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 22:15:05\n",
      "Accuracy: 0.9842 - Precision: 0.9057 - Recall: 0.4853 - Specificity: 0.9988 - F1: 0.5979 - Loss: 0.0039\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 22:15:14\n",
      "Accuracy: 0.9842 - Precision: 0.9026 - Recall: 0.4835 - Specificity: 0.9988 - F1: 0.5958 - Loss: 0.0039\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 22:15:23\n",
      "Accuracy: 0.9841 - Precision: 0.9029 - Recall: 0.4818 - Specificity: 0.9988 - F1: 0.5937 - Loss: 0.0039\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 22:15:32\n",
      "Accuracy: 0.9841 - Precision: 0.9031 - Recall: 0.4802 - Specificity: 0.9988 - F1: 0.5918 - Loss: 0.0039\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 22:15:41\n",
      "Accuracy: 0.9841 - Precision: 0.9018 - Recall: 0.4787 - Specificity: 0.9988 - F1: 0.5901 - Loss: 0.0039\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 22:15:50\n",
      "Accuracy: 0.9841 - Precision: 0.8997 - Recall: 0.4770 - Specificity: 0.9988 - F1: 0.5880 - Loss: 0.0039\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 22:15:58\n",
      "Accuracy: 0.9841 - Precision: 0.8998 - Recall: 0.4754 - Specificity: 0.9988 - F1: 0.5861 - Loss: 0.0039\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 22:16:07\n",
      "Accuracy: 0.9841 - Precision: 0.8984 - Recall: 0.4737 - Specificity: 0.9988 - F1: 0.5841 - Loss: 0.0039\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 22:16:16\n",
      "Accuracy: 0.9841 - Precision: 0.8952 - Recall: 0.4721 - Specificity: 0.9988 - F1: 0.5820 - Loss: 0.0039\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 22:16:24\n",
      "Accuracy: 0.9841 - Precision: 0.8956 - Recall: 0.4704 - Specificity: 0.9988 - F1: 0.5800 - Loss: 0.0039\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 22:16:34\n",
      "Accuracy: 0.9840 - Precision: 0.8956 - Recall: 0.4688 - Specificity: 0.9989 - F1: 0.5780 - Loss: 0.0039\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 22:16:43\n",
      "Accuracy: 0.9839 - Precision: 0.8958 - Recall: 0.4672 - Specificity: 0.9989 - F1: 0.5761 - Loss: 0.0039\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 22:16:52\n",
      "Accuracy: 0.9839 - Precision: 0.8958 - Recall: 0.4656 - Specificity: 0.9989 - F1: 0.5742 - Loss: 0.0039\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 22:17:00\n",
      "Accuracy: 0.9839 - Precision: 0.8959 - Recall: 0.4641 - Specificity: 0.9989 - F1: 0.5722 - Loss: 0.0039\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 22:17:09\n",
      "Accuracy: 0.9839 - Precision: 0.8958 - Recall: 0.4625 - Specificity: 0.9989 - F1: 0.5704 - Loss: 0.0040\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 22:17:18\n",
      "Accuracy: 0.9838 - Precision: 0.8960 - Recall: 0.4610 - Specificity: 0.9989 - F1: 0.5685 - Loss: 0.0040\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 22:17:26\n",
      "Accuracy: 0.9838 - Precision: 0.8957 - Recall: 0.4595 - Specificity: 0.9989 - F1: 0.5668 - Loss: 0.0040\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 22:17:35\n",
      "Accuracy: 0.9838 - Precision: 0.8957 - Recall: 0.4582 - Specificity: 0.9989 - F1: 0.5653 - Loss: 0.0040\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 22:17:44\n",
      "Accuracy: 0.9837 - Precision: 0.8960 - Recall: 0.4568 - Specificity: 0.9989 - F1: 0.5637 - Loss: 0.0040\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 22:17:52\n",
      "Accuracy: 0.9837 - Precision: 0.8956 - Recall: 0.4554 - Specificity: 0.9989 - F1: 0.5620 - Loss: 0.0040\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 22:18:01\n",
      "Accuracy: 0.9837 - Precision: 0.8956 - Recall: 0.4541 - Specificity: 0.9989 - F1: 0.5606 - Loss: 0.0040\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 22:18:10\n",
      "Accuracy: 0.9837 - Precision: 0.8958 - Recall: 0.4528 - Specificity: 0.9989 - F1: 0.5592 - Loss: 0.0040\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 22:18:18\n",
      "Accuracy: 0.9836 - Precision: 0.8959 - Recall: 0.4514 - Specificity: 0.9989 - F1: 0.5576 - Loss: 0.0040\n",
      "\n",
      "Epoch 13/20\n",
      "Validation - Accuracy: 0.9799, Precision: 0.9288, Recall: 0.0667, Specificity: 0.9999, F1: 0.1239, Loss: 0.0047\n",
      "\n",
      "\n",
      "Epoch 14/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 22:26:57\n",
      "Accuracy: 0.9753 - Precision: 0.9799 - Recall: 0.0619 - Specificity: 1.0000 - F1: 0.1165 - Loss: 0.0055\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 22:27:06\n",
      "Accuracy: 0.9743 - Precision: 0.9862 - Recall: 0.0744 - Specificity: 1.0000 - F1: 0.1382 - Loss: 0.0057\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 22:27:15\n",
      "Accuracy: 0.9738 - Precision: 0.9862 - Recall: 0.0935 - Specificity: 1.0000 - F1: 0.1695 - Loss: 0.0053\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 22:27:24\n",
      "Accuracy: 0.9767 - Precision: 0.9867 - Recall: 0.1030 - Specificity: 1.0000 - F1: 0.1852 - Loss: 0.0047\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 22:27:33\n",
      "Accuracy: 0.9787 - Precision: 0.9698 - Recall: 0.1175 - Specificity: 0.9999 - F1: 0.2069 - Loss: 0.0044\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 22:27:42\n",
      "Accuracy: 0.9792 - Precision: 0.9736 - Recall: 0.1373 - Specificity: 0.9999 - F1: 0.2361 - Loss: 0.0042\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 22:27:50\n",
      "Accuracy: 0.9807 - Precision: 0.9726 - Recall: 0.1601 - Specificity: 0.9999 - F1: 0.2673 - Loss: 0.0040\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 22:27:59\n",
      "Accuracy: 0.9815 - Precision: 0.9440 - Recall: 0.1859 - Specificity: 0.9996 - F1: 0.2952 - Loss: 0.0039\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 22:28:08\n",
      "Accuracy: 0.9826 - Precision: 0.9456 - Recall: 0.2170 - Specificity: 0.9996 - F1: 0.3321 - Loss: 0.0037\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 22:28:16\n",
      "Accuracy: 0.9831 - Precision: 0.9467 - Recall: 0.2230 - Specificity: 0.9997 - F1: 0.3418 - Loss: 0.0036\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 22:28:24\n",
      "Accuracy: 0.9836 - Precision: 0.9359 - Recall: 0.2472 - Specificity: 0.9995 - F1: 0.3667 - Loss: 0.0035\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 22:28:35\n",
      "Accuracy: 0.9842 - Precision: 0.9397 - Recall: 0.2674 - Specificity: 0.9995 - F1: 0.3905 - Loss: 0.0034\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 22:28:45\n",
      "Accuracy: 0.9846 - Precision: 0.9393 - Recall: 0.2831 - Specificity: 0.9995 - F1: 0.4087 - Loss: 0.0034\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 22:28:55\n",
      "Accuracy: 0.9847 - Precision: 0.9186 - Recall: 0.2887 - Specificity: 0.9993 - F1: 0.4127 - Loss: 0.0034\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 22:29:03\n",
      "Accuracy: 0.9850 - Precision: 0.9215 - Recall: 0.2999 - Specificity: 0.9993 - F1: 0.4265 - Loss: 0.0033\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 22:29:11\n",
      "Accuracy: 0.9848 - Precision: 0.9231 - Recall: 0.3031 - Specificity: 0.9994 - F1: 0.4318 - Loss: 0.0034\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 22:29:20\n",
      "Accuracy: 0.9853 - Precision: 0.9245 - Recall: 0.3201 - Specificity: 0.9994 - F1: 0.4493 - Loss: 0.0033\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 22:29:29\n",
      "Accuracy: 0.9855 - Precision: 0.9264 - Recall: 0.3324 - Specificity: 0.9994 - F1: 0.4627 - Loss: 0.0033\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 22:29:38\n",
      "Accuracy: 0.9858 - Precision: 0.9261 - Recall: 0.3447 - Specificity: 0.9993 - F1: 0.4753 - Loss: 0.0032\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 22:29:46\n",
      "Accuracy: 0.9861 - Precision: 0.9210 - Recall: 0.3600 - Specificity: 0.9993 - F1: 0.4879 - Loss: 0.0032\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 22:29:55\n",
      "Accuracy: 0.9862 - Precision: 0.9150 - Recall: 0.3680 - Specificity: 0.9992 - F1: 0.4949 - Loss: 0.0032\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 22:30:04\n",
      "Accuracy: 0.9858 - Precision: 0.8989 - Recall: 0.3662 - Specificity: 0.9989 - F1: 0.4912 - Loss: 0.0034\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 22:30:12\n",
      "Accuracy: 0.9859 - Precision: 0.9028 - Recall: 0.3682 - Specificity: 0.9990 - F1: 0.4952 - Loss: 0.0033\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 22:30:21\n",
      "Accuracy: 0.9858 - Precision: 0.9060 - Recall: 0.3667 - Specificity: 0.9990 - F1: 0.4952 - Loss: 0.0033\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 22:30:30\n",
      "Accuracy: 0.9858 - Precision: 0.9090 - Recall: 0.3642 - Specificity: 0.9990 - F1: 0.4939 - Loss: 0.0033\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 22:30:40\n",
      "Accuracy: 0.9859 - Precision: 0.9110 - Recall: 0.3652 - Specificity: 0.9991 - F1: 0.4963 - Loss: 0.0033\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 22:30:49\n",
      "Accuracy: 0.9859 - Precision: 0.9140 - Recall: 0.3612 - Specificity: 0.9991 - F1: 0.4931 - Loss: 0.0032\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 22:30:58\n",
      "Accuracy: 0.9857 - Precision: 0.9160 - Recall: 0.3543 - Specificity: 0.9991 - F1: 0.4856 - Loss: 0.0033\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 22:31:09\n",
      "Accuracy: 0.9854 - Precision: 0.9161 - Recall: 0.3485 - Specificity: 0.9991 - F1: 0.4796 - Loss: 0.0033\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 22:31:17\n",
      "Accuracy: 0.9854 - Precision: 0.9178 - Recall: 0.3490 - Specificity: 0.9992 - F1: 0.4812 - Loss: 0.0033\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 22:31:25\n",
      "Accuracy: 0.9855 - Precision: 0.9179 - Recall: 0.3500 - Specificity: 0.9992 - F1: 0.4831 - Loss: 0.0033\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 22:31:33\n",
      "Accuracy: 0.9855 - Precision: 0.9183 - Recall: 0.3484 - Specificity: 0.9992 - F1: 0.4821 - Loss: 0.0033\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 22:31:41\n",
      "Accuracy: 0.9855 - Precision: 0.9191 - Recall: 0.3492 - Specificity: 0.9992 - F1: 0.4837 - Loss: 0.0033\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 22:31:49\n",
      "Accuracy: 0.9854 - Precision: 0.9208 - Recall: 0.3482 - Specificity: 0.9992 - F1: 0.4836 - Loss: 0.0032\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 22:31:57\n",
      "Accuracy: 0.9854 - Precision: 0.9219 - Recall: 0.3465 - Specificity: 0.9992 - F1: 0.4825 - Loss: 0.0032\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 22:32:05\n",
      "Accuracy: 0.9855 - Precision: 0.9220 - Recall: 0.3477 - Specificity: 0.9992 - F1: 0.4842 - Loss: 0.0032\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 22:32:13\n",
      "Accuracy: 0.9855 - Precision: 0.9233 - Recall: 0.3510 - Specificity: 0.9992 - F1: 0.4883 - Loss: 0.0032\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 22:32:21\n",
      "Accuracy: 0.9855 - Precision: 0.9235 - Recall: 0.3523 - Specificity: 0.9992 - F1: 0.4902 - Loss: 0.0032\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 22:32:29\n",
      "Accuracy: 0.9856 - Precision: 0.9246 - Recall: 0.3547 - Specificity: 0.9992 - F1: 0.4932 - Loss: 0.0032\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 22:32:37\n",
      "Accuracy: 0.9856 - Precision: 0.9248 - Recall: 0.3597 - Specificity: 0.9992 - F1: 0.4983 - Loss: 0.0032\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 22:32:45\n",
      "Accuracy: 0.9856 - Precision: 0.9247 - Recall: 0.3607 - Specificity: 0.9992 - F1: 0.4998 - Loss: 0.0032\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 22:32:53\n",
      "Accuracy: 0.9857 - Precision: 0.9254 - Recall: 0.3664 - Specificity: 0.9992 - F1: 0.5054 - Loss: 0.0032\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 22:33:01\n",
      "Accuracy: 0.9858 - Precision: 0.9251 - Recall: 0.3721 - Specificity: 0.9992 - F1: 0.5107 - Loss: 0.0032\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 22:33:10\n",
      "Accuracy: 0.9859 - Precision: 0.9246 - Recall: 0.3790 - Specificity: 0.9992 - F1: 0.5166 - Loss: 0.0031\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 22:33:17\n",
      "Accuracy: 0.9860 - Precision: 0.9188 - Recall: 0.3860 - Specificity: 0.9991 - F1: 0.5202 - Loss: 0.0031\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 22:33:27\n",
      "Accuracy: 0.9861 - Precision: 0.9194 - Recall: 0.3908 - Specificity: 0.9991 - F1: 0.5250 - Loss: 0.0031\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 22:33:36\n",
      "Accuracy: 0.9861 - Precision: 0.9195 - Recall: 0.3941 - Specificity: 0.9991 - F1: 0.5284 - Loss: 0.0031\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 22:33:44\n",
      "Accuracy: 0.9862 - Precision: 0.9201 - Recall: 0.3972 - Specificity: 0.9991 - F1: 0.5318 - Loss: 0.0031\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 22:33:52\n",
      "Accuracy: 0.9863 - Precision: 0.9202 - Recall: 0.4016 - Specificity: 0.9991 - F1: 0.5360 - Loss: 0.0031\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 22:34:00\n",
      "Accuracy: 0.9863 - Precision: 0.9214 - Recall: 0.4061 - Specificity: 0.9991 - F1: 0.5406 - Loss: 0.0031\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 22:34:08\n",
      "Accuracy: 0.9865 - Precision: 0.9213 - Recall: 0.4112 - Specificity: 0.9991 - F1: 0.5450 - Loss: 0.0031\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 22:34:16\n",
      "Accuracy: 0.9865 - Precision: 0.9208 - Recall: 0.4145 - Specificity: 0.9991 - F1: 0.5482 - Loss: 0.0031\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 22:34:24\n",
      "Accuracy: 0.9867 - Precision: 0.9206 - Recall: 0.4199 - Specificity: 0.9991 - F1: 0.5528 - Loss: 0.0030\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 22:34:32\n",
      "Accuracy: 0.9868 - Precision: 0.9208 - Recall: 0.4260 - Specificity: 0.9991 - F1: 0.5579 - Loss: 0.0030\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 22:34:40\n",
      "Accuracy: 0.9869 - Precision: 0.9206 - Recall: 0.4307 - Specificity: 0.9991 - F1: 0.5620 - Loss: 0.0030\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 22:34:48\n",
      "Accuracy: 0.9870 - Precision: 0.9197 - Recall: 0.4372 - Specificity: 0.9991 - F1: 0.5668 - Loss: 0.0030\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 22:34:56\n",
      "Accuracy: 0.9871 - Precision: 0.9189 - Recall: 0.4416 - Specificity: 0.9990 - F1: 0.5704 - Loss: 0.0030\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 22:35:04\n",
      "Accuracy: 0.9872 - Precision: 0.9187 - Recall: 0.4462 - Specificity: 0.9990 - F1: 0.5742 - Loss: 0.0029\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 22:35:12\n",
      "Accuracy: 0.9873 - Precision: 0.9191 - Recall: 0.4499 - Specificity: 0.9990 - F1: 0.5777 - Loss: 0.0029\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 22:35:20\n",
      "Accuracy: 0.9873 - Precision: 0.9180 - Recall: 0.4525 - Specificity: 0.9990 - F1: 0.5799 - Loss: 0.0029\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 22:35:28\n",
      "Accuracy: 0.9874 - Precision: 0.9176 - Recall: 0.4549 - Specificity: 0.9990 - F1: 0.5821 - Loss: 0.0029\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 22:35:36\n",
      "Accuracy: 0.9875 - Precision: 0.9183 - Recall: 0.4577 - Specificity: 0.9990 - F1: 0.5850 - Loss: 0.0029\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 22:35:44\n",
      "Accuracy: 0.9875 - Precision: 0.9191 - Recall: 0.4612 - Specificity: 0.9990 - F1: 0.5883 - Loss: 0.0029\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 22:35:52\n",
      "Accuracy: 0.9876 - Precision: 0.9192 - Recall: 0.4650 - Specificity: 0.9990 - F1: 0.5917 - Loss: 0.0029\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 22:35:59\n",
      "Accuracy: 0.9877 - Precision: 0.9194 - Recall: 0.4680 - Specificity: 0.9990 - F1: 0.5945 - Loss: 0.0029\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 22:36:07\n",
      "Accuracy: 0.9877 - Precision: 0.9193 - Recall: 0.4696 - Specificity: 0.9990 - F1: 0.5962 - Loss: 0.0029\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 22:36:15\n",
      "Accuracy: 0.9877 - Precision: 0.9186 - Recall: 0.4715 - Specificity: 0.9990 - F1: 0.5978 - Loss: 0.0029\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 22:36:23\n",
      "Accuracy: 0.9877 - Precision: 0.9187 - Recall: 0.4733 - Specificity: 0.9990 - F1: 0.5996 - Loss: 0.0029\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 22:36:31\n",
      "Accuracy: 0.9878 - Precision: 0.9191 - Recall: 0.4762 - Specificity: 0.9990 - F1: 0.6024 - Loss: 0.0028\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 22:36:39\n",
      "Accuracy: 0.9879 - Precision: 0.9194 - Recall: 0.4791 - Specificity: 0.9990 - F1: 0.6051 - Loss: 0.0028\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 22:36:47\n",
      "Accuracy: 0.9879 - Precision: 0.9174 - Recall: 0.4815 - Specificity: 0.9990 - F1: 0.6065 - Loss: 0.0028\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 22:36:55\n",
      "Accuracy: 0.9879 - Precision: 0.9160 - Recall: 0.4834 - Specificity: 0.9989 - F1: 0.6079 - Loss: 0.0028\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 22:37:03\n",
      "Accuracy: 0.9879 - Precision: 0.9166 - Recall: 0.4847 - Specificity: 0.9989 - F1: 0.6094 - Loss: 0.0028\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 22:37:11\n",
      "Accuracy: 0.9879 - Precision: 0.9173 - Recall: 0.4853 - Specificity: 0.9990 - F1: 0.6104 - Loss: 0.0028\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 22:37:19\n",
      "Accuracy: 0.9879 - Precision: 0.9177 - Recall: 0.4858 - Specificity: 0.9990 - F1: 0.6113 - Loss: 0.0028\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 22:37:27\n",
      "Accuracy: 0.9880 - Precision: 0.9183 - Recall: 0.4869 - Specificity: 0.9990 - F1: 0.6126 - Loss: 0.0028\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 22:37:35\n",
      "Accuracy: 0.9880 - Precision: 0.9183 - Recall: 0.4881 - Specificity: 0.9990 - F1: 0.6139 - Loss: 0.0028\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 22:37:43\n",
      "Accuracy: 0.9880 - Precision: 0.9190 - Recall: 0.4893 - Specificity: 0.9990 - F1: 0.6153 - Loss: 0.0028\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 22:37:51\n",
      "Accuracy: 0.9880 - Precision: 0.9191 - Recall: 0.4902 - Specificity: 0.9990 - F1: 0.6164 - Loss: 0.0028\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 22:37:59\n",
      "Accuracy: 0.9881 - Precision: 0.9197 - Recall: 0.4923 - Specificity: 0.9990 - F1: 0.6185 - Loss: 0.0028\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 22:38:07\n",
      "Accuracy: 0.9881 - Precision: 0.9197 - Recall: 0.4946 - Specificity: 0.9990 - F1: 0.6205 - Loss: 0.0028\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 22:38:15\n",
      "Accuracy: 0.9882 - Precision: 0.9193 - Recall: 0.4958 - Specificity: 0.9990 - F1: 0.6216 - Loss: 0.0028\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 22:38:23\n",
      "Accuracy: 0.9882 - Precision: 0.9192 - Recall: 0.4974 - Specificity: 0.9990 - F1: 0.6231 - Loss: 0.0028\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 22:38:31\n",
      "Accuracy: 0.9882 - Precision: 0.9185 - Recall: 0.4989 - Specificity: 0.9990 - F1: 0.6243 - Loss: 0.0028\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 22:38:39\n",
      "Accuracy: 0.9883 - Precision: 0.9189 - Recall: 0.5017 - Specificity: 0.9990 - F1: 0.6267 - Loss: 0.0028\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 22:38:46\n",
      "Accuracy: 0.9883 - Precision: 0.9186 - Recall: 0.5035 - Specificity: 0.9990 - F1: 0.6282 - Loss: 0.0027\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 22:38:54\n",
      "Accuracy: 0.9884 - Precision: 0.9190 - Recall: 0.5054 - Specificity: 0.9990 - F1: 0.6300 - Loss: 0.0027\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 22:39:02\n",
      "Accuracy: 0.9884 - Precision: 0.9191 - Recall: 0.5067 - Specificity: 0.9990 - F1: 0.6313 - Loss: 0.0027\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 22:39:10\n",
      "Accuracy: 0.9884 - Precision: 0.9198 - Recall: 0.5076 - Specificity: 0.9990 - F1: 0.6325 - Loss: 0.0027\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 22:39:18\n",
      "Accuracy: 0.9884 - Precision: 0.9203 - Recall: 0.5082 - Specificity: 0.9990 - F1: 0.6334 - Loss: 0.0027\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 22:39:26\n",
      "Accuracy: 0.9884 - Precision: 0.9206 - Recall: 0.5094 - Specificity: 0.9990 - F1: 0.6346 - Loss: 0.0027\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 22:39:34\n",
      "Accuracy: 0.9885 - Precision: 0.9202 - Recall: 0.5111 - Specificity: 0.9990 - F1: 0.6360 - Loss: 0.0027\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 22:39:42\n",
      "Accuracy: 0.9885 - Precision: 0.9199 - Recall: 0.5133 - Specificity: 0.9990 - F1: 0.6376 - Loss: 0.0027\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 22:39:50\n",
      "Accuracy: 0.9886 - Precision: 0.9197 - Recall: 0.5155 - Specificity: 0.9990 - F1: 0.6394 - Loss: 0.0027\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 22:39:58\n",
      "Accuracy: 0.9886 - Precision: 0.9185 - Recall: 0.5178 - Specificity: 0.9989 - F1: 0.6408 - Loss: 0.0027\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 22:40:06\n",
      "Accuracy: 0.9886 - Precision: 0.9182 - Recall: 0.5193 - Specificity: 0.9989 - F1: 0.6420 - Loss: 0.0027\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 22:40:14\n",
      "Accuracy: 0.9887 - Precision: 0.9186 - Recall: 0.5207 - Specificity: 0.9989 - F1: 0.6433 - Loss: 0.0027\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 22:40:22\n",
      "Accuracy: 0.9887 - Precision: 0.9184 - Recall: 0.5222 - Specificity: 0.9989 - F1: 0.6447 - Loss: 0.0027\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 22:40:30\n",
      "Accuracy: 0.9887 - Precision: 0.9183 - Recall: 0.5228 - Specificity: 0.9989 - F1: 0.6453 - Loss: 0.0027\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 22:40:38\n",
      "Accuracy: 0.9888 - Precision: 0.9182 - Recall: 0.5238 - Specificity: 0.9989 - F1: 0.6462 - Loss: 0.0027\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 22:40:46\n",
      "Accuracy: 0.9888 - Precision: 0.9180 - Recall: 0.5238 - Specificity: 0.9989 - F1: 0.6464 - Loss: 0.0027\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 22:40:54\n",
      "Accuracy: 0.9888 - Precision: 0.9165 - Recall: 0.5233 - Specificity: 0.9989 - F1: 0.6458 - Loss: 0.0027\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 22:41:02\n",
      "Accuracy: 0.9889 - Precision: 0.9162 - Recall: 0.5237 - Specificity: 0.9989 - F1: 0.6462 - Loss: 0.0026\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 22:41:10\n",
      "Accuracy: 0.9888 - Precision: 0.9163 - Recall: 0.5237 - Specificity: 0.9989 - F1: 0.6464 - Loss: 0.0026\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 22:41:18\n",
      "Accuracy: 0.9889 - Precision: 0.9154 - Recall: 0.5241 - Specificity: 0.9989 - F1: 0.6466 - Loss: 0.0026\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 22:41:26\n",
      "Accuracy: 0.9889 - Precision: 0.9155 - Recall: 0.5248 - Specificity: 0.9989 - F1: 0.6474 - Loss: 0.0026\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 22:41:34\n",
      "Accuracy: 0.9889 - Precision: 0.9151 - Recall: 0.5245 - Specificity: 0.9989 - F1: 0.6472 - Loss: 0.0026\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 22:41:42\n",
      "Accuracy: 0.9889 - Precision: 0.9145 - Recall: 0.5243 - Specificity: 0.9989 - F1: 0.6471 - Loss: 0.0026\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 22:41:50\n",
      "Accuracy: 0.9889 - Precision: 0.9145 - Recall: 0.5254 - Specificity: 0.9989 - F1: 0.6481 - Loss: 0.0026\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 22:41:57\n",
      "Accuracy: 0.9890 - Precision: 0.9144 - Recall: 0.5270 - Specificity: 0.9989 - F1: 0.6493 - Loss: 0.0026\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 22:42:05\n",
      "Accuracy: 0.9890 - Precision: 0.9137 - Recall: 0.5275 - Specificity: 0.9989 - F1: 0.6497 - Loss: 0.0026\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 22:42:13\n",
      "Accuracy: 0.9890 - Precision: 0.9134 - Recall: 0.5284 - Specificity: 0.9989 - F1: 0.6505 - Loss: 0.0026\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 22:42:21\n",
      "Accuracy: 0.9891 - Precision: 0.9132 - Recall: 0.5295 - Specificity: 0.9989 - F1: 0.6514 - Loss: 0.0026\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 22:42:29\n",
      "Accuracy: 0.9891 - Precision: 0.9136 - Recall: 0.5301 - Specificity: 0.9989 - F1: 0.6521 - Loss: 0.0026\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 22:42:37\n",
      "Accuracy: 0.9891 - Precision: 0.9141 - Recall: 0.5304 - Specificity: 0.9989 - F1: 0.6526 - Loss: 0.0026\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 22:42:45\n",
      "Accuracy: 0.9891 - Precision: 0.9139 - Recall: 0.5306 - Specificity: 0.9989 - F1: 0.6529 - Loss: 0.0026\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 22:42:53\n",
      "Accuracy: 0.9891 - Precision: 0.9142 - Recall: 0.5303 - Specificity: 0.9989 - F1: 0.6529 - Loss: 0.0026\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 22:43:03\n",
      "Accuracy: 0.9891 - Precision: 0.9144 - Recall: 0.5302 - Specificity: 0.9989 - F1: 0.6530 - Loss: 0.0026\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 22:43:11\n",
      "Accuracy: 0.9891 - Precision: 0.9139 - Recall: 0.5309 - Specificity: 0.9989 - F1: 0.6536 - Loss: 0.0026\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 22:43:19\n",
      "Accuracy: 0.9891 - Precision: 0.9133 - Recall: 0.5318 - Specificity: 0.9989 - F1: 0.6542 - Loss: 0.0026\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 22:43:27\n",
      "Accuracy: 0.9892 - Precision: 0.9131 - Recall: 0.5322 - Specificity: 0.9989 - F1: 0.6545 - Loss: 0.0026\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 22:43:35\n",
      "Accuracy: 0.9892 - Precision: 0.9134 - Recall: 0.5324 - Specificity: 0.9989 - F1: 0.6549 - Loss: 0.0026\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 22:43:44\n",
      "Accuracy: 0.9891 - Precision: 0.9137 - Recall: 0.5328 - Specificity: 0.9989 - F1: 0.6554 - Loss: 0.0026\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 22:43:51\n",
      "Accuracy: 0.9892 - Precision: 0.9141 - Recall: 0.5340 - Specificity: 0.9989 - F1: 0.6566 - Loss: 0.0026\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 22:43:59\n",
      "Accuracy: 0.9892 - Precision: 0.9139 - Recall: 0.5351 - Specificity: 0.9989 - F1: 0.6575 - Loss: 0.0026\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 22:44:07\n",
      "Accuracy: 0.9892 - Precision: 0.9140 - Recall: 0.5367 - Specificity: 0.9989 - F1: 0.6588 - Loss: 0.0026\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 22:44:15\n",
      "Accuracy: 0.9893 - Precision: 0.9131 - Recall: 0.5379 - Specificity: 0.9989 - F1: 0.6594 - Loss: 0.0026\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 22:44:23\n",
      "Accuracy: 0.9893 - Precision: 0.9130 - Recall: 0.5386 - Specificity: 0.9989 - F1: 0.6601 - Loss: 0.0026\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 22:44:31\n",
      "Accuracy: 0.9893 - Precision: 0.9134 - Recall: 0.5397 - Specificity: 0.9989 - F1: 0.6611 - Loss: 0.0026\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 22:44:39\n",
      "Accuracy: 0.9893 - Precision: 0.9136 - Recall: 0.5400 - Specificity: 0.9989 - F1: 0.6615 - Loss: 0.0026\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 22:44:47\n",
      "Accuracy: 0.9893 - Precision: 0.9140 - Recall: 0.5401 - Specificity: 0.9989 - F1: 0.6619 - Loss: 0.0026\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 22:44:55\n",
      "Accuracy: 0.9893 - Precision: 0.9140 - Recall: 0.5408 - Specificity: 0.9989 - F1: 0.6625 - Loss: 0.0026\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 22:45:03\n",
      "Accuracy: 0.9893 - Precision: 0.9144 - Recall: 0.5406 - Specificity: 0.9989 - F1: 0.6626 - Loss: 0.0026\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 22:45:10\n",
      "Accuracy: 0.9893 - Precision: 0.9148 - Recall: 0.5409 - Specificity: 0.9989 - F1: 0.6630 - Loss: 0.0026\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 22:45:18\n",
      "Accuracy: 0.9893 - Precision: 0.9152 - Recall: 0.5415 - Specificity: 0.9989 - F1: 0.6638 - Loss: 0.0026\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 22:45:26\n",
      "Accuracy: 0.9894 - Precision: 0.9151 - Recall: 0.5424 - Specificity: 0.9989 - F1: 0.6645 - Loss: 0.0026\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 22:45:34\n",
      "Accuracy: 0.9894 - Precision: 0.9154 - Recall: 0.5433 - Specificity: 0.9989 - F1: 0.6654 - Loss: 0.0025\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 22:45:42\n",
      "Accuracy: 0.9894 - Precision: 0.9156 - Recall: 0.5444 - Specificity: 0.9989 - F1: 0.6664 - Loss: 0.0025\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 22:45:50\n",
      "Accuracy: 0.9894 - Precision: 0.9157 - Recall: 0.5452 - Specificity: 0.9989 - F1: 0.6671 - Loss: 0.0025\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 22:45:58\n",
      "Accuracy: 0.9895 - Precision: 0.9159 - Recall: 0.5468 - Specificity: 0.9989 - F1: 0.6684 - Loss: 0.0025\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 22:46:05\n",
      "Accuracy: 0.9895 - Precision: 0.9160 - Recall: 0.5480 - Specificity: 0.9989 - F1: 0.6693 - Loss: 0.0025\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 22:46:13\n",
      "Accuracy: 0.9895 - Precision: 0.9161 - Recall: 0.5486 - Specificity: 0.9989 - F1: 0.6700 - Loss: 0.0025\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 22:46:21\n",
      "Accuracy: 0.9895 - Precision: 0.9160 - Recall: 0.5492 - Specificity: 0.9989 - F1: 0.6705 - Loss: 0.0025\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 22:46:29\n",
      "Accuracy: 0.9895 - Precision: 0.9160 - Recall: 0.5501 - Specificity: 0.9989 - F1: 0.6713 - Loss: 0.0025\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 22:46:37\n",
      "Accuracy: 0.9895 - Precision: 0.9164 - Recall: 0.5503 - Specificity: 0.9989 - F1: 0.6717 - Loss: 0.0025\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 22:46:45\n",
      "Accuracy: 0.9896 - Precision: 0.9165 - Recall: 0.5511 - Specificity: 0.9989 - F1: 0.6724 - Loss: 0.0025\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 22:46:52\n",
      "Accuracy: 0.9896 - Precision: 0.9169 - Recall: 0.5513 - Specificity: 0.9989 - F1: 0.6728 - Loss: 0.0025\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 22:47:00\n",
      "Accuracy: 0.9896 - Precision: 0.9171 - Recall: 0.5520 - Specificity: 0.9989 - F1: 0.6735 - Loss: 0.0025\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 22:47:09\n",
      "Accuracy: 0.9896 - Precision: 0.9169 - Recall: 0.5502 - Specificity: 0.9989 - F1: 0.6719 - Loss: 0.0025\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 22:47:17\n",
      "Accuracy: 0.9896 - Precision: 0.9170 - Recall: 0.5507 - Specificity: 0.9989 - F1: 0.6724 - Loss: 0.0025\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 22:47:25\n",
      "Accuracy: 0.9896 - Precision: 0.9170 - Recall: 0.5508 - Specificity: 0.9989 - F1: 0.6725 - Loss: 0.0025\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 22:47:32\n",
      "Accuracy: 0.9896 - Precision: 0.9170 - Recall: 0.5512 - Specificity: 0.9989 - F1: 0.6729 - Loss: 0.0025\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 22:47:40\n",
      "Accuracy: 0.9896 - Precision: 0.9171 - Recall: 0.5518 - Specificity: 0.9989 - F1: 0.6735 - Loss: 0.0025\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 22:47:48\n",
      "Accuracy: 0.9896 - Precision: 0.9174 - Recall: 0.5526 - Specificity: 0.9989 - F1: 0.6743 - Loss: 0.0025\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 22:47:56\n",
      "Accuracy: 0.9896 - Precision: 0.9176 - Recall: 0.5532 - Specificity: 0.9989 - F1: 0.6749 - Loss: 0.0025\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 22:48:04\n",
      "Accuracy: 0.9896 - Precision: 0.9178 - Recall: 0.5536 - Specificity: 0.9989 - F1: 0.6754 - Loss: 0.0025\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 22:48:12\n",
      "Accuracy: 0.9896 - Precision: 0.9180 - Recall: 0.5543 - Specificity: 0.9989 - F1: 0.6760 - Loss: 0.0025\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 22:48:20\n",
      "Accuracy: 0.9897 - Precision: 0.9181 - Recall: 0.5552 - Specificity: 0.9989 - F1: 0.6768 - Loss: 0.0025\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 22:48:28\n",
      "Accuracy: 0.9897 - Precision: 0.9184 - Recall: 0.5559 - Specificity: 0.9989 - F1: 0.6775 - Loss: 0.0025\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 22:48:36\n",
      "Accuracy: 0.9897 - Precision: 0.9186 - Recall: 0.5566 - Specificity: 0.9989 - F1: 0.6782 - Loss: 0.0025\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 22:48:44\n",
      "Accuracy: 0.9897 - Precision: 0.9187 - Recall: 0.5572 - Specificity: 0.9989 - F1: 0.6787 - Loss: 0.0025\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 22:48:52\n",
      "Accuracy: 0.9897 - Precision: 0.9188 - Recall: 0.5579 - Specificity: 0.9989 - F1: 0.6794 - Loss: 0.0025\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 22:48:59\n",
      "Accuracy: 0.9898 - Precision: 0.9183 - Recall: 0.5587 - Specificity: 0.9989 - F1: 0.6798 - Loss: 0.0025\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 22:49:09\n",
      "Accuracy: 0.9898 - Precision: 0.9185 - Recall: 0.5589 - Specificity: 0.9989 - F1: 0.6801 - Loss: 0.0025\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 22:49:17\n",
      "Accuracy: 0.9898 - Precision: 0.9187 - Recall: 0.5595 - Specificity: 0.9989 - F1: 0.6808 - Loss: 0.0025\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 22:49:25\n",
      "Accuracy: 0.9898 - Precision: 0.9188 - Recall: 0.5599 - Specificity: 0.9989 - F1: 0.6812 - Loss: 0.0025\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 22:49:33\n",
      "Accuracy: 0.9898 - Precision: 0.9191 - Recall: 0.5600 - Specificity: 0.9989 - F1: 0.6814 - Loss: 0.0025\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 22:49:40\n",
      "Accuracy: 0.9898 - Precision: 0.9195 - Recall: 0.5601 - Specificity: 0.9989 - F1: 0.6817 - Loss: 0.0025\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 22:49:48\n",
      "Accuracy: 0.9898 - Precision: 0.9196 - Recall: 0.5604 - Specificity: 0.9989 - F1: 0.6820 - Loss: 0.0025\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 22:49:56\n",
      "Accuracy: 0.9898 - Precision: 0.9199 - Recall: 0.5608 - Specificity: 0.9989 - F1: 0.6825 - Loss: 0.0025\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 22:50:04\n",
      "Accuracy: 0.9899 - Precision: 0.9201 - Recall: 0.5612 - Specificity: 0.9990 - F1: 0.6829 - Loss: 0.0025\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 22:50:12\n",
      "Accuracy: 0.9899 - Precision: 0.9201 - Recall: 0.5617 - Specificity: 0.9989 - F1: 0.6834 - Loss: 0.0025\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 22:50:19\n",
      "Accuracy: 0.9899 - Precision: 0.9200 - Recall: 0.5622 - Specificity: 0.9989 - F1: 0.6838 - Loss: 0.0025\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 22:50:27\n",
      "Accuracy: 0.9899 - Precision: 0.9200 - Recall: 0.5626 - Specificity: 0.9989 - F1: 0.6842 - Loss: 0.0025\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 22:50:35\n",
      "Accuracy: 0.9899 - Precision: 0.9197 - Recall: 0.5631 - Specificity: 0.9989 - F1: 0.6845 - Loss: 0.0025\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 22:50:43\n",
      "Accuracy: 0.9899 - Precision: 0.9199 - Recall: 0.5640 - Specificity: 0.9989 - F1: 0.6853 - Loss: 0.0025\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 22:50:51\n",
      "Accuracy: 0.9899 - Precision: 0.9198 - Recall: 0.5649 - Specificity: 0.9989 - F1: 0.6860 - Loss: 0.0025\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 22:50:59\n",
      "Accuracy: 0.9899 - Precision: 0.9198 - Recall: 0.5656 - Specificity: 0.9989 - F1: 0.6865 - Loss: 0.0025\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 22:51:08\n",
      "Accuracy: 0.9899 - Precision: 0.9195 - Recall: 0.5659 - Specificity: 0.9989 - F1: 0.6867 - Loss: 0.0025\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 22:51:17\n",
      "Accuracy: 0.9899 - Precision: 0.9197 - Recall: 0.5660 - Specificity: 0.9989 - F1: 0.6869 - Loss: 0.0024\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 22:51:24\n",
      "Accuracy: 0.9899 - Precision: 0.9198 - Recall: 0.5659 - Specificity: 0.9989 - F1: 0.6870 - Loss: 0.0024\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 22:51:32\n",
      "Accuracy: 0.9899 - Precision: 0.9202 - Recall: 0.5658 - Specificity: 0.9989 - F1: 0.6871 - Loss: 0.0024\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 22:51:40\n",
      "Accuracy: 0.9899 - Precision: 0.9204 - Recall: 0.5654 - Specificity: 0.9989 - F1: 0.6869 - Loss: 0.0024\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 22:51:48\n",
      "Accuracy: 0.9899 - Precision: 0.9205 - Recall: 0.5651 - Specificity: 0.9989 - F1: 0.6867 - Loss: 0.0024\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 22:51:56\n",
      "Accuracy: 0.9900 - Precision: 0.9206 - Recall: 0.5653 - Specificity: 0.9990 - F1: 0.6869 - Loss: 0.0024\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 22:52:04\n",
      "Accuracy: 0.9900 - Precision: 0.9207 - Recall: 0.5656 - Specificity: 0.9990 - F1: 0.6873 - Loss: 0.0024\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 22:52:12\n",
      "Accuracy: 0.9900 - Precision: 0.9207 - Recall: 0.5659 - Specificity: 0.9990 - F1: 0.6876 - Loss: 0.0024\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 22:52:20\n",
      "Accuracy: 0.9900 - Precision: 0.9205 - Recall: 0.5667 - Specificity: 0.9989 - F1: 0.6881 - Loss: 0.0024\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 22:52:28\n",
      "Accuracy: 0.9900 - Precision: 0.9204 - Recall: 0.5676 - Specificity: 0.9989 - F1: 0.6888 - Loss: 0.0024\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 22:52:35\n",
      "Accuracy: 0.9900 - Precision: 0.9206 - Recall: 0.5682 - Specificity: 0.9989 - F1: 0.6894 - Loss: 0.0024\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 22:52:43\n",
      "Accuracy: 0.9900 - Precision: 0.9208 - Recall: 0.5687 - Specificity: 0.9989 - F1: 0.6899 - Loss: 0.0024\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 22:52:51\n",
      "Accuracy: 0.9900 - Precision: 0.9208 - Recall: 0.5690 - Specificity: 0.9989 - F1: 0.6902 - Loss: 0.0024\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 22:52:59\n",
      "Accuracy: 0.9900 - Precision: 0.9202 - Recall: 0.5695 - Specificity: 0.9989 - F1: 0.6904 - Loss: 0.0024\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 22:53:07\n",
      "Accuracy: 0.9900 - Precision: 0.9204 - Recall: 0.5699 - Specificity: 0.9989 - F1: 0.6908 - Loss: 0.0024\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 22:53:16\n",
      "Accuracy: 0.9901 - Precision: 0.9207 - Recall: 0.5698 - Specificity: 0.9989 - F1: 0.6909 - Loss: 0.0024\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 22:53:25\n",
      "Accuracy: 0.9901 - Precision: 0.9209 - Recall: 0.5703 - Specificity: 0.9989 - F1: 0.6913 - Loss: 0.0024\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 22:53:33\n",
      "Accuracy: 0.9901 - Precision: 0.9208 - Recall: 0.5705 - Specificity: 0.9989 - F1: 0.6915 - Loss: 0.0024\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 22:53:41\n",
      "Accuracy: 0.9901 - Precision: 0.9211 - Recall: 0.5706 - Specificity: 0.9990 - F1: 0.6917 - Loss: 0.0024\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 22:53:49\n",
      "Accuracy: 0.9901 - Precision: 0.9213 - Recall: 0.5707 - Specificity: 0.9990 - F1: 0.6920 - Loss: 0.0024\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 22:53:57\n",
      "Accuracy: 0.9901 - Precision: 0.9216 - Recall: 0.5710 - Specificity: 0.9990 - F1: 0.6923 - Loss: 0.0024\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 22:54:05\n",
      "Accuracy: 0.9901 - Precision: 0.9216 - Recall: 0.5715 - Specificity: 0.9990 - F1: 0.6928 - Loss: 0.0024\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 22:54:13\n",
      "Accuracy: 0.9901 - Precision: 0.9216 - Recall: 0.5725 - Specificity: 0.9990 - F1: 0.6935 - Loss: 0.0024\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 22:54:21\n",
      "Accuracy: 0.9901 - Precision: 0.9216 - Recall: 0.5735 - Specificity: 0.9990 - F1: 0.6942 - Loss: 0.0024\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 22:54:29\n",
      "Accuracy: 0.9902 - Precision: 0.9211 - Recall: 0.5745 - Specificity: 0.9989 - F1: 0.6947 - Loss: 0.0024\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 22:54:37\n",
      "Accuracy: 0.9902 - Precision: 0.9210 - Recall: 0.5756 - Specificity: 0.9989 - F1: 0.6955 - Loss: 0.0024\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 22:54:44\n",
      "Accuracy: 0.9902 - Precision: 0.9210 - Recall: 0.5765 - Specificity: 0.9989 - F1: 0.6961 - Loss: 0.0024\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 22:54:52\n",
      "Accuracy: 0.9902 - Precision: 0.9208 - Recall: 0.5772 - Specificity: 0.9989 - F1: 0.6966 - Loss: 0.0024\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 22:55:00\n",
      "Accuracy: 0.9903 - Precision: 0.9209 - Recall: 0.5778 - Specificity: 0.9989 - F1: 0.6971 - Loss: 0.0024\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 22:55:08\n",
      "Accuracy: 0.9903 - Precision: 0.9211 - Recall: 0.5782 - Specificity: 0.9989 - F1: 0.6976 - Loss: 0.0024\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 22:55:17\n",
      "Accuracy: 0.9903 - Precision: 0.9212 - Recall: 0.5785 - Specificity: 0.9989 - F1: 0.6979 - Loss: 0.0024\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 22:55:25\n",
      "Accuracy: 0.9903 - Precision: 0.9215 - Recall: 0.5787 - Specificity: 0.9990 - F1: 0.6982 - Loss: 0.0024\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 22:55:33\n",
      "Accuracy: 0.9903 - Precision: 0.9217 - Recall: 0.5790 - Specificity: 0.9990 - F1: 0.6985 - Loss: 0.0024\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 22:55:41\n",
      "Accuracy: 0.9903 - Precision: 0.9218 - Recall: 0.5787 - Specificity: 0.9990 - F1: 0.6983 - Loss: 0.0024\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 22:55:49\n",
      "Accuracy: 0.9903 - Precision: 0.9218 - Recall: 0.5777 - Specificity: 0.9990 - F1: 0.6976 - Loss: 0.0024\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 22:55:57\n",
      "Accuracy: 0.9902 - Precision: 0.9214 - Recall: 0.5772 - Specificity: 0.9990 - F1: 0.6971 - Loss: 0.0024\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 22:56:05\n",
      "Accuracy: 0.9902 - Precision: 0.9211 - Recall: 0.5768 - Specificity: 0.9989 - F1: 0.6968 - Loss: 0.0024\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 22:56:13\n",
      "Accuracy: 0.9902 - Precision: 0.9210 - Recall: 0.5766 - Specificity: 0.9989 - F1: 0.6967 - Loss: 0.0024\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 22:56:21\n",
      "Accuracy: 0.9902 - Precision: 0.9211 - Recall: 0.5768 - Specificity: 0.9989 - F1: 0.6969 - Loss: 0.0024\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 22:56:29\n",
      "Accuracy: 0.9902 - Precision: 0.9209 - Recall: 0.5766 - Specificity: 0.9989 - F1: 0.6967 - Loss: 0.0024\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 22:56:37\n",
      "Accuracy: 0.9901 - Precision: 0.9206 - Recall: 0.5761 - Specificity: 0.9989 - F1: 0.6963 - Loss: 0.0024\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 22:56:45\n",
      "Accuracy: 0.9901 - Precision: 0.9206 - Recall: 0.5761 - Specificity: 0.9989 - F1: 0.6964 - Loss: 0.0024\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 22:56:52\n",
      "Accuracy: 0.9901 - Precision: 0.9205 - Recall: 0.5756 - Specificity: 0.9989 - F1: 0.6960 - Loss: 0.0024\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 22:57:00\n",
      "Accuracy: 0.9901 - Precision: 0.9202 - Recall: 0.5752 - Specificity: 0.9989 - F1: 0.6956 - Loss: 0.0024\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 22:57:08\n",
      "Accuracy: 0.9901 - Precision: 0.9203 - Recall: 0.5753 - Specificity: 0.9989 - F1: 0.6958 - Loss: 0.0024\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 22:57:16\n",
      "Accuracy: 0.9901 - Precision: 0.9204 - Recall: 0.5746 - Specificity: 0.9989 - F1: 0.6953 - Loss: 0.0024\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 22:57:26\n",
      "Accuracy: 0.9900 - Precision: 0.9206 - Recall: 0.5736 - Specificity: 0.9989 - F1: 0.6944 - Loss: 0.0024\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 22:57:34\n",
      "Accuracy: 0.9900 - Precision: 0.9209 - Recall: 0.5728 - Specificity: 0.9989 - F1: 0.6939 - Loss: 0.0024\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 22:57:42\n",
      "Accuracy: 0.9900 - Precision: 0.9211 - Recall: 0.5721 - Specificity: 0.9989 - F1: 0.6934 - Loss: 0.0024\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 22:57:50\n",
      "Accuracy: 0.9900 - Precision: 0.9213 - Recall: 0.5712 - Specificity: 0.9989 - F1: 0.6926 - Loss: 0.0024\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 22:57:58\n",
      "Accuracy: 0.9900 - Precision: 0.9214 - Recall: 0.5705 - Specificity: 0.9989 - F1: 0.6921 - Loss: 0.0024\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 22:58:06\n",
      "Accuracy: 0.9900 - Precision: 0.9215 - Recall: 0.5703 - Specificity: 0.9990 - F1: 0.6920 - Loss: 0.0024\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 22:58:14\n",
      "Accuracy: 0.9900 - Precision: 0.9213 - Recall: 0.5698 - Specificity: 0.9989 - F1: 0.6916 - Loss: 0.0024\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 22:58:22\n",
      "Accuracy: 0.9899 - Precision: 0.9211 - Recall: 0.5692 - Specificity: 0.9989 - F1: 0.6912 - Loss: 0.0025\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 22:58:30\n",
      "Accuracy: 0.9899 - Precision: 0.9208 - Recall: 0.5690 - Specificity: 0.9989 - F1: 0.6910 - Loss: 0.0025\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 22:58:38\n",
      "Accuracy: 0.9898 - Precision: 0.9207 - Recall: 0.5684 - Specificity: 0.9989 - F1: 0.6905 - Loss: 0.0025\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 22:58:46\n",
      "Accuracy: 0.9898 - Precision: 0.9207 - Recall: 0.5680 - Specificity: 0.9989 - F1: 0.6902 - Loss: 0.0025\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 22:58:54\n",
      "Accuracy: 0.9898 - Precision: 0.9208 - Recall: 0.5676 - Specificity: 0.9989 - F1: 0.6900 - Loss: 0.0025\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 22:59:02\n",
      "Accuracy: 0.9897 - Precision: 0.9208 - Recall: 0.5667 - Specificity: 0.9989 - F1: 0.6892 - Loss: 0.0025\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 22:59:09\n",
      "Accuracy: 0.9897 - Precision: 0.9209 - Recall: 0.5664 - Specificity: 0.9989 - F1: 0.6890 - Loss: 0.0025\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 22:59:17\n",
      "Accuracy: 0.9894 - Precision: 0.9208 - Recall: 0.5644 - Specificity: 0.9989 - F1: 0.6869 - Loss: 0.0026\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 22:59:27\n",
      "Accuracy: 0.9892 - Precision: 0.9208 - Recall: 0.5632 - Specificity: 0.9989 - F1: 0.6857 - Loss: 0.0027\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 22:59:35\n",
      "Accuracy: 0.9891 - Precision: 0.9208 - Recall: 0.5629 - Specificity: 0.9989 - F1: 0.6856 - Loss: 0.0027\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 22:59:43\n",
      "Accuracy: 0.9889 - Precision: 0.9202 - Recall: 0.5629 - Specificity: 0.9988 - F1: 0.6854 - Loss: 0.0028\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 22:59:51\n",
      "Accuracy: 0.9887 - Precision: 0.9198 - Recall: 0.5626 - Specificity: 0.9988 - F1: 0.6852 - Loss: 0.0028\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 22:59:59\n",
      "Accuracy: 0.9885 - Precision: 0.9191 - Recall: 0.5617 - Specificity: 0.9988 - F1: 0.6843 - Loss: 0.0029\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 23:00:06\n",
      "Accuracy: 0.9883 - Precision: 0.9190 - Recall: 0.5597 - Specificity: 0.9988 - F1: 0.6821 - Loss: 0.0029\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 23:00:14\n",
      "Accuracy: 0.9880 - Precision: 0.9185 - Recall: 0.5577 - Specificity: 0.9988 - F1: 0.6798 - Loss: 0.0030\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 23:00:22\n",
      "Accuracy: 0.9877 - Precision: 0.9187 - Recall: 0.5556 - Specificity: 0.9988 - F1: 0.6773 - Loss: 0.0030\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 23:00:30\n",
      "Accuracy: 0.9874 - Precision: 0.9186 - Recall: 0.5535 - Specificity: 0.9988 - F1: 0.6748 - Loss: 0.0031\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 23:00:37\n",
      "Accuracy: 0.9871 - Precision: 0.9189 - Recall: 0.5516 - Specificity: 0.9988 - F1: 0.6726 - Loss: 0.0031\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 23:00:45\n",
      "Accuracy: 0.9870 - Precision: 0.9184 - Recall: 0.5496 - Specificity: 0.9988 - F1: 0.6704 - Loss: 0.0032\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 23:00:53\n",
      "Accuracy: 0.9867 - Precision: 0.9180 - Recall: 0.5476 - Specificity: 0.9988 - F1: 0.6681 - Loss: 0.0032\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 23:01:01\n",
      "Accuracy: 0.9865 - Precision: 0.9169 - Recall: 0.5457 - Specificity: 0.9988 - F1: 0.6658 - Loss: 0.0033\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 23:01:09\n",
      "Accuracy: 0.9863 - Precision: 0.9162 - Recall: 0.5437 - Specificity: 0.9988 - F1: 0.6636 - Loss: 0.0033\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 23:01:17\n",
      "Accuracy: 0.9859 - Precision: 0.9158 - Recall: 0.5418 - Specificity: 0.9988 - F1: 0.6614 - Loss: 0.0034\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 23:01:26\n",
      "Accuracy: 0.9857 - Precision: 0.9155 - Recall: 0.5400 - Specificity: 0.9988 - F1: 0.6593 - Loss: 0.0034\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 23:01:35\n",
      "Accuracy: 0.9855 - Precision: 0.9144 - Recall: 0.5383 - Specificity: 0.9988 - F1: 0.6575 - Loss: 0.0034\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 23:01:43\n",
      "Accuracy: 0.9854 - Precision: 0.9120 - Recall: 0.5363 - Specificity: 0.9988 - F1: 0.6552 - Loss: 0.0035\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 23:01:51\n",
      "Accuracy: 0.9854 - Precision: 0.9113 - Recall: 0.5345 - Specificity: 0.9988 - F1: 0.6531 - Loss: 0.0035\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 23:01:59\n",
      "Accuracy: 0.9854 - Precision: 0.9111 - Recall: 0.5329 - Specificity: 0.9988 - F1: 0.6513 - Loss: 0.0035\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 23:02:07\n",
      "Accuracy: 0.9853 - Precision: 0.9112 - Recall: 0.5311 - Specificity: 0.9988 - F1: 0.6493 - Loss: 0.0035\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 23:02:14\n",
      "Accuracy: 0.9852 - Precision: 0.9115 - Recall: 0.5294 - Specificity: 0.9988 - F1: 0.6475 - Loss: 0.0036\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 23:02:22\n",
      "Accuracy: 0.9851 - Precision: 0.9111 - Recall: 0.5276 - Specificity: 0.9988 - F1: 0.6455 - Loss: 0.0036\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 23:02:30\n",
      "Accuracy: 0.9851 - Precision: 0.9114 - Recall: 0.5258 - Specificity: 0.9988 - F1: 0.6433 - Loss: 0.0036\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 23:02:38\n",
      "Accuracy: 0.9850 - Precision: 0.9109 - Recall: 0.5239 - Specificity: 0.9988 - F1: 0.6411 - Loss: 0.0036\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 23:02:46\n",
      "Accuracy: 0.9850 - Precision: 0.9112 - Recall: 0.5220 - Specificity: 0.9988 - F1: 0.6389 - Loss: 0.0037\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 23:02:53\n",
      "Accuracy: 0.9850 - Precision: 0.9115 - Recall: 0.5202 - Specificity: 0.9988 - F1: 0.6367 - Loss: 0.0037\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 23:03:01\n",
      "Accuracy: 0.9849 - Precision: 0.9118 - Recall: 0.5184 - Specificity: 0.9988 - F1: 0.6347 - Loss: 0.0037\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 23:03:09\n",
      "Accuracy: 0.9849 - Precision: 0.9103 - Recall: 0.5167 - Specificity: 0.9988 - F1: 0.6326 - Loss: 0.0037\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 23:03:17\n",
      "Accuracy: 0.9848 - Precision: 0.9106 - Recall: 0.5150 - Specificity: 0.9988 - F1: 0.6308 - Loss: 0.0037\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 23:03:25\n",
      "Accuracy: 0.9848 - Precision: 0.9107 - Recall: 0.5134 - Specificity: 0.9988 - F1: 0.6289 - Loss: 0.0037\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 23:03:35\n",
      "Accuracy: 0.9847 - Precision: 0.9107 - Recall: 0.5117 - Specificity: 0.9988 - F1: 0.6270 - Loss: 0.0037\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 23:03:43\n",
      "Accuracy: 0.9847 - Precision: 0.9103 - Recall: 0.5100 - Specificity: 0.9988 - F1: 0.6250 - Loss: 0.0037\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 23:03:51\n",
      "Accuracy: 0.9847 - Precision: 0.9100 - Recall: 0.5084 - Specificity: 0.9988 - F1: 0.6232 - Loss: 0.0037\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 23:03:59\n",
      "Accuracy: 0.9846 - Precision: 0.9080 - Recall: 0.5066 - Specificity: 0.9988 - F1: 0.6210 - Loss: 0.0037\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 23:04:07\n",
      "Accuracy: 0.9846 - Precision: 0.9081 - Recall: 0.5048 - Specificity: 0.9988 - F1: 0.6189 - Loss: 0.0038\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 23:04:14\n",
      "Accuracy: 0.9846 - Precision: 0.9048 - Recall: 0.5030 - Specificity: 0.9988 - F1: 0.6167 - Loss: 0.0038\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 23:04:22\n",
      "Accuracy: 0.9845 - Precision: 0.9052 - Recall: 0.5012 - Specificity: 0.9988 - F1: 0.6145 - Loss: 0.0038\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 23:04:30\n",
      "Accuracy: 0.9845 - Precision: 0.9054 - Recall: 0.4995 - Specificity: 0.9988 - F1: 0.6125 - Loss: 0.0038\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 23:04:38\n",
      "Accuracy: 0.9845 - Precision: 0.9040 - Recall: 0.4979 - Specificity: 0.9989 - F1: 0.6106 - Loss: 0.0038\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 23:04:45\n",
      "Accuracy: 0.9845 - Precision: 0.9017 - Recall: 0.4961 - Specificity: 0.9989 - F1: 0.6084 - Loss: 0.0038\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 23:04:53\n",
      "Accuracy: 0.9845 - Precision: 0.9008 - Recall: 0.4944 - Specificity: 0.9989 - F1: 0.6064 - Loss: 0.0038\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 23:05:01\n",
      "Accuracy: 0.9845 - Precision: 0.8976 - Recall: 0.4927 - Specificity: 0.9989 - F1: 0.6043 - Loss: 0.0038\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 23:05:09\n",
      "Accuracy: 0.9844 - Precision: 0.8945 - Recall: 0.4910 - Specificity: 0.9989 - F1: 0.6021 - Loss: 0.0038\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 23:05:17\n",
      "Accuracy: 0.9844 - Precision: 0.8946 - Recall: 0.4894 - Specificity: 0.9989 - F1: 0.6003 - Loss: 0.0038\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 23:05:25\n",
      "Accuracy: 0.9844 - Precision: 0.8948 - Recall: 0.4877 - Specificity: 0.9989 - F1: 0.5983 - Loss: 0.0038\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 23:05:33\n",
      "Accuracy: 0.9843 - Precision: 0.8951 - Recall: 0.4861 - Specificity: 0.9989 - F1: 0.5964 - Loss: 0.0038\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 23:05:41\n",
      "Accuracy: 0.9843 - Precision: 0.8954 - Recall: 0.4845 - Specificity: 0.9989 - F1: 0.5945 - Loss: 0.0038\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 23:05:48\n",
      "Accuracy: 0.9843 - Precision: 0.8956 - Recall: 0.4829 - Specificity: 0.9989 - F1: 0.5926 - Loss: 0.0038\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 23:05:57\n",
      "Accuracy: 0.9843 - Precision: 0.8952 - Recall: 0.4815 - Specificity: 0.9989 - F1: 0.5910 - Loss: 0.0038\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 23:06:06\n",
      "Accuracy: 0.9842 - Precision: 0.8950 - Recall: 0.4800 - Specificity: 0.9989 - F1: 0.5893 - Loss: 0.0038\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 23:06:14\n",
      "Accuracy: 0.9842 - Precision: 0.8947 - Recall: 0.4787 - Specificity: 0.9989 - F1: 0.5878 - Loss: 0.0039\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 23:06:22\n",
      "Accuracy: 0.9842 - Precision: 0.8946 - Recall: 0.4776 - Specificity: 0.9989 - F1: 0.5867 - Loss: 0.0039\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 23:06:30\n",
      "Accuracy: 0.9841 - Precision: 0.8949 - Recall: 0.4762 - Specificity: 0.9989 - F1: 0.5852 - Loss: 0.0039\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 23:06:37\n",
      "Accuracy: 0.9841 - Precision: 0.8948 - Recall: 0.4749 - Specificity: 0.9989 - F1: 0.5837 - Loss: 0.0039\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 23:06:45\n",
      "Accuracy: 0.9841 - Precision: 0.8944 - Recall: 0.4738 - Specificity: 0.9989 - F1: 0.5826 - Loss: 0.0039\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 23:06:53\n",
      "Accuracy: 0.9841 - Precision: 0.8945 - Recall: 0.4727 - Specificity: 0.9989 - F1: 0.5816 - Loss: 0.0039\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 23:07:01\n",
      "Accuracy: 0.9840 - Precision: 0.8945 - Recall: 0.4715 - Specificity: 0.9989 - F1: 0.5803 - Loss: 0.0039\n",
      "\n",
      "Epoch 14/20\n",
      "Validation - Accuracy: 0.9811, Precision: 0.8833, Recall: 0.1449, Specificity: 0.9996, F1: 0.2477, Loss: 0.0046\n",
      "\n",
      "\n",
      "Epoch 15/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 23:14:25\n",
      "Accuracy: 0.9770 - Precision: 0.9123 - Recall: 0.1357 - Specificity: 0.9996 - F1: 0.2363 - Loss: 0.0053\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 23:14:33\n",
      "Accuracy: 0.9757 - Precision: 0.9367 - Recall: 0.1370 - Specificity: 0.9997 - F1: 0.2391 - Loss: 0.0055\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 23:14:41\n",
      "Accuracy: 0.9755 - Precision: 0.9516 - Recall: 0.1594 - Specificity: 0.9998 - F1: 0.2721 - Loss: 0.0051\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 23:14:49\n",
      "Accuracy: 0.9782 - Precision: 0.9612 - Recall: 0.1646 - Specificity: 0.9998 - F1: 0.2802 - Loss: 0.0045\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 23:14:57\n",
      "Accuracy: 0.9798 - Precision: 0.9393 - Recall: 0.1635 - Specificity: 0.9998 - F1: 0.2778 - Loss: 0.0042\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 23:15:05\n",
      "Accuracy: 0.9801 - Precision: 0.9480 - Recall: 0.1740 - Specificity: 0.9998 - F1: 0.2930 - Loss: 0.0040\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 23:15:13\n",
      "Accuracy: 0.9814 - Precision: 0.9442 - Recall: 0.1871 - Specificity: 0.9998 - F1: 0.3101 - Loss: 0.0038\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 23:15:21\n",
      "Accuracy: 0.9819 - Precision: 0.9152 - Recall: 0.1974 - Specificity: 0.9996 - F1: 0.3202 - Loss: 0.0037\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 23:15:29\n",
      "Accuracy: 0.9828 - Precision: 0.9196 - Recall: 0.2152 - Specificity: 0.9996 - F1: 0.3424 - Loss: 0.0035\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 23:15:37\n",
      "Accuracy: 0.9831 - Precision: 0.9189 - Recall: 0.2181 - Specificity: 0.9996 - F1: 0.3468 - Loss: 0.0035\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 23:15:46\n",
      "Accuracy: 0.9836 - Precision: 0.9087 - Recall: 0.2385 - Specificity: 0.9995 - F1: 0.3672 - Loss: 0.0034\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 23:15:55\n",
      "Accuracy: 0.9842 - Precision: 0.9136 - Recall: 0.2592 - Specificity: 0.9995 - F1: 0.3905 - Loss: 0.0033\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 23:16:03\n",
      "Accuracy: 0.9846 - Precision: 0.9147 - Recall: 0.2780 - Specificity: 0.9995 - F1: 0.4108 - Loss: 0.0033\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 23:16:11\n",
      "Accuracy: 0.9848 - Precision: 0.8977 - Recall: 0.2885 - Specificity: 0.9992 - F1: 0.4187 - Loss: 0.0033\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 23:16:19\n",
      "Accuracy: 0.9852 - Precision: 0.9001 - Recall: 0.3037 - Specificity: 0.9992 - F1: 0.4351 - Loss: 0.0032\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 23:16:26\n",
      "Accuracy: 0.9850 - Precision: 0.9026 - Recall: 0.3094 - Specificity: 0.9993 - F1: 0.4427 - Loss: 0.0033\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 23:16:35\n",
      "Accuracy: 0.9856 - Precision: 0.9042 - Recall: 0.3301 - Specificity: 0.9992 - F1: 0.4621 - Loss: 0.0032\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 23:16:42\n",
      "Accuracy: 0.9858 - Precision: 0.9066 - Recall: 0.3445 - Specificity: 0.9992 - F1: 0.4768 - Loss: 0.0031\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 23:16:51\n",
      "Accuracy: 0.9861 - Precision: 0.9070 - Recall: 0.3596 - Specificity: 0.9992 - F1: 0.4910 - Loss: 0.0031\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 23:16:59\n",
      "Accuracy: 0.9864 - Precision: 0.9032 - Recall: 0.3759 - Specificity: 0.9991 - F1: 0.5040 - Loss: 0.0031\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 23:17:07\n",
      "Accuracy: 0.9865 - Precision: 0.8991 - Recall: 0.3826 - Specificity: 0.9991 - F1: 0.5102 - Loss: 0.0031\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 23:17:14\n",
      "Accuracy: 0.9861 - Precision: 0.8849 - Recall: 0.3807 - Specificity: 0.9989 - F1: 0.5066 - Loss: 0.0032\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 23:17:22\n",
      "Accuracy: 0.9862 - Precision: 0.8892 - Recall: 0.3819 - Specificity: 0.9989 - F1: 0.5097 - Loss: 0.0032\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 23:17:30\n",
      "Accuracy: 0.9861 - Precision: 0.8929 - Recall: 0.3827 - Specificity: 0.9989 - F1: 0.5122 - Loss: 0.0032\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 23:17:38\n",
      "Accuracy: 0.9862 - Precision: 0.8966 - Recall: 0.3829 - Specificity: 0.9990 - F1: 0.5139 - Loss: 0.0032\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 23:17:46\n",
      "Accuracy: 0.9864 - Precision: 0.8997 - Recall: 0.3849 - Specificity: 0.9990 - F1: 0.5173 - Loss: 0.0031\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 23:17:54\n",
      "Accuracy: 0.9863 - Precision: 0.9026 - Recall: 0.3818 - Specificity: 0.9990 - F1: 0.5152 - Loss: 0.0031\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 23:18:03\n",
      "Accuracy: 0.9862 - Precision: 0.9046 - Recall: 0.3761 - Specificity: 0.9991 - F1: 0.5096 - Loss: 0.0031\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 23:18:12\n",
      "Accuracy: 0.9859 - Precision: 0.9050 - Recall: 0.3720 - Specificity: 0.9991 - F1: 0.5060 - Loss: 0.0032\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 23:18:20\n",
      "Accuracy: 0.9859 - Precision: 0.9070 - Recall: 0.3729 - Specificity: 0.9991 - F1: 0.5079 - Loss: 0.0031\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 23:18:28\n",
      "Accuracy: 0.9860 - Precision: 0.9076 - Recall: 0.3748 - Specificity: 0.9991 - F1: 0.5105 - Loss: 0.0031\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 23:18:36\n",
      "Accuracy: 0.9860 - Precision: 0.9083 - Recall: 0.3738 - Specificity: 0.9991 - F1: 0.5102 - Loss: 0.0031\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 23:18:44\n",
      "Accuracy: 0.9861 - Precision: 0.9092 - Recall: 0.3747 - Specificity: 0.9991 - F1: 0.5119 - Loss: 0.0031\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 23:18:52\n",
      "Accuracy: 0.9860 - Precision: 0.9111 - Recall: 0.3737 - Specificity: 0.9991 - F1: 0.5116 - Loss: 0.0031\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 23:19:00\n",
      "Accuracy: 0.9859 - Precision: 0.9125 - Recall: 0.3715 - Specificity: 0.9992 - F1: 0.5100 - Loss: 0.0031\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 23:19:08\n",
      "Accuracy: 0.9860 - Precision: 0.9127 - Recall: 0.3736 - Specificity: 0.9992 - F1: 0.5125 - Loss: 0.0031\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 23:19:16\n",
      "Accuracy: 0.9861 - Precision: 0.9136 - Recall: 0.3776 - Specificity: 0.9992 - F1: 0.5169 - Loss: 0.0030\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 23:19:24\n",
      "Accuracy: 0.9861 - Precision: 0.9135 - Recall: 0.3798 - Specificity: 0.9992 - F1: 0.5193 - Loss: 0.0030\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 23:19:32\n",
      "Accuracy: 0.9861 - Precision: 0.9143 - Recall: 0.3830 - Specificity: 0.9992 - F1: 0.5229 - Loss: 0.0030\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 23:19:40\n",
      "Accuracy: 0.9862 - Precision: 0.9141 - Recall: 0.3874 - Specificity: 0.9991 - F1: 0.5271 - Loss: 0.0030\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 23:19:48\n",
      "Accuracy: 0.9861 - Precision: 0.9135 - Recall: 0.3886 - Specificity: 0.9991 - F1: 0.5286 - Loss: 0.0030\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 23:19:56\n",
      "Accuracy: 0.9862 - Precision: 0.9144 - Recall: 0.3930 - Specificity: 0.9991 - F1: 0.5330 - Loss: 0.0030\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 23:20:04\n",
      "Accuracy: 0.9863 - Precision: 0.9146 - Recall: 0.3973 - Specificity: 0.9991 - F1: 0.5372 - Loss: 0.0030\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 23:20:12\n",
      "Accuracy: 0.9864 - Precision: 0.9145 - Recall: 0.4027 - Specificity: 0.9991 - F1: 0.5419 - Loss: 0.0030\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 23:20:20\n",
      "Accuracy: 0.9865 - Precision: 0.9109 - Recall: 0.4090 - Specificity: 0.9991 - F1: 0.5458 - Loss: 0.0030\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 23:20:29\n",
      "Accuracy: 0.9866 - Precision: 0.9119 - Recall: 0.4124 - Specificity: 0.9991 - F1: 0.5495 - Loss: 0.0030\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 23:20:38\n",
      "Accuracy: 0.9866 - Precision: 0.9121 - Recall: 0.4150 - Specificity: 0.9991 - F1: 0.5522 - Loss: 0.0030\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 23:20:45\n",
      "Accuracy: 0.9866 - Precision: 0.9130 - Recall: 0.4179 - Specificity: 0.9991 - F1: 0.5552 - Loss: 0.0030\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 23:20:53\n",
      "Accuracy: 0.9867 - Precision: 0.9134 - Recall: 0.4211 - Specificity: 0.9991 - F1: 0.5584 - Loss: 0.0029\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 23:21:01\n",
      "Accuracy: 0.9868 - Precision: 0.9146 - Recall: 0.4252 - Specificity: 0.9991 - F1: 0.5625 - Loss: 0.0029\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 23:21:09\n",
      "Accuracy: 0.9869 - Precision: 0.9146 - Recall: 0.4301 - Specificity: 0.9991 - F1: 0.5667 - Loss: 0.0029\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 23:21:17\n",
      "Accuracy: 0.9869 - Precision: 0.9136 - Recall: 0.4336 - Specificity: 0.9991 - F1: 0.5696 - Loss: 0.0029\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 23:21:25\n",
      "Accuracy: 0.9871 - Precision: 0.9137 - Recall: 0.4382 - Specificity: 0.9990 - F1: 0.5735 - Loss: 0.0029\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 23:21:33\n",
      "Accuracy: 0.9872 - Precision: 0.9143 - Recall: 0.4429 - Specificity: 0.9991 - F1: 0.5777 - Loss: 0.0029\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 23:21:41\n",
      "Accuracy: 0.9872 - Precision: 0.9147 - Recall: 0.4459 - Specificity: 0.9991 - F1: 0.5806 - Loss: 0.0029\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 23:21:49\n",
      "Accuracy: 0.9873 - Precision: 0.9146 - Recall: 0.4509 - Specificity: 0.9990 - F1: 0.5847 - Loss: 0.0028\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 23:21:56\n",
      "Accuracy: 0.9874 - Precision: 0.9146 - Recall: 0.4543 - Specificity: 0.9990 - F1: 0.5877 - Loss: 0.0028\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 23:22:05\n",
      "Accuracy: 0.9875 - Precision: 0.9151 - Recall: 0.4573 - Specificity: 0.9990 - F1: 0.5906 - Loss: 0.0028\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 23:22:13\n",
      "Accuracy: 0.9876 - Precision: 0.9158 - Recall: 0.4599 - Specificity: 0.9991 - F1: 0.5932 - Loss: 0.0028\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 23:22:21\n",
      "Accuracy: 0.9876 - Precision: 0.9149 - Recall: 0.4619 - Specificity: 0.9990 - F1: 0.5949 - Loss: 0.0028\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 23:22:28\n",
      "Accuracy: 0.9877 - Precision: 0.9149 - Recall: 0.4640 - Specificity: 0.9990 - F1: 0.5969 - Loss: 0.0028\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 23:22:36\n",
      "Accuracy: 0.9877 - Precision: 0.9157 - Recall: 0.4668 - Specificity: 0.9990 - F1: 0.5996 - Loss: 0.0028\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 23:22:44\n",
      "Accuracy: 0.9878 - Precision: 0.9165 - Recall: 0.4697 - Specificity: 0.9990 - F1: 0.6024 - Loss: 0.0028\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 23:22:52\n",
      "Accuracy: 0.9879 - Precision: 0.9166 - Recall: 0.4730 - Specificity: 0.9990 - F1: 0.6052 - Loss: 0.0027\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 23:23:01\n",
      "Accuracy: 0.9879 - Precision: 0.9169 - Recall: 0.4759 - Specificity: 0.9990 - F1: 0.6079 - Loss: 0.0027\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 23:23:10\n",
      "Accuracy: 0.9879 - Precision: 0.9168 - Recall: 0.4768 - Specificity: 0.9990 - F1: 0.6089 - Loss: 0.0027\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 23:23:18\n",
      "Accuracy: 0.9879 - Precision: 0.9162 - Recall: 0.4785 - Specificity: 0.9990 - F1: 0.6103 - Loss: 0.0027\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 23:23:25\n",
      "Accuracy: 0.9880 - Precision: 0.9158 - Recall: 0.4807 - Specificity: 0.9990 - F1: 0.6122 - Loss: 0.0027\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 23:23:33\n",
      "Accuracy: 0.9880 - Precision: 0.9163 - Recall: 0.4841 - Specificity: 0.9990 - F1: 0.6151 - Loss: 0.0027\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 23:23:41\n",
      "Accuracy: 0.9881 - Precision: 0.9165 - Recall: 0.4873 - Specificity: 0.9990 - F1: 0.6178 - Loss: 0.0027\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 23:23:49\n",
      "Accuracy: 0.9882 - Precision: 0.9151 - Recall: 0.4897 - Specificity: 0.9990 - F1: 0.6194 - Loss: 0.0027\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 23:23:57\n",
      "Accuracy: 0.9882 - Precision: 0.9140 - Recall: 0.4920 - Specificity: 0.9990 - F1: 0.6210 - Loss: 0.0027\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 23:24:05\n",
      "Accuracy: 0.9882 - Precision: 0.9147 - Recall: 0.4932 - Specificity: 0.9990 - F1: 0.6224 - Loss: 0.0027\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 23:24:13\n",
      "Accuracy: 0.9882 - Precision: 0.9154 - Recall: 0.4937 - Specificity: 0.9990 - F1: 0.6232 - Loss: 0.0027\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 23:24:21\n",
      "Accuracy: 0.9882 - Precision: 0.9156 - Recall: 0.4945 - Specificity: 0.9990 - F1: 0.6242 - Loss: 0.0027\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 23:24:29\n",
      "Accuracy: 0.9882 - Precision: 0.9163 - Recall: 0.4956 - Specificity: 0.9990 - F1: 0.6255 - Loss: 0.0027\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 23:24:37\n",
      "Accuracy: 0.9883 - Precision: 0.9163 - Recall: 0.4971 - Specificity: 0.9990 - F1: 0.6269 - Loss: 0.0027\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 23:24:45\n",
      "Accuracy: 0.9883 - Precision: 0.9170 - Recall: 0.4984 - Specificity: 0.9990 - F1: 0.6284 - Loss: 0.0027\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 23:24:52\n",
      "Accuracy: 0.9883 - Precision: 0.9171 - Recall: 0.5000 - Specificity: 0.9990 - F1: 0.6298 - Loss: 0.0027\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 23:25:00\n",
      "Accuracy: 0.9883 - Precision: 0.9175 - Recall: 0.5020 - Specificity: 0.9990 - F1: 0.6317 - Loss: 0.0027\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 23:25:08\n",
      "Accuracy: 0.9884 - Precision: 0.9174 - Recall: 0.5045 - Specificity: 0.9990 - F1: 0.6337 - Loss: 0.0027\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 23:25:16\n",
      "Accuracy: 0.9884 - Precision: 0.9171 - Recall: 0.5060 - Specificity: 0.9990 - F1: 0.6350 - Loss: 0.0027\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 23:25:24\n",
      "Accuracy: 0.9885 - Precision: 0.9171 - Recall: 0.5077 - Specificity: 0.9990 - F1: 0.6365 - Loss: 0.0027\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 23:25:32\n",
      "Accuracy: 0.9885 - Precision: 0.9169 - Recall: 0.5091 - Specificity: 0.9990 - F1: 0.6377 - Loss: 0.0027\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 23:25:40\n",
      "Accuracy: 0.9886 - Precision: 0.9173 - Recall: 0.5117 - Specificity: 0.9990 - F1: 0.6399 - Loss: 0.0026\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 23:25:47\n",
      "Accuracy: 0.9886 - Precision: 0.9171 - Recall: 0.5132 - Specificity: 0.9990 - F1: 0.6411 - Loss: 0.0026\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 23:25:57\n",
      "Accuracy: 0.9886 - Precision: 0.9176 - Recall: 0.5149 - Specificity: 0.9990 - F1: 0.6428 - Loss: 0.0026\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 23:26:05\n",
      "Accuracy: 0.9887 - Precision: 0.9178 - Recall: 0.5158 - Specificity: 0.9990 - F1: 0.6438 - Loss: 0.0026\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 23:26:13\n",
      "Accuracy: 0.9887 - Precision: 0.9186 - Recall: 0.5165 - Specificity: 0.9990 - F1: 0.6447 - Loss: 0.0026\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 23:26:21\n",
      "Accuracy: 0.9887 - Precision: 0.9191 - Recall: 0.5171 - Specificity: 0.9990 - F1: 0.6455 - Loss: 0.0026\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 23:26:29\n",
      "Accuracy: 0.9887 - Precision: 0.9195 - Recall: 0.5190 - Specificity: 0.9990 - F1: 0.6472 - Loss: 0.0026\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 23:26:37\n",
      "Accuracy: 0.9888 - Precision: 0.9193 - Recall: 0.5209 - Specificity: 0.9990 - F1: 0.6487 - Loss: 0.0026\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 23:26:44\n",
      "Accuracy: 0.9888 - Precision: 0.9190 - Recall: 0.5230 - Specificity: 0.9990 - F1: 0.6503 - Loss: 0.0026\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 23:26:52\n",
      "Accuracy: 0.9889 - Precision: 0.9190 - Recall: 0.5250 - Specificity: 0.9990 - F1: 0.6519 - Loss: 0.0026\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 23:27:00\n",
      "Accuracy: 0.9889 - Precision: 0.9178 - Recall: 0.5270 - Specificity: 0.9990 - F1: 0.6530 - Loss: 0.0026\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 23:27:08\n",
      "Accuracy: 0.9889 - Precision: 0.9176 - Recall: 0.5280 - Specificity: 0.9989 - F1: 0.6539 - Loss: 0.0026\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 23:27:16\n",
      "Accuracy: 0.9889 - Precision: 0.9181 - Recall: 0.5291 - Specificity: 0.9990 - F1: 0.6550 - Loss: 0.0026\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 23:27:24\n",
      "Accuracy: 0.9890 - Precision: 0.9184 - Recall: 0.5303 - Specificity: 0.9990 - F1: 0.6562 - Loss: 0.0026\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 23:27:32\n",
      "Accuracy: 0.9890 - Precision: 0.9187 - Recall: 0.5304 - Specificity: 0.9990 - F1: 0.6565 - Loss: 0.0026\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 23:27:40\n",
      "Accuracy: 0.9890 - Precision: 0.9187 - Recall: 0.5308 - Specificity: 0.9990 - F1: 0.6570 - Loss: 0.0026\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 23:27:47\n",
      "Accuracy: 0.9890 - Precision: 0.9185 - Recall: 0.5311 - Specificity: 0.9990 - F1: 0.6573 - Loss: 0.0026\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 23:27:55\n",
      "Accuracy: 0.9890 - Precision: 0.9169 - Recall: 0.5303 - Specificity: 0.9990 - F1: 0.6564 - Loss: 0.0026\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 23:28:03\n",
      "Accuracy: 0.9891 - Precision: 0.9167 - Recall: 0.5307 - Specificity: 0.9990 - F1: 0.6568 - Loss: 0.0025\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 23:28:10\n",
      "Accuracy: 0.9891 - Precision: 0.9169 - Recall: 0.5304 - Specificity: 0.9990 - F1: 0.6567 - Loss: 0.0025\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 23:28:18\n",
      "Accuracy: 0.9891 - Precision: 0.9160 - Recall: 0.5306 - Specificity: 0.9989 - F1: 0.6568 - Loss: 0.0025\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 23:28:26\n",
      "Accuracy: 0.9891 - Precision: 0.9161 - Recall: 0.5314 - Specificity: 0.9989 - F1: 0.6575 - Loss: 0.0025\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 23:28:34\n",
      "Accuracy: 0.9891 - Precision: 0.9156 - Recall: 0.5316 - Specificity: 0.9989 - F1: 0.6577 - Loss: 0.0025\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 23:28:42\n",
      "Accuracy: 0.9891 - Precision: 0.9148 - Recall: 0.5314 - Specificity: 0.9989 - F1: 0.6575 - Loss: 0.0025\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 23:28:50\n",
      "Accuracy: 0.9892 - Precision: 0.9149 - Recall: 0.5322 - Specificity: 0.9989 - F1: 0.6582 - Loss: 0.0025\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 23:28:58\n",
      "Accuracy: 0.9892 - Precision: 0.9150 - Recall: 0.5336 - Specificity: 0.9989 - F1: 0.6594 - Loss: 0.0025\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 23:29:07\n",
      "Accuracy: 0.9892 - Precision: 0.9144 - Recall: 0.5338 - Specificity: 0.9989 - F1: 0.6595 - Loss: 0.0025\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 23:29:15\n",
      "Accuracy: 0.9892 - Precision: 0.9141 - Recall: 0.5345 - Specificity: 0.9989 - F1: 0.6600 - Loss: 0.0025\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 23:29:23\n",
      "Accuracy: 0.9893 - Precision: 0.9139 - Recall: 0.5355 - Specificity: 0.9989 - F1: 0.6609 - Loss: 0.0025\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 23:29:31\n",
      "Accuracy: 0.9893 - Precision: 0.9141 - Recall: 0.5361 - Specificity: 0.9989 - F1: 0.6615 - Loss: 0.0025\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 23:29:39\n",
      "Accuracy: 0.9893 - Precision: 0.9146 - Recall: 0.5366 - Specificity: 0.9989 - F1: 0.6622 - Loss: 0.0025\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 23:29:47\n",
      "Accuracy: 0.9893 - Precision: 0.9144 - Recall: 0.5369 - Specificity: 0.9989 - F1: 0.6625 - Loss: 0.0025\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 23:29:55\n",
      "Accuracy: 0.9893 - Precision: 0.9145 - Recall: 0.5371 - Specificity: 0.9989 - F1: 0.6628 - Loss: 0.0025\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 23:30:02\n",
      "Accuracy: 0.9893 - Precision: 0.9148 - Recall: 0.5375 - Specificity: 0.9989 - F1: 0.6633 - Loss: 0.0025\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 23:30:11\n",
      "Accuracy: 0.9893 - Precision: 0.9142 - Recall: 0.5382 - Specificity: 0.9989 - F1: 0.6637 - Loss: 0.0025\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 23:30:18\n",
      "Accuracy: 0.9894 - Precision: 0.9136 - Recall: 0.5392 - Specificity: 0.9989 - F1: 0.6644 - Loss: 0.0025\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 23:30:26\n",
      "Accuracy: 0.9894 - Precision: 0.9134 - Recall: 0.5397 - Specificity: 0.9989 - F1: 0.6648 - Loss: 0.0025\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 23:30:34\n",
      "Accuracy: 0.9894 - Precision: 0.9137 - Recall: 0.5401 - Specificity: 0.9989 - F1: 0.6653 - Loss: 0.0025\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 23:30:43\n",
      "Accuracy: 0.9894 - Precision: 0.9140 - Recall: 0.5406 - Specificity: 0.9989 - F1: 0.6659 - Loss: 0.0025\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 23:30:50\n",
      "Accuracy: 0.9894 - Precision: 0.9144 - Recall: 0.5420 - Specificity: 0.9989 - F1: 0.6671 - Loss: 0.0025\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 23:30:58\n",
      "Accuracy: 0.9894 - Precision: 0.9143 - Recall: 0.5430 - Specificity: 0.9989 - F1: 0.6679 - Loss: 0.0025\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 23:31:06\n",
      "Accuracy: 0.9895 - Precision: 0.9145 - Recall: 0.5445 - Specificity: 0.9989 - F1: 0.6691 - Loss: 0.0025\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 23:31:15\n",
      "Accuracy: 0.9895 - Precision: 0.9135 - Recall: 0.5457 - Specificity: 0.9989 - F1: 0.6697 - Loss: 0.0025\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 23:31:23\n",
      "Accuracy: 0.9895 - Precision: 0.9134 - Recall: 0.5466 - Specificity: 0.9989 - F1: 0.6704 - Loss: 0.0025\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 23:31:31\n",
      "Accuracy: 0.9895 - Precision: 0.9138 - Recall: 0.5476 - Specificity: 0.9989 - F1: 0.6714 - Loss: 0.0025\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 23:31:39\n",
      "Accuracy: 0.9896 - Precision: 0.9140 - Recall: 0.5481 - Specificity: 0.9989 - F1: 0.6719 - Loss: 0.0025\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 23:31:47\n",
      "Accuracy: 0.9896 - Precision: 0.9143 - Recall: 0.5484 - Specificity: 0.9989 - F1: 0.6723 - Loss: 0.0025\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 23:31:55\n",
      "Accuracy: 0.9896 - Precision: 0.9143 - Recall: 0.5494 - Specificity: 0.9989 - F1: 0.6732 - Loss: 0.0025\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 23:32:03\n",
      "Accuracy: 0.9896 - Precision: 0.9146 - Recall: 0.5492 - Specificity: 0.9989 - F1: 0.6732 - Loss: 0.0025\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 23:32:11\n",
      "Accuracy: 0.9896 - Precision: 0.9150 - Recall: 0.5496 - Specificity: 0.9989 - F1: 0.6737 - Loss: 0.0025\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 23:32:19\n",
      "Accuracy: 0.9896 - Precision: 0.9152 - Recall: 0.5505 - Specificity: 0.9989 - F1: 0.6745 - Loss: 0.0025\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 23:32:26\n",
      "Accuracy: 0.9896 - Precision: 0.9152 - Recall: 0.5514 - Specificity: 0.9989 - F1: 0.6752 - Loss: 0.0025\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 23:32:34\n",
      "Accuracy: 0.9896 - Precision: 0.9154 - Recall: 0.5522 - Specificity: 0.9989 - F1: 0.6760 - Loss: 0.0025\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 23:32:42\n",
      "Accuracy: 0.9896 - Precision: 0.9155 - Recall: 0.5530 - Specificity: 0.9989 - F1: 0.6767 - Loss: 0.0025\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 23:32:50\n",
      "Accuracy: 0.9897 - Precision: 0.9158 - Recall: 0.5538 - Specificity: 0.9989 - F1: 0.6775 - Loss: 0.0024\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 23:32:58\n",
      "Accuracy: 0.9897 - Precision: 0.9160 - Recall: 0.5551 - Specificity: 0.9989 - F1: 0.6786 - Loss: 0.0024\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 23:33:06\n",
      "Accuracy: 0.9897 - Precision: 0.9162 - Recall: 0.5561 - Specificity: 0.9989 - F1: 0.6794 - Loss: 0.0024\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 23:33:14\n",
      "Accuracy: 0.9897 - Precision: 0.9163 - Recall: 0.5566 - Specificity: 0.9989 - F1: 0.6799 - Loss: 0.0024\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 23:33:22\n",
      "Accuracy: 0.9897 - Precision: 0.9164 - Recall: 0.5573 - Specificity: 0.9989 - F1: 0.6805 - Loss: 0.0024\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 23:33:31\n",
      "Accuracy: 0.9898 - Precision: 0.9163 - Recall: 0.5581 - Specificity: 0.9989 - F1: 0.6812 - Loss: 0.0024\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 23:33:38\n",
      "Accuracy: 0.9898 - Precision: 0.9166 - Recall: 0.5584 - Specificity: 0.9989 - F1: 0.6816 - Loss: 0.0024\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 23:33:46\n",
      "Accuracy: 0.9898 - Precision: 0.9169 - Recall: 0.5591 - Specificity: 0.9989 - F1: 0.6823 - Loss: 0.0024\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 23:33:54\n",
      "Accuracy: 0.9898 - Precision: 0.9173 - Recall: 0.5593 - Specificity: 0.9989 - F1: 0.6826 - Loss: 0.0024\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 23:34:02\n",
      "Accuracy: 0.9898 - Precision: 0.9176 - Recall: 0.5599 - Specificity: 0.9989 - F1: 0.6833 - Loss: 0.0024\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 23:34:10\n",
      "Accuracy: 0.9898 - Precision: 0.9175 - Recall: 0.5580 - Specificity: 0.9989 - F1: 0.6815 - Loss: 0.0024\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 23:34:18\n",
      "Accuracy: 0.9898 - Precision: 0.9177 - Recall: 0.5584 - Specificity: 0.9990 - F1: 0.6819 - Loss: 0.0024\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 23:34:27\n",
      "Accuracy: 0.9898 - Precision: 0.9178 - Recall: 0.5584 - Specificity: 0.9990 - F1: 0.6820 - Loss: 0.0024\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 23:34:36\n",
      "Accuracy: 0.9898 - Precision: 0.9177 - Recall: 0.5589 - Specificity: 0.9989 - F1: 0.6825 - Loss: 0.0024\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 23:34:44\n",
      "Accuracy: 0.9898 - Precision: 0.9178 - Recall: 0.5596 - Specificity: 0.9989 - F1: 0.6831 - Loss: 0.0024\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 23:34:52\n",
      "Accuracy: 0.9898 - Precision: 0.9181 - Recall: 0.5603 - Specificity: 0.9990 - F1: 0.6838 - Loss: 0.0024\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 23:34:59\n",
      "Accuracy: 0.9898 - Precision: 0.9183 - Recall: 0.5611 - Specificity: 0.9990 - F1: 0.6845 - Loss: 0.0024\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 23:35:07\n",
      "Accuracy: 0.9898 - Precision: 0.9185 - Recall: 0.5615 - Specificity: 0.9990 - F1: 0.6849 - Loss: 0.0024\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 23:35:15\n",
      "Accuracy: 0.9899 - Precision: 0.9187 - Recall: 0.5622 - Specificity: 0.9990 - F1: 0.6856 - Loss: 0.0024\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 23:35:23\n",
      "Accuracy: 0.9899 - Precision: 0.9187 - Recall: 0.5629 - Specificity: 0.9990 - F1: 0.6861 - Loss: 0.0024\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 23:35:31\n",
      "Accuracy: 0.9899 - Precision: 0.9191 - Recall: 0.5633 - Specificity: 0.9990 - F1: 0.6866 - Loss: 0.0024\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 23:35:39\n",
      "Accuracy: 0.9899 - Precision: 0.9194 - Recall: 0.5637 - Specificity: 0.9990 - F1: 0.6871 - Loss: 0.0024\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 23:35:46\n",
      "Accuracy: 0.9899 - Precision: 0.9196 - Recall: 0.5638 - Specificity: 0.9990 - F1: 0.6874 - Loss: 0.0024\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 23:35:54\n",
      "Accuracy: 0.9899 - Precision: 0.9199 - Recall: 0.5643 - Specificity: 0.9990 - F1: 0.6879 - Loss: 0.0024\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 23:36:02\n",
      "Accuracy: 0.9900 - Precision: 0.9197 - Recall: 0.5651 - Specificity: 0.9990 - F1: 0.6884 - Loss: 0.0024\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 23:36:10\n",
      "Accuracy: 0.9900 - Precision: 0.9199 - Recall: 0.5656 - Specificity: 0.9990 - F1: 0.6889 - Loss: 0.0024\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 23:36:17\n",
      "Accuracy: 0.9900 - Precision: 0.9201 - Recall: 0.5664 - Specificity: 0.9990 - F1: 0.6897 - Loss: 0.0024\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 23:36:25\n",
      "Accuracy: 0.9900 - Precision: 0.9199 - Recall: 0.5670 - Specificity: 0.9990 - F1: 0.6901 - Loss: 0.0024\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 23:36:35\n",
      "Accuracy: 0.9900 - Precision: 0.9202 - Recall: 0.5673 - Specificity: 0.9990 - F1: 0.6905 - Loss: 0.0024\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 23:36:43\n",
      "Accuracy: 0.9900 - Precision: 0.9205 - Recall: 0.5673 - Specificity: 0.9990 - F1: 0.6906 - Loss: 0.0024\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 23:36:51\n",
      "Accuracy: 0.9900 - Precision: 0.9207 - Recall: 0.5677 - Specificity: 0.9990 - F1: 0.6910 - Loss: 0.0024\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 23:36:59\n",
      "Accuracy: 0.9901 - Precision: 0.9209 - Recall: 0.5684 - Specificity: 0.9990 - F1: 0.6917 - Loss: 0.0024\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 23:37:07\n",
      "Accuracy: 0.9901 - Precision: 0.9212 - Recall: 0.5689 - Specificity: 0.9990 - F1: 0.6922 - Loss: 0.0024\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 23:37:15\n",
      "Accuracy: 0.9901 - Precision: 0.9211 - Recall: 0.5695 - Specificity: 0.9990 - F1: 0.6927 - Loss: 0.0024\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 23:37:23\n",
      "Accuracy: 0.9901 - Precision: 0.9211 - Recall: 0.5701 - Specificity: 0.9990 - F1: 0.6932 - Loss: 0.0024\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 23:37:31\n",
      "Accuracy: 0.9901 - Precision: 0.9212 - Recall: 0.5707 - Specificity: 0.9990 - F1: 0.6937 - Loss: 0.0024\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 23:37:39\n",
      "Accuracy: 0.9901 - Precision: 0.9210 - Recall: 0.5711 - Specificity: 0.9990 - F1: 0.6939 - Loss: 0.0024\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 23:37:47\n",
      "Accuracy: 0.9901 - Precision: 0.9213 - Recall: 0.5717 - Specificity: 0.9990 - F1: 0.6945 - Loss: 0.0024\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 23:37:54\n",
      "Accuracy: 0.9901 - Precision: 0.9213 - Recall: 0.5724 - Specificity: 0.9990 - F1: 0.6951 - Loss: 0.0024\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 23:38:02\n",
      "Accuracy: 0.9901 - Precision: 0.9214 - Recall: 0.5725 - Specificity: 0.9990 - F1: 0.6953 - Loss: 0.0024\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 23:38:10\n",
      "Accuracy: 0.9901 - Precision: 0.9211 - Recall: 0.5726 - Specificity: 0.9990 - F1: 0.6953 - Loss: 0.0024\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 23:38:18\n",
      "Accuracy: 0.9901 - Precision: 0.9214 - Recall: 0.5726 - Specificity: 0.9990 - F1: 0.6954 - Loss: 0.0024\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 23:38:26\n",
      "Accuracy: 0.9902 - Precision: 0.9216 - Recall: 0.5726 - Specificity: 0.9990 - F1: 0.6956 - Loss: 0.0024\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 23:38:34\n",
      "Accuracy: 0.9902 - Precision: 0.9219 - Recall: 0.5728 - Specificity: 0.9990 - F1: 0.6959 - Loss: 0.0024\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 23:38:44\n",
      "Accuracy: 0.9902 - Precision: 0.9221 - Recall: 0.5727 - Specificity: 0.9990 - F1: 0.6959 - Loss: 0.0024\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 23:38:52\n",
      "Accuracy: 0.9902 - Precision: 0.9222 - Recall: 0.5728 - Specificity: 0.9990 - F1: 0.6961 - Loss: 0.0024\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 23:39:00\n",
      "Accuracy: 0.9902 - Precision: 0.9221 - Recall: 0.5733 - Specificity: 0.9990 - F1: 0.6964 - Loss: 0.0023\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 23:39:08\n",
      "Accuracy: 0.9902 - Precision: 0.9221 - Recall: 0.5736 - Specificity: 0.9990 - F1: 0.6967 - Loss: 0.0023\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 23:39:16\n",
      "Accuracy: 0.9902 - Precision: 0.9221 - Recall: 0.5741 - Specificity: 0.9990 - F1: 0.6971 - Loss: 0.0023\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 23:39:24\n",
      "Accuracy: 0.9902 - Precision: 0.9219 - Recall: 0.5749 - Specificity: 0.9990 - F1: 0.6977 - Loss: 0.0023\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 23:39:32\n",
      "Accuracy: 0.9902 - Precision: 0.9219 - Recall: 0.5756 - Specificity: 0.9990 - F1: 0.6982 - Loss: 0.0023\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 23:39:40\n",
      "Accuracy: 0.9902 - Precision: 0.9221 - Recall: 0.5761 - Specificity: 0.9990 - F1: 0.6987 - Loss: 0.0023\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 23:39:48\n",
      "Accuracy: 0.9902 - Precision: 0.9223 - Recall: 0.5764 - Specificity: 0.9990 - F1: 0.6990 - Loss: 0.0023\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 23:39:56\n",
      "Accuracy: 0.9902 - Precision: 0.9224 - Recall: 0.5767 - Specificity: 0.9990 - F1: 0.6994 - Loss: 0.0023\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 23:40:04\n",
      "Accuracy: 0.9903 - Precision: 0.9219 - Recall: 0.5770 - Specificity: 0.9990 - F1: 0.6994 - Loss: 0.0023\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 23:40:12\n",
      "Accuracy: 0.9903 - Precision: 0.9221 - Recall: 0.5772 - Specificity: 0.9990 - F1: 0.6997 - Loss: 0.0023\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 23:40:20\n",
      "Accuracy: 0.9903 - Precision: 0.9224 - Recall: 0.5770 - Specificity: 0.9990 - F1: 0.6997 - Loss: 0.0023\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 23:40:27\n",
      "Accuracy: 0.9903 - Precision: 0.9226 - Recall: 0.5773 - Specificity: 0.9990 - F1: 0.7000 - Loss: 0.0023\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 23:40:35\n",
      "Accuracy: 0.9903 - Precision: 0.9228 - Recall: 0.5774 - Specificity: 0.9990 - F1: 0.7002 - Loss: 0.0023\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 23:40:43\n",
      "Accuracy: 0.9903 - Precision: 0.9229 - Recall: 0.5774 - Specificity: 0.9990 - F1: 0.7003 - Loss: 0.0023\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 23:40:51\n",
      "Accuracy: 0.9903 - Precision: 0.9231 - Recall: 0.5776 - Specificity: 0.9990 - F1: 0.7005 - Loss: 0.0023\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 23:41:00\n",
      "Accuracy: 0.9903 - Precision: 0.9233 - Recall: 0.5782 - Specificity: 0.9990 - F1: 0.7010 - Loss: 0.0023\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 23:41:08\n",
      "Accuracy: 0.9903 - Precision: 0.9233 - Recall: 0.5786 - Specificity: 0.9990 - F1: 0.7014 - Loss: 0.0023\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 23:41:16\n",
      "Accuracy: 0.9903 - Precision: 0.9233 - Recall: 0.5797 - Specificity: 0.9990 - F1: 0.7022 - Loss: 0.0023\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 23:41:24\n",
      "Accuracy: 0.9904 - Precision: 0.9234 - Recall: 0.5808 - Specificity: 0.9990 - F1: 0.7030 - Loss: 0.0023\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 23:41:32\n",
      "Accuracy: 0.9904 - Precision: 0.9231 - Recall: 0.5817 - Specificity: 0.9990 - F1: 0.7035 - Loss: 0.0023\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 23:41:40\n",
      "Accuracy: 0.9904 - Precision: 0.9231 - Recall: 0.5827 - Specificity: 0.9990 - F1: 0.7042 - Loss: 0.0023\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 23:41:48\n",
      "Accuracy: 0.9904 - Precision: 0.9231 - Recall: 0.5834 - Specificity: 0.9990 - F1: 0.7048 - Loss: 0.0023\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 23:41:55\n",
      "Accuracy: 0.9904 - Precision: 0.9230 - Recall: 0.5840 - Specificity: 0.9990 - F1: 0.7052 - Loss: 0.0023\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 23:42:03\n",
      "Accuracy: 0.9905 - Precision: 0.9232 - Recall: 0.5845 - Specificity: 0.9990 - F1: 0.7057 - Loss: 0.0023\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 23:42:11\n",
      "Accuracy: 0.9905 - Precision: 0.9234 - Recall: 0.5848 - Specificity: 0.9990 - F1: 0.7060 - Loss: 0.0023\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 23:42:19\n",
      "Accuracy: 0.9905 - Precision: 0.9235 - Recall: 0.5851 - Specificity: 0.9990 - F1: 0.7063 - Loss: 0.0023\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 23:42:27\n",
      "Accuracy: 0.9905 - Precision: 0.9238 - Recall: 0.5851 - Specificity: 0.9990 - F1: 0.7064 - Loss: 0.0023\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 23:42:35\n",
      "Accuracy: 0.9905 - Precision: 0.9240 - Recall: 0.5853 - Specificity: 0.9990 - F1: 0.7067 - Loss: 0.0023\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 23:42:42\n",
      "Accuracy: 0.9905 - Precision: 0.9242 - Recall: 0.5850 - Specificity: 0.9990 - F1: 0.7065 - Loss: 0.0023\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 23:42:51\n",
      "Accuracy: 0.9905 - Precision: 0.9242 - Recall: 0.5842 - Specificity: 0.9990 - F1: 0.7059 - Loss: 0.0023\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 23:42:58\n",
      "Accuracy: 0.9904 - Precision: 0.9241 - Recall: 0.5839 - Specificity: 0.9990 - F1: 0.7057 - Loss: 0.0023\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 23:43:08\n",
      "Accuracy: 0.9904 - Precision: 0.9237 - Recall: 0.5834 - Specificity: 0.9990 - F1: 0.7052 - Loss: 0.0023\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 23:43:16\n",
      "Accuracy: 0.9904 - Precision: 0.9238 - Recall: 0.5831 - Specificity: 0.9990 - F1: 0.7051 - Loss: 0.0023\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 23:43:24\n",
      "Accuracy: 0.9904 - Precision: 0.9239 - Recall: 0.5831 - Specificity: 0.9990 - F1: 0.7051 - Loss: 0.0023\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 23:43:33\n",
      "Accuracy: 0.9904 - Precision: 0.9237 - Recall: 0.5828 - Specificity: 0.9990 - F1: 0.7049 - Loss: 0.0023\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 23:43:41\n",
      "Accuracy: 0.9903 - Precision: 0.9236 - Recall: 0.5822 - Specificity: 0.9990 - F1: 0.7044 - Loss: 0.0023\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 23:43:48\n",
      "Accuracy: 0.9903 - Precision: 0.9235 - Recall: 0.5823 - Specificity: 0.9990 - F1: 0.7046 - Loss: 0.0023\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 23:43:56\n",
      "Accuracy: 0.9903 - Precision: 0.9233 - Recall: 0.5820 - Specificity: 0.9990 - F1: 0.7043 - Loss: 0.0023\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 23:44:04\n",
      "Accuracy: 0.9903 - Precision: 0.9231 - Recall: 0.5818 - Specificity: 0.9990 - F1: 0.7041 - Loss: 0.0023\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 23:44:12\n",
      "Accuracy: 0.9903 - Precision: 0.9232 - Recall: 0.5818 - Specificity: 0.9990 - F1: 0.7042 - Loss: 0.0023\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 23:44:19\n",
      "Accuracy: 0.9903 - Precision: 0.9233 - Recall: 0.5811 - Specificity: 0.9990 - F1: 0.7037 - Loss: 0.0023\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 23:44:27\n",
      "Accuracy: 0.9902 - Precision: 0.9236 - Recall: 0.5798 - Specificity: 0.9990 - F1: 0.7026 - Loss: 0.0023\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 23:44:35\n",
      "Accuracy: 0.9902 - Precision: 0.9238 - Recall: 0.5788 - Specificity: 0.9990 - F1: 0.7017 - Loss: 0.0023\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 23:44:43\n",
      "Accuracy: 0.9902 - Precision: 0.9240 - Recall: 0.5781 - Specificity: 0.9990 - F1: 0.7012 - Loss: 0.0023\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 23:44:51\n",
      "Accuracy: 0.9902 - Precision: 0.9243 - Recall: 0.5770 - Specificity: 0.9990 - F1: 0.7002 - Loss: 0.0023\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 23:44:59\n",
      "Accuracy: 0.9902 - Precision: 0.9245 - Recall: 0.5761 - Specificity: 0.9990 - F1: 0.6995 - Loss: 0.0023\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 23:45:06\n",
      "Accuracy: 0.9902 - Precision: 0.9247 - Recall: 0.5758 - Specificity: 0.9990 - F1: 0.6994 - Loss: 0.0023\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 23:45:14\n",
      "Accuracy: 0.9902 - Precision: 0.9246 - Recall: 0.5750 - Specificity: 0.9990 - F1: 0.6988 - Loss: 0.0023\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 23:45:22\n",
      "Accuracy: 0.9901 - Precision: 0.9244 - Recall: 0.5744 - Specificity: 0.9990 - F1: 0.6982 - Loss: 0.0024\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 23:45:30\n",
      "Accuracy: 0.9901 - Precision: 0.9243 - Recall: 0.5740 - Specificity: 0.9990 - F1: 0.6979 - Loss: 0.0024\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 23:45:38\n",
      "Accuracy: 0.9900 - Precision: 0.9241 - Recall: 0.5737 - Specificity: 0.9990 - F1: 0.6977 - Loss: 0.0024\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 23:45:48\n",
      "Accuracy: 0.9900 - Precision: 0.9240 - Recall: 0.5733 - Specificity: 0.9990 - F1: 0.6974 - Loss: 0.0024\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 23:45:57\n",
      "Accuracy: 0.9900 - Precision: 0.9240 - Recall: 0.5732 - Specificity: 0.9990 - F1: 0.6973 - Loss: 0.0024\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 23:46:06\n",
      "Accuracy: 0.9899 - Precision: 0.9240 - Recall: 0.5725 - Specificity: 0.9990 - F1: 0.6968 - Loss: 0.0024\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 23:46:14\n",
      "Accuracy: 0.9899 - Precision: 0.9240 - Recall: 0.5724 - Specificity: 0.9990 - F1: 0.6967 - Loss: 0.0024\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 23:46:22\n",
      "Accuracy: 0.9896 - Precision: 0.9240 - Recall: 0.5705 - Specificity: 0.9990 - F1: 0.6947 - Loss: 0.0025\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 23:46:30\n",
      "Accuracy: 0.9894 - Precision: 0.9240 - Recall: 0.5688 - Specificity: 0.9990 - F1: 0.6930 - Loss: 0.0026\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 23:46:38\n",
      "Accuracy: 0.9892 - Precision: 0.9241 - Recall: 0.5678 - Specificity: 0.9990 - F1: 0.6922 - Loss: 0.0026\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 23:46:46\n",
      "Accuracy: 0.9890 - Precision: 0.9241 - Recall: 0.5670 - Specificity: 0.9990 - F1: 0.6915 - Loss: 0.0027\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 23:46:53\n",
      "Accuracy: 0.9888 - Precision: 0.9235 - Recall: 0.5668 - Specificity: 0.9989 - F1: 0.6912 - Loss: 0.0027\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 23:47:01\n",
      "Accuracy: 0.9887 - Precision: 0.9227 - Recall: 0.5666 - Specificity: 0.9989 - F1: 0.6909 - Loss: 0.0028\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 23:47:09\n",
      "Accuracy: 0.9884 - Precision: 0.9221 - Recall: 0.5650 - Specificity: 0.9989 - F1: 0.6892 - Loss: 0.0029\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 23:47:17\n",
      "Accuracy: 0.9882 - Precision: 0.9214 - Recall: 0.5631 - Specificity: 0.9988 - F1: 0.6871 - Loss: 0.0029\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 23:47:24\n",
      "Accuracy: 0.9878 - Precision: 0.9216 - Recall: 0.5610 - Specificity: 0.9988 - F1: 0.6846 - Loss: 0.0030\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 23:47:32\n",
      "Accuracy: 0.9875 - Precision: 0.9216 - Recall: 0.5588 - Specificity: 0.9989 - F1: 0.6820 - Loss: 0.0030\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 23:47:40\n",
      "Accuracy: 0.9872 - Precision: 0.9219 - Recall: 0.5566 - Specificity: 0.9989 - F1: 0.6794 - Loss: 0.0031\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 23:47:48\n",
      "Accuracy: 0.9871 - Precision: 0.9221 - Recall: 0.5545 - Specificity: 0.9989 - F1: 0.6768 - Loss: 0.0031\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 23:47:56\n",
      "Accuracy: 0.9868 - Precision: 0.9223 - Recall: 0.5523 - Specificity: 0.9989 - F1: 0.6741 - Loss: 0.0031\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 23:48:04\n",
      "Accuracy: 0.9867 - Precision: 0.9221 - Recall: 0.5501 - Specificity: 0.9989 - F1: 0.6715 - Loss: 0.0032\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 23:48:12\n",
      "Accuracy: 0.9864 - Precision: 0.9222 - Recall: 0.5480 - Specificity: 0.9989 - F1: 0.6689 - Loss: 0.0032\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 23:48:20\n",
      "Accuracy: 0.9860 - Precision: 0.9224 - Recall: 0.5459 - Specificity: 0.9989 - F1: 0.6664 - Loss: 0.0033\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 23:48:27\n",
      "Accuracy: 0.9857 - Precision: 0.9226 - Recall: 0.5438 - Specificity: 0.9989 - F1: 0.6638 - Loss: 0.0033\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 23:48:35\n",
      "Accuracy: 0.9856 - Precision: 0.9226 - Recall: 0.5417 - Specificity: 0.9989 - F1: 0.6614 - Loss: 0.0033\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 23:48:43\n",
      "Accuracy: 0.9855 - Precision: 0.9222 - Recall: 0.5396 - Specificity: 0.9989 - F1: 0.6589 - Loss: 0.0034\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 23:48:51\n",
      "Accuracy: 0.9855 - Precision: 0.9224 - Recall: 0.5376 - Specificity: 0.9989 - F1: 0.6564 - Loss: 0.0034\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 23:48:59\n",
      "Accuracy: 0.9854 - Precision: 0.9226 - Recall: 0.5357 - Specificity: 0.9989 - F1: 0.6542 - Loss: 0.0034\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 23:49:07\n",
      "Accuracy: 0.9854 - Precision: 0.9229 - Recall: 0.5337 - Specificity: 0.9989 - F1: 0.6519 - Loss: 0.0034\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 23:49:15\n",
      "Accuracy: 0.9852 - Precision: 0.9232 - Recall: 0.5318 - Specificity: 0.9989 - F1: 0.6495 - Loss: 0.0035\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 23:49:23\n",
      "Accuracy: 0.9852 - Precision: 0.9230 - Recall: 0.5298 - Specificity: 0.9989 - F1: 0.6471 - Loss: 0.0035\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 23:49:31\n",
      "Accuracy: 0.9851 - Precision: 0.9232 - Recall: 0.5278 - Specificity: 0.9989 - F1: 0.6448 - Loss: 0.0035\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 23:49:39\n",
      "Accuracy: 0.9851 - Precision: 0.9204 - Recall: 0.5258 - Specificity: 0.9989 - F1: 0.6423 - Loss: 0.0036\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 23:49:47\n",
      "Accuracy: 0.9850 - Precision: 0.9170 - Recall: 0.5239 - Specificity: 0.9989 - F1: 0.6399 - Loss: 0.0036\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 23:49:55\n",
      "Accuracy: 0.9850 - Precision: 0.9165 - Recall: 0.5219 - Specificity: 0.9989 - F1: 0.6375 - Loss: 0.0036\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 23:50:03\n",
      "Accuracy: 0.9849 - Precision: 0.9168 - Recall: 0.5199 - Specificity: 0.9989 - F1: 0.6352 - Loss: 0.0036\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 23:50:11\n",
      "Accuracy: 0.9849 - Precision: 0.9151 - Recall: 0.5180 - Specificity: 0.9989 - F1: 0.6328 - Loss: 0.0036\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 23:50:18\n",
      "Accuracy: 0.9849 - Precision: 0.9154 - Recall: 0.5161 - Specificity: 0.9989 - F1: 0.6305 - Loss: 0.0036\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 23:50:26\n",
      "Accuracy: 0.9848 - Precision: 0.9157 - Recall: 0.5143 - Specificity: 0.9989 - F1: 0.6283 - Loss: 0.0036\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 23:50:34\n",
      "Accuracy: 0.9848 - Precision: 0.9159 - Recall: 0.5124 - Specificity: 0.9989 - F1: 0.6261 - Loss: 0.0037\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 23:50:42\n",
      "Accuracy: 0.9847 - Precision: 0.9157 - Recall: 0.5106 - Specificity: 0.9990 - F1: 0.6239 - Loss: 0.0037\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 23:50:50\n",
      "Accuracy: 0.9847 - Precision: 0.9152 - Recall: 0.5089 - Specificity: 0.9990 - F1: 0.6218 - Loss: 0.0037\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 23:50:57\n",
      "Accuracy: 0.9846 - Precision: 0.9135 - Recall: 0.5070 - Specificity: 0.9990 - F1: 0.6196 - Loss: 0.0037\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 23:51:05\n",
      "Accuracy: 0.9846 - Precision: 0.9134 - Recall: 0.5052 - Specificity: 0.9990 - F1: 0.6174 - Loss: 0.0037\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 23:51:13\n",
      "Accuracy: 0.9846 - Precision: 0.9110 - Recall: 0.5034 - Specificity: 0.9990 - F1: 0.6152 - Loss: 0.0037\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 23:51:21\n",
      "Accuracy: 0.9846 - Precision: 0.9112 - Recall: 0.5016 - Specificity: 0.9990 - F1: 0.6130 - Loss: 0.0037\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 23:51:29\n",
      "Accuracy: 0.9845 - Precision: 0.9114 - Recall: 0.4999 - Specificity: 0.9990 - F1: 0.6109 - Loss: 0.0037\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 23:51:38\n",
      "Accuracy: 0.9845 - Precision: 0.9101 - Recall: 0.4981 - Specificity: 0.9990 - F1: 0.6088 - Loss: 0.0037\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 23:51:47\n",
      "Accuracy: 0.9845 - Precision: 0.9069 - Recall: 0.4963 - Specificity: 0.9990 - F1: 0.6067 - Loss: 0.0037\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 23:51:54\n",
      "Accuracy: 0.9845 - Precision: 0.9064 - Recall: 0.4946 - Specificity: 0.9990 - F1: 0.6046 - Loss: 0.0037\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 23:52:02\n",
      "Accuracy: 0.9845 - Precision: 0.9032 - Recall: 0.4929 - Specificity: 0.9990 - F1: 0.6024 - Loss: 0.0037\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 23:52:10\n",
      "Accuracy: 0.9845 - Precision: 0.9035 - Recall: 0.4911 - Specificity: 0.9990 - F1: 0.6003 - Loss: 0.0038\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 23:52:18\n",
      "Accuracy: 0.9845 - Precision: 0.9036 - Recall: 0.4894 - Specificity: 0.9990 - F1: 0.5982 - Loss: 0.0038\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 23:52:26\n",
      "Accuracy: 0.9844 - Precision: 0.9039 - Recall: 0.4877 - Specificity: 0.9990 - F1: 0.5962 - Loss: 0.0038\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 23:52:33\n",
      "Accuracy: 0.9843 - Precision: 0.9041 - Recall: 0.4861 - Specificity: 0.9990 - F1: 0.5942 - Loss: 0.0038\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 23:52:41\n",
      "Accuracy: 0.9843 - Precision: 0.9045 - Recall: 0.4844 - Specificity: 0.9990 - F1: 0.5921 - Loss: 0.0038\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 23:52:49\n",
      "Accuracy: 0.9843 - Precision: 0.9047 - Recall: 0.4827 - Specificity: 0.9990 - F1: 0.5901 - Loss: 0.0038\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 23:52:57\n",
      "Accuracy: 0.9842 - Precision: 0.9048 - Recall: 0.4811 - Specificity: 0.9990 - F1: 0.5882 - Loss: 0.0038\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 23:53:05\n",
      "Accuracy: 0.9842 - Precision: 0.9046 - Recall: 0.4795 - Specificity: 0.9990 - F1: 0.5863 - Loss: 0.0038\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 23:53:13\n",
      "Accuracy: 0.9842 - Precision: 0.9041 - Recall: 0.4780 - Specificity: 0.9990 - F1: 0.5844 - Loss: 0.0038\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 23:53:21\n",
      "Accuracy: 0.9842 - Precision: 0.9041 - Recall: 0.4765 - Specificity: 0.9990 - F1: 0.5827 - Loss: 0.0038\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 23:53:29\n",
      "Accuracy: 0.9841 - Precision: 0.9043 - Recall: 0.4750 - Specificity: 0.9990 - F1: 0.5809 - Loss: 0.0038\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 23:53:37\n",
      "Accuracy: 0.9841 - Precision: 0.9044 - Recall: 0.4734 - Specificity: 0.9990 - F1: 0.5791 - Loss: 0.0038\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 23:53:45\n",
      "Accuracy: 0.9840 - Precision: 0.9043 - Recall: 0.4720 - Specificity: 0.9990 - F1: 0.5775 - Loss: 0.0038\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 23:53:53\n",
      "Accuracy: 0.9840 - Precision: 0.9045 - Recall: 0.4706 - Specificity: 0.9990 - F1: 0.5760 - Loss: 0.0038\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 23:54:00\n",
      "Accuracy: 0.9839 - Precision: 0.9045 - Recall: 0.4692 - Specificity: 0.9990 - F1: 0.5743 - Loss: 0.0038\n",
      "\n",
      "Epoch 15/20\n",
      "Validation - Accuracy: 0.9798, Precision: 0.9124, Recall: 0.0663, Specificity: 0.9999, F1: 0.1231, Loss: 0.0047\n",
      "\n",
      "\n",
      "Epoch 16/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 00:01:08\n",
      "Accuracy: 0.9756 - Precision: 0.9463 - Recall: 0.0755 - Specificity: 0.9999 - F1: 0.1398 - Loss: 0.0055\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 00:01:18\n",
      "Accuracy: 0.9745 - Precision: 0.9551 - Recall: 0.0850 - Specificity: 0.9999 - F1: 0.1560 - Loss: 0.0055\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 00:01:26\n",
      "Accuracy: 0.9743 - Precision: 0.9573 - Recall: 0.1145 - Specificity: 0.9999 - F1: 0.2021 - Loss: 0.0052\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 00:01:34\n",
      "Accuracy: 0.9772 - Precision: 0.9564 - Recall: 0.1224 - Specificity: 0.9999 - F1: 0.2148 - Loss: 0.0046\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 00:01:42\n",
      "Accuracy: 0.9790 - Precision: 0.9523 - Recall: 0.1278 - Specificity: 0.9999 - F1: 0.2235 - Loss: 0.0043\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 00:01:50\n",
      "Accuracy: 0.9792 - Precision: 0.9549 - Recall: 0.1366 - Specificity: 0.9999 - F1: 0.2369 - Loss: 0.0042\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 00:01:58\n",
      "Accuracy: 0.9808 - Precision: 0.9549 - Recall: 0.1654 - Specificity: 0.9998 - F1: 0.2744 - Loss: 0.0039\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 00:02:06\n",
      "Accuracy: 0.9815 - Precision: 0.9275 - Recall: 0.1867 - Specificity: 0.9996 - F1: 0.2977 - Loss: 0.0038\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 00:02:14\n",
      "Accuracy: 0.9826 - Precision: 0.9314 - Recall: 0.2180 - Specificity: 0.9996 - F1: 0.3347 - Loss: 0.0036\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 00:02:22\n",
      "Accuracy: 0.9831 - Precision: 0.9330 - Recall: 0.2257 - Specificity: 0.9996 - F1: 0.3462 - Loss: 0.0035\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 00:02:29\n",
      "Accuracy: 0.9836 - Precision: 0.9220 - Recall: 0.2473 - Specificity: 0.9995 - F1: 0.3683 - Loss: 0.0035\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 00:02:37\n",
      "Accuracy: 0.9842 - Precision: 0.9258 - Recall: 0.2676 - Specificity: 0.9995 - F1: 0.3920 - Loss: 0.0034\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 00:02:45\n",
      "Accuracy: 0.9846 - Precision: 0.9265 - Recall: 0.2847 - Specificity: 0.9995 - F1: 0.4113 - Loss: 0.0033\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 00:02:53\n",
      "Accuracy: 0.9847 - Precision: 0.9100 - Recall: 0.2912 - Specificity: 0.9993 - F1: 0.4167 - Loss: 0.0033\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 00:03:01\n",
      "Accuracy: 0.9851 - Precision: 0.9142 - Recall: 0.3055 - Specificity: 0.9993 - F1: 0.4333 - Loss: 0.0032\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 00:03:09\n",
      "Accuracy: 0.9850 - Precision: 0.9169 - Recall: 0.3095 - Specificity: 0.9994 - F1: 0.4396 - Loss: 0.0033\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 00:03:17\n",
      "Accuracy: 0.9855 - Precision: 0.9181 - Recall: 0.3265 - Specificity: 0.9994 - F1: 0.4567 - Loss: 0.0032\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 00:03:24\n",
      "Accuracy: 0.9857 - Precision: 0.9190 - Recall: 0.3400 - Specificity: 0.9993 - F1: 0.4706 - Loss: 0.0032\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 00:03:32\n",
      "Accuracy: 0.9860 - Precision: 0.9174 - Recall: 0.3546 - Specificity: 0.9993 - F1: 0.4842 - Loss: 0.0031\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 00:03:40\n",
      "Accuracy: 0.9864 - Precision: 0.9154 - Recall: 0.3726 - Specificity: 0.9992 - F1: 0.4994 - Loss: 0.0031\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 00:03:48\n",
      "Accuracy: 0.9865 - Precision: 0.9114 - Recall: 0.3798 - Specificity: 0.9992 - F1: 0.5062 - Loss: 0.0031\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 00:03:56\n",
      "Accuracy: 0.9861 - Precision: 0.8959 - Recall: 0.3779 - Specificity: 0.9989 - F1: 0.5025 - Loss: 0.0032\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 00:04:04\n",
      "Accuracy: 0.9861 - Precision: 0.8998 - Recall: 0.3789 - Specificity: 0.9990 - F1: 0.5054 - Loss: 0.0032\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 00:04:13\n",
      "Accuracy: 0.9860 - Precision: 0.9034 - Recall: 0.3770 - Specificity: 0.9990 - F1: 0.5051 - Loss: 0.0032\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 00:04:22\n",
      "Accuracy: 0.9860 - Precision: 0.9062 - Recall: 0.3744 - Specificity: 0.9990 - F1: 0.5038 - Loss: 0.0032\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 00:04:30\n",
      "Accuracy: 0.9861 - Precision: 0.9087 - Recall: 0.3751 - Specificity: 0.9991 - F1: 0.5059 - Loss: 0.0031\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 00:04:38\n",
      "Accuracy: 0.9861 - Precision: 0.9117 - Recall: 0.3717 - Specificity: 0.9991 - F1: 0.5035 - Loss: 0.0031\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 00:04:45\n",
      "Accuracy: 0.9860 - Precision: 0.9147 - Recall: 0.3650 - Specificity: 0.9991 - F1: 0.4967 - Loss: 0.0031\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 00:04:53\n",
      "Accuracy: 0.9856 - Precision: 0.9142 - Recall: 0.3594 - Specificity: 0.9991 - F1: 0.4910 - Loss: 0.0032\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 00:05:01\n",
      "Accuracy: 0.9857 - Precision: 0.9160 - Recall: 0.3619 - Specificity: 0.9992 - F1: 0.4946 - Loss: 0.0032\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 00:05:09\n",
      "Accuracy: 0.9858 - Precision: 0.9158 - Recall: 0.3647 - Specificity: 0.9992 - F1: 0.4980 - Loss: 0.0031\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 00:05:17\n",
      "Accuracy: 0.9858 - Precision: 0.9167 - Recall: 0.3631 - Specificity: 0.9992 - F1: 0.4971 - Loss: 0.0032\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 00:05:24\n",
      "Accuracy: 0.9859 - Precision: 0.9177 - Recall: 0.3652 - Specificity: 0.9992 - F1: 0.5001 - Loss: 0.0031\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 00:05:32\n",
      "Accuracy: 0.9858 - Precision: 0.9196 - Recall: 0.3655 - Specificity: 0.9992 - F1: 0.5014 - Loss: 0.0031\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 00:05:40\n",
      "Accuracy: 0.9858 - Precision: 0.9201 - Recall: 0.3653 - Specificity: 0.9992 - F1: 0.5019 - Loss: 0.0031\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 00:05:48\n",
      "Accuracy: 0.9859 - Precision: 0.9208 - Recall: 0.3674 - Specificity: 0.9992 - F1: 0.5046 - Loss: 0.0031\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 00:05:56\n",
      "Accuracy: 0.9860 - Precision: 0.9222 - Recall: 0.3718 - Specificity: 0.9992 - F1: 0.5095 - Loss: 0.0031\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 00:06:04\n",
      "Accuracy: 0.9860 - Precision: 0.9226 - Recall: 0.3738 - Specificity: 0.9992 - F1: 0.5121 - Loss: 0.0031\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 00:06:11\n",
      "Accuracy: 0.9861 - Precision: 0.9238 - Recall: 0.3775 - Specificity: 0.9992 - F1: 0.5163 - Loss: 0.0031\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 00:06:19\n",
      "Accuracy: 0.9862 - Precision: 0.9245 - Recall: 0.3836 - Specificity: 0.9992 - F1: 0.5222 - Loss: 0.0030\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 00:06:27\n",
      "Accuracy: 0.9861 - Precision: 0.9247 - Recall: 0.3851 - Specificity: 0.9992 - F1: 0.5241 - Loss: 0.0031\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 00:06:35\n",
      "Accuracy: 0.9862 - Precision: 0.9251 - Recall: 0.3918 - Specificity: 0.9992 - F1: 0.5303 - Loss: 0.0030\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 00:06:42\n",
      "Accuracy: 0.9863 - Precision: 0.9242 - Recall: 0.3987 - Specificity: 0.9992 - F1: 0.5359 - Loss: 0.0030\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 00:06:50\n",
      "Accuracy: 0.9865 - Precision: 0.9233 - Recall: 0.4069 - Specificity: 0.9992 - F1: 0.5423 - Loss: 0.0030\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 00:06:58\n",
      "Accuracy: 0.9866 - Precision: 0.9173 - Recall: 0.4153 - Specificity: 0.9991 - F1: 0.5461 - Loss: 0.0030\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 00:07:06\n",
      "Accuracy: 0.9867 - Precision: 0.9177 - Recall: 0.4211 - Specificity: 0.9991 - F1: 0.5513 - Loss: 0.0030\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 00:07:14\n",
      "Accuracy: 0.9867 - Precision: 0.9175 - Recall: 0.4249 - Specificity: 0.9990 - F1: 0.5550 - Loss: 0.0030\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 00:07:22\n",
      "Accuracy: 0.9868 - Precision: 0.9179 - Recall: 0.4285 - Specificity: 0.9990 - F1: 0.5586 - Loss: 0.0030\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 00:07:30\n",
      "Accuracy: 0.9869 - Precision: 0.9185 - Recall: 0.4323 - Specificity: 0.9990 - F1: 0.5624 - Loss: 0.0030\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 00:07:38\n",
      "Accuracy: 0.9869 - Precision: 0.9197 - Recall: 0.4363 - Specificity: 0.9991 - F1: 0.5665 - Loss: 0.0030\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 00:07:46\n",
      "Accuracy: 0.9870 - Precision: 0.9201 - Recall: 0.4401 - Specificity: 0.9991 - F1: 0.5703 - Loss: 0.0029\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 00:07:54\n",
      "Accuracy: 0.9871 - Precision: 0.9203 - Recall: 0.4430 - Specificity: 0.9991 - F1: 0.5732 - Loss: 0.0029\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 00:08:01\n",
      "Accuracy: 0.9872 - Precision: 0.9209 - Recall: 0.4474 - Specificity: 0.9991 - F1: 0.5773 - Loss: 0.0029\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 00:08:09\n",
      "Accuracy: 0.9873 - Precision: 0.9211 - Recall: 0.4528 - Specificity: 0.9991 - F1: 0.5818 - Loss: 0.0029\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 00:08:17\n",
      "Accuracy: 0.9874 - Precision: 0.9211 - Recall: 0.4567 - Specificity: 0.9991 - F1: 0.5854 - Loss: 0.0029\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 00:08:25\n",
      "Accuracy: 0.9875 - Precision: 0.9205 - Recall: 0.4630 - Specificity: 0.9990 - F1: 0.5900 - Loss: 0.0029\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 00:08:33\n",
      "Accuracy: 0.9876 - Precision: 0.9196 - Recall: 0.4676 - Specificity: 0.9990 - F1: 0.5935 - Loss: 0.0028\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 00:08:40\n",
      "Accuracy: 0.9877 - Precision: 0.9191 - Recall: 0.4726 - Specificity: 0.9990 - F1: 0.5974 - Loss: 0.0028\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 00:08:48\n",
      "Accuracy: 0.9879 - Precision: 0.9194 - Recall: 0.4768 - Specificity: 0.9990 - F1: 0.6011 - Loss: 0.0028\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 00:08:56\n",
      "Accuracy: 0.9879 - Precision: 0.9183 - Recall: 0.4803 - Specificity: 0.9990 - F1: 0.6038 - Loss: 0.0028\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 00:09:04\n",
      "Accuracy: 0.9879 - Precision: 0.9178 - Recall: 0.4830 - Specificity: 0.9990 - F1: 0.6061 - Loss: 0.0028\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 00:09:12\n",
      "Accuracy: 0.9880 - Precision: 0.9186 - Recall: 0.4856 - Specificity: 0.9990 - F1: 0.6088 - Loss: 0.0028\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 00:09:20\n",
      "Accuracy: 0.9881 - Precision: 0.9195 - Recall: 0.4877 - Specificity: 0.9990 - F1: 0.6111 - Loss: 0.0028\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 00:09:28\n",
      "Accuracy: 0.9882 - Precision: 0.9199 - Recall: 0.4902 - Specificity: 0.9990 - F1: 0.6136 - Loss: 0.0027\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 00:09:36\n",
      "Accuracy: 0.9882 - Precision: 0.9205 - Recall: 0.4921 - Specificity: 0.9990 - F1: 0.6157 - Loss: 0.0027\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 00:09:44\n",
      "Accuracy: 0.9881 - Precision: 0.9205 - Recall: 0.4925 - Specificity: 0.9990 - F1: 0.6164 - Loss: 0.0027\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 00:09:52\n",
      "Accuracy: 0.9882 - Precision: 0.9201 - Recall: 0.4937 - Specificity: 0.9990 - F1: 0.6177 - Loss: 0.0027\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 00:10:00\n",
      "Accuracy: 0.9882 - Precision: 0.9206 - Recall: 0.4951 - Specificity: 0.9990 - F1: 0.6193 - Loss: 0.0027\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 00:10:08\n",
      "Accuracy: 0.9883 - Precision: 0.9209 - Recall: 0.4981 - Specificity: 0.9990 - F1: 0.6220 - Loss: 0.0027\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 00:10:16\n",
      "Accuracy: 0.9884 - Precision: 0.9210 - Recall: 0.5012 - Specificity: 0.9990 - F1: 0.6246 - Loss: 0.0027\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 00:10:23\n",
      "Accuracy: 0.9884 - Precision: 0.9194 - Recall: 0.5039 - Specificity: 0.9990 - F1: 0.6263 - Loss: 0.0027\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 00:10:31\n",
      "Accuracy: 0.9884 - Precision: 0.9181 - Recall: 0.5062 - Specificity: 0.9989 - F1: 0.6278 - Loss: 0.0027\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 00:10:39\n",
      "Accuracy: 0.9884 - Precision: 0.9185 - Recall: 0.5080 - Specificity: 0.9989 - F1: 0.6297 - Loss: 0.0027\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 00:10:47\n",
      "Accuracy: 0.9884 - Precision: 0.9192 - Recall: 0.5088 - Specificity: 0.9989 - F1: 0.6309 - Loss: 0.0027\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 00:10:55\n",
      "Accuracy: 0.9884 - Precision: 0.9192 - Recall: 0.5099 - Specificity: 0.9989 - F1: 0.6321 - Loss: 0.0027\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 00:11:03\n",
      "Accuracy: 0.9885 - Precision: 0.9200 - Recall: 0.5109 - Specificity: 0.9990 - F1: 0.6334 - Loss: 0.0027\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 00:11:11\n",
      "Accuracy: 0.9885 - Precision: 0.9201 - Recall: 0.5120 - Specificity: 0.9990 - F1: 0.6346 - Loss: 0.0027\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 00:11:18\n",
      "Accuracy: 0.9885 - Precision: 0.9208 - Recall: 0.5127 - Specificity: 0.9990 - F1: 0.6357 - Loss: 0.0027\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 00:11:26\n",
      "Accuracy: 0.9885 - Precision: 0.9213 - Recall: 0.5139 - Specificity: 0.9990 - F1: 0.6371 - Loss: 0.0027\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 00:11:34\n",
      "Accuracy: 0.9886 - Precision: 0.9219 - Recall: 0.5160 - Specificity: 0.9990 - F1: 0.6391 - Loss: 0.0027\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 00:11:42\n",
      "Accuracy: 0.9886 - Precision: 0.9221 - Recall: 0.5175 - Specificity: 0.9990 - F1: 0.6405 - Loss: 0.0027\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 00:11:50\n",
      "Accuracy: 0.9887 - Precision: 0.9219 - Recall: 0.5183 - Specificity: 0.9990 - F1: 0.6414 - Loss: 0.0027\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 00:11:58\n",
      "Accuracy: 0.9887 - Precision: 0.9219 - Recall: 0.5198 - Specificity: 0.9990 - F1: 0.6428 - Loss: 0.0027\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 00:12:06\n",
      "Accuracy: 0.9887 - Precision: 0.9213 - Recall: 0.5215 - Specificity: 0.9990 - F1: 0.6441 - Loss: 0.0026\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 00:12:14\n",
      "Accuracy: 0.9888 - Precision: 0.9214 - Recall: 0.5247 - Specificity: 0.9990 - F1: 0.6466 - Loss: 0.0026\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 00:12:22\n",
      "Accuracy: 0.9888 - Precision: 0.9209 - Recall: 0.5270 - Specificity: 0.9990 - F1: 0.6483 - Loss: 0.0026\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 00:12:30\n",
      "Accuracy: 0.9889 - Precision: 0.9210 - Recall: 0.5293 - Specificity: 0.9989 - F1: 0.6502 - Loss: 0.0026\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 00:12:38\n",
      "Accuracy: 0.9889 - Precision: 0.9209 - Recall: 0.5308 - Specificity: 0.9989 - F1: 0.6516 - Loss: 0.0026\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 00:12:46\n",
      "Accuracy: 0.9890 - Precision: 0.9215 - Recall: 0.5327 - Specificity: 0.9990 - F1: 0.6534 - Loss: 0.0026\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 00:12:54\n",
      "Accuracy: 0.9889 - Precision: 0.9220 - Recall: 0.5335 - Specificity: 0.9990 - F1: 0.6544 - Loss: 0.0026\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 00:13:02\n",
      "Accuracy: 0.9890 - Precision: 0.9224 - Recall: 0.5347 - Specificity: 0.9990 - F1: 0.6557 - Loss: 0.0026\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 00:13:09\n",
      "Accuracy: 0.9890 - Precision: 0.9226 - Recall: 0.5359 - Specificity: 0.9990 - F1: 0.6569 - Loss: 0.0026\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 00:13:18\n",
      "Accuracy: 0.9891 - Precision: 0.9227 - Recall: 0.5375 - Specificity: 0.9990 - F1: 0.6583 - Loss: 0.0026\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 00:13:26\n",
      "Accuracy: 0.9891 - Precision: 0.9227 - Recall: 0.5391 - Specificity: 0.9990 - F1: 0.6597 - Loss: 0.0026\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 00:13:35\n",
      "Accuracy: 0.9891 - Precision: 0.9219 - Recall: 0.5409 - Specificity: 0.9989 - F1: 0.6609 - Loss: 0.0026\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 00:13:44\n",
      "Accuracy: 0.9892 - Precision: 0.9219 - Recall: 0.5422 - Specificity: 0.9989 - F1: 0.6621 - Loss: 0.0026\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 00:13:52\n",
      "Accuracy: 0.9892 - Precision: 0.9221 - Recall: 0.5439 - Specificity: 0.9989 - F1: 0.6635 - Loss: 0.0026\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 00:14:00\n",
      "Accuracy: 0.9892 - Precision: 0.9221 - Recall: 0.5458 - Specificity: 0.9989 - F1: 0.6651 - Loss: 0.0025\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 00:14:08\n",
      "Accuracy: 0.9893 - Precision: 0.9218 - Recall: 0.5469 - Specificity: 0.9989 - F1: 0.6660 - Loss: 0.0025\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 00:14:16\n",
      "Accuracy: 0.9893 - Precision: 0.9216 - Recall: 0.5482 - Specificity: 0.9989 - F1: 0.6671 - Loss: 0.0025\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 00:14:24\n",
      "Accuracy: 0.9894 - Precision: 0.9214 - Recall: 0.5491 - Specificity: 0.9989 - F1: 0.6678 - Loss: 0.0025\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 00:14:34\n",
      "Accuracy: 0.9894 - Precision: 0.9201 - Recall: 0.5492 - Specificity: 0.9989 - F1: 0.6677 - Loss: 0.0025\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 00:14:43\n",
      "Accuracy: 0.9894 - Precision: 0.9200 - Recall: 0.5494 - Specificity: 0.9989 - F1: 0.6680 - Loss: 0.0025\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 00:14:51\n",
      "Accuracy: 0.9894 - Precision: 0.9199 - Recall: 0.5490 - Specificity: 0.9989 - F1: 0.6679 - Loss: 0.0025\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 00:14:59\n",
      "Accuracy: 0.9894 - Precision: 0.9195 - Recall: 0.5484 - Specificity: 0.9989 - F1: 0.6675 - Loss: 0.0025\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 00:15:06\n",
      "Accuracy: 0.9894 - Precision: 0.9197 - Recall: 0.5487 - Specificity: 0.9989 - F1: 0.6680 - Loss: 0.0025\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 00:15:14\n",
      "Accuracy: 0.9894 - Precision: 0.9195 - Recall: 0.5484 - Specificity: 0.9989 - F1: 0.6678 - Loss: 0.0025\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 00:15:22\n",
      "Accuracy: 0.9894 - Precision: 0.9190 - Recall: 0.5480 - Specificity: 0.9989 - F1: 0.6676 - Loss: 0.0025\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 00:15:30\n",
      "Accuracy: 0.9895 - Precision: 0.9190 - Recall: 0.5486 - Specificity: 0.9989 - F1: 0.6682 - Loss: 0.0025\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 00:15:38\n",
      "Accuracy: 0.9895 - Precision: 0.9189 - Recall: 0.5499 - Specificity: 0.9989 - F1: 0.6692 - Loss: 0.0025\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 00:15:46\n",
      "Accuracy: 0.9895 - Precision: 0.9185 - Recall: 0.5500 - Specificity: 0.9989 - F1: 0.6694 - Loss: 0.0025\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 00:15:54\n",
      "Accuracy: 0.9895 - Precision: 0.9183 - Recall: 0.5506 - Specificity: 0.9989 - F1: 0.6699 - Loss: 0.0025\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 00:16:02\n",
      "Accuracy: 0.9896 - Precision: 0.9181 - Recall: 0.5516 - Specificity: 0.9989 - F1: 0.6707 - Loss: 0.0025\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 00:16:10\n",
      "Accuracy: 0.9896 - Precision: 0.9183 - Recall: 0.5521 - Specificity: 0.9989 - F1: 0.6714 - Loss: 0.0025\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 00:16:18\n",
      "Accuracy: 0.9896 - Precision: 0.9187 - Recall: 0.5526 - Specificity: 0.9989 - F1: 0.6720 - Loss: 0.0025\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 00:16:25\n",
      "Accuracy: 0.9896 - Precision: 0.9186 - Recall: 0.5528 - Specificity: 0.9989 - F1: 0.6723 - Loss: 0.0025\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 00:16:33\n",
      "Accuracy: 0.9896 - Precision: 0.9188 - Recall: 0.5529 - Specificity: 0.9989 - F1: 0.6726 - Loss: 0.0025\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 00:16:41\n",
      "Accuracy: 0.9896 - Precision: 0.9190 - Recall: 0.5531 - Specificity: 0.9989 - F1: 0.6729 - Loss: 0.0025\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 00:16:49\n",
      "Accuracy: 0.9896 - Precision: 0.9185 - Recall: 0.5538 - Specificity: 0.9989 - F1: 0.6734 - Loss: 0.0025\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 00:16:57\n",
      "Accuracy: 0.9897 - Precision: 0.9180 - Recall: 0.5547 - Specificity: 0.9989 - F1: 0.6740 - Loss: 0.0025\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 00:17:04\n",
      "Accuracy: 0.9897 - Precision: 0.9178 - Recall: 0.5551 - Specificity: 0.9989 - F1: 0.6744 - Loss: 0.0025\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 00:17:12\n",
      "Accuracy: 0.9897 - Precision: 0.9182 - Recall: 0.5551 - Specificity: 0.9989 - F1: 0.6746 - Loss: 0.0025\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 00:17:20\n",
      "Accuracy: 0.9897 - Precision: 0.9184 - Recall: 0.5556 - Specificity: 0.9989 - F1: 0.6752 - Loss: 0.0025\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 00:17:28\n",
      "Accuracy: 0.9897 - Precision: 0.9187 - Recall: 0.5566 - Specificity: 0.9989 - F1: 0.6763 - Loss: 0.0025\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 00:17:36\n",
      "Accuracy: 0.9897 - Precision: 0.9185 - Recall: 0.5577 - Specificity: 0.9989 - F1: 0.6771 - Loss: 0.0025\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 00:17:44\n",
      "Accuracy: 0.9897 - Precision: 0.9185 - Recall: 0.5593 - Specificity: 0.9989 - F1: 0.6783 - Loss: 0.0025\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 00:17:51\n",
      "Accuracy: 0.9898 - Precision: 0.9174 - Recall: 0.5604 - Specificity: 0.9989 - F1: 0.6788 - Loss: 0.0025\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 00:17:59\n",
      "Accuracy: 0.9898 - Precision: 0.9174 - Recall: 0.5612 - Specificity: 0.9989 - F1: 0.6794 - Loss: 0.0025\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 00:18:07\n",
      "Accuracy: 0.9898 - Precision: 0.9176 - Recall: 0.5622 - Specificity: 0.9989 - F1: 0.6803 - Loss: 0.0024\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 00:18:15\n",
      "Accuracy: 0.9898 - Precision: 0.9178 - Recall: 0.5625 - Specificity: 0.9989 - F1: 0.6808 - Loss: 0.0024\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 00:18:23\n",
      "Accuracy: 0.9898 - Precision: 0.9181 - Recall: 0.5626 - Specificity: 0.9989 - F1: 0.6810 - Loss: 0.0024\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 00:18:31\n",
      "Accuracy: 0.9898 - Precision: 0.9182 - Recall: 0.5633 - Specificity: 0.9989 - F1: 0.6817 - Loss: 0.0024\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 00:18:39\n",
      "Accuracy: 0.9898 - Precision: 0.9185 - Recall: 0.5629 - Specificity: 0.9989 - F1: 0.6816 - Loss: 0.0024\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 00:18:47\n",
      "Accuracy: 0.9898 - Precision: 0.9189 - Recall: 0.5633 - Specificity: 0.9989 - F1: 0.6822 - Loss: 0.0024\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 00:18:55\n",
      "Accuracy: 0.9898 - Precision: 0.9193 - Recall: 0.5636 - Specificity: 0.9989 - F1: 0.6826 - Loss: 0.0024\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 00:19:02\n",
      "Accuracy: 0.9899 - Precision: 0.9194 - Recall: 0.5641 - Specificity: 0.9989 - F1: 0.6832 - Loss: 0.0024\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 00:19:10\n",
      "Accuracy: 0.9899 - Precision: 0.9197 - Recall: 0.5648 - Specificity: 0.9989 - F1: 0.6839 - Loss: 0.0024\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 00:19:18\n",
      "Accuracy: 0.9899 - Precision: 0.9199 - Recall: 0.5654 - Specificity: 0.9989 - F1: 0.6845 - Loss: 0.0024\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 00:19:26\n",
      "Accuracy: 0.9899 - Precision: 0.9200 - Recall: 0.5662 - Specificity: 0.9989 - F1: 0.6852 - Loss: 0.0024\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 00:19:33\n",
      "Accuracy: 0.9899 - Precision: 0.9202 - Recall: 0.5676 - Specificity: 0.9989 - F1: 0.6863 - Loss: 0.0024\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 00:19:41\n",
      "Accuracy: 0.9900 - Precision: 0.9203 - Recall: 0.5687 - Specificity: 0.9989 - F1: 0.6873 - Loss: 0.0024\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 00:19:49\n",
      "Accuracy: 0.9900 - Precision: 0.9204 - Recall: 0.5694 - Specificity: 0.9989 - F1: 0.6879 - Loss: 0.0024\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 00:19:57\n",
      "Accuracy: 0.9900 - Precision: 0.9204 - Recall: 0.5700 - Specificity: 0.9989 - F1: 0.6885 - Loss: 0.0024\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 00:20:05\n",
      "Accuracy: 0.9900 - Precision: 0.9203 - Recall: 0.5709 - Specificity: 0.9989 - F1: 0.6891 - Loss: 0.0024\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 00:20:13\n",
      "Accuracy: 0.9900 - Precision: 0.9205 - Recall: 0.5712 - Specificity: 0.9989 - F1: 0.6895 - Loss: 0.0024\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 00:20:23\n",
      "Accuracy: 0.9900 - Precision: 0.9205 - Recall: 0.5718 - Specificity: 0.9989 - F1: 0.6901 - Loss: 0.0024\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 00:20:31\n",
      "Accuracy: 0.9900 - Precision: 0.9209 - Recall: 0.5717 - Specificity: 0.9989 - F1: 0.6902 - Loss: 0.0024\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 00:20:39\n",
      "Accuracy: 0.9900 - Precision: 0.9213 - Recall: 0.5722 - Specificity: 0.9989 - F1: 0.6908 - Loss: 0.0024\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 00:20:47\n",
      "Accuracy: 0.9900 - Precision: 0.9212 - Recall: 0.5702 - Specificity: 0.9989 - F1: 0.6890 - Loss: 0.0024\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 00:20:55\n",
      "Accuracy: 0.9900 - Precision: 0.9214 - Recall: 0.5702 - Specificity: 0.9990 - F1: 0.6892 - Loss: 0.0024\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 00:21:02\n",
      "Accuracy: 0.9900 - Precision: 0.9216 - Recall: 0.5700 - Specificity: 0.9990 - F1: 0.6892 - Loss: 0.0024\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 00:21:10\n",
      "Accuracy: 0.9900 - Precision: 0.9216 - Recall: 0.5704 - Specificity: 0.9990 - F1: 0.6896 - Loss: 0.0024\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 00:21:18\n",
      "Accuracy: 0.9900 - Precision: 0.9218 - Recall: 0.5707 - Specificity: 0.9990 - F1: 0.6900 - Loss: 0.0024\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 00:21:26\n",
      "Accuracy: 0.9900 - Precision: 0.9220 - Recall: 0.5714 - Specificity: 0.9990 - F1: 0.6906 - Loss: 0.0024\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 00:21:34\n",
      "Accuracy: 0.9900 - Precision: 0.9221 - Recall: 0.5720 - Specificity: 0.9990 - F1: 0.6912 - Loss: 0.0024\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 00:21:42\n",
      "Accuracy: 0.9901 - Precision: 0.9223 - Recall: 0.5726 - Specificity: 0.9990 - F1: 0.6918 - Loss: 0.0024\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 00:21:50\n",
      "Accuracy: 0.9901 - Precision: 0.9223 - Recall: 0.5733 - Specificity: 0.9990 - F1: 0.6924 - Loss: 0.0024\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 00:21:58\n",
      "Accuracy: 0.9901 - Precision: 0.9224 - Recall: 0.5741 - Specificity: 0.9990 - F1: 0.6930 - Loss: 0.0024\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 00:22:05\n",
      "Accuracy: 0.9901 - Precision: 0.9227 - Recall: 0.5747 - Specificity: 0.9990 - F1: 0.6937 - Loss: 0.0024\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 00:22:13\n",
      "Accuracy: 0.9901 - Precision: 0.9228 - Recall: 0.5750 - Specificity: 0.9990 - F1: 0.6941 - Loss: 0.0024\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 00:22:21\n",
      "Accuracy: 0.9901 - Precision: 0.9230 - Recall: 0.5754 - Specificity: 0.9990 - F1: 0.6945 - Loss: 0.0024\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 00:22:29\n",
      "Accuracy: 0.9902 - Precision: 0.9232 - Recall: 0.5760 - Specificity: 0.9990 - F1: 0.6950 - Loss: 0.0024\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 00:22:37\n",
      "Accuracy: 0.9902 - Precision: 0.9230 - Recall: 0.5767 - Specificity: 0.9990 - F1: 0.6955 - Loss: 0.0024\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 00:22:45\n",
      "Accuracy: 0.9902 - Precision: 0.9232 - Recall: 0.5772 - Specificity: 0.9990 - F1: 0.6961 - Loss: 0.0024\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 00:22:53\n",
      "Accuracy: 0.9902 - Precision: 0.9234 - Recall: 0.5780 - Specificity: 0.9990 - F1: 0.6968 - Loss: 0.0024\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 00:23:01\n",
      "Accuracy: 0.9902 - Precision: 0.9233 - Recall: 0.5784 - Specificity: 0.9990 - F1: 0.6972 - Loss: 0.0024\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 00:23:08\n",
      "Accuracy: 0.9902 - Precision: 0.9236 - Recall: 0.5788 - Specificity: 0.9990 - F1: 0.6976 - Loss: 0.0024\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 00:23:16\n",
      "Accuracy: 0.9902 - Precision: 0.9239 - Recall: 0.5791 - Specificity: 0.9990 - F1: 0.6980 - Loss: 0.0024\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 00:23:24\n",
      "Accuracy: 0.9903 - Precision: 0.9241 - Recall: 0.5796 - Specificity: 0.9990 - F1: 0.6985 - Loss: 0.0023\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 00:23:32\n",
      "Accuracy: 0.9903 - Precision: 0.9243 - Recall: 0.5800 - Specificity: 0.9990 - F1: 0.6989 - Loss: 0.0023\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 00:23:40\n",
      "Accuracy: 0.9903 - Precision: 0.9246 - Recall: 0.5801 - Specificity: 0.9990 - F1: 0.6992 - Loss: 0.0023\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 00:23:48\n",
      "Accuracy: 0.9903 - Precision: 0.9248 - Recall: 0.5804 - Specificity: 0.9990 - F1: 0.6996 - Loss: 0.0023\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 00:23:56\n",
      "Accuracy: 0.9903 - Precision: 0.9248 - Recall: 0.5807 - Specificity: 0.9990 - F1: 0.6998 - Loss: 0.0023\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 00:24:03\n",
      "Accuracy: 0.9903 - Precision: 0.9248 - Recall: 0.5814 - Specificity: 0.9990 - F1: 0.7004 - Loss: 0.0023\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 00:24:11\n",
      "Accuracy: 0.9903 - Precision: 0.9243 - Recall: 0.5821 - Specificity: 0.9990 - F1: 0.7008 - Loss: 0.0023\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 00:24:19\n",
      "Accuracy: 0.9903 - Precision: 0.9245 - Recall: 0.5829 - Specificity: 0.9990 - F1: 0.7015 - Loss: 0.0023\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 00:24:27\n",
      "Accuracy: 0.9903 - Precision: 0.9245 - Recall: 0.5836 - Specificity: 0.9990 - F1: 0.7021 - Loss: 0.0023\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 00:24:34\n",
      "Accuracy: 0.9904 - Precision: 0.9247 - Recall: 0.5840 - Specificity: 0.9990 - F1: 0.7025 - Loss: 0.0023\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 00:24:42\n",
      "Accuracy: 0.9904 - Precision: 0.9245 - Recall: 0.5840 - Specificity: 0.9990 - F1: 0.7025 - Loss: 0.0023\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 00:24:50\n",
      "Accuracy: 0.9904 - Precision: 0.9249 - Recall: 0.5838 - Specificity: 0.9990 - F1: 0.7025 - Loss: 0.0023\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 00:24:58\n",
      "Accuracy: 0.9904 - Precision: 0.9252 - Recall: 0.5833 - Specificity: 0.9990 - F1: 0.7023 - Loss: 0.0023\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 00:25:06\n",
      "Accuracy: 0.9904 - Precision: 0.9255 - Recall: 0.5829 - Specificity: 0.9990 - F1: 0.7021 - Loss: 0.0023\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 00:25:13\n",
      "Accuracy: 0.9904 - Precision: 0.9257 - Recall: 0.5826 - Specificity: 0.9990 - F1: 0.7020 - Loss: 0.0023\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 00:25:21\n",
      "Accuracy: 0.9904 - Precision: 0.9258 - Recall: 0.5824 - Specificity: 0.9990 - F1: 0.7019 - Loss: 0.0023\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 00:25:29\n",
      "Accuracy: 0.9904 - Precision: 0.9256 - Recall: 0.5827 - Specificity: 0.9990 - F1: 0.7022 - Loss: 0.0023\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 00:25:37\n",
      "Accuracy: 0.9904 - Precision: 0.9257 - Recall: 0.5832 - Specificity: 0.9990 - F1: 0.7026 - Loss: 0.0023\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 00:25:45\n",
      "Accuracy: 0.9904 - Precision: 0.9257 - Recall: 0.5836 - Specificity: 0.9990 - F1: 0.7029 - Loss: 0.0023\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 00:25:53\n",
      "Accuracy: 0.9904 - Precision: 0.9256 - Recall: 0.5843 - Specificity: 0.9990 - F1: 0.7035 - Loss: 0.0023\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 00:26:00\n",
      "Accuracy: 0.9904 - Precision: 0.9256 - Recall: 0.5852 - Specificity: 0.9990 - F1: 0.7041 - Loss: 0.0023\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 00:26:08\n",
      "Accuracy: 0.9904 - Precision: 0.9257 - Recall: 0.5859 - Specificity: 0.9990 - F1: 0.7047 - Loss: 0.0023\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 00:26:16\n",
      "Accuracy: 0.9904 - Precision: 0.9258 - Recall: 0.5864 - Specificity: 0.9990 - F1: 0.7052 - Loss: 0.0023\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 00:26:24\n",
      "Accuracy: 0.9904 - Precision: 0.9259 - Recall: 0.5867 - Specificity: 0.9990 - F1: 0.7055 - Loss: 0.0023\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 00:26:32\n",
      "Accuracy: 0.9904 - Precision: 0.9253 - Recall: 0.5871 - Specificity: 0.9990 - F1: 0.7056 - Loss: 0.0023\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 00:26:40\n",
      "Accuracy: 0.9905 - Precision: 0.9255 - Recall: 0.5874 - Specificity: 0.9990 - F1: 0.7060 - Loss: 0.0023\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 00:26:48\n",
      "Accuracy: 0.9905 - Precision: 0.9258 - Recall: 0.5873 - Specificity: 0.9990 - F1: 0.7061 - Loss: 0.0023\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 00:26:56\n",
      "Accuracy: 0.9905 - Precision: 0.9259 - Recall: 0.5878 - Specificity: 0.9990 - F1: 0.7065 - Loss: 0.0023\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 00:27:03\n",
      "Accuracy: 0.9905 - Precision: 0.9262 - Recall: 0.5879 - Specificity: 0.9990 - F1: 0.7068 - Loss: 0.0023\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 00:27:11\n",
      "Accuracy: 0.9905 - Precision: 0.9264 - Recall: 0.5880 - Specificity: 0.9990 - F1: 0.7070 - Loss: 0.0023\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 00:27:19\n",
      "Accuracy: 0.9905 - Precision: 0.9266 - Recall: 0.5882 - Specificity: 0.9990 - F1: 0.7072 - Loss: 0.0023\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 00:27:27\n",
      "Accuracy: 0.9905 - Precision: 0.9268 - Recall: 0.5885 - Specificity: 0.9990 - F1: 0.7076 - Loss: 0.0023\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 00:27:35\n",
      "Accuracy: 0.9905 - Precision: 0.9269 - Recall: 0.5890 - Specificity: 0.9990 - F1: 0.7080 - Loss: 0.0023\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 00:27:43\n",
      "Accuracy: 0.9905 - Precision: 0.9269 - Recall: 0.5900 - Specificity: 0.9990 - F1: 0.7087 - Loss: 0.0023\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 00:27:51\n",
      "Accuracy: 0.9906 - Precision: 0.9269 - Recall: 0.5909 - Specificity: 0.9990 - F1: 0.7094 - Loss: 0.0023\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 00:27:59\n",
      "Accuracy: 0.9906 - Precision: 0.9266 - Recall: 0.5919 - Specificity: 0.9990 - F1: 0.7100 - Loss: 0.0023\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 00:28:07\n",
      "Accuracy: 0.9906 - Precision: 0.9265 - Recall: 0.5930 - Specificity: 0.9990 - F1: 0.7107 - Loss: 0.0023\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 00:28:15\n",
      "Accuracy: 0.9906 - Precision: 0.9265 - Recall: 0.5937 - Specificity: 0.9990 - F1: 0.7113 - Loss: 0.0023\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 00:28:23\n",
      "Accuracy: 0.9906 - Precision: 0.9264 - Recall: 0.5945 - Specificity: 0.9990 - F1: 0.7118 - Loss: 0.0023\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 00:28:31\n",
      "Accuracy: 0.9907 - Precision: 0.9265 - Recall: 0.5952 - Specificity: 0.9990 - F1: 0.7124 - Loss: 0.0023\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 00:28:39\n",
      "Accuracy: 0.9907 - Precision: 0.9267 - Recall: 0.5957 - Specificity: 0.9990 - F1: 0.7129 - Loss: 0.0023\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 00:28:47\n",
      "Accuracy: 0.9907 - Precision: 0.9268 - Recall: 0.5961 - Specificity: 0.9990 - F1: 0.7132 - Loss: 0.0022\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 00:28:54\n",
      "Accuracy: 0.9907 - Precision: 0.9270 - Recall: 0.5962 - Specificity: 0.9990 - F1: 0.7135 - Loss: 0.0022\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 00:29:02\n",
      "Accuracy: 0.9907 - Precision: 0.9273 - Recall: 0.5964 - Specificity: 0.9990 - F1: 0.7137 - Loss: 0.0022\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 00:29:10\n",
      "Accuracy: 0.9907 - Precision: 0.9275 - Recall: 0.5959 - Specificity: 0.9990 - F1: 0.7134 - Loss: 0.0022\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 00:29:18\n",
      "Accuracy: 0.9907 - Precision: 0.9276 - Recall: 0.5949 - Specificity: 0.9990 - F1: 0.7127 - Loss: 0.0022\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 00:29:26\n",
      "Accuracy: 0.9906 - Precision: 0.9274 - Recall: 0.5943 - Specificity: 0.9990 - F1: 0.7122 - Loss: 0.0023\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 00:29:34\n",
      "Accuracy: 0.9906 - Precision: 0.9274 - Recall: 0.5936 - Specificity: 0.9990 - F1: 0.7117 - Loss: 0.0023\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 00:29:42\n",
      "Accuracy: 0.9906 - Precision: 0.9275 - Recall: 0.5932 - Specificity: 0.9990 - F1: 0.7114 - Loss: 0.0023\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 00:29:51\n",
      "Accuracy: 0.9906 - Precision: 0.9275 - Recall: 0.5935 - Specificity: 0.9990 - F1: 0.7117 - Loss: 0.0023\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 00:30:00\n",
      "Accuracy: 0.9906 - Precision: 0.9272 - Recall: 0.5933 - Specificity: 0.9990 - F1: 0.7115 - Loss: 0.0023\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 00:30:08\n",
      "Accuracy: 0.9905 - Precision: 0.9271 - Recall: 0.5928 - Specificity: 0.9990 - F1: 0.7112 - Loss: 0.0023\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 00:30:16\n",
      "Accuracy: 0.9905 - Precision: 0.9270 - Recall: 0.5931 - Specificity: 0.9990 - F1: 0.7114 - Loss: 0.0023\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 00:30:24\n",
      "Accuracy: 0.9905 - Precision: 0.9268 - Recall: 0.5927 - Specificity: 0.9990 - F1: 0.7111 - Loss: 0.0023\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 00:30:31\n",
      "Accuracy: 0.9905 - Precision: 0.9263 - Recall: 0.5928 - Specificity: 0.9990 - F1: 0.7111 - Loss: 0.0023\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 00:30:39\n",
      "Accuracy: 0.9905 - Precision: 0.9265 - Recall: 0.5929 - Specificity: 0.9990 - F1: 0.7112 - Loss: 0.0023\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 00:30:47\n",
      "Accuracy: 0.9905 - Precision: 0.9263 - Recall: 0.5923 - Specificity: 0.9990 - F1: 0.7107 - Loss: 0.0023\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 00:30:55\n",
      "Accuracy: 0.9905 - Precision: 0.9265 - Recall: 0.5913 - Specificity: 0.9990 - F1: 0.7099 - Loss: 0.0023\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 00:31:03\n",
      "Accuracy: 0.9904 - Precision: 0.9267 - Recall: 0.5903 - Specificity: 0.9990 - F1: 0.7092 - Loss: 0.0023\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 00:31:11\n",
      "Accuracy: 0.9904 - Precision: 0.9270 - Recall: 0.5896 - Specificity: 0.9990 - F1: 0.7087 - Loss: 0.0023\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 00:31:19\n",
      "Accuracy: 0.9904 - Precision: 0.9272 - Recall: 0.5883 - Specificity: 0.9990 - F1: 0.7076 - Loss: 0.0023\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 00:31:28\n",
      "Accuracy: 0.9904 - Precision: 0.9273 - Recall: 0.5873 - Specificity: 0.9990 - F1: 0.7067 - Loss: 0.0023\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 00:31:36\n",
      "Accuracy: 0.9904 - Precision: 0.9275 - Recall: 0.5867 - Specificity: 0.9990 - F1: 0.7063 - Loss: 0.0023\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 00:31:44\n",
      "Accuracy: 0.9904 - Precision: 0.9275 - Recall: 0.5859 - Specificity: 0.9990 - F1: 0.7057 - Loss: 0.0023\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 00:31:52\n",
      "Accuracy: 0.9903 - Precision: 0.9274 - Recall: 0.5851 - Specificity: 0.9990 - F1: 0.7051 - Loss: 0.0023\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 00:32:00\n",
      "Accuracy: 0.9903 - Precision: 0.9273 - Recall: 0.5847 - Specificity: 0.9990 - F1: 0.7048 - Loss: 0.0023\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 00:32:07\n",
      "Accuracy: 0.9902 - Precision: 0.9272 - Recall: 0.5841 - Specificity: 0.9990 - F1: 0.7043 - Loss: 0.0023\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 00:32:15\n",
      "Accuracy: 0.9902 - Precision: 0.9269 - Recall: 0.5837 - Specificity: 0.9990 - F1: 0.7040 - Loss: 0.0024\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 00:32:23\n",
      "Accuracy: 0.9902 - Precision: 0.9268 - Recall: 0.5836 - Specificity: 0.9990 - F1: 0.7039 - Loss: 0.0024\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 00:32:31\n",
      "Accuracy: 0.9901 - Precision: 0.9268 - Recall: 0.5829 - Specificity: 0.9990 - F1: 0.7033 - Loss: 0.0024\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 00:32:39\n",
      "Accuracy: 0.9901 - Precision: 0.9268 - Recall: 0.5829 - Specificity: 0.9990 - F1: 0.7034 - Loss: 0.0024\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 00:32:48\n",
      "Accuracy: 0.9898 - Precision: 0.9268 - Recall: 0.5809 - Specificity: 0.9990 - F1: 0.7012 - Loss: 0.0025\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 00:32:55\n",
      "Accuracy: 0.9896 - Precision: 0.9268 - Recall: 0.5791 - Specificity: 0.9990 - F1: 0.6994 - Loss: 0.0025\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 00:33:03\n",
      "Accuracy: 0.9894 - Precision: 0.9268 - Recall: 0.5783 - Specificity: 0.9990 - F1: 0.6987 - Loss: 0.0026\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 00:33:11\n",
      "Accuracy: 0.9892 - Precision: 0.9265 - Recall: 0.5778 - Specificity: 0.9990 - F1: 0.6983 - Loss: 0.0026\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 00:33:19\n",
      "Accuracy: 0.9891 - Precision: 0.9259 - Recall: 0.5777 - Specificity: 0.9989 - F1: 0.6981 - Loss: 0.0027\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 00:33:27\n",
      "Accuracy: 0.9889 - Precision: 0.9251 - Recall: 0.5775 - Specificity: 0.9988 - F1: 0.6978 - Loss: 0.0027\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 00:33:35\n",
      "Accuracy: 0.9887 - Precision: 0.9247 - Recall: 0.5762 - Specificity: 0.9988 - F1: 0.6965 - Loss: 0.0028\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 00:33:42\n",
      "Accuracy: 0.9885 - Precision: 0.9239 - Recall: 0.5745 - Specificity: 0.9988 - F1: 0.6947 - Loss: 0.0028\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 00:33:50\n",
      "Accuracy: 0.9881 - Precision: 0.9241 - Recall: 0.5724 - Specificity: 0.9988 - F1: 0.6923 - Loss: 0.0029\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 00:33:58\n",
      "Accuracy: 0.9878 - Precision: 0.9239 - Recall: 0.5702 - Specificity: 0.9988 - F1: 0.6897 - Loss: 0.0029\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 00:34:06\n",
      "Accuracy: 0.9875 - Precision: 0.9241 - Recall: 0.5680 - Specificity: 0.9988 - F1: 0.6872 - Loss: 0.0030\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 00:34:14\n",
      "Accuracy: 0.9874 - Precision: 0.9239 - Recall: 0.5659 - Specificity: 0.9988 - F1: 0.6847 - Loss: 0.0030\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 00:34:22\n",
      "Accuracy: 0.9871 - Precision: 0.9241 - Recall: 0.5636 - Specificity: 0.9988 - F1: 0.6820 - Loss: 0.0031\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 00:34:30\n",
      "Accuracy: 0.9869 - Precision: 0.9236 - Recall: 0.5615 - Specificity: 0.9988 - F1: 0.6794 - Loss: 0.0031\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 00:34:37\n",
      "Accuracy: 0.9866 - Precision: 0.9233 - Recall: 0.5593 - Specificity: 0.9988 - F1: 0.6769 - Loss: 0.0032\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 00:34:45\n",
      "Accuracy: 0.9862 - Precision: 0.9234 - Recall: 0.5572 - Specificity: 0.9988 - F1: 0.6743 - Loss: 0.0032\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 00:34:53\n",
      "Accuracy: 0.9860 - Precision: 0.9232 - Recall: 0.5551 - Specificity: 0.9988 - F1: 0.6718 - Loss: 0.0032\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 00:35:01\n",
      "Accuracy: 0.9858 - Precision: 0.9220 - Recall: 0.5531 - Specificity: 0.9988 - F1: 0.6695 - Loss: 0.0033\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 00:35:09\n",
      "Accuracy: 0.9858 - Precision: 0.9194 - Recall: 0.5510 - Specificity: 0.9988 - F1: 0.6671 - Loss: 0.0033\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 00:35:17\n",
      "Accuracy: 0.9857 - Precision: 0.9178 - Recall: 0.5490 - Specificity: 0.9988 - F1: 0.6646 - Loss: 0.0033\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 00:35:25\n",
      "Accuracy: 0.9857 - Precision: 0.9180 - Recall: 0.5470 - Specificity: 0.9988 - F1: 0.6624 - Loss: 0.0034\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 00:35:33\n",
      "Accuracy: 0.9856 - Precision: 0.9183 - Recall: 0.5450 - Specificity: 0.9988 - F1: 0.6600 - Loss: 0.0034\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 00:35:41\n",
      "Accuracy: 0.9855 - Precision: 0.9186 - Recall: 0.5430 - Specificity: 0.9989 - F1: 0.6576 - Loss: 0.0034\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 00:35:49\n",
      "Accuracy: 0.9854 - Precision: 0.9184 - Recall: 0.5410 - Specificity: 0.9989 - F1: 0.6552 - Loss: 0.0034\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 00:35:56\n",
      "Accuracy: 0.9854 - Precision: 0.9184 - Recall: 0.5390 - Specificity: 0.9989 - F1: 0.6529 - Loss: 0.0035\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 00:36:04\n",
      "Accuracy: 0.9853 - Precision: 0.9178 - Recall: 0.5370 - Specificity: 0.9989 - F1: 0.6505 - Loss: 0.0035\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 00:36:12\n",
      "Accuracy: 0.9853 - Precision: 0.9181 - Recall: 0.5351 - Specificity: 0.9989 - F1: 0.6482 - Loss: 0.0035\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 00:36:20\n",
      "Accuracy: 0.9852 - Precision: 0.9184 - Recall: 0.5331 - Specificity: 0.9989 - F1: 0.6459 - Loss: 0.0035\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 00:36:28\n",
      "Accuracy: 0.9852 - Precision: 0.9187 - Recall: 0.5312 - Specificity: 0.9989 - F1: 0.6435 - Loss: 0.0035\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 00:36:36\n",
      "Accuracy: 0.9852 - Precision: 0.9169 - Recall: 0.5292 - Specificity: 0.9989 - F1: 0.6412 - Loss: 0.0036\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 00:36:43\n",
      "Accuracy: 0.9851 - Precision: 0.9171 - Recall: 0.5273 - Specificity: 0.9989 - F1: 0.6390 - Loss: 0.0036\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 00:36:51\n",
      "Accuracy: 0.9851 - Precision: 0.9174 - Recall: 0.5254 - Specificity: 0.9989 - F1: 0.6367 - Loss: 0.0036\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 00:36:59\n",
      "Accuracy: 0.9850 - Precision: 0.9176 - Recall: 0.5236 - Specificity: 0.9989 - F1: 0.6345 - Loss: 0.0036\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 00:37:07\n",
      "Accuracy: 0.9850 - Precision: 0.9174 - Recall: 0.5217 - Specificity: 0.9989 - F1: 0.6323 - Loss: 0.0036\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 00:37:15\n",
      "Accuracy: 0.9849 - Precision: 0.9174 - Recall: 0.5199 - Specificity: 0.9989 - F1: 0.6302 - Loss: 0.0036\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 00:37:23\n",
      "Accuracy: 0.9849 - Precision: 0.9162 - Recall: 0.5180 - Specificity: 0.9989 - F1: 0.6279 - Loss: 0.0036\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 00:37:31\n",
      "Accuracy: 0.9848 - Precision: 0.9161 - Recall: 0.5162 - Specificity: 0.9989 - F1: 0.6257 - Loss: 0.0036\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 00:37:39\n",
      "Accuracy: 0.9849 - Precision: 0.9128 - Recall: 0.5143 - Specificity: 0.9989 - F1: 0.6234 - Loss: 0.0036\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 00:37:46\n",
      "Accuracy: 0.9848 - Precision: 0.9131 - Recall: 0.5125 - Specificity: 0.9989 - F1: 0.6212 - Loss: 0.0036\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 00:37:54\n",
      "Accuracy: 0.9848 - Precision: 0.9134 - Recall: 0.5107 - Specificity: 0.9989 - F1: 0.6191 - Loss: 0.0036\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 00:38:02\n",
      "Accuracy: 0.9848 - Precision: 0.9123 - Recall: 0.5089 - Specificity: 0.9989 - F1: 0.6170 - Loss: 0.0037\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 00:38:10\n",
      "Accuracy: 0.9847 - Precision: 0.9103 - Recall: 0.5071 - Specificity: 0.9989 - F1: 0.6149 - Loss: 0.0037\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 00:38:18\n",
      "Accuracy: 0.9847 - Precision: 0.9098 - Recall: 0.5054 - Specificity: 0.9989 - F1: 0.6128 - Loss: 0.0037\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 00:38:26\n",
      "Accuracy: 0.9847 - Precision: 0.9074 - Recall: 0.5036 - Specificity: 0.9989 - F1: 0.6106 - Loss: 0.0037\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 00:38:35\n",
      "Accuracy: 0.9847 - Precision: 0.9077 - Recall: 0.5018 - Specificity: 0.9989 - F1: 0.6085 - Loss: 0.0037\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 00:38:44\n",
      "Accuracy: 0.9847 - Precision: 0.9072 - Recall: 0.5001 - Specificity: 0.9989 - F1: 0.6064 - Loss: 0.0037\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 00:38:51\n",
      "Accuracy: 0.9847 - Precision: 0.9074 - Recall: 0.4984 - Specificity: 0.9989 - F1: 0.6044 - Loss: 0.0037\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 00:38:59\n",
      "Accuracy: 0.9846 - Precision: 0.9077 - Recall: 0.4968 - Specificity: 0.9989 - F1: 0.6025 - Loss: 0.0037\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 00:39:07\n",
      "Accuracy: 0.9846 - Precision: 0.9079 - Recall: 0.4951 - Specificity: 0.9990 - F1: 0.6004 - Loss: 0.0037\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 00:39:16\n",
      "Accuracy: 0.9845 - Precision: 0.9080 - Recall: 0.4934 - Specificity: 0.9990 - F1: 0.5984 - Loss: 0.0037\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 00:39:23\n",
      "Accuracy: 0.9845 - Precision: 0.9077 - Recall: 0.4918 - Specificity: 0.9990 - F1: 0.5965 - Loss: 0.0037\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 00:39:31\n",
      "Accuracy: 0.9845 - Precision: 0.9074 - Recall: 0.4902 - Specificity: 0.9990 - F1: 0.5946 - Loss: 0.0037\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 00:39:39\n",
      "Accuracy: 0.9844 - Precision: 0.9070 - Recall: 0.4886 - Specificity: 0.9990 - F1: 0.5928 - Loss: 0.0037\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 00:39:47\n",
      "Accuracy: 0.9844 - Precision: 0.9069 - Recall: 0.4872 - Specificity: 0.9990 - F1: 0.5912 - Loss: 0.0037\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 00:39:55\n",
      "Accuracy: 0.9844 - Precision: 0.9072 - Recall: 0.4856 - Specificity: 0.9990 - F1: 0.5894 - Loss: 0.0037\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 00:40:03\n",
      "Accuracy: 0.9843 - Precision: 0.9069 - Recall: 0.4840 - Specificity: 0.9990 - F1: 0.5875 - Loss: 0.0038\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 00:40:11\n",
      "Accuracy: 0.9843 - Precision: 0.9067 - Recall: 0.4826 - Specificity: 0.9990 - F1: 0.5860 - Loss: 0.0038\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 00:40:19\n",
      "Accuracy: 0.9843 - Precision: 0.9070 - Recall: 0.4812 - Specificity: 0.9990 - F1: 0.5844 - Loss: 0.0038\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 00:40:27\n",
      "Accuracy: 0.9842 - Precision: 0.9069 - Recall: 0.4798 - Specificity: 0.9990 - F1: 0.5828 - Loss: 0.0038\n",
      "\n",
      "Epoch 16/20\n",
      "Validation - Accuracy: 0.9798, Precision: 0.9173, Recall: 0.0644, Specificity: 0.9999, F1: 0.1199, Loss: 0.0047\n",
      "\n",
      "\n",
      "Epoch 17/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 00:47:40\n",
      "Accuracy: 0.9754 - Precision: 0.9582 - Recall: 0.0650 - Specificity: 0.9999 - F1: 0.1217 - Loss: 0.0053\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 00:47:48\n",
      "Accuracy: 0.9741 - Precision: 0.9720 - Recall: 0.0708 - Specificity: 0.9999 - F1: 0.1320 - Loss: 0.0055\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 00:47:56\n",
      "Accuracy: 0.9736 - Precision: 0.9757 - Recall: 0.0866 - Specificity: 0.9999 - F1: 0.1583 - Loss: 0.0052\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 00:48:04\n",
      "Accuracy: 0.9764 - Precision: 0.9782 - Recall: 0.0912 - Specificity: 0.9999 - F1: 0.1661 - Loss: 0.0046\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 00:48:12\n",
      "Accuracy: 0.9783 - Precision: 0.9728 - Recall: 0.0944 - Specificity: 0.9999 - F1: 0.1714 - Loss: 0.0043\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 00:48:20\n",
      "Accuracy: 0.9786 - Precision: 0.9762 - Recall: 0.1055 - Specificity: 0.9999 - F1: 0.1890 - Loss: 0.0041\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 00:48:28\n",
      "Accuracy: 0.9802 - Precision: 0.9731 - Recall: 0.1314 - Specificity: 0.9999 - F1: 0.2250 - Loss: 0.0038\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 00:48:36\n",
      "Accuracy: 0.9809 - Precision: 0.9411 - Recall: 0.1554 - Specificity: 0.9996 - F1: 0.2527 - Loss: 0.0037\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 00:48:44\n",
      "Accuracy: 0.9820 - Precision: 0.9451 - Recall: 0.1865 - Specificity: 0.9997 - F1: 0.2915 - Loss: 0.0035\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 00:48:52\n",
      "Accuracy: 0.9825 - Precision: 0.9477 - Recall: 0.1944 - Specificity: 0.9997 - F1: 0.3040 - Loss: 0.0035\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 00:49:00\n",
      "Accuracy: 0.9831 - Precision: 0.9373 - Recall: 0.2164 - Specificity: 0.9996 - F1: 0.3285 - Loss: 0.0034\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 00:49:08\n",
      "Accuracy: 0.9837 - Precision: 0.9408 - Recall: 0.2367 - Specificity: 0.9996 - F1: 0.3533 - Loss: 0.0033\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 00:49:16\n",
      "Accuracy: 0.9841 - Precision: 0.9401 - Recall: 0.2569 - Specificity: 0.9996 - F1: 0.3761 - Loss: 0.0032\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 00:49:24\n",
      "Accuracy: 0.9843 - Precision: 0.9198 - Recall: 0.2683 - Specificity: 0.9993 - F1: 0.3857 - Loss: 0.0033\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 00:49:33\n",
      "Accuracy: 0.9847 - Precision: 0.9225 - Recall: 0.2815 - Specificity: 0.9994 - F1: 0.4018 - Loss: 0.0032\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 00:49:42\n",
      "Accuracy: 0.9845 - Precision: 0.9230 - Recall: 0.2857 - Specificity: 0.9993 - F1: 0.4084 - Loss: 0.0033\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 00:49:50\n",
      "Accuracy: 0.9850 - Precision: 0.9255 - Recall: 0.3013 - Specificity: 0.9994 - F1: 0.4257 - Loss: 0.0032\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 00:49:58\n",
      "Accuracy: 0.9852 - Precision: 0.9287 - Recall: 0.3117 - Specificity: 0.9994 - F1: 0.4383 - Loss: 0.0031\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 00:50:06\n",
      "Accuracy: 0.9855 - Precision: 0.9306 - Recall: 0.3234 - Specificity: 0.9994 - F1: 0.4513 - Loss: 0.0031\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 00:50:14\n",
      "Accuracy: 0.9858 - Precision: 0.9292 - Recall: 0.3364 - Specificity: 0.9994 - F1: 0.4643 - Loss: 0.0030\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 00:50:22\n",
      "Accuracy: 0.9859 - Precision: 0.9264 - Recall: 0.3432 - Specificity: 0.9993 - F1: 0.4715 - Loss: 0.0030\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 00:50:30\n",
      "Accuracy: 0.9856 - Precision: 0.9113 - Recall: 0.3423 - Specificity: 0.9991 - F1: 0.4692 - Loss: 0.0032\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 00:50:38\n",
      "Accuracy: 0.9856 - Precision: 0.9146 - Recall: 0.3440 - Specificity: 0.9992 - F1: 0.4727 - Loss: 0.0032\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 00:50:45\n",
      "Accuracy: 0.9855 - Precision: 0.9166 - Recall: 0.3443 - Specificity: 0.9992 - F1: 0.4744 - Loss: 0.0032\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 00:50:53\n",
      "Accuracy: 0.9856 - Precision: 0.9189 - Recall: 0.3463 - Specificity: 0.9992 - F1: 0.4779 - Loss: 0.0031\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 00:51:01\n",
      "Accuracy: 0.9858 - Precision: 0.9205 - Recall: 0.3513 - Specificity: 0.9992 - F1: 0.4840 - Loss: 0.0031\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 00:51:09\n",
      "Accuracy: 0.9858 - Precision: 0.9226 - Recall: 0.3512 - Specificity: 0.9992 - F1: 0.4851 - Loss: 0.0031\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 00:51:17\n",
      "Accuracy: 0.9857 - Precision: 0.9242 - Recall: 0.3475 - Specificity: 0.9993 - F1: 0.4818 - Loss: 0.0031\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 00:51:24\n",
      "Accuracy: 0.9854 - Precision: 0.9230 - Recall: 0.3426 - Specificity: 0.9993 - F1: 0.4768 - Loss: 0.0031\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 00:51:32\n",
      "Accuracy: 0.9854 - Precision: 0.9246 - Recall: 0.3445 - Specificity: 0.9993 - F1: 0.4798 - Loss: 0.0031\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 00:51:42\n",
      "Accuracy: 0.9856 - Precision: 0.9257 - Recall: 0.3461 - Specificity: 0.9993 - F1: 0.4823 - Loss: 0.0031\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 00:51:50\n",
      "Accuracy: 0.9855 - Precision: 0.9270 - Recall: 0.3438 - Specificity: 0.9993 - F1: 0.4805 - Loss: 0.0031\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 00:51:58\n",
      "Accuracy: 0.9856 - Precision: 0.9281 - Recall: 0.3445 - Specificity: 0.9993 - F1: 0.4821 - Loss: 0.0031\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 00:52:06\n",
      "Accuracy: 0.9854 - Precision: 0.9297 - Recall: 0.3425 - Specificity: 0.9993 - F1: 0.4806 - Loss: 0.0031\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 00:52:14\n",
      "Accuracy: 0.9854 - Precision: 0.9311 - Recall: 0.3409 - Specificity: 0.9994 - F1: 0.4795 - Loss: 0.0031\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 00:52:22\n",
      "Accuracy: 0.9855 - Precision: 0.9314 - Recall: 0.3430 - Specificity: 0.9994 - F1: 0.4822 - Loss: 0.0030\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 00:52:29\n",
      "Accuracy: 0.9856 - Precision: 0.9327 - Recall: 0.3471 - Specificity: 0.9994 - F1: 0.4870 - Loss: 0.0030\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 00:52:37\n",
      "Accuracy: 0.9856 - Precision: 0.9329 - Recall: 0.3504 - Specificity: 0.9994 - F1: 0.4907 - Loss: 0.0030\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 00:52:45\n",
      "Accuracy: 0.9857 - Precision: 0.9337 - Recall: 0.3548 - Specificity: 0.9994 - F1: 0.4954 - Loss: 0.0030\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 00:52:53\n",
      "Accuracy: 0.9858 - Precision: 0.9335 - Recall: 0.3611 - Specificity: 0.9994 - F1: 0.5014 - Loss: 0.0030\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 00:53:01\n",
      "Accuracy: 0.9857 - Precision: 0.9338 - Recall: 0.3616 - Specificity: 0.9994 - F1: 0.5025 - Loss: 0.0030\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 00:53:08\n",
      "Accuracy: 0.9858 - Precision: 0.9344 - Recall: 0.3674 - Specificity: 0.9994 - F1: 0.5082 - Loss: 0.0030\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 00:53:16\n",
      "Accuracy: 0.9859 - Precision: 0.9346 - Recall: 0.3734 - Specificity: 0.9994 - F1: 0.5138 - Loss: 0.0030\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 00:53:24\n",
      "Accuracy: 0.9861 - Precision: 0.9346 - Recall: 0.3805 - Specificity: 0.9993 - F1: 0.5202 - Loss: 0.0030\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 00:53:33\n",
      "Accuracy: 0.9862 - Precision: 0.9300 - Recall: 0.3880 - Specificity: 0.9993 - F1: 0.5246 - Loss: 0.0030\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 00:53:40\n",
      "Accuracy: 0.9863 - Precision: 0.9304 - Recall: 0.3930 - Specificity: 0.9993 - F1: 0.5295 - Loss: 0.0029\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 00:53:48\n",
      "Accuracy: 0.9864 - Precision: 0.9302 - Recall: 0.3969 - Specificity: 0.9993 - F1: 0.5333 - Loss: 0.0029\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 00:53:58\n",
      "Accuracy: 0.9864 - Precision: 0.9305 - Recall: 0.4013 - Specificity: 0.9993 - F1: 0.5376 - Loss: 0.0029\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 00:54:06\n",
      "Accuracy: 0.9865 - Precision: 0.9306 - Recall: 0.4060 - Specificity: 0.9993 - F1: 0.5421 - Loss: 0.0029\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 00:54:14\n",
      "Accuracy: 0.9866 - Precision: 0.9311 - Recall: 0.4114 - Specificity: 0.9992 - F1: 0.5470 - Loss: 0.0029\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 00:54:22\n",
      "Accuracy: 0.9867 - Precision: 0.9308 - Recall: 0.4169 - Specificity: 0.9992 - F1: 0.5518 - Loss: 0.0029\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 00:54:30\n",
      "Accuracy: 0.9868 - Precision: 0.9301 - Recall: 0.4213 - Specificity: 0.9992 - F1: 0.5556 - Loss: 0.0029\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 00:54:38\n",
      "Accuracy: 0.9869 - Precision: 0.9302 - Recall: 0.4266 - Specificity: 0.9992 - F1: 0.5602 - Loss: 0.0029\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 00:54:46\n",
      "Accuracy: 0.9871 - Precision: 0.9302 - Recall: 0.4328 - Specificity: 0.9992 - F1: 0.5653 - Loss: 0.0028\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 00:54:53\n",
      "Accuracy: 0.9872 - Precision: 0.9299 - Recall: 0.4378 - Specificity: 0.9992 - F1: 0.5696 - Loss: 0.0028\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 00:55:01\n",
      "Accuracy: 0.9873 - Precision: 0.9290 - Recall: 0.4442 - Specificity: 0.9992 - F1: 0.5743 - Loss: 0.0028\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 00:55:09\n",
      "Accuracy: 0.9874 - Precision: 0.9282 - Recall: 0.4493 - Specificity: 0.9992 - F1: 0.5784 - Loss: 0.0028\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 00:55:17\n",
      "Accuracy: 0.9875 - Precision: 0.9278 - Recall: 0.4542 - Specificity: 0.9991 - F1: 0.5824 - Loss: 0.0028\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 00:55:25\n",
      "Accuracy: 0.9876 - Precision: 0.9281 - Recall: 0.4582 - Specificity: 0.9991 - F1: 0.5860 - Loss: 0.0028\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 00:55:33\n",
      "Accuracy: 0.9876 - Precision: 0.9268 - Recall: 0.4615 - Specificity: 0.9991 - F1: 0.5886 - Loss: 0.0028\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 00:55:41\n",
      "Accuracy: 0.9877 - Precision: 0.9266 - Recall: 0.4640 - Specificity: 0.9991 - F1: 0.5910 - Loss: 0.0028\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 00:55:48\n",
      "Accuracy: 0.9878 - Precision: 0.9272 - Recall: 0.4665 - Specificity: 0.9991 - F1: 0.5936 - Loss: 0.0027\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 00:55:56\n",
      "Accuracy: 0.9878 - Precision: 0.9280 - Recall: 0.4690 - Specificity: 0.9991 - F1: 0.5963 - Loss: 0.0027\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 00:56:04\n",
      "Accuracy: 0.9879 - Precision: 0.9283 - Recall: 0.4719 - Specificity: 0.9991 - F1: 0.5990 - Loss: 0.0027\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 00:56:14\n",
      "Accuracy: 0.9879 - Precision: 0.9286 - Recall: 0.4735 - Specificity: 0.9991 - F1: 0.6009 - Loss: 0.0027\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 00:56:22\n",
      "Accuracy: 0.9879 - Precision: 0.9286 - Recall: 0.4744 - Specificity: 0.9991 - F1: 0.6020 - Loss: 0.0027\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 00:56:30\n",
      "Accuracy: 0.9879 - Precision: 0.9284 - Recall: 0.4761 - Specificity: 0.9991 - F1: 0.6037 - Loss: 0.0027\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 00:56:38\n",
      "Accuracy: 0.9880 - Precision: 0.9287 - Recall: 0.4775 - Specificity: 0.9991 - F1: 0.6053 - Loss: 0.0027\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 00:56:46\n",
      "Accuracy: 0.9880 - Precision: 0.9288 - Recall: 0.4805 - Specificity: 0.9991 - F1: 0.6080 - Loss: 0.0027\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 00:56:54\n",
      "Accuracy: 0.9881 - Precision: 0.9288 - Recall: 0.4837 - Specificity: 0.9991 - F1: 0.6108 - Loss: 0.0027\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 00:57:01\n",
      "Accuracy: 0.9882 - Precision: 0.9272 - Recall: 0.4862 - Specificity: 0.9991 - F1: 0.6125 - Loss: 0.0027\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 00:57:09\n",
      "Accuracy: 0.9882 - Precision: 0.9259 - Recall: 0.4888 - Specificity: 0.9991 - F1: 0.6143 - Loss: 0.0027\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 00:57:17\n",
      "Accuracy: 0.9882 - Precision: 0.9263 - Recall: 0.4908 - Specificity: 0.9991 - F1: 0.6163 - Loss: 0.0027\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 00:57:25\n",
      "Accuracy: 0.9882 - Precision: 0.9268 - Recall: 0.4919 - Specificity: 0.9991 - F1: 0.6177 - Loss: 0.0027\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 00:57:33\n",
      "Accuracy: 0.9882 - Precision: 0.9270 - Recall: 0.4929 - Specificity: 0.9991 - F1: 0.6189 - Loss: 0.0027\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 00:57:41\n",
      "Accuracy: 0.9882 - Precision: 0.9276 - Recall: 0.4938 - Specificity: 0.9991 - F1: 0.6201 - Loss: 0.0027\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 00:57:48\n",
      "Accuracy: 0.9883 - Precision: 0.9276 - Recall: 0.4950 - Specificity: 0.9991 - F1: 0.6214 - Loss: 0.0027\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 00:57:56\n",
      "Accuracy: 0.9883 - Precision: 0.9281 - Recall: 0.4962 - Specificity: 0.9991 - F1: 0.6228 - Loss: 0.0027\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 00:58:04\n",
      "Accuracy: 0.9883 - Precision: 0.9283 - Recall: 0.4976 - Specificity: 0.9991 - F1: 0.6243 - Loss: 0.0027\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 00:58:12\n",
      "Accuracy: 0.9884 - Precision: 0.9287 - Recall: 0.4997 - Specificity: 0.9991 - F1: 0.6263 - Loss: 0.0026\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 00:58:20\n",
      "Accuracy: 0.9884 - Precision: 0.9288 - Recall: 0.5017 - Specificity: 0.9991 - F1: 0.6282 - Loss: 0.0026\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 00:58:28\n",
      "Accuracy: 0.9884 - Precision: 0.9286 - Recall: 0.5029 - Specificity: 0.9991 - F1: 0.6293 - Loss: 0.0026\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 00:58:36\n",
      "Accuracy: 0.9885 - Precision: 0.9284 - Recall: 0.5045 - Specificity: 0.9991 - F1: 0.6308 - Loss: 0.0026\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 00:58:44\n",
      "Accuracy: 0.9885 - Precision: 0.9278 - Recall: 0.5063 - Specificity: 0.9991 - F1: 0.6322 - Loss: 0.0026\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 00:58:51\n",
      "Accuracy: 0.9886 - Precision: 0.9280 - Recall: 0.5095 - Specificity: 0.9991 - F1: 0.6348 - Loss: 0.0026\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 00:58:59\n",
      "Accuracy: 0.9886 - Precision: 0.9275 - Recall: 0.5118 - Specificity: 0.9991 - F1: 0.6365 - Loss: 0.0026\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 00:59:07\n",
      "Accuracy: 0.9887 - Precision: 0.9277 - Recall: 0.5141 - Specificity: 0.9991 - F1: 0.6386 - Loss: 0.0026\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 00:59:15\n",
      "Accuracy: 0.9887 - Precision: 0.9276 - Recall: 0.5153 - Specificity: 0.9991 - F1: 0.6397 - Loss: 0.0026\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 00:59:23\n",
      "Accuracy: 0.9887 - Precision: 0.9282 - Recall: 0.5169 - Specificity: 0.9991 - F1: 0.6414 - Loss: 0.0026\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 00:59:31\n",
      "Accuracy: 0.9887 - Precision: 0.9287 - Recall: 0.5175 - Specificity: 0.9991 - F1: 0.6422 - Loss: 0.0026\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 00:59:39\n",
      "Accuracy: 0.9888 - Precision: 0.9291 - Recall: 0.5189 - Specificity: 0.9991 - F1: 0.6437 - Loss: 0.0026\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 00:59:46\n",
      "Accuracy: 0.9888 - Precision: 0.9293 - Recall: 0.5205 - Specificity: 0.9991 - F1: 0.6452 - Loss: 0.0026\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 00:59:54\n",
      "Accuracy: 0.9889 - Precision: 0.9295 - Recall: 0.5221 - Specificity: 0.9991 - F1: 0.6467 - Loss: 0.0026\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 01:00:02\n",
      "Accuracy: 0.9889 - Precision: 0.9294 - Recall: 0.5238 - Specificity: 0.9991 - F1: 0.6481 - Loss: 0.0025\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 01:00:10\n",
      "Accuracy: 0.9889 - Precision: 0.9287 - Recall: 0.5258 - Specificity: 0.9991 - F1: 0.6496 - Loss: 0.0025\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 01:00:18\n",
      "Accuracy: 0.9890 - Precision: 0.9282 - Recall: 0.5279 - Specificity: 0.9991 - F1: 0.6510 - Loss: 0.0025\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 01:00:26\n",
      "Accuracy: 0.9890 - Precision: 0.9283 - Recall: 0.5300 - Specificity: 0.9991 - F1: 0.6528 - Loss: 0.0025\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 01:00:34\n",
      "Accuracy: 0.9891 - Precision: 0.9283 - Recall: 0.5321 - Specificity: 0.9991 - F1: 0.6545 - Loss: 0.0025\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 01:00:41\n",
      "Accuracy: 0.9891 - Precision: 0.9281 - Recall: 0.5334 - Specificity: 0.9990 - F1: 0.6557 - Loss: 0.0025\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 01:00:49\n",
      "Accuracy: 0.9891 - Precision: 0.9277 - Recall: 0.5350 - Specificity: 0.9990 - F1: 0.6569 - Loss: 0.0025\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 01:00:57\n",
      "Accuracy: 0.9892 - Precision: 0.9272 - Recall: 0.5362 - Specificity: 0.9990 - F1: 0.6579 - Loss: 0.0025\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 01:01:05\n",
      "Accuracy: 0.9892 - Precision: 0.9262 - Recall: 0.5363 - Specificity: 0.9990 - F1: 0.6578 - Loss: 0.0025\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 01:01:13\n",
      "Accuracy: 0.9892 - Precision: 0.9261 - Recall: 0.5366 - Specificity: 0.9990 - F1: 0.6583 - Loss: 0.0025\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 01:01:20\n",
      "Accuracy: 0.9892 - Precision: 0.9262 - Recall: 0.5365 - Specificity: 0.9990 - F1: 0.6584 - Loss: 0.0025\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 01:01:28\n",
      "Accuracy: 0.9892 - Precision: 0.9259 - Recall: 0.5363 - Specificity: 0.9990 - F1: 0.6584 - Loss: 0.0025\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 01:01:36\n",
      "Accuracy: 0.9893 - Precision: 0.9259 - Recall: 0.5367 - Specificity: 0.9990 - F1: 0.6588 - Loss: 0.0025\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 01:01:44\n",
      "Accuracy: 0.9893 - Precision: 0.9256 - Recall: 0.5370 - Specificity: 0.9990 - F1: 0.6592 - Loss: 0.0025\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 01:01:52\n",
      "Accuracy: 0.9893 - Precision: 0.9250 - Recall: 0.5373 - Specificity: 0.9990 - F1: 0.6594 - Loss: 0.0025\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 01:01:59\n",
      "Accuracy: 0.9893 - Precision: 0.9250 - Recall: 0.5384 - Specificity: 0.9990 - F1: 0.6604 - Loss: 0.0025\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 01:02:08\n",
      "Accuracy: 0.9894 - Precision: 0.9249 - Recall: 0.5400 - Specificity: 0.9990 - F1: 0.6617 - Loss: 0.0025\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 01:02:16\n",
      "Accuracy: 0.9894 - Precision: 0.9242 - Recall: 0.5405 - Specificity: 0.9990 - F1: 0.6620 - Loss: 0.0025\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 01:02:23\n",
      "Accuracy: 0.9894 - Precision: 0.9237 - Recall: 0.5416 - Specificity: 0.9990 - F1: 0.6629 - Loss: 0.0025\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 01:02:31\n",
      "Accuracy: 0.9895 - Precision: 0.9233 - Recall: 0.5426 - Specificity: 0.9990 - F1: 0.6636 - Loss: 0.0025\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 01:02:39\n",
      "Accuracy: 0.9895 - Precision: 0.9234 - Recall: 0.5434 - Specificity: 0.9990 - F1: 0.6645 - Loss: 0.0025\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 01:02:47\n",
      "Accuracy: 0.9895 - Precision: 0.9237 - Recall: 0.5441 - Specificity: 0.9990 - F1: 0.6652 - Loss: 0.0024\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 01:02:56\n",
      "Accuracy: 0.9895 - Precision: 0.9238 - Recall: 0.5445 - Specificity: 0.9990 - F1: 0.6657 - Loss: 0.0024\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 01:03:04\n",
      "Accuracy: 0.9895 - Precision: 0.9239 - Recall: 0.5445 - Specificity: 0.9990 - F1: 0.6660 - Loss: 0.0024\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 01:03:12\n",
      "Accuracy: 0.9895 - Precision: 0.9242 - Recall: 0.5447 - Specificity: 0.9990 - F1: 0.6663 - Loss: 0.0024\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 01:03:20\n",
      "Accuracy: 0.9895 - Precision: 0.9240 - Recall: 0.5451 - Specificity: 0.9990 - F1: 0.6668 - Loss: 0.0024\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 01:03:28\n",
      "Accuracy: 0.9896 - Precision: 0.9237 - Recall: 0.5458 - Specificity: 0.9990 - F1: 0.6673 - Loss: 0.0024\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 01:03:36\n",
      "Accuracy: 0.9896 - Precision: 0.9235 - Recall: 0.5461 - Specificity: 0.9990 - F1: 0.6676 - Loss: 0.0024\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 01:03:44\n",
      "Accuracy: 0.9896 - Precision: 0.9238 - Recall: 0.5460 - Specificity: 0.9990 - F1: 0.6678 - Loss: 0.0024\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 01:03:52\n",
      "Accuracy: 0.9895 - Precision: 0.9240 - Recall: 0.5463 - Specificity: 0.9990 - F1: 0.6682 - Loss: 0.0024\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 01:04:00\n",
      "Accuracy: 0.9896 - Precision: 0.9243 - Recall: 0.5473 - Specificity: 0.9990 - F1: 0.6692 - Loss: 0.0024\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 01:04:08\n",
      "Accuracy: 0.9896 - Precision: 0.9241 - Recall: 0.5485 - Specificity: 0.9990 - F1: 0.6702 - Loss: 0.0024\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 01:04:16\n",
      "Accuracy: 0.9896 - Precision: 0.9241 - Recall: 0.5502 - Specificity: 0.9990 - F1: 0.6714 - Loss: 0.0024\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 01:04:24\n",
      "Accuracy: 0.9897 - Precision: 0.9230 - Recall: 0.5515 - Specificity: 0.9990 - F1: 0.6720 - Loss: 0.0024\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 01:04:32\n",
      "Accuracy: 0.9897 - Precision: 0.9228 - Recall: 0.5523 - Specificity: 0.9990 - F1: 0.6727 - Loss: 0.0024\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 01:04:40\n",
      "Accuracy: 0.9897 - Precision: 0.9231 - Recall: 0.5536 - Specificity: 0.9990 - F1: 0.6739 - Loss: 0.0024\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 01:04:48\n",
      "Accuracy: 0.9897 - Precision: 0.9231 - Recall: 0.5543 - Specificity: 0.9990 - F1: 0.6746 - Loss: 0.0024\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 01:04:56\n",
      "Accuracy: 0.9897 - Precision: 0.9234 - Recall: 0.5545 - Specificity: 0.9990 - F1: 0.6749 - Loss: 0.0024\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 01:05:03\n",
      "Accuracy: 0.9897 - Precision: 0.9235 - Recall: 0.5553 - Specificity: 0.9990 - F1: 0.6757 - Loss: 0.0024\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 01:05:11\n",
      "Accuracy: 0.9897 - Precision: 0.9237 - Recall: 0.5550 - Specificity: 0.9990 - F1: 0.6756 - Loss: 0.0024\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 01:05:19\n",
      "Accuracy: 0.9897 - Precision: 0.9241 - Recall: 0.5552 - Specificity: 0.9990 - F1: 0.6760 - Loss: 0.0024\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 01:05:27\n",
      "Accuracy: 0.9897 - Precision: 0.9246 - Recall: 0.5555 - Specificity: 0.9990 - F1: 0.6765 - Loss: 0.0024\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 01:05:35\n",
      "Accuracy: 0.9898 - Precision: 0.9247 - Recall: 0.5561 - Specificity: 0.9990 - F1: 0.6771 - Loss: 0.0024\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 01:05:43\n",
      "Accuracy: 0.9898 - Precision: 0.9250 - Recall: 0.5566 - Specificity: 0.9990 - F1: 0.6777 - Loss: 0.0024\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 01:05:51\n",
      "Accuracy: 0.9898 - Precision: 0.9253 - Recall: 0.5574 - Specificity: 0.9990 - F1: 0.6785 - Loss: 0.0024\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 01:05:59\n",
      "Accuracy: 0.9898 - Precision: 0.9255 - Recall: 0.5582 - Specificity: 0.9990 - F1: 0.6793 - Loss: 0.0024\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 01:06:07\n",
      "Accuracy: 0.9898 - Precision: 0.9255 - Recall: 0.5598 - Specificity: 0.9990 - F1: 0.6805 - Loss: 0.0024\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 01:06:15\n",
      "Accuracy: 0.9899 - Precision: 0.9255 - Recall: 0.5611 - Specificity: 0.9990 - F1: 0.6816 - Loss: 0.0024\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 01:06:23\n",
      "Accuracy: 0.9899 - Precision: 0.9255 - Recall: 0.5619 - Specificity: 0.9990 - F1: 0.6822 - Loss: 0.0024\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 01:06:30\n",
      "Accuracy: 0.9899 - Precision: 0.9256 - Recall: 0.5627 - Specificity: 0.9990 - F1: 0.6830 - Loss: 0.0024\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 01:06:38\n",
      "Accuracy: 0.9899 - Precision: 0.9253 - Recall: 0.5638 - Specificity: 0.9990 - F1: 0.6837 - Loss: 0.0024\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 01:06:46\n",
      "Accuracy: 0.9899 - Precision: 0.9253 - Recall: 0.5644 - Specificity: 0.9990 - F1: 0.6843 - Loss: 0.0024\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 01:06:54\n",
      "Accuracy: 0.9899 - Precision: 0.9255 - Recall: 0.5651 - Specificity: 0.9990 - F1: 0.6850 - Loss: 0.0024\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 01:07:02\n",
      "Accuracy: 0.9900 - Precision: 0.9258 - Recall: 0.5653 - Specificity: 0.9990 - F1: 0.6854 - Loss: 0.0024\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 01:07:09\n",
      "Accuracy: 0.9900 - Precision: 0.9261 - Recall: 0.5661 - Specificity: 0.9990 - F1: 0.6861 - Loss: 0.0024\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 01:07:17\n",
      "Accuracy: 0.9900 - Precision: 0.9258 - Recall: 0.5646 - Specificity: 0.9990 - F1: 0.6848 - Loss: 0.0024\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 01:07:25\n",
      "Accuracy: 0.9900 - Precision: 0.9261 - Recall: 0.5646 - Specificity: 0.9990 - F1: 0.6850 - Loss: 0.0024\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 01:07:32\n",
      "Accuracy: 0.9900 - Precision: 0.9263 - Recall: 0.5642 - Specificity: 0.9990 - F1: 0.6848 - Loss: 0.0024\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 01:07:40\n",
      "Accuracy: 0.9900 - Precision: 0.9264 - Recall: 0.5642 - Specificity: 0.9990 - F1: 0.6850 - Loss: 0.0024\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 01:07:48\n",
      "Accuracy: 0.9900 - Precision: 0.9266 - Recall: 0.5646 - Specificity: 0.9990 - F1: 0.6854 - Loss: 0.0024\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 01:07:56\n",
      "Accuracy: 0.9900 - Precision: 0.9268 - Recall: 0.5652 - Specificity: 0.9990 - F1: 0.6860 - Loss: 0.0024\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 01:08:04\n",
      "Accuracy: 0.9900 - Precision: 0.9270 - Recall: 0.5659 - Specificity: 0.9990 - F1: 0.6867 - Loss: 0.0024\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 01:08:12\n",
      "Accuracy: 0.9900 - Precision: 0.9270 - Recall: 0.5667 - Specificity: 0.9990 - F1: 0.6874 - Loss: 0.0024\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 01:08:20\n",
      "Accuracy: 0.9900 - Precision: 0.9270 - Recall: 0.5678 - Specificity: 0.9990 - F1: 0.6883 - Loss: 0.0024\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 01:08:28\n",
      "Accuracy: 0.9900 - Precision: 0.9269 - Recall: 0.5688 - Specificity: 0.9990 - F1: 0.6891 - Loss: 0.0024\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 01:08:35\n",
      "Accuracy: 0.9901 - Precision: 0.9272 - Recall: 0.5696 - Specificity: 0.9990 - F1: 0.6898 - Loss: 0.0024\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 01:08:43\n",
      "Accuracy: 0.9901 - Precision: 0.9273 - Recall: 0.5705 - Specificity: 0.9990 - F1: 0.6905 - Loss: 0.0023\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 01:08:51\n",
      "Accuracy: 0.9901 - Precision: 0.9274 - Recall: 0.5709 - Specificity: 0.9990 - F1: 0.6909 - Loss: 0.0023\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 01:08:59\n",
      "Accuracy: 0.9901 - Precision: 0.9275 - Recall: 0.5716 - Specificity: 0.9990 - F1: 0.6916 - Loss: 0.0023\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 01:09:07\n",
      "Accuracy: 0.9901 - Precision: 0.9277 - Recall: 0.5723 - Specificity: 0.9990 - F1: 0.6923 - Loss: 0.0023\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 01:09:14\n",
      "Accuracy: 0.9902 - Precision: 0.9279 - Recall: 0.5728 - Specificity: 0.9990 - F1: 0.6928 - Loss: 0.0023\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 01:09:22\n",
      "Accuracy: 0.9902 - Precision: 0.9280 - Recall: 0.5735 - Specificity: 0.9990 - F1: 0.6935 - Loss: 0.0023\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 01:09:30\n",
      "Accuracy: 0.9902 - Precision: 0.9282 - Recall: 0.5742 - Specificity: 0.9990 - F1: 0.6941 - Loss: 0.0023\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 01:09:38\n",
      "Accuracy: 0.9902 - Precision: 0.9284 - Recall: 0.5747 - Specificity: 0.9990 - F1: 0.6946 - Loss: 0.0023\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 01:09:46\n",
      "Accuracy: 0.9902 - Precision: 0.9286 - Recall: 0.5751 - Specificity: 0.9991 - F1: 0.6951 - Loss: 0.0023\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 01:09:53\n",
      "Accuracy: 0.9902 - Precision: 0.9286 - Recall: 0.5758 - Specificity: 0.9991 - F1: 0.6957 - Loss: 0.0023\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 01:10:02\n",
      "Accuracy: 0.9903 - Precision: 0.9288 - Recall: 0.5763 - Specificity: 0.9991 - F1: 0.6962 - Loss: 0.0023\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 01:10:10\n",
      "Accuracy: 0.9903 - Precision: 0.9290 - Recall: 0.5765 - Specificity: 0.9991 - F1: 0.6964 - Loss: 0.0023\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 01:10:18\n",
      "Accuracy: 0.9903 - Precision: 0.9292 - Recall: 0.5767 - Specificity: 0.9991 - F1: 0.6968 - Loss: 0.0023\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 01:10:26\n",
      "Accuracy: 0.9903 - Precision: 0.9293 - Recall: 0.5772 - Specificity: 0.9991 - F1: 0.6972 - Loss: 0.0023\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 01:10:34\n",
      "Accuracy: 0.9903 - Precision: 0.9294 - Recall: 0.5778 - Specificity: 0.9991 - F1: 0.6978 - Loss: 0.0023\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 01:10:42\n",
      "Accuracy: 0.9903 - Precision: 0.9295 - Recall: 0.5782 - Specificity: 0.9991 - F1: 0.6982 - Loss: 0.0023\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 01:10:50\n",
      "Accuracy: 0.9903 - Precision: 0.9295 - Recall: 0.5790 - Specificity: 0.9991 - F1: 0.6989 - Loss: 0.0023\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 01:10:57\n",
      "Accuracy: 0.9903 - Precision: 0.9293 - Recall: 0.5800 - Specificity: 0.9991 - F1: 0.6995 - Loss: 0.0023\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 01:11:05\n",
      "Accuracy: 0.9904 - Precision: 0.9294 - Recall: 0.5809 - Specificity: 0.9991 - F1: 0.7002 - Loss: 0.0023\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 01:11:13\n",
      "Accuracy: 0.9904 - Precision: 0.9286 - Recall: 0.5814 - Specificity: 0.9990 - F1: 0.7004 - Loss: 0.0023\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 01:11:21\n",
      "Accuracy: 0.9904 - Precision: 0.9288 - Recall: 0.5816 - Specificity: 0.9990 - F1: 0.7007 - Loss: 0.0023\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 01:11:30\n",
      "Accuracy: 0.9904 - Precision: 0.9290 - Recall: 0.5814 - Specificity: 0.9991 - F1: 0.7007 - Loss: 0.0023\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 01:11:39\n",
      "Accuracy: 0.9904 - Precision: 0.9294 - Recall: 0.5807 - Specificity: 0.9991 - F1: 0.7002 - Loss: 0.0023\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 01:11:47\n",
      "Accuracy: 0.9903 - Precision: 0.9296 - Recall: 0.5796 - Specificity: 0.9991 - F1: 0.6994 - Loss: 0.0023\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 01:11:55\n",
      "Accuracy: 0.9903 - Precision: 0.9298 - Recall: 0.5783 - Specificity: 0.9991 - F1: 0.6983 - Loss: 0.0023\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 01:12:02\n",
      "Accuracy: 0.9903 - Precision: 0.9299 - Recall: 0.5777 - Specificity: 0.9991 - F1: 0.6980 - Loss: 0.0023\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 01:12:11\n",
      "Accuracy: 0.9903 - Precision: 0.9301 - Recall: 0.5776 - Specificity: 0.9991 - F1: 0.6980 - Loss: 0.0023\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 01:12:20\n",
      "Accuracy: 0.9903 - Precision: 0.9304 - Recall: 0.5776 - Specificity: 0.9991 - F1: 0.6981 - Loss: 0.0023\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 01:12:29\n",
      "Accuracy: 0.9903 - Precision: 0.9304 - Recall: 0.5781 - Specificity: 0.9991 - F1: 0.6986 - Loss: 0.0023\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 01:12:37\n",
      "Accuracy: 0.9903 - Precision: 0.9306 - Recall: 0.5788 - Specificity: 0.9991 - F1: 0.6992 - Loss: 0.0023\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 01:12:45\n",
      "Accuracy: 0.9904 - Precision: 0.9306 - Recall: 0.5796 - Specificity: 0.9991 - F1: 0.6998 - Loss: 0.0023\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 01:12:53\n",
      "Accuracy: 0.9904 - Precision: 0.9306 - Recall: 0.5803 - Specificity: 0.9991 - F1: 0.7004 - Loss: 0.0023\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 01:13:01\n",
      "Accuracy: 0.9904 - Precision: 0.9305 - Recall: 0.5810 - Specificity: 0.9991 - F1: 0.7009 - Loss: 0.0023\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 01:13:09\n",
      "Accuracy: 0.9904 - Precision: 0.9297 - Recall: 0.5816 - Specificity: 0.9991 - F1: 0.7011 - Loss: 0.0023\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 01:13:16\n",
      "Accuracy: 0.9904 - Precision: 0.9298 - Recall: 0.5821 - Specificity: 0.9991 - F1: 0.7016 - Loss: 0.0023\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 01:13:24\n",
      "Accuracy: 0.9904 - Precision: 0.9300 - Recall: 0.5821 - Specificity: 0.9991 - F1: 0.7017 - Loss: 0.0023\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 01:13:32\n",
      "Accuracy: 0.9904 - Precision: 0.9302 - Recall: 0.5826 - Specificity: 0.9991 - F1: 0.7022 - Loss: 0.0023\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 01:13:40\n",
      "Accuracy: 0.9904 - Precision: 0.9303 - Recall: 0.5827 - Specificity: 0.9991 - F1: 0.7024 - Loss: 0.0023\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 01:13:48\n",
      "Accuracy: 0.9904 - Precision: 0.9305 - Recall: 0.5826 - Specificity: 0.9991 - F1: 0.7024 - Loss: 0.0023\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 01:13:56\n",
      "Accuracy: 0.9904 - Precision: 0.9307 - Recall: 0.5826 - Specificity: 0.9991 - F1: 0.7026 - Loss: 0.0023\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 01:14:04\n",
      "Accuracy: 0.9904 - Precision: 0.9310 - Recall: 0.5825 - Specificity: 0.9991 - F1: 0.7027 - Loss: 0.0023\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 01:14:12\n",
      "Accuracy: 0.9904 - Precision: 0.9311 - Recall: 0.5829 - Specificity: 0.9991 - F1: 0.7030 - Loss: 0.0023\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 01:14:20\n",
      "Accuracy: 0.9905 - Precision: 0.9312 - Recall: 0.5837 - Specificity: 0.9991 - F1: 0.7037 - Loss: 0.0023\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 01:14:28\n",
      "Accuracy: 0.9905 - Precision: 0.9312 - Recall: 0.5846 - Specificity: 0.9991 - F1: 0.7043 - Loss: 0.0023\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 01:14:36\n",
      "Accuracy: 0.9905 - Precision: 0.9305 - Recall: 0.5855 - Specificity: 0.9991 - F1: 0.7048 - Loss: 0.0023\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 01:14:45\n",
      "Accuracy: 0.9905 - Precision: 0.9303 - Recall: 0.5866 - Specificity: 0.9991 - F1: 0.7055 - Loss: 0.0023\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 01:14:54\n",
      "Accuracy: 0.9905 - Precision: 0.9302 - Recall: 0.5876 - Specificity: 0.9991 - F1: 0.7061 - Loss: 0.0023\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 01:15:02\n",
      "Accuracy: 0.9906 - Precision: 0.9299 - Recall: 0.5886 - Specificity: 0.9991 - F1: 0.7067 - Loss: 0.0023\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 01:15:10\n",
      "Accuracy: 0.9906 - Precision: 0.9299 - Recall: 0.5895 - Specificity: 0.9991 - F1: 0.7074 - Loss: 0.0022\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 01:15:18\n",
      "Accuracy: 0.9906 - Precision: 0.9301 - Recall: 0.5901 - Specificity: 0.9991 - F1: 0.7079 - Loss: 0.0022\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 01:15:25\n",
      "Accuracy: 0.9906 - Precision: 0.9301 - Recall: 0.5905 - Specificity: 0.9991 - F1: 0.7083 - Loss: 0.0022\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 01:15:33\n",
      "Accuracy: 0.9906 - Precision: 0.9304 - Recall: 0.5907 - Specificity: 0.9991 - F1: 0.7086 - Loss: 0.0022\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 01:15:41\n",
      "Accuracy: 0.9906 - Precision: 0.9306 - Recall: 0.5908 - Specificity: 0.9991 - F1: 0.7088 - Loss: 0.0022\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 01:15:49\n",
      "Accuracy: 0.9906 - Precision: 0.9308 - Recall: 0.5903 - Specificity: 0.9991 - F1: 0.7085 - Loss: 0.0022\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 01:15:57\n",
      "Accuracy: 0.9906 - Precision: 0.9309 - Recall: 0.5892 - Specificity: 0.9991 - F1: 0.7077 - Loss: 0.0022\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 01:16:04\n",
      "Accuracy: 0.9906 - Precision: 0.9308 - Recall: 0.5885 - Specificity: 0.9991 - F1: 0.7071 - Loss: 0.0022\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 01:16:12\n",
      "Accuracy: 0.9905 - Precision: 0.9309 - Recall: 0.5875 - Specificity: 0.9991 - F1: 0.7063 - Loss: 0.0023\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 01:16:20\n",
      "Accuracy: 0.9905 - Precision: 0.9310 - Recall: 0.5871 - Specificity: 0.9991 - F1: 0.7061 - Loss: 0.0023\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 01:16:28\n",
      "Accuracy: 0.9905 - Precision: 0.9311 - Recall: 0.5872 - Specificity: 0.9991 - F1: 0.7062 - Loss: 0.0023\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 01:16:36\n",
      "Accuracy: 0.9905 - Precision: 0.9309 - Recall: 0.5868 - Specificity: 0.9991 - F1: 0.7060 - Loss: 0.0023\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 01:16:44\n",
      "Accuracy: 0.9904 - Precision: 0.9306 - Recall: 0.5864 - Specificity: 0.9991 - F1: 0.7056 - Loss: 0.0023\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 01:16:52\n",
      "Accuracy: 0.9904 - Precision: 0.9305 - Recall: 0.5868 - Specificity: 0.9991 - F1: 0.7059 - Loss: 0.0023\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 01:17:00\n",
      "Accuracy: 0.9904 - Precision: 0.9302 - Recall: 0.5867 - Specificity: 0.9991 - F1: 0.7058 - Loss: 0.0023\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 01:17:08\n",
      "Accuracy: 0.9904 - Precision: 0.9296 - Recall: 0.5871 - Specificity: 0.9990 - F1: 0.7059 - Loss: 0.0023\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 01:17:15\n",
      "Accuracy: 0.9904 - Precision: 0.9296 - Recall: 0.5874 - Specificity: 0.9990 - F1: 0.7062 - Loss: 0.0023\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 01:17:23\n",
      "Accuracy: 0.9904 - Precision: 0.9295 - Recall: 0.5870 - Specificity: 0.9990 - F1: 0.7060 - Loss: 0.0023\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 01:17:31\n",
      "Accuracy: 0.9904 - Precision: 0.9297 - Recall: 0.5863 - Specificity: 0.9990 - F1: 0.7054 - Loss: 0.0023\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 01:17:39\n",
      "Accuracy: 0.9904 - Precision: 0.9299 - Recall: 0.5854 - Specificity: 0.9990 - F1: 0.7047 - Loss: 0.0023\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 01:17:47\n",
      "Accuracy: 0.9904 - Precision: 0.9300 - Recall: 0.5848 - Specificity: 0.9990 - F1: 0.7044 - Loss: 0.0023\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 01:17:55\n",
      "Accuracy: 0.9903 - Precision: 0.9303 - Recall: 0.5835 - Specificity: 0.9991 - F1: 0.7032 - Loss: 0.0023\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 01:18:03\n",
      "Accuracy: 0.9903 - Precision: 0.9304 - Recall: 0.5826 - Specificity: 0.9991 - F1: 0.7025 - Loss: 0.0023\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 01:18:11\n",
      "Accuracy: 0.9903 - Precision: 0.9306 - Recall: 0.5819 - Specificity: 0.9991 - F1: 0.7020 - Loss: 0.0023\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 01:18:19\n",
      "Accuracy: 0.9903 - Precision: 0.9306 - Recall: 0.5810 - Specificity: 0.9991 - F1: 0.7013 - Loss: 0.0023\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 01:18:27\n",
      "Accuracy: 0.9902 - Precision: 0.9305 - Recall: 0.5801 - Specificity: 0.9991 - F1: 0.7005 - Loss: 0.0023\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 01:18:34\n",
      "Accuracy: 0.9902 - Precision: 0.9305 - Recall: 0.5796 - Specificity: 0.9991 - F1: 0.7002 - Loss: 0.0023\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 01:18:42\n",
      "Accuracy: 0.9901 - Precision: 0.9304 - Recall: 0.5790 - Specificity: 0.9991 - F1: 0.6997 - Loss: 0.0023\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 01:18:50\n",
      "Accuracy: 0.9901 - Precision: 0.9302 - Recall: 0.5787 - Specificity: 0.9990 - F1: 0.6995 - Loss: 0.0023\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 01:18:58\n",
      "Accuracy: 0.9901 - Precision: 0.9301 - Recall: 0.5787 - Specificity: 0.9990 - F1: 0.6995 - Loss: 0.0024\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 01:19:05\n",
      "Accuracy: 0.9901 - Precision: 0.9298 - Recall: 0.5781 - Specificity: 0.9990 - F1: 0.6990 - Loss: 0.0024\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 01:19:13\n",
      "Accuracy: 0.9900 - Precision: 0.9299 - Recall: 0.5781 - Specificity: 0.9990 - F1: 0.6991 - Loss: 0.0024\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 01:19:21\n",
      "Accuracy: 0.9897 - Precision: 0.9297 - Recall: 0.5762 - Specificity: 0.9990 - F1: 0.6970 - Loss: 0.0025\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 01:19:29\n",
      "Accuracy: 0.9896 - Precision: 0.9296 - Recall: 0.5747 - Specificity: 0.9990 - F1: 0.6956 - Loss: 0.0025\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 01:19:37\n",
      "Accuracy: 0.9894 - Precision: 0.9297 - Recall: 0.5738 - Specificity: 0.9990 - F1: 0.6949 - Loss: 0.0025\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 01:19:45\n",
      "Accuracy: 0.9892 - Precision: 0.9296 - Recall: 0.5731 - Specificity: 0.9990 - F1: 0.6943 - Loss: 0.0026\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 01:19:52\n",
      "Accuracy: 0.9890 - Precision: 0.9293 - Recall: 0.5730 - Specificity: 0.9990 - F1: 0.6942 - Loss: 0.0026\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 01:20:00\n",
      "Accuracy: 0.9889 - Precision: 0.9283 - Recall: 0.5734 - Specificity: 0.9989 - F1: 0.6941 - Loss: 0.0027\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 01:20:08\n",
      "Accuracy: 0.9887 - Precision: 0.9279 - Recall: 0.5724 - Specificity: 0.9989 - F1: 0.6932 - Loss: 0.0028\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 01:20:17\n",
      "Accuracy: 0.9885 - Precision: 0.9271 - Recall: 0.5705 - Specificity: 0.9989 - F1: 0.6912 - Loss: 0.0028\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 01:20:25\n",
      "Accuracy: 0.9881 - Precision: 0.9270 - Recall: 0.5684 - Specificity: 0.9989 - F1: 0.6887 - Loss: 0.0029\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 01:20:32\n",
      "Accuracy: 0.9878 - Precision: 0.9271 - Recall: 0.5662 - Specificity: 0.9989 - F1: 0.6861 - Loss: 0.0029\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 01:20:40\n",
      "Accuracy: 0.9875 - Precision: 0.9274 - Recall: 0.5640 - Specificity: 0.9989 - F1: 0.6835 - Loss: 0.0030\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 01:20:48\n",
      "Accuracy: 0.9874 - Precision: 0.9272 - Recall: 0.5618 - Specificity: 0.9989 - F1: 0.6808 - Loss: 0.0030\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 01:20:56\n",
      "Accuracy: 0.9871 - Precision: 0.9275 - Recall: 0.5595 - Specificity: 0.9989 - F1: 0.6781 - Loss: 0.0030\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 01:21:04\n",
      "Accuracy: 0.9869 - Precision: 0.9272 - Recall: 0.5573 - Specificity: 0.9989 - F1: 0.6754 - Loss: 0.0031\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 01:21:12\n",
      "Accuracy: 0.9866 - Precision: 0.9275 - Recall: 0.5551 - Specificity: 0.9989 - F1: 0.6728 - Loss: 0.0031\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 01:21:19\n",
      "Accuracy: 0.9862 - Precision: 0.9278 - Recall: 0.5530 - Specificity: 0.9989 - F1: 0.6701 - Loss: 0.0032\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 01:21:27\n",
      "Accuracy: 0.9860 - Precision: 0.9276 - Recall: 0.5508 - Specificity: 0.9989 - F1: 0.6675 - Loss: 0.0032\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 01:21:35\n",
      "Accuracy: 0.9858 - Precision: 0.9272 - Recall: 0.5487 - Specificity: 0.9989 - F1: 0.6649 - Loss: 0.0032\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 01:21:43\n",
      "Accuracy: 0.9857 - Precision: 0.9270 - Recall: 0.5466 - Specificity: 0.9989 - F1: 0.6624 - Loss: 0.0033\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 01:21:51\n",
      "Accuracy: 0.9857 - Precision: 0.9270 - Recall: 0.5444 - Specificity: 0.9989 - F1: 0.6598 - Loss: 0.0033\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 01:21:59\n",
      "Accuracy: 0.9856 - Precision: 0.9273 - Recall: 0.5424 - Specificity: 0.9989 - F1: 0.6573 - Loss: 0.0033\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 01:22:06\n",
      "Accuracy: 0.9856 - Precision: 0.9275 - Recall: 0.5403 - Specificity: 0.9989 - F1: 0.6548 - Loss: 0.0034\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 01:22:14\n",
      "Accuracy: 0.9855 - Precision: 0.9278 - Recall: 0.5383 - Specificity: 0.9989 - F1: 0.6524 - Loss: 0.0034\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 01:22:22\n",
      "Accuracy: 0.9854 - Precision: 0.9280 - Recall: 0.5362 - Specificity: 0.9989 - F1: 0.6499 - Loss: 0.0034\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 01:22:30\n",
      "Accuracy: 0.9853 - Precision: 0.9277 - Recall: 0.5342 - Specificity: 0.9989 - F1: 0.6475 - Loss: 0.0035\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 01:22:37\n",
      "Accuracy: 0.9853 - Precision: 0.9271 - Recall: 0.5322 - Specificity: 0.9989 - F1: 0.6450 - Loss: 0.0035\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 01:22:45\n",
      "Accuracy: 0.9852 - Precision: 0.9274 - Recall: 0.5302 - Specificity: 0.9989 - F1: 0.6426 - Loss: 0.0035\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 01:22:53\n",
      "Accuracy: 0.9852 - Precision: 0.9274 - Recall: 0.5282 - Specificity: 0.9989 - F1: 0.6403 - Loss: 0.0035\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 01:23:01\n",
      "Accuracy: 0.9851 - Precision: 0.9276 - Recall: 0.5263 - Specificity: 0.9989 - F1: 0.6379 - Loss: 0.0035\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 01:23:09\n",
      "Accuracy: 0.9851 - Precision: 0.9263 - Recall: 0.5243 - Specificity: 0.9990 - F1: 0.6355 - Loss: 0.0035\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 01:23:17\n",
      "Accuracy: 0.9851 - Precision: 0.9266 - Recall: 0.5224 - Specificity: 0.9990 - F1: 0.6332 - Loss: 0.0035\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 01:23:25\n",
      "Accuracy: 0.9850 - Precision: 0.9269 - Recall: 0.5205 - Specificity: 0.9990 - F1: 0.6309 - Loss: 0.0036\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 01:23:33\n",
      "Accuracy: 0.9850 - Precision: 0.9271 - Recall: 0.5186 - Specificity: 0.9990 - F1: 0.6286 - Loss: 0.0036\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 01:23:41\n",
      "Accuracy: 0.9849 - Precision: 0.9274 - Recall: 0.5167 - Specificity: 0.9990 - F1: 0.6263 - Loss: 0.0036\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 01:23:49\n",
      "Accuracy: 0.9849 - Precision: 0.9272 - Recall: 0.5148 - Specificity: 0.9990 - F1: 0.6240 - Loss: 0.0036\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 01:23:57\n",
      "Accuracy: 0.9848 - Precision: 0.9257 - Recall: 0.5129 - Specificity: 0.9990 - F1: 0.6218 - Loss: 0.0036\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 01:24:05\n",
      "Accuracy: 0.9848 - Precision: 0.9259 - Recall: 0.5111 - Specificity: 0.9990 - F1: 0.6195 - Loss: 0.0036\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 01:24:13\n",
      "Accuracy: 0.9848 - Precision: 0.9262 - Recall: 0.5092 - Specificity: 0.9990 - F1: 0.6173 - Loss: 0.0036\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 01:24:21\n",
      "Accuracy: 0.9847 - Precision: 0.9256 - Recall: 0.5074 - Specificity: 0.9990 - F1: 0.6151 - Loss: 0.0036\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 01:24:31\n",
      "Accuracy: 0.9847 - Precision: 0.9259 - Recall: 0.5056 - Specificity: 0.9990 - F1: 0.6129 - Loss: 0.0036\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 01:24:39\n",
      "Accuracy: 0.9847 - Precision: 0.9247 - Recall: 0.5038 - Specificity: 0.9990 - F1: 0.6108 - Loss: 0.0036\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 01:24:47\n",
      "Accuracy: 0.9847 - Precision: 0.9227 - Recall: 0.5020 - Specificity: 0.9990 - F1: 0.6086 - Loss: 0.0036\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 01:24:55\n",
      "Accuracy: 0.9847 - Precision: 0.9226 - Recall: 0.5003 - Specificity: 0.9990 - F1: 0.6065 - Loss: 0.0037\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 01:25:03\n",
      "Accuracy: 0.9847 - Precision: 0.9208 - Recall: 0.4985 - Specificity: 0.9990 - F1: 0.6044 - Loss: 0.0037\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 01:25:10\n",
      "Accuracy: 0.9846 - Precision: 0.9211 - Recall: 0.4968 - Specificity: 0.9990 - F1: 0.6022 - Loss: 0.0037\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 01:25:19\n",
      "Accuracy: 0.9846 - Precision: 0.9209 - Recall: 0.4950 - Specificity: 0.9990 - F1: 0.6002 - Loss: 0.0037\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 01:25:27\n",
      "Accuracy: 0.9846 - Precision: 0.9211 - Recall: 0.4934 - Specificity: 0.9990 - F1: 0.5982 - Loss: 0.0037\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 01:25:35\n",
      "Accuracy: 0.9845 - Precision: 0.9214 - Recall: 0.4917 - Specificity: 0.9990 - F1: 0.5961 - Loss: 0.0037\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 01:25:43\n",
      "Accuracy: 0.9845 - Precision: 0.9217 - Recall: 0.4900 - Specificity: 0.9990 - F1: 0.5941 - Loss: 0.0037\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 01:25:51\n",
      "Accuracy: 0.9845 - Precision: 0.9219 - Recall: 0.4883 - Specificity: 0.9990 - F1: 0.5921 - Loss: 0.0037\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 01:25:59\n",
      "Accuracy: 0.9844 - Precision: 0.9218 - Recall: 0.4866 - Specificity: 0.9990 - F1: 0.5901 - Loss: 0.0037\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 01:26:06\n",
      "Accuracy: 0.9844 - Precision: 0.9218 - Recall: 0.4850 - Specificity: 0.9990 - F1: 0.5881 - Loss: 0.0037\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 01:26:14\n",
      "Accuracy: 0.9844 - Precision: 0.9215 - Recall: 0.4834 - Specificity: 0.9990 - F1: 0.5861 - Loss: 0.0037\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 01:26:22\n",
      "Accuracy: 0.9843 - Precision: 0.9214 - Recall: 0.4818 - Specificity: 0.9990 - F1: 0.5843 - Loss: 0.0037\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 01:26:30\n",
      "Accuracy: 0.9843 - Precision: 0.9217 - Recall: 0.4802 - Specificity: 0.9990 - F1: 0.5823 - Loss: 0.0037\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 01:26:38\n",
      "Accuracy: 0.9842 - Precision: 0.9214 - Recall: 0.4786 - Specificity: 0.9990 - F1: 0.5804 - Loss: 0.0037\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 01:26:46\n",
      "Accuracy: 0.9842 - Precision: 0.9212 - Recall: 0.4770 - Specificity: 0.9990 - F1: 0.5786 - Loss: 0.0037\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 01:26:54\n",
      "Accuracy: 0.9842 - Precision: 0.9214 - Recall: 0.4755 - Specificity: 0.9990 - F1: 0.5768 - Loss: 0.0037\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 01:27:02\n",
      "Accuracy: 0.9841 - Precision: 0.9214 - Recall: 0.4739 - Specificity: 0.9991 - F1: 0.5750 - Loss: 0.0037\n",
      "\n",
      "Epoch 17/20\n",
      "Validation - Accuracy: 0.9790, Precision: 0.9254, Recall: 0.0197, Specificity: 1.0000, F1: 0.0385, Loss: 0.0046\n",
      "\n",
      "\n",
      "Epoch 18/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 01:34:16\n",
      "Accuracy: 0.9742 - Precision: 0.9259 - Recall: 0.0195 - Specificity: 1.0000 - F1: 0.0382 - Loss: 0.0053\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 01:34:24\n",
      "Accuracy: 0.9727 - Precision: 0.9546 - Recall: 0.0193 - Specificity: 1.0000 - F1: 0.0379 - Loss: 0.0054\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 01:34:32\n",
      "Accuracy: 0.9718 - Precision: 0.9601 - Recall: 0.0266 - Specificity: 1.0000 - F1: 0.0515 - Loss: 0.0050\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 01:34:40\n",
      "Accuracy: 0.9748 - Precision: 0.9653 - Recall: 0.0273 - Specificity: 1.0000 - F1: 0.0530 - Loss: 0.0044\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 01:34:48\n",
      "Accuracy: 0.9768 - Precision: 0.9574 - Recall: 0.0274 - Specificity: 1.0000 - F1: 0.0532 - Loss: 0.0042\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 01:34:56\n",
      "Accuracy: 0.9768 - Precision: 0.9638 - Recall: 0.0294 - Specificity: 1.0000 - F1: 0.0569 - Loss: 0.0040\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 01:35:04\n",
      "Accuracy: 0.9782 - Precision: 0.9686 - Recall: 0.0323 - Specificity: 1.0000 - F1: 0.0623 - Loss: 0.0037\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 01:35:12\n",
      "Accuracy: 0.9788 - Precision: 0.9441 - Recall: 0.0360 - Specificity: 0.9999 - F1: 0.0688 - Loss: 0.0036\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 01:35:20\n",
      "Accuracy: 0.9796 - Precision: 0.9458 - Recall: 0.0411 - Specificity: 0.9999 - F1: 0.0779 - Loss: 0.0034\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 01:35:27\n",
      "Accuracy: 0.9800 - Precision: 0.9458 - Recall: 0.0425 - Specificity: 0.9999 - F1: 0.0807 - Loss: 0.0034\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 01:35:36\n",
      "Accuracy: 0.9803 - Precision: 0.9379 - Recall: 0.0480 - Specificity: 0.9999 - F1: 0.0901 - Loss: 0.0033\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 01:35:45\n",
      "Accuracy: 0.9806 - Precision: 0.9402 - Recall: 0.0498 - Specificity: 0.9999 - F1: 0.0933 - Loss: 0.0033\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 01:35:55\n",
      "Accuracy: 0.9808 - Precision: 0.9410 - Recall: 0.0532 - Specificity: 0.9999 - F1: 0.0993 - Loss: 0.0032\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 01:36:03\n",
      "Accuracy: 0.9810 - Precision: 0.9286 - Recall: 0.0557 - Specificity: 0.9999 - F1: 0.1035 - Loss: 0.0032\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 01:36:11\n",
      "Accuracy: 0.9812 - Precision: 0.9328 - Recall: 0.0589 - Specificity: 0.9999 - F1: 0.1091 - Loss: 0.0031\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 01:36:20\n",
      "Accuracy: 0.9809 - Precision: 0.9355 - Recall: 0.0620 - Specificity: 0.9999 - F1: 0.1145 - Loss: 0.0032\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 01:36:28\n",
      "Accuracy: 0.9812 - Precision: 0.9378 - Recall: 0.0679 - Specificity: 0.9999 - F1: 0.1241 - Loss: 0.0031\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 01:36:37\n",
      "Accuracy: 0.9812 - Precision: 0.9409 - Recall: 0.0737 - Specificity: 0.9999 - F1: 0.1335 - Loss: 0.0031\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 01:36:45\n",
      "Accuracy: 0.9814 - Precision: 0.9413 - Recall: 0.0804 - Specificity: 0.9999 - F1: 0.1440 - Loss: 0.0031\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 01:36:54\n",
      "Accuracy: 0.9817 - Precision: 0.9413 - Recall: 0.0898 - Specificity: 0.9999 - F1: 0.1577 - Loss: 0.0030\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 01:37:02\n",
      "Accuracy: 0.9818 - Precision: 0.9379 - Recall: 0.0964 - Specificity: 0.9999 - F1: 0.1674 - Loss: 0.0030\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 01:37:10\n",
      "Accuracy: 0.9816 - Precision: 0.9249 - Recall: 0.1000 - Specificity: 0.9998 - F1: 0.1723 - Loss: 0.0031\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 01:37:18\n",
      "Accuracy: 0.9817 - Precision: 0.9273 - Recall: 0.1074 - Specificity: 0.9998 - F1: 0.1832 - Loss: 0.0031\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 01:37:26\n",
      "Accuracy: 0.9818 - Precision: 0.9283 - Recall: 0.1158 - Specificity: 0.9998 - F1: 0.1951 - Loss: 0.0031\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 01:37:34\n",
      "Accuracy: 0.9819 - Precision: 0.9296 - Recall: 0.1251 - Specificity: 0.9998 - F1: 0.2077 - Loss: 0.0031\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 01:37:42\n",
      "Accuracy: 0.9823 - Precision: 0.9301 - Recall: 0.1376 - Specificity: 0.9998 - F1: 0.2232 - Loss: 0.0030\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 01:37:50\n",
      "Accuracy: 0.9824 - Precision: 0.9312 - Recall: 0.1468 - Specificity: 0.9997 - F1: 0.2353 - Loss: 0.0030\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 01:37:57\n",
      "Accuracy: 0.9825 - Precision: 0.9314 - Recall: 0.1520 - Specificity: 0.9997 - F1: 0.2428 - Loss: 0.0030\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 01:38:05\n",
      "Accuracy: 0.9824 - Precision: 0.9300 - Recall: 0.1577 - Specificity: 0.9997 - F1: 0.2506 - Loss: 0.0031\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 01:38:13\n",
      "Accuracy: 0.9826 - Precision: 0.9303 - Recall: 0.1704 - Specificity: 0.9997 - F1: 0.2650 - Loss: 0.0030\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 01:38:21\n",
      "Accuracy: 0.9829 - Precision: 0.9285 - Recall: 0.1823 - Specificity: 0.9997 - F1: 0.2780 - Loss: 0.0030\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 01:38:29\n",
      "Accuracy: 0.9830 - Precision: 0.9275 - Recall: 0.1913 - Specificity: 0.9996 - F1: 0.2886 - Loss: 0.0030\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 01:38:37\n",
      "Accuracy: 0.9832 - Precision: 0.9276 - Recall: 0.2015 - Specificity: 0.9996 - F1: 0.3003 - Loss: 0.0030\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 01:38:45\n",
      "Accuracy: 0.9833 - Precision: 0.9290 - Recall: 0.2104 - Specificity: 0.9996 - F1: 0.3110 - Loss: 0.0030\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 01:38:53\n",
      "Accuracy: 0.9834 - Precision: 0.9295 - Recall: 0.2168 - Specificity: 0.9996 - F1: 0.3191 - Loss: 0.0030\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 01:39:00\n",
      "Accuracy: 0.9837 - Precision: 0.9294 - Recall: 0.2280 - Specificity: 0.9996 - F1: 0.3309 - Loss: 0.0029\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 01:39:08\n",
      "Accuracy: 0.9839 - Precision: 0.9299 - Recall: 0.2387 - Specificity: 0.9996 - F1: 0.3423 - Loss: 0.0029\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 01:39:16\n",
      "Accuracy: 0.9840 - Precision: 0.9299 - Recall: 0.2479 - Specificity: 0.9996 - F1: 0.3522 - Loss: 0.0029\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 01:39:24\n",
      "Accuracy: 0.9842 - Precision: 0.9300 - Recall: 0.2577 - Specificity: 0.9996 - F1: 0.3625 - Loss: 0.0029\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 01:39:32\n",
      "Accuracy: 0.9844 - Precision: 0.9301 - Recall: 0.2679 - Specificity: 0.9995 - F1: 0.3728 - Loss: 0.0029\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 01:39:40\n",
      "Accuracy: 0.9844 - Precision: 0.9297 - Recall: 0.2733 - Specificity: 0.9995 - F1: 0.3794 - Loss: 0.0029\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 01:39:48\n",
      "Accuracy: 0.9845 - Precision: 0.9304 - Recall: 0.2821 - Specificity: 0.9995 - F1: 0.3886 - Loss: 0.0029\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 01:39:56\n",
      "Accuracy: 0.9847 - Precision: 0.9301 - Recall: 0.2904 - Specificity: 0.9995 - F1: 0.3971 - Loss: 0.0029\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 01:40:04\n",
      "Accuracy: 0.9849 - Precision: 0.9302 - Recall: 0.2994 - Specificity: 0.9995 - F1: 0.4061 - Loss: 0.0028\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 01:40:12\n",
      "Accuracy: 0.9850 - Precision: 0.9258 - Recall: 0.3081 - Specificity: 0.9994 - F1: 0.4129 - Loss: 0.0029\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 01:40:20\n",
      "Accuracy: 0.9851 - Precision: 0.9266 - Recall: 0.3143 - Specificity: 0.9994 - F1: 0.4199 - Loss: 0.0028\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 01:40:27\n",
      "Accuracy: 0.9852 - Precision: 0.9270 - Recall: 0.3185 - Specificity: 0.9994 - F1: 0.4251 - Loss: 0.0028\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 01:40:35\n",
      "Accuracy: 0.9852 - Precision: 0.9281 - Recall: 0.3221 - Specificity: 0.9994 - F1: 0.4299 - Loss: 0.0028\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 01:40:44\n",
      "Accuracy: 0.9853 - Precision: 0.9289 - Recall: 0.3256 - Specificity: 0.9994 - F1: 0.4343 - Loss: 0.0028\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 01:40:54\n",
      "Accuracy: 0.9853 - Precision: 0.9301 - Recall: 0.3297 - Specificity: 0.9994 - F1: 0.4395 - Loss: 0.0028\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 01:41:02\n",
      "Accuracy: 0.9854 - Precision: 0.9306 - Recall: 0.3336 - Specificity: 0.9994 - F1: 0.4442 - Loss: 0.0028\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 01:41:10\n",
      "Accuracy: 0.9855 - Precision: 0.9306 - Recall: 0.3363 - Specificity: 0.9994 - F1: 0.4478 - Loss: 0.0028\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 01:41:18\n",
      "Accuracy: 0.9856 - Precision: 0.9314 - Recall: 0.3408 - Specificity: 0.9994 - F1: 0.4530 - Loss: 0.0028\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 01:41:26\n",
      "Accuracy: 0.9857 - Precision: 0.9319 - Recall: 0.3461 - Specificity: 0.9994 - F1: 0.4586 - Loss: 0.0027\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 01:41:34\n",
      "Accuracy: 0.9858 - Precision: 0.9323 - Recall: 0.3507 - Specificity: 0.9994 - F1: 0.4636 - Loss: 0.0027\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 01:41:42\n",
      "Accuracy: 0.9859 - Precision: 0.9320 - Recall: 0.3568 - Specificity: 0.9994 - F1: 0.4695 - Loss: 0.0027\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 01:41:50\n",
      "Accuracy: 0.9861 - Precision: 0.9319 - Recall: 0.3618 - Specificity: 0.9994 - F1: 0.4746 - Loss: 0.0027\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 01:41:58\n",
      "Accuracy: 0.9862 - Precision: 0.9316 - Recall: 0.3674 - Specificity: 0.9994 - F1: 0.4799 - Loss: 0.0027\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 01:42:06\n",
      "Accuracy: 0.9863 - Precision: 0.9321 - Recall: 0.3724 - Specificity: 0.9994 - F1: 0.4850 - Loss: 0.0027\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 01:42:13\n",
      "Accuracy: 0.9864 - Precision: 0.9312 - Recall: 0.3767 - Specificity: 0.9994 - F1: 0.4892 - Loss: 0.0027\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 01:42:21\n",
      "Accuracy: 0.9864 - Precision: 0.9312 - Recall: 0.3807 - Specificity: 0.9994 - F1: 0.4933 - Loss: 0.0027\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 01:42:29\n",
      "Accuracy: 0.9866 - Precision: 0.9316 - Recall: 0.3851 - Specificity: 0.9994 - F1: 0.4980 - Loss: 0.0027\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 01:42:37\n",
      "Accuracy: 0.9866 - Precision: 0.9322 - Recall: 0.3894 - Specificity: 0.9994 - F1: 0.5024 - Loss: 0.0026\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 01:42:44\n",
      "Accuracy: 0.9867 - Precision: 0.9322 - Recall: 0.3942 - Specificity: 0.9994 - F1: 0.5071 - Loss: 0.0026\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 01:42:52\n",
      "Accuracy: 0.9868 - Precision: 0.9324 - Recall: 0.3979 - Specificity: 0.9994 - F1: 0.5109 - Loss: 0.0026\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 01:43:00\n",
      "Accuracy: 0.9868 - Precision: 0.9322 - Recall: 0.4004 - Specificity: 0.9994 - F1: 0.5138 - Loss: 0.0026\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 01:43:08\n",
      "Accuracy: 0.9868 - Precision: 0.9318 - Recall: 0.4034 - Specificity: 0.9993 - F1: 0.5169 - Loss: 0.0026\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 01:43:16\n",
      "Accuracy: 0.9869 - Precision: 0.9321 - Recall: 0.4059 - Specificity: 0.9993 - F1: 0.5198 - Loss: 0.0026\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 01:43:24\n",
      "Accuracy: 0.9870 - Precision: 0.9324 - Recall: 0.4102 - Specificity: 0.9993 - F1: 0.5240 - Loss: 0.0026\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 01:43:32\n",
      "Accuracy: 0.9871 - Precision: 0.9326 - Recall: 0.4143 - Specificity: 0.9993 - F1: 0.5280 - Loss: 0.0026\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 01:43:40\n",
      "Accuracy: 0.9872 - Precision: 0.9312 - Recall: 0.4180 - Specificity: 0.9993 - F1: 0.5310 - Loss: 0.0026\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 01:43:48\n",
      "Accuracy: 0.9872 - Precision: 0.9298 - Recall: 0.4218 - Specificity: 0.9993 - F1: 0.5342 - Loss: 0.0026\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 01:43:55\n",
      "Accuracy: 0.9872 - Precision: 0.9299 - Recall: 0.4247 - Specificity: 0.9993 - F1: 0.5372 - Loss: 0.0026\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 01:44:03\n",
      "Accuracy: 0.9872 - Precision: 0.9306 - Recall: 0.4265 - Specificity: 0.9993 - F1: 0.5396 - Loss: 0.0026\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 01:44:11\n",
      "Accuracy: 0.9873 - Precision: 0.9308 - Recall: 0.4287 - Specificity: 0.9993 - F1: 0.5421 - Loss: 0.0026\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 01:44:19\n",
      "Accuracy: 0.9873 - Precision: 0.9314 - Recall: 0.4307 - Specificity: 0.9993 - F1: 0.5445 - Loss: 0.0026\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 01:44:27\n",
      "Accuracy: 0.9874 - Precision: 0.9314 - Recall: 0.4330 - Specificity: 0.9993 - F1: 0.5470 - Loss: 0.0026\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 01:44:35\n",
      "Accuracy: 0.9874 - Precision: 0.9320 - Recall: 0.4349 - Specificity: 0.9993 - F1: 0.5493 - Loss: 0.0026\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 01:44:42\n",
      "Accuracy: 0.9874 - Precision: 0.9323 - Recall: 0.4371 - Specificity: 0.9993 - F1: 0.5518 - Loss: 0.0026\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 01:44:50\n",
      "Accuracy: 0.9875 - Precision: 0.9328 - Recall: 0.4395 - Specificity: 0.9993 - F1: 0.5544 - Loss: 0.0026\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 01:44:58\n",
      "Accuracy: 0.9875 - Precision: 0.9330 - Recall: 0.4421 - Specificity: 0.9993 - F1: 0.5571 - Loss: 0.0026\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 01:45:06\n",
      "Accuracy: 0.9876 - Precision: 0.9331 - Recall: 0.4432 - Specificity: 0.9993 - F1: 0.5587 - Loss: 0.0025\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 01:45:14\n",
      "Accuracy: 0.9876 - Precision: 0.9331 - Recall: 0.4454 - Specificity: 0.9993 - F1: 0.5610 - Loss: 0.0025\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 01:45:22\n",
      "Accuracy: 0.9877 - Precision: 0.9329 - Recall: 0.4473 - Specificity: 0.9993 - F1: 0.5629 - Loss: 0.0025\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 01:45:30\n",
      "Accuracy: 0.9878 - Precision: 0.9331 - Recall: 0.4510 - Specificity: 0.9993 - F1: 0.5663 - Loss: 0.0025\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 01:45:38\n",
      "Accuracy: 0.9878 - Precision: 0.9328 - Recall: 0.4538 - Specificity: 0.9993 - F1: 0.5688 - Loss: 0.0025\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 01:45:46\n",
      "Accuracy: 0.9879 - Precision: 0.9330 - Recall: 0.4566 - Specificity: 0.9993 - F1: 0.5715 - Loss: 0.0025\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 01:45:54\n",
      "Accuracy: 0.9879 - Precision: 0.9331 - Recall: 0.4590 - Specificity: 0.9993 - F1: 0.5739 - Loss: 0.0025\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 01:46:01\n",
      "Accuracy: 0.9880 - Precision: 0.9336 - Recall: 0.4615 - Specificity: 0.9993 - F1: 0.5764 - Loss: 0.0025\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 01:46:09\n",
      "Accuracy: 0.9880 - Precision: 0.9339 - Recall: 0.4631 - Specificity: 0.9993 - F1: 0.5783 - Loss: 0.0025\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 01:46:17\n",
      "Accuracy: 0.9880 - Precision: 0.9342 - Recall: 0.4655 - Specificity: 0.9993 - F1: 0.5807 - Loss: 0.0025\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 01:46:25\n",
      "Accuracy: 0.9881 - Precision: 0.9343 - Recall: 0.4679 - Specificity: 0.9993 - F1: 0.5831 - Loss: 0.0025\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 01:46:33\n",
      "Accuracy: 0.9881 - Precision: 0.9343 - Recall: 0.4703 - Specificity: 0.9993 - F1: 0.5853 - Loss: 0.0025\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 01:46:41\n",
      "Accuracy: 0.9882 - Precision: 0.9343 - Recall: 0.4725 - Specificity: 0.9993 - F1: 0.5875 - Loss: 0.0025\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 01:46:49\n",
      "Accuracy: 0.9882 - Precision: 0.9342 - Recall: 0.4743 - Specificity: 0.9993 - F1: 0.5893 - Loss: 0.0025\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 01:46:57\n",
      "Accuracy: 0.9882 - Precision: 0.9345 - Recall: 0.4758 - Specificity: 0.9993 - F1: 0.5910 - Loss: 0.0025\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 01:47:05\n",
      "Accuracy: 0.9883 - Precision: 0.9345 - Recall: 0.4784 - Specificity: 0.9993 - F1: 0.5933 - Loss: 0.0024\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 01:47:13\n",
      "Accuracy: 0.9884 - Precision: 0.9344 - Recall: 0.4814 - Specificity: 0.9993 - F1: 0.5958 - Loss: 0.0024\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 01:47:21\n",
      "Accuracy: 0.9884 - Precision: 0.9336 - Recall: 0.4839 - Specificity: 0.9993 - F1: 0.5978 - Loss: 0.0024\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 01:47:29\n",
      "Accuracy: 0.9885 - Precision: 0.9332 - Recall: 0.4862 - Specificity: 0.9992 - F1: 0.5998 - Loss: 0.0024\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 01:47:37\n",
      "Accuracy: 0.9885 - Precision: 0.9325 - Recall: 0.4882 - Specificity: 0.9992 - F1: 0.6014 - Loss: 0.0024\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 01:47:44\n",
      "Accuracy: 0.9885 - Precision: 0.9311 - Recall: 0.4887 - Specificity: 0.9992 - F1: 0.6018 - Loss: 0.0024\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 01:47:52\n",
      "Accuracy: 0.9886 - Precision: 0.9312 - Recall: 0.4895 - Specificity: 0.9992 - F1: 0.6028 - Loss: 0.0024\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 01:48:00\n",
      "Accuracy: 0.9886 - Precision: 0.9315 - Recall: 0.4895 - Specificity: 0.9992 - F1: 0.6033 - Loss: 0.0024\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 01:48:08\n",
      "Accuracy: 0.9886 - Precision: 0.9320 - Recall: 0.4885 - Specificity: 0.9992 - F1: 0.6028 - Loss: 0.0024\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 01:48:16\n",
      "Accuracy: 0.9886 - Precision: 0.9321 - Recall: 0.4883 - Specificity: 0.9992 - F1: 0.6030 - Loss: 0.0024\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 01:48:24\n",
      "Accuracy: 0.9886 - Precision: 0.9319 - Recall: 0.4871 - Specificity: 0.9992 - F1: 0.6022 - Loss: 0.0024\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 01:48:32\n",
      "Accuracy: 0.9886 - Precision: 0.9313 - Recall: 0.4863 - Specificity: 0.9992 - F1: 0.6017 - Loss: 0.0024\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 01:48:40\n",
      "Accuracy: 0.9886 - Precision: 0.9315 - Recall: 0.4868 - Specificity: 0.9992 - F1: 0.6025 - Loss: 0.0024\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 01:48:47\n",
      "Accuracy: 0.9887 - Precision: 0.9315 - Recall: 0.4877 - Specificity: 0.9992 - F1: 0.6036 - Loss: 0.0024\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 01:48:55\n",
      "Accuracy: 0.9887 - Precision: 0.9313 - Recall: 0.4877 - Specificity: 0.9992 - F1: 0.6039 - Loss: 0.0024\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 01:49:03\n",
      "Accuracy: 0.9887 - Precision: 0.9311 - Recall: 0.4884 - Specificity: 0.9992 - F1: 0.6047 - Loss: 0.0024\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 01:49:11\n",
      "Accuracy: 0.9887 - Precision: 0.9309 - Recall: 0.4894 - Specificity: 0.9992 - F1: 0.6057 - Loss: 0.0024\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 01:49:18\n",
      "Accuracy: 0.9887 - Precision: 0.9310 - Recall: 0.4899 - Specificity: 0.9992 - F1: 0.6065 - Loss: 0.0024\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 01:49:26\n",
      "Accuracy: 0.9887 - Precision: 0.9314 - Recall: 0.4903 - Specificity: 0.9992 - F1: 0.6072 - Loss: 0.0024\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 01:49:34\n",
      "Accuracy: 0.9888 - Precision: 0.9317 - Recall: 0.4906 - Specificity: 0.9992 - F1: 0.6079 - Loss: 0.0024\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 01:49:42\n",
      "Accuracy: 0.9888 - Precision: 0.9319 - Recall: 0.4907 - Specificity: 0.9992 - F1: 0.6083 - Loss: 0.0024\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 01:49:50\n",
      "Accuracy: 0.9888 - Precision: 0.9321 - Recall: 0.4913 - Specificity: 0.9992 - F1: 0.6091 - Loss: 0.0024\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 01:49:57\n",
      "Accuracy: 0.9888 - Precision: 0.9321 - Recall: 0.4923 - Specificity: 0.9992 - F1: 0.6102 - Loss: 0.0024\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 01:50:05\n",
      "Accuracy: 0.9888 - Precision: 0.9317 - Recall: 0.4932 - Specificity: 0.9992 - F1: 0.6111 - Loss: 0.0024\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 01:50:13\n",
      "Accuracy: 0.9888 - Precision: 0.9315 - Recall: 0.4938 - Specificity: 0.9992 - F1: 0.6118 - Loss: 0.0024\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 01:50:21\n",
      "Accuracy: 0.9889 - Precision: 0.9317 - Recall: 0.4945 - Specificity: 0.9992 - F1: 0.6127 - Loss: 0.0024\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 01:50:29\n",
      "Accuracy: 0.9888 - Precision: 0.9319 - Recall: 0.4954 - Specificity: 0.9992 - F1: 0.6138 - Loss: 0.0024\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 01:50:37\n",
      "Accuracy: 0.9889 - Precision: 0.9322 - Recall: 0.4970 - Specificity: 0.9992 - F1: 0.6153 - Loss: 0.0024\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 01:50:45\n",
      "Accuracy: 0.9889 - Precision: 0.9317 - Recall: 0.4983 - Specificity: 0.9992 - F1: 0.6164 - Loss: 0.0024\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 01:50:53\n",
      "Accuracy: 0.9890 - Precision: 0.9316 - Recall: 0.5003 - Specificity: 0.9992 - F1: 0.6181 - Loss: 0.0024\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 01:51:01\n",
      "Accuracy: 0.9890 - Precision: 0.9309 - Recall: 0.5019 - Specificity: 0.9992 - F1: 0.6192 - Loss: 0.0024\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 01:51:09\n",
      "Accuracy: 0.9890 - Precision: 0.9309 - Recall: 0.5032 - Specificity: 0.9992 - F1: 0.6205 - Loss: 0.0024\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 01:51:17\n",
      "Accuracy: 0.9890 - Precision: 0.9312 - Recall: 0.5047 - Specificity: 0.9992 - F1: 0.6220 - Loss: 0.0024\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 01:51:25\n",
      "Accuracy: 0.9891 - Precision: 0.9312 - Recall: 0.5060 - Specificity: 0.9992 - F1: 0.6231 - Loss: 0.0024\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 01:51:32\n",
      "Accuracy: 0.9891 - Precision: 0.9314 - Recall: 0.5066 - Specificity: 0.9992 - F1: 0.6240 - Loss: 0.0024\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 01:51:40\n",
      "Accuracy: 0.9891 - Precision: 0.9314 - Recall: 0.5081 - Specificity: 0.9992 - F1: 0.6254 - Loss: 0.0024\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 01:51:48\n",
      "Accuracy: 0.9891 - Precision: 0.9315 - Recall: 0.5084 - Specificity: 0.9992 - F1: 0.6258 - Loss: 0.0024\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 01:51:56\n",
      "Accuracy: 0.9891 - Precision: 0.9317 - Recall: 0.5095 - Specificity: 0.9992 - F1: 0.6270 - Loss: 0.0024\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 01:52:04\n",
      "Accuracy: 0.9891 - Precision: 0.9321 - Recall: 0.5104 - Specificity: 0.9992 - F1: 0.6280 - Loss: 0.0024\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 01:52:12\n",
      "Accuracy: 0.9892 - Precision: 0.9321 - Recall: 0.5114 - Specificity: 0.9992 - F1: 0.6291 - Loss: 0.0023\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 01:52:20\n",
      "Accuracy: 0.9892 - Precision: 0.9324 - Recall: 0.5122 - Specificity: 0.9992 - F1: 0.6300 - Loss: 0.0023\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 01:52:28\n",
      "Accuracy: 0.9892 - Precision: 0.9326 - Recall: 0.5132 - Specificity: 0.9992 - F1: 0.6311 - Loss: 0.0023\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 01:52:36\n",
      "Accuracy: 0.9892 - Precision: 0.9328 - Recall: 0.5141 - Specificity: 0.9992 - F1: 0.6320 - Loss: 0.0023\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 01:52:44\n",
      "Accuracy: 0.9893 - Precision: 0.9330 - Recall: 0.5155 - Specificity: 0.9992 - F1: 0.6333 - Loss: 0.0023\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 01:52:52\n",
      "Accuracy: 0.9893 - Precision: 0.9331 - Recall: 0.5169 - Specificity: 0.9992 - F1: 0.6346 - Loss: 0.0023\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 01:52:59\n",
      "Accuracy: 0.9893 - Precision: 0.9331 - Recall: 0.5177 - Specificity: 0.9992 - F1: 0.6354 - Loss: 0.0023\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 01:53:07\n",
      "Accuracy: 0.9893 - Precision: 0.9331 - Recall: 0.5189 - Specificity: 0.9992 - F1: 0.6365 - Loss: 0.0023\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 01:53:15\n",
      "Accuracy: 0.9893 - Precision: 0.9328 - Recall: 0.5202 - Specificity: 0.9992 - F1: 0.6376 - Loss: 0.0023\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 01:53:24\n",
      "Accuracy: 0.9894 - Precision: 0.9329 - Recall: 0.5212 - Specificity: 0.9992 - F1: 0.6386 - Loss: 0.0023\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 01:53:31\n",
      "Accuracy: 0.9894 - Precision: 0.9327 - Recall: 0.5225 - Specificity: 0.9992 - F1: 0.6396 - Loss: 0.0023\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 01:53:39\n",
      "Accuracy: 0.9894 - Precision: 0.9329 - Recall: 0.5230 - Specificity: 0.9992 - F1: 0.6403 - Loss: 0.0023\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 01:53:47\n",
      "Accuracy: 0.9894 - Precision: 0.9332 - Recall: 0.5242 - Specificity: 0.9992 - F1: 0.6415 - Loss: 0.0023\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 01:53:55\n",
      "Accuracy: 0.9894 - Precision: 0.9331 - Recall: 0.5226 - Specificity: 0.9992 - F1: 0.6401 - Loss: 0.0023\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 01:54:03\n",
      "Accuracy: 0.9894 - Precision: 0.9335 - Recall: 0.5226 - Specificity: 0.9992 - F1: 0.6404 - Loss: 0.0023\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 01:54:11\n",
      "Accuracy: 0.9894 - Precision: 0.9337 - Recall: 0.5222 - Specificity: 0.9992 - F1: 0.6403 - Loss: 0.0023\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 01:54:19\n",
      "Accuracy: 0.9894 - Precision: 0.9339 - Recall: 0.5224 - Specificity: 0.9992 - F1: 0.6407 - Loss: 0.0023\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 01:54:27\n",
      "Accuracy: 0.9894 - Precision: 0.9341 - Recall: 0.5229 - Specificity: 0.9992 - F1: 0.6413 - Loss: 0.0023\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 01:54:35\n",
      "Accuracy: 0.9894 - Precision: 0.9344 - Recall: 0.5234 - Specificity: 0.9992 - F1: 0.6420 - Loss: 0.0023\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 01:54:43\n",
      "Accuracy: 0.9894 - Precision: 0.9346 - Recall: 0.5241 - Specificity: 0.9992 - F1: 0.6428 - Loss: 0.0023\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 01:54:51\n",
      "Accuracy: 0.9894 - Precision: 0.9347 - Recall: 0.5251 - Specificity: 0.9992 - F1: 0.6438 - Loss: 0.0023\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 01:54:59\n",
      "Accuracy: 0.9895 - Precision: 0.9346 - Recall: 0.5261 - Specificity: 0.9992 - F1: 0.6447 - Loss: 0.0023\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 01:55:07\n",
      "Accuracy: 0.9895 - Precision: 0.9344 - Recall: 0.5275 - Specificity: 0.9992 - F1: 0.6457 - Loss: 0.0023\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 01:55:14\n",
      "Accuracy: 0.9895 - Precision: 0.9346 - Recall: 0.5285 - Specificity: 0.9992 - F1: 0.6467 - Loss: 0.0023\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 01:55:22\n",
      "Accuracy: 0.9895 - Precision: 0.9346 - Recall: 0.5295 - Specificity: 0.9992 - F1: 0.6476 - Loss: 0.0023\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 01:55:30\n",
      "Accuracy: 0.9896 - Precision: 0.9347 - Recall: 0.5301 - Specificity: 0.9992 - F1: 0.6484 - Loss: 0.0023\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 01:55:38\n",
      "Accuracy: 0.9896 - Precision: 0.9349 - Recall: 0.5311 - Specificity: 0.9992 - F1: 0.6493 - Loss: 0.0023\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 01:55:45\n",
      "Accuracy: 0.9896 - Precision: 0.9351 - Recall: 0.5320 - Specificity: 0.9992 - F1: 0.6502 - Loss: 0.0023\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 01:55:53\n",
      "Accuracy: 0.9896 - Precision: 0.9353 - Recall: 0.5326 - Specificity: 0.9992 - F1: 0.6509 - Loss: 0.0023\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 01:56:02\n",
      "Accuracy: 0.9897 - Precision: 0.9355 - Recall: 0.5335 - Specificity: 0.9992 - F1: 0.6518 - Loss: 0.0023\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 01:56:10\n",
      "Accuracy: 0.9897 - Precision: 0.9356 - Recall: 0.5340 - Specificity: 0.9992 - F1: 0.6524 - Loss: 0.0023\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 01:56:18\n",
      "Accuracy: 0.9897 - Precision: 0.9358 - Recall: 0.5346 - Specificity: 0.9992 - F1: 0.6531 - Loss: 0.0023\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 01:56:25\n",
      "Accuracy: 0.9897 - Precision: 0.9360 - Recall: 0.5353 - Specificity: 0.9992 - F1: 0.6538 - Loss: 0.0023\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 01:56:33\n",
      "Accuracy: 0.9897 - Precision: 0.9361 - Recall: 0.5362 - Specificity: 0.9992 - F1: 0.6547 - Loss: 0.0023\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 01:56:41\n",
      "Accuracy: 0.9897 - Precision: 0.9361 - Recall: 0.5373 - Specificity: 0.9992 - F1: 0.6556 - Loss: 0.0023\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 01:56:49\n",
      "Accuracy: 0.9898 - Precision: 0.9363 - Recall: 0.5380 - Specificity: 0.9992 - F1: 0.6564 - Loss: 0.0023\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 01:56:57\n",
      "Accuracy: 0.9898 - Precision: 0.9362 - Recall: 0.5388 - Specificity: 0.9992 - F1: 0.6571 - Loss: 0.0023\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 01:57:05\n",
      "Accuracy: 0.9898 - Precision: 0.9361 - Recall: 0.5395 - Specificity: 0.9992 - F1: 0.6577 - Loss: 0.0023\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 01:57:13\n",
      "Accuracy: 0.9898 - Precision: 0.9362 - Recall: 0.5402 - Specificity: 0.9992 - F1: 0.6584 - Loss: 0.0023\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 01:57:20\n",
      "Accuracy: 0.9898 - Precision: 0.9363 - Recall: 0.5407 - Specificity: 0.9992 - F1: 0.6590 - Loss: 0.0023\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 01:57:28\n",
      "Accuracy: 0.9898 - Precision: 0.9364 - Recall: 0.5417 - Specificity: 0.9992 - F1: 0.6599 - Loss: 0.0023\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 01:57:36\n",
      "Accuracy: 0.9898 - Precision: 0.9362 - Recall: 0.5428 - Specificity: 0.9992 - F1: 0.6607 - Loss: 0.0023\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 01:57:44\n",
      "Accuracy: 0.9899 - Precision: 0.9363 - Recall: 0.5437 - Specificity: 0.9992 - F1: 0.6616 - Loss: 0.0023\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 01:57:52\n",
      "Accuracy: 0.9899 - Precision: 0.9361 - Recall: 0.5442 - Specificity: 0.9992 - F1: 0.6621 - Loss: 0.0023\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 01:58:00\n",
      "Accuracy: 0.9899 - Precision: 0.9361 - Recall: 0.5449 - Specificity: 0.9992 - F1: 0.6627 - Loss: 0.0022\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 01:58:08\n",
      "Accuracy: 0.9899 - Precision: 0.9363 - Recall: 0.5452 - Specificity: 0.9992 - F1: 0.6631 - Loss: 0.0022\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 01:58:16\n",
      "Accuracy: 0.9899 - Precision: 0.9365 - Recall: 0.5454 - Specificity: 0.9992 - F1: 0.6635 - Loss: 0.0022\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 01:58:24\n",
      "Accuracy: 0.9899 - Precision: 0.9367 - Recall: 0.5455 - Specificity: 0.9992 - F1: 0.6637 - Loss: 0.0022\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 01:58:32\n",
      "Accuracy: 0.9899 - Precision: 0.9368 - Recall: 0.5454 - Specificity: 0.9992 - F1: 0.6639 - Loss: 0.0022\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 01:58:40\n",
      "Accuracy: 0.9899 - Precision: 0.9368 - Recall: 0.5455 - Specificity: 0.9992 - F1: 0.6641 - Loss: 0.0022\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 01:58:48\n",
      "Accuracy: 0.9899 - Precision: 0.9369 - Recall: 0.5458 - Specificity: 0.9992 - F1: 0.6645 - Loss: 0.0022\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 01:58:56\n",
      "Accuracy: 0.9899 - Precision: 0.9370 - Recall: 0.5460 - Specificity: 0.9992 - F1: 0.6648 - Loss: 0.0022\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 01:59:04\n",
      "Accuracy: 0.9899 - Precision: 0.9371 - Recall: 0.5465 - Specificity: 0.9992 - F1: 0.6653 - Loss: 0.0022\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 01:59:12\n",
      "Accuracy: 0.9899 - Precision: 0.9373 - Recall: 0.5474 - Specificity: 0.9992 - F1: 0.6662 - Loss: 0.0022\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 01:59:20\n",
      "Accuracy: 0.9900 - Precision: 0.9373 - Recall: 0.5482 - Specificity: 0.9992 - F1: 0.6669 - Loss: 0.0022\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 01:59:28\n",
      "Accuracy: 0.9900 - Precision: 0.9374 - Recall: 0.5491 - Specificity: 0.9992 - F1: 0.6677 - Loss: 0.0022\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 01:59:35\n",
      "Accuracy: 0.9900 - Precision: 0.9372 - Recall: 0.5502 - Specificity: 0.9992 - F1: 0.6685 - Loss: 0.0022\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 01:59:43\n",
      "Accuracy: 0.9900 - Precision: 0.9366 - Recall: 0.5511 - Specificity: 0.9992 - F1: 0.6690 - Loss: 0.0022\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 01:59:51\n",
      "Accuracy: 0.9900 - Precision: 0.9367 - Recall: 0.5518 - Specificity: 0.9992 - F1: 0.6698 - Loss: 0.0022\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 01:59:59\n",
      "Accuracy: 0.9900 - Precision: 0.9369 - Recall: 0.5519 - Specificity: 0.9992 - F1: 0.6700 - Loss: 0.0022\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 02:00:07\n",
      "Accuracy: 0.9901 - Precision: 0.9370 - Recall: 0.5525 - Specificity: 0.9992 - F1: 0.6706 - Loss: 0.0022\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 02:00:15\n",
      "Accuracy: 0.9901 - Precision: 0.9371 - Recall: 0.5526 - Specificity: 0.9992 - F1: 0.6708 - Loss: 0.0022\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 02:00:23\n",
      "Accuracy: 0.9901 - Precision: 0.9373 - Recall: 0.5526 - Specificity: 0.9992 - F1: 0.6710 - Loss: 0.0022\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 02:00:31\n",
      "Accuracy: 0.9901 - Precision: 0.9375 - Recall: 0.5526 - Specificity: 0.9992 - F1: 0.6712 - Loss: 0.0022\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 02:00:39\n",
      "Accuracy: 0.9901 - Precision: 0.9377 - Recall: 0.5528 - Specificity: 0.9992 - F1: 0.6715 - Loss: 0.0022\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 02:00:47\n",
      "Accuracy: 0.9901 - Precision: 0.9378 - Recall: 0.5532 - Specificity: 0.9992 - F1: 0.6719 - Loss: 0.0022\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 02:00:54\n",
      "Accuracy: 0.9901 - Precision: 0.9379 - Recall: 0.5542 - Specificity: 0.9992 - F1: 0.6728 - Loss: 0.0022\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 02:01:02\n",
      "Accuracy: 0.9901 - Precision: 0.9378 - Recall: 0.5553 - Specificity: 0.9992 - F1: 0.6736 - Loss: 0.0022\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 02:01:11\n",
      "Accuracy: 0.9901 - Precision: 0.9372 - Recall: 0.5564 - Specificity: 0.9992 - F1: 0.6742 - Loss: 0.0022\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 02:01:19\n",
      "Accuracy: 0.9902 - Precision: 0.9371 - Recall: 0.5574 - Specificity: 0.9992 - F1: 0.6750 - Loss: 0.0022\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 02:01:26\n",
      "Accuracy: 0.9902 - Precision: 0.9371 - Recall: 0.5583 - Specificity: 0.9992 - F1: 0.6757 - Loss: 0.0022\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 02:01:34\n",
      "Accuracy: 0.9902 - Precision: 0.9371 - Recall: 0.5588 - Specificity: 0.9992 - F1: 0.6762 - Loss: 0.0022\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 02:01:42\n",
      "Accuracy: 0.9902 - Precision: 0.9372 - Recall: 0.5595 - Specificity: 0.9992 - F1: 0.6769 - Loss: 0.0022\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 02:01:50\n",
      "Accuracy: 0.9902 - Precision: 0.9374 - Recall: 0.5599 - Specificity: 0.9992 - F1: 0.6773 - Loss: 0.0022\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 02:01:58\n",
      "Accuracy: 0.9902 - Precision: 0.9375 - Recall: 0.5604 - Specificity: 0.9992 - F1: 0.6779 - Loss: 0.0022\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 02:02:06\n",
      "Accuracy: 0.9903 - Precision: 0.9377 - Recall: 0.5607 - Specificity: 0.9992 - F1: 0.6783 - Loss: 0.0022\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 02:02:14\n",
      "Accuracy: 0.9903 - Precision: 0.9380 - Recall: 0.5611 - Specificity: 0.9992 - F1: 0.6787 - Loss: 0.0022\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 02:02:22\n",
      "Accuracy: 0.9903 - Precision: 0.9381 - Recall: 0.5609 - Specificity: 0.9992 - F1: 0.6788 - Loss: 0.0022\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 02:02:30\n",
      "Accuracy: 0.9903 - Precision: 0.9381 - Recall: 0.5602 - Specificity: 0.9992 - F1: 0.6783 - Loss: 0.0022\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 02:02:38\n",
      "Accuracy: 0.9902 - Precision: 0.9380 - Recall: 0.5600 - Specificity: 0.9992 - F1: 0.6782 - Loss: 0.0022\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 02:02:46\n",
      "Accuracy: 0.9902 - Precision: 0.9380 - Recall: 0.5596 - Specificity: 0.9992 - F1: 0.6779 - Loss: 0.0022\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 02:02:54\n",
      "Accuracy: 0.9902 - Precision: 0.9380 - Recall: 0.5594 - Specificity: 0.9992 - F1: 0.6779 - Loss: 0.0022\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 02:03:02\n",
      "Accuracy: 0.9902 - Precision: 0.9380 - Recall: 0.5596 - Specificity: 0.9992 - F1: 0.6782 - Loss: 0.0022\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 02:03:09\n",
      "Accuracy: 0.9902 - Precision: 0.9379 - Recall: 0.5594 - Specificity: 0.9992 - F1: 0.6781 - Loss: 0.0022\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 02:03:17\n",
      "Accuracy: 0.9901 - Precision: 0.9379 - Recall: 0.5590 - Specificity: 0.9992 - F1: 0.6778 - Loss: 0.0022\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 02:03:25\n",
      "Accuracy: 0.9901 - Precision: 0.9378 - Recall: 0.5594 - Specificity: 0.9992 - F1: 0.6782 - Loss: 0.0022\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 02:03:33\n",
      "Accuracy: 0.9901 - Precision: 0.9374 - Recall: 0.5594 - Specificity: 0.9992 - F1: 0.6782 - Loss: 0.0022\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 02:03:40\n",
      "Accuracy: 0.9901 - Precision: 0.9371 - Recall: 0.5597 - Specificity: 0.9992 - F1: 0.6784 - Loss: 0.0022\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 02:03:48\n",
      "Accuracy: 0.9901 - Precision: 0.9372 - Recall: 0.5599 - Specificity: 0.9992 - F1: 0.6787 - Loss: 0.0022\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 02:03:56\n",
      "Accuracy: 0.9901 - Precision: 0.9372 - Recall: 0.5595 - Specificity: 0.9992 - F1: 0.6785 - Loss: 0.0022\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 02:04:04\n",
      "Accuracy: 0.9901 - Precision: 0.9374 - Recall: 0.5587 - Specificity: 0.9992 - F1: 0.6778 - Loss: 0.0022\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 02:04:12\n",
      "Accuracy: 0.9901 - Precision: 0.9375 - Recall: 0.5579 - Specificity: 0.9992 - F1: 0.6773 - Loss: 0.0022\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 02:04:20\n",
      "Accuracy: 0.9900 - Precision: 0.9377 - Recall: 0.5573 - Specificity: 0.9992 - F1: 0.6768 - Loss: 0.0022\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 02:04:28\n",
      "Accuracy: 0.9900 - Precision: 0.9379 - Recall: 0.5560 - Specificity: 0.9992 - F1: 0.6758 - Loss: 0.0022\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 02:04:36\n",
      "Accuracy: 0.9900 - Precision: 0.9380 - Recall: 0.5551 - Specificity: 0.9992 - F1: 0.6750 - Loss: 0.0022\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 02:04:44\n",
      "Accuracy: 0.9900 - Precision: 0.9382 - Recall: 0.5546 - Specificity: 0.9992 - F1: 0.6748 - Loss: 0.0022\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 02:04:52\n",
      "Accuracy: 0.9900 - Precision: 0.9382 - Recall: 0.5539 - Specificity: 0.9992 - F1: 0.6742 - Loss: 0.0022\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 02:05:00\n",
      "Accuracy: 0.9899 - Precision: 0.9381 - Recall: 0.5530 - Specificity: 0.9992 - F1: 0.6734 - Loss: 0.0023\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 02:05:07\n",
      "Accuracy: 0.9899 - Precision: 0.9380 - Recall: 0.5526 - Specificity: 0.9992 - F1: 0.6732 - Loss: 0.0023\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 02:05:15\n",
      "Accuracy: 0.9898 - Precision: 0.9378 - Recall: 0.5520 - Specificity: 0.9992 - F1: 0.6727 - Loss: 0.0023\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 02:05:23\n",
      "Accuracy: 0.9898 - Precision: 0.9376 - Recall: 0.5519 - Specificity: 0.9992 - F1: 0.6727 - Loss: 0.0023\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 02:05:31\n",
      "Accuracy: 0.9898 - Precision: 0.9375 - Recall: 0.5520 - Specificity: 0.9992 - F1: 0.6728 - Loss: 0.0023\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 02:05:39\n",
      "Accuracy: 0.9898 - Precision: 0.9372 - Recall: 0.5514 - Specificity: 0.9992 - F1: 0.6724 - Loss: 0.0023\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 02:05:47\n",
      "Accuracy: 0.9897 - Precision: 0.9372 - Recall: 0.5515 - Specificity: 0.9992 - F1: 0.6725 - Loss: 0.0023\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 02:05:55\n",
      "Accuracy: 0.9894 - Precision: 0.9370 - Recall: 0.5497 - Specificity: 0.9992 - F1: 0.6707 - Loss: 0.0024\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 02:06:03\n",
      "Accuracy: 0.9893 - Precision: 0.9369 - Recall: 0.5482 - Specificity: 0.9992 - F1: 0.6691 - Loss: 0.0025\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 02:06:11\n",
      "Accuracy: 0.9890 - Precision: 0.9370 - Recall: 0.5468 - Specificity: 0.9992 - F1: 0.6678 - Loss: 0.0025\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 02:06:19\n",
      "Accuracy: 0.9888 - Precision: 0.9367 - Recall: 0.5459 - Specificity: 0.9992 - F1: 0.6669 - Loss: 0.0026\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 02:06:27\n",
      "Accuracy: 0.9886 - Precision: 0.9365 - Recall: 0.5450 - Specificity: 0.9992 - F1: 0.6662 - Loss: 0.0026\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 02:06:35\n",
      "Accuracy: 0.9884 - Precision: 0.9357 - Recall: 0.5449 - Specificity: 0.9991 - F1: 0.6660 - Loss: 0.0027\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 02:06:43\n",
      "Accuracy: 0.9882 - Precision: 0.9351 - Recall: 0.5442 - Specificity: 0.9991 - F1: 0.6654 - Loss: 0.0028\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 02:06:51\n",
      "Accuracy: 0.9880 - Precision: 0.9343 - Recall: 0.5431 - Specificity: 0.9991 - F1: 0.6642 - Loss: 0.0028\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 02:06:58\n",
      "Accuracy: 0.9877 - Precision: 0.9343 - Recall: 0.5413 - Specificity: 0.9991 - F1: 0.6623 - Loss: 0.0029\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 02:07:06\n",
      "Accuracy: 0.9874 - Precision: 0.9339 - Recall: 0.5393 - Specificity: 0.9991 - F1: 0.6600 - Loss: 0.0029\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 02:07:14\n",
      "Accuracy: 0.9871 - Precision: 0.9341 - Recall: 0.5375 - Specificity: 0.9991 - F1: 0.6580 - Loss: 0.0030\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 02:07:23\n",
      "Accuracy: 0.9870 - Precision: 0.9339 - Recall: 0.5356 - Specificity: 0.9991 - F1: 0.6558 - Loss: 0.0030\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 02:07:30\n",
      "Accuracy: 0.9867 - Precision: 0.9338 - Recall: 0.5336 - Specificity: 0.9991 - F1: 0.6534 - Loss: 0.0030\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 02:07:38\n",
      "Accuracy: 0.9866 - Precision: 0.9333 - Recall: 0.5316 - Specificity: 0.9991 - F1: 0.6511 - Loss: 0.0031\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 02:07:46\n",
      "Accuracy: 0.9863 - Precision: 0.9332 - Recall: 0.5296 - Specificity: 0.9991 - F1: 0.6488 - Loss: 0.0031\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 02:07:54\n",
      "Accuracy: 0.9859 - Precision: 0.9330 - Recall: 0.5277 - Specificity: 0.9991 - F1: 0.6464 - Loss: 0.0032\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 02:08:02\n",
      "Accuracy: 0.9857 - Precision: 0.9327 - Recall: 0.5258 - Specificity: 0.9991 - F1: 0.6442 - Loss: 0.0032\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 02:08:10\n",
      "Accuracy: 0.9855 - Precision: 0.9320 - Recall: 0.5240 - Specificity: 0.9991 - F1: 0.6422 - Loss: 0.0032\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 02:08:18\n",
      "Accuracy: 0.9854 - Precision: 0.9301 - Recall: 0.5221 - Specificity: 0.9991 - F1: 0.6400 - Loss: 0.0033\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 02:08:26\n",
      "Accuracy: 0.9854 - Precision: 0.9295 - Recall: 0.5202 - Specificity: 0.9991 - F1: 0.6377 - Loss: 0.0033\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 02:08:34\n",
      "Accuracy: 0.9854 - Precision: 0.9295 - Recall: 0.5185 - Specificity: 0.9991 - F1: 0.6357 - Loss: 0.0033\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 02:08:42\n",
      "Accuracy: 0.9853 - Precision: 0.9295 - Recall: 0.5166 - Specificity: 0.9991 - F1: 0.6336 - Loss: 0.0033\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 02:08:50\n",
      "Accuracy: 0.9852 - Precision: 0.9298 - Recall: 0.5149 - Specificity: 0.9991 - F1: 0.6316 - Loss: 0.0034\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 02:08:58\n",
      "Accuracy: 0.9851 - Precision: 0.9296 - Recall: 0.5130 - Specificity: 0.9991 - F1: 0.6294 - Loss: 0.0034\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 02:09:06\n",
      "Accuracy: 0.9851 - Precision: 0.9297 - Recall: 0.5113 - Specificity: 0.9991 - F1: 0.6273 - Loss: 0.0034\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 02:09:14\n",
      "Accuracy: 0.9850 - Precision: 0.9291 - Recall: 0.5095 - Specificity: 0.9991 - F1: 0.6253 - Loss: 0.0035\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 02:09:22\n",
      "Accuracy: 0.9850 - Precision: 0.9294 - Recall: 0.5077 - Specificity: 0.9991 - F1: 0.6233 - Loss: 0.0035\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 02:09:30\n",
      "Accuracy: 0.9850 - Precision: 0.9296 - Recall: 0.5061 - Specificity: 0.9991 - F1: 0.6214 - Loss: 0.0035\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 02:09:38\n",
      "Accuracy: 0.9849 - Precision: 0.9299 - Recall: 0.5044 - Specificity: 0.9991 - F1: 0.6194 - Loss: 0.0035\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 02:09:46\n",
      "Accuracy: 0.9849 - Precision: 0.9284 - Recall: 0.5026 - Specificity: 0.9991 - F1: 0.6174 - Loss: 0.0035\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 02:09:54\n",
      "Accuracy: 0.9848 - Precision: 0.9286 - Recall: 0.5009 - Specificity: 0.9991 - F1: 0.6154 - Loss: 0.0035\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 02:10:02\n",
      "Accuracy: 0.9848 - Precision: 0.9288 - Recall: 0.4992 - Specificity: 0.9991 - F1: 0.6134 - Loss: 0.0035\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 02:10:10\n",
      "Accuracy: 0.9847 - Precision: 0.9288 - Recall: 0.4976 - Specificity: 0.9991 - F1: 0.6115 - Loss: 0.0036\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 02:10:17\n",
      "Accuracy: 0.9847 - Precision: 0.9288 - Recall: 0.4959 - Specificity: 0.9991 - F1: 0.6095 - Loss: 0.0036\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 02:10:26\n",
      "Accuracy: 0.9847 - Precision: 0.9284 - Recall: 0.4944 - Specificity: 0.9991 - F1: 0.6078 - Loss: 0.0036\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 02:10:34\n",
      "Accuracy: 0.9846 - Precision: 0.9263 - Recall: 0.4926 - Specificity: 0.9991 - F1: 0.6057 - Loss: 0.0036\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 02:10:42\n",
      "Accuracy: 0.9846 - Precision: 0.9260 - Recall: 0.4910 - Specificity: 0.9991 - F1: 0.6038 - Loss: 0.0036\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 02:10:50\n",
      "Accuracy: 0.9846 - Precision: 0.9233 - Recall: 0.4892 - Specificity: 0.9991 - F1: 0.6016 - Loss: 0.0036\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 02:10:57\n",
      "Accuracy: 0.9845 - Precision: 0.9228 - Recall: 0.4875 - Specificity: 0.9991 - F1: 0.5996 - Loss: 0.0036\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 02:11:05\n",
      "Accuracy: 0.9845 - Precision: 0.9229 - Recall: 0.4860 - Specificity: 0.9991 - F1: 0.5978 - Loss: 0.0036\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 02:11:13\n",
      "Accuracy: 0.9845 - Precision: 0.9217 - Recall: 0.4845 - Specificity: 0.9991 - F1: 0.5962 - Loss: 0.0036\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 02:11:21\n",
      "Accuracy: 0.9845 - Precision: 0.9203 - Recall: 0.4828 - Specificity: 0.9991 - F1: 0.5941 - Loss: 0.0036\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 02:11:29\n",
      "Accuracy: 0.9845 - Precision: 0.9197 - Recall: 0.4812 - Specificity: 0.9991 - F1: 0.5921 - Loss: 0.0036\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 02:11:37\n",
      "Accuracy: 0.9845 - Precision: 0.9165 - Recall: 0.4795 - Specificity: 0.9991 - F1: 0.5900 - Loss: 0.0036\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 02:11:45\n",
      "Accuracy: 0.9844 - Precision: 0.9133 - Recall: 0.4778 - Specificity: 0.9991 - F1: 0.5879 - Loss: 0.0036\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 02:11:53\n",
      "Accuracy: 0.9844 - Precision: 0.9129 - Recall: 0.4761 - Specificity: 0.9991 - F1: 0.5860 - Loss: 0.0037\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 02:12:01\n",
      "Accuracy: 0.9844 - Precision: 0.9132 - Recall: 0.4746 - Specificity: 0.9991 - F1: 0.5841 - Loss: 0.0037\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 02:12:09\n",
      "Accuracy: 0.9843 - Precision: 0.9135 - Recall: 0.4729 - Specificity: 0.9991 - F1: 0.5821 - Loss: 0.0037\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 02:12:17\n",
      "Accuracy: 0.9843 - Precision: 0.9138 - Recall: 0.4713 - Specificity: 0.9991 - F1: 0.5801 - Loss: 0.0037\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 02:12:25\n",
      "Accuracy: 0.9843 - Precision: 0.9140 - Recall: 0.4697 - Specificity: 0.9991 - F1: 0.5782 - Loss: 0.0037\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 02:12:33\n",
      "Accuracy: 0.9842 - Precision: 0.9136 - Recall: 0.4682 - Specificity: 0.9991 - F1: 0.5764 - Loss: 0.0037\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 02:12:41\n",
      "Accuracy: 0.9842 - Precision: 0.9138 - Recall: 0.4667 - Specificity: 0.9992 - F1: 0.5746 - Loss: 0.0037\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 02:12:49\n",
      "Accuracy: 0.9842 - Precision: 0.9135 - Recall: 0.4654 - Specificity: 0.9992 - F1: 0.5731 - Loss: 0.0037\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 02:12:57\n",
      "Accuracy: 0.9842 - Precision: 0.9134 - Recall: 0.4641 - Specificity: 0.9992 - F1: 0.5717 - Loss: 0.0037\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 02:13:05\n",
      "Accuracy: 0.9841 - Precision: 0.9137 - Recall: 0.4627 - Specificity: 0.9992 - F1: 0.5701 - Loss: 0.0037\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 02:13:13\n",
      "Accuracy: 0.9841 - Precision: 0.9135 - Recall: 0.4613 - Specificity: 0.9992 - F1: 0.5685 - Loss: 0.0037\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 02:13:21\n",
      "Accuracy: 0.9841 - Precision: 0.9134 - Recall: 0.4601 - Specificity: 0.9992 - F1: 0.5672 - Loss: 0.0037\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 02:13:29\n",
      "Accuracy: 0.9840 - Precision: 0.9135 - Recall: 0.4589 - Specificity: 0.9992 - F1: 0.5660 - Loss: 0.0037\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 02:13:37\n",
      "Accuracy: 0.9840 - Precision: 0.9135 - Recall: 0.4576 - Specificity: 0.9992 - F1: 0.5645 - Loss: 0.0037\n",
      "\n",
      "Epoch 18/20\n",
      "Validation - Accuracy: 0.9804, Precision: 0.9055, Recall: 0.0967, Specificity: 0.9998, F1: 0.1741, Loss: 0.0046\n",
      "\n",
      "\n",
      "Epoch 19/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 02:20:50\n",
      "Accuracy: 0.9758 - Precision: 0.9663 - Recall: 0.0824 - Specificity: 0.9999 - F1: 0.1518 - Loss: 0.0050\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 02:20:58\n",
      "Accuracy: 0.9745 - Precision: 0.9558 - Recall: 0.0885 - Specificity: 0.9999 - F1: 0.1620 - Loss: 0.0052\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 02:21:07\n",
      "Accuracy: 0.9743 - Precision: 0.9633 - Recall: 0.1145 - Specificity: 0.9999 - F1: 0.2029 - Loss: 0.0049\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 02:21:15\n",
      "Accuracy: 0.9771 - Precision: 0.9702 - Recall: 0.1176 - Specificity: 0.9999 - F1: 0.2083 - Loss: 0.0044\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 02:21:23\n",
      "Accuracy: 0.9788 - Precision: 0.9488 - Recall: 0.1171 - Specificity: 0.9999 - F1: 0.2074 - Loss: 0.0041\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 02:21:31\n",
      "Accuracy: 0.9791 - Precision: 0.9558 - Recall: 0.1265 - Specificity: 0.9999 - F1: 0.2219 - Loss: 0.0039\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 02:21:39\n",
      "Accuracy: 0.9805 - Precision: 0.9552 - Recall: 0.1405 - Specificity: 0.9999 - F1: 0.2422 - Loss: 0.0037\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 02:21:47\n",
      "Accuracy: 0.9810 - Precision: 0.9287 - Recall: 0.1527 - Specificity: 0.9997 - F1: 0.2569 - Loss: 0.0036\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 02:21:55\n",
      "Accuracy: 0.9819 - Precision: 0.9341 - Recall: 0.1647 - Specificity: 0.9997 - F1: 0.2742 - Loss: 0.0034\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 02:22:03\n",
      "Accuracy: 0.9823 - Precision: 0.9368 - Recall: 0.1679 - Specificity: 0.9997 - F1: 0.2794 - Loss: 0.0034\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 02:22:11\n",
      "Accuracy: 0.9826 - Precision: 0.9279 - Recall: 0.1769 - Specificity: 0.9997 - F1: 0.2909 - Loss: 0.0033\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 02:22:19\n",
      "Accuracy: 0.9829 - Precision: 0.9327 - Recall: 0.1825 - Specificity: 0.9997 - F1: 0.2992 - Loss: 0.0032\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 02:22:27\n",
      "Accuracy: 0.9832 - Precision: 0.9331 - Recall: 0.1901 - Specificity: 0.9997 - F1: 0.3095 - Loss: 0.0032\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 02:22:35\n",
      "Accuracy: 0.9834 - Precision: 0.9200 - Recall: 0.1939 - Specificity: 0.9996 - F1: 0.3136 - Loss: 0.0032\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 02:22:43\n",
      "Accuracy: 0.9836 - Precision: 0.9240 - Recall: 0.2016 - Specificity: 0.9996 - F1: 0.3241 - Loss: 0.0031\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 02:22:51\n",
      "Accuracy: 0.9834 - Precision: 0.9261 - Recall: 0.2058 - Specificity: 0.9996 - F1: 0.3301 - Loss: 0.0032\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 02:22:59\n",
      "Accuracy: 0.9838 - Precision: 0.9267 - Recall: 0.2188 - Specificity: 0.9996 - F1: 0.3451 - Loss: 0.0031\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 02:23:06\n",
      "Accuracy: 0.9840 - Precision: 0.9284 - Recall: 0.2299 - Specificity: 0.9996 - F1: 0.3583 - Loss: 0.0031\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 02:23:14\n",
      "Accuracy: 0.9842 - Precision: 0.9274 - Recall: 0.2413 - Specificity: 0.9996 - F1: 0.3709 - Loss: 0.0030\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 02:23:22\n",
      "Accuracy: 0.9845 - Precision: 0.9255 - Recall: 0.2540 - Specificity: 0.9996 - F1: 0.3842 - Loss: 0.0030\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 02:23:30\n",
      "Accuracy: 0.9847 - Precision: 0.9223 - Recall: 0.2624 - Specificity: 0.9995 - F1: 0.3932 - Loss: 0.0030\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 02:23:38\n",
      "Accuracy: 0.9844 - Precision: 0.9080 - Recall: 0.2626 - Specificity: 0.9994 - F1: 0.3922 - Loss: 0.0031\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 02:23:46\n",
      "Accuracy: 0.9845 - Precision: 0.9110 - Recall: 0.2674 - Specificity: 0.9994 - F1: 0.3986 - Loss: 0.0031\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 02:23:54\n",
      "Accuracy: 0.9845 - Precision: 0.9132 - Recall: 0.2728 - Specificity: 0.9994 - F1: 0.4055 - Loss: 0.0031\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 02:24:02\n",
      "Accuracy: 0.9846 - Precision: 0.9157 - Recall: 0.2785 - Specificity: 0.9994 - F1: 0.4126 - Loss: 0.0031\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 02:24:10\n",
      "Accuracy: 0.9849 - Precision: 0.9172 - Recall: 0.2863 - Specificity: 0.9994 - F1: 0.4212 - Loss: 0.0030\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 02:24:19\n",
      "Accuracy: 0.9850 - Precision: 0.9196 - Recall: 0.2911 - Specificity: 0.9994 - F1: 0.4274 - Loss: 0.0030\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 02:24:27\n",
      "Accuracy: 0.9850 - Precision: 0.9212 - Recall: 0.2918 - Specificity: 0.9994 - F1: 0.4288 - Loss: 0.0030\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 02:24:35\n",
      "Accuracy: 0.9848 - Precision: 0.9207 - Recall: 0.2919 - Specificity: 0.9994 - F1: 0.4294 - Loss: 0.0030\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 02:24:43\n",
      "Accuracy: 0.9849 - Precision: 0.9218 - Recall: 0.3001 - Specificity: 0.9994 - F1: 0.4380 - Loss: 0.0030\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 02:24:51\n",
      "Accuracy: 0.9851 - Precision: 0.9211 - Recall: 0.3081 - Specificity: 0.9994 - F1: 0.4459 - Loss: 0.0030\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 02:24:59\n",
      "Accuracy: 0.9852 - Precision: 0.9214 - Recall: 0.3126 - Specificity: 0.9994 - F1: 0.4509 - Loss: 0.0030\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 02:25:07\n",
      "Accuracy: 0.9853 - Precision: 0.9224 - Recall: 0.3197 - Specificity: 0.9994 - F1: 0.4583 - Loss: 0.0030\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 02:25:16\n",
      "Accuracy: 0.9853 - Precision: 0.9241 - Recall: 0.3238 - Specificity: 0.9994 - F1: 0.4632 - Loss: 0.0030\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 02:25:24\n",
      "Accuracy: 0.9854 - Precision: 0.9253 - Recall: 0.3256 - Specificity: 0.9994 - F1: 0.4658 - Loss: 0.0030\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 02:25:32\n",
      "Accuracy: 0.9855 - Precision: 0.9260 - Recall: 0.3320 - Specificity: 0.9994 - F1: 0.4724 - Loss: 0.0029\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 02:25:40\n",
      "Accuracy: 0.9857 - Precision: 0.9271 - Recall: 0.3390 - Specificity: 0.9994 - F1: 0.4795 - Loss: 0.0029\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 02:25:48\n",
      "Accuracy: 0.9857 - Precision: 0.9275 - Recall: 0.3446 - Specificity: 0.9994 - F1: 0.4851 - Loss: 0.0029\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 02:25:56\n",
      "Accuracy: 0.9859 - Precision: 0.9285 - Recall: 0.3508 - Specificity: 0.9994 - F1: 0.4914 - Loss: 0.0029\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 02:26:04\n",
      "Accuracy: 0.9860 - Precision: 0.9291 - Recall: 0.3574 - Specificity: 0.9994 - F1: 0.4978 - Loss: 0.0029\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 02:26:12\n",
      "Accuracy: 0.9859 - Precision: 0.9295 - Recall: 0.3596 - Specificity: 0.9994 - F1: 0.5004 - Loss: 0.0029\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 02:26:20\n",
      "Accuracy: 0.9860 - Precision: 0.9301 - Recall: 0.3661 - Specificity: 0.9994 - F1: 0.5067 - Loss: 0.0029\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 02:26:28\n",
      "Accuracy: 0.9862 - Precision: 0.9303 - Recall: 0.3728 - Specificity: 0.9994 - F1: 0.5128 - Loss: 0.0029\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 02:26:36\n",
      "Accuracy: 0.9863 - Precision: 0.9299 - Recall: 0.3809 - Specificity: 0.9994 - F1: 0.5195 - Loss: 0.0028\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 02:26:44\n",
      "Accuracy: 0.9865 - Precision: 0.9252 - Recall: 0.3893 - Specificity: 0.9993 - F1: 0.5244 - Loss: 0.0028\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 02:26:52\n",
      "Accuracy: 0.9866 - Precision: 0.9253 - Recall: 0.3954 - Specificity: 0.9993 - F1: 0.5299 - Loss: 0.0028\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 02:27:00\n",
      "Accuracy: 0.9866 - Precision: 0.9254 - Recall: 0.3996 - Specificity: 0.9993 - F1: 0.5341 - Loss: 0.0028\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 02:27:08\n",
      "Accuracy: 0.9867 - Precision: 0.9261 - Recall: 0.4037 - Specificity: 0.9993 - F1: 0.5383 - Loss: 0.0028\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 02:27:16\n",
      "Accuracy: 0.9868 - Precision: 0.9266 - Recall: 0.4074 - Specificity: 0.9993 - F1: 0.5421 - Loss: 0.0028\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 02:27:24\n",
      "Accuracy: 0.9868 - Precision: 0.9278 - Recall: 0.4113 - Specificity: 0.9993 - F1: 0.5462 - Loss: 0.0028\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 02:27:32\n",
      "Accuracy: 0.9869 - Precision: 0.9282 - Recall: 0.4147 - Specificity: 0.9993 - F1: 0.5497 - Loss: 0.0028\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 02:27:40\n",
      "Accuracy: 0.9869 - Precision: 0.9282 - Recall: 0.4173 - Specificity: 0.9993 - F1: 0.5524 - Loss: 0.0028\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 02:27:48\n",
      "Accuracy: 0.9871 - Precision: 0.9291 - Recall: 0.4214 - Specificity: 0.9993 - F1: 0.5564 - Loss: 0.0027\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 02:27:56\n",
      "Accuracy: 0.9872 - Precision: 0.9299 - Recall: 0.4259 - Specificity: 0.9993 - F1: 0.5608 - Loss: 0.0027\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 02:28:04\n",
      "Accuracy: 0.9872 - Precision: 0.9304 - Recall: 0.4295 - Specificity: 0.9993 - F1: 0.5643 - Loss: 0.0027\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 02:28:12\n",
      "Accuracy: 0.9873 - Precision: 0.9301 - Recall: 0.4347 - Specificity: 0.9993 - F1: 0.5687 - Loss: 0.0027\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 02:28:20\n",
      "Accuracy: 0.9874 - Precision: 0.9300 - Recall: 0.4386 - Specificity: 0.9993 - F1: 0.5721 - Loss: 0.0027\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 02:28:28\n",
      "Accuracy: 0.9875 - Precision: 0.9296 - Recall: 0.4435 - Specificity: 0.9993 - F1: 0.5762 - Loss: 0.0027\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 02:28:37\n",
      "Accuracy: 0.9876 - Precision: 0.9296 - Recall: 0.4476 - Specificity: 0.9993 - F1: 0.5798 - Loss: 0.0027\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 02:28:44\n",
      "Accuracy: 0.9877 - Precision: 0.9291 - Recall: 0.4515 - Specificity: 0.9993 - F1: 0.5830 - Loss: 0.0026\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 02:28:53\n",
      "Accuracy: 0.9878 - Precision: 0.9291 - Recall: 0.4548 - Specificity: 0.9993 - F1: 0.5860 - Loss: 0.0026\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 02:29:01\n",
      "Accuracy: 0.9879 - Precision: 0.9296 - Recall: 0.4584 - Specificity: 0.9993 - F1: 0.5894 - Loss: 0.0026\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 02:29:10\n",
      "Accuracy: 0.9879 - Precision: 0.9303 - Recall: 0.4614 - Specificity: 0.9993 - F1: 0.5924 - Loss: 0.0026\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 02:29:18\n",
      "Accuracy: 0.9880 - Precision: 0.9304 - Recall: 0.4655 - Specificity: 0.9993 - F1: 0.5959 - Loss: 0.0026\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 02:29:26\n",
      "Accuracy: 0.9881 - Precision: 0.9306 - Recall: 0.4681 - Specificity: 0.9993 - F1: 0.5984 - Loss: 0.0026\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 02:29:34\n",
      "Accuracy: 0.9880 - Precision: 0.9306 - Recall: 0.4694 - Specificity: 0.9992 - F1: 0.5998 - Loss: 0.0026\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 02:29:41\n",
      "Accuracy: 0.9881 - Precision: 0.9306 - Recall: 0.4708 - Specificity: 0.9992 - F1: 0.6013 - Loss: 0.0026\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 02:29:50\n",
      "Accuracy: 0.9881 - Precision: 0.9311 - Recall: 0.4721 - Specificity: 0.9992 - F1: 0.6029 - Loss: 0.0026\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 02:29:58\n",
      "Accuracy: 0.9882 - Precision: 0.9316 - Recall: 0.4753 - Specificity: 0.9993 - F1: 0.6059 - Loss: 0.0026\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 02:30:06\n",
      "Accuracy: 0.9882 - Precision: 0.9320 - Recall: 0.4779 - Specificity: 0.9993 - F1: 0.6084 - Loss: 0.0026\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 02:30:14\n",
      "Accuracy: 0.9883 - Precision: 0.9306 - Recall: 0.4802 - Specificity: 0.9992 - F1: 0.6100 - Loss: 0.0026\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 02:30:22\n",
      "Accuracy: 0.9883 - Precision: 0.9293 - Recall: 0.4832 - Specificity: 0.9992 - F1: 0.6121 - Loss: 0.0026\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 02:30:30\n",
      "Accuracy: 0.9883 - Precision: 0.9296 - Recall: 0.4853 - Specificity: 0.9992 - F1: 0.6142 - Loss: 0.0026\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 02:30:38\n",
      "Accuracy: 0.9883 - Precision: 0.9299 - Recall: 0.4869 - Specificity: 0.9992 - F1: 0.6158 - Loss: 0.0026\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 02:30:46\n",
      "Accuracy: 0.9884 - Precision: 0.9299 - Recall: 0.4887 - Specificity: 0.9992 - F1: 0.6176 - Loss: 0.0026\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 02:30:54\n",
      "Accuracy: 0.9884 - Precision: 0.9304 - Recall: 0.4900 - Specificity: 0.9992 - F1: 0.6191 - Loss: 0.0026\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 02:31:02\n",
      "Accuracy: 0.9884 - Precision: 0.9304 - Recall: 0.4916 - Specificity: 0.9992 - F1: 0.6206 - Loss: 0.0026\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 02:31:10\n",
      "Accuracy: 0.9885 - Precision: 0.9310 - Recall: 0.4926 - Specificity: 0.9992 - F1: 0.6219 - Loss: 0.0025\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 02:31:18\n",
      "Accuracy: 0.9884 - Precision: 0.9314 - Recall: 0.4938 - Specificity: 0.9992 - F1: 0.6233 - Loss: 0.0025\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 02:31:26\n",
      "Accuracy: 0.9885 - Precision: 0.9319 - Recall: 0.4951 - Specificity: 0.9992 - F1: 0.6247 - Loss: 0.0025\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 02:31:34\n",
      "Accuracy: 0.9885 - Precision: 0.9323 - Recall: 0.4966 - Specificity: 0.9992 - F1: 0.6263 - Loss: 0.0025\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 02:31:42\n",
      "Accuracy: 0.9886 - Precision: 0.9325 - Recall: 0.4974 - Specificity: 0.9992 - F1: 0.6273 - Loss: 0.0025\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 02:31:51\n",
      "Accuracy: 0.9886 - Precision: 0.9326 - Recall: 0.4985 - Specificity: 0.9992 - F1: 0.6285 - Loss: 0.0025\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 02:31:59\n",
      "Accuracy: 0.9886 - Precision: 0.9322 - Recall: 0.5001 - Specificity: 0.9992 - F1: 0.6298 - Loss: 0.0025\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 02:32:07\n",
      "Accuracy: 0.9887 - Precision: 0.9325 - Recall: 0.5029 - Specificity: 0.9992 - F1: 0.6322 - Loss: 0.0025\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 02:32:15\n",
      "Accuracy: 0.9887 - Precision: 0.9320 - Recall: 0.5051 - Specificity: 0.9992 - F1: 0.6339 - Loss: 0.0025\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 02:32:23\n",
      "Accuracy: 0.9888 - Precision: 0.9323 - Recall: 0.5076 - Specificity: 0.9992 - F1: 0.6361 - Loss: 0.0025\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 02:32:31\n",
      "Accuracy: 0.9888 - Precision: 0.9323 - Recall: 0.5092 - Specificity: 0.9992 - F1: 0.6375 - Loss: 0.0025\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 02:32:39\n",
      "Accuracy: 0.9889 - Precision: 0.9328 - Recall: 0.5113 - Specificity: 0.9992 - F1: 0.6395 - Loss: 0.0025\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 02:32:47\n",
      "Accuracy: 0.9888 - Precision: 0.9331 - Recall: 0.5121 - Specificity: 0.9992 - F1: 0.6405 - Loss: 0.0025\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 02:32:55\n",
      "Accuracy: 0.9889 - Precision: 0.9334 - Recall: 0.5136 - Specificity: 0.9992 - F1: 0.6420 - Loss: 0.0025\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 02:33:03\n",
      "Accuracy: 0.9889 - Precision: 0.9335 - Recall: 0.5152 - Specificity: 0.9992 - F1: 0.6434 - Loss: 0.0025\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 02:33:11\n",
      "Accuracy: 0.9890 - Precision: 0.9336 - Recall: 0.5171 - Specificity: 0.9992 - F1: 0.6451 - Loss: 0.0025\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 02:33:20\n",
      "Accuracy: 0.9890 - Precision: 0.9337 - Recall: 0.5189 - Specificity: 0.9992 - F1: 0.6467 - Loss: 0.0024\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 02:33:28\n",
      "Accuracy: 0.9891 - Precision: 0.9338 - Recall: 0.5208 - Specificity: 0.9992 - F1: 0.6483 - Loss: 0.0024\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 02:33:36\n",
      "Accuracy: 0.9891 - Precision: 0.9338 - Recall: 0.5228 - Specificity: 0.9992 - F1: 0.6500 - Loss: 0.0024\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 02:33:44\n",
      "Accuracy: 0.9891 - Precision: 0.9339 - Recall: 0.5248 - Specificity: 0.9992 - F1: 0.6517 - Loss: 0.0024\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 02:33:52\n",
      "Accuracy: 0.9892 - Precision: 0.9338 - Recall: 0.5272 - Specificity: 0.9992 - F1: 0.6536 - Loss: 0.0024\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 02:34:00\n",
      "Accuracy: 0.9892 - Precision: 0.9337 - Recall: 0.5292 - Specificity: 0.9992 - F1: 0.6551 - Loss: 0.0024\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 02:34:08\n",
      "Accuracy: 0.9893 - Precision: 0.9332 - Recall: 0.5316 - Specificity: 0.9992 - F1: 0.6568 - Loss: 0.0024\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 02:34:16\n",
      "Accuracy: 0.9894 - Precision: 0.9325 - Recall: 0.5335 - Specificity: 0.9992 - F1: 0.6581 - Loss: 0.0024\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 02:34:24\n",
      "Accuracy: 0.9894 - Precision: 0.9314 - Recall: 0.5342 - Specificity: 0.9992 - F1: 0.6584 - Loss: 0.0024\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 02:34:31\n",
      "Accuracy: 0.9894 - Precision: 0.9314 - Recall: 0.5350 - Specificity: 0.9992 - F1: 0.6593 - Loss: 0.0024\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 02:34:39\n",
      "Accuracy: 0.9894 - Precision: 0.9316 - Recall: 0.5349 - Specificity: 0.9992 - F1: 0.6594 - Loss: 0.0024\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 02:34:47\n",
      "Accuracy: 0.9894 - Precision: 0.9316 - Recall: 0.5349 - Specificity: 0.9992 - F1: 0.6597 - Loss: 0.0024\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 02:34:55\n",
      "Accuracy: 0.9895 - Precision: 0.9317 - Recall: 0.5355 - Specificity: 0.9992 - F1: 0.6603 - Loss: 0.0024\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 02:35:03\n",
      "Accuracy: 0.9895 - Precision: 0.9315 - Recall: 0.5351 - Specificity: 0.9992 - F1: 0.6601 - Loss: 0.0024\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 02:35:11\n",
      "Accuracy: 0.9895 - Precision: 0.9309 - Recall: 0.5346 - Specificity: 0.9992 - F1: 0.6597 - Loss: 0.0024\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 02:35:19\n",
      "Accuracy: 0.9895 - Precision: 0.9310 - Recall: 0.5353 - Specificity: 0.9992 - F1: 0.6605 - Loss: 0.0024\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 02:35:27\n",
      "Accuracy: 0.9895 - Precision: 0.9310 - Recall: 0.5364 - Specificity: 0.9992 - F1: 0.6615 - Loss: 0.0024\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 02:35:35\n",
      "Accuracy: 0.9895 - Precision: 0.9306 - Recall: 0.5364 - Specificity: 0.9992 - F1: 0.6615 - Loss: 0.0024\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 02:35:43\n",
      "Accuracy: 0.9896 - Precision: 0.9304 - Recall: 0.5372 - Specificity: 0.9992 - F1: 0.6623 - Loss: 0.0024\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 02:35:51\n",
      "Accuracy: 0.9896 - Precision: 0.9301 - Recall: 0.5380 - Specificity: 0.9992 - F1: 0.6630 - Loss: 0.0024\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 02:35:59\n",
      "Accuracy: 0.9896 - Precision: 0.9301 - Recall: 0.5386 - Specificity: 0.9992 - F1: 0.6636 - Loss: 0.0024\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 02:36:07\n",
      "Accuracy: 0.9896 - Precision: 0.9303 - Recall: 0.5391 - Specificity: 0.9992 - F1: 0.6641 - Loss: 0.0024\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 02:36:14\n",
      "Accuracy: 0.9896 - Precision: 0.9300 - Recall: 0.5396 - Specificity: 0.9992 - F1: 0.6646 - Loss: 0.0023\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 02:36:23\n",
      "Accuracy: 0.9896 - Precision: 0.9301 - Recall: 0.5396 - Specificity: 0.9992 - F1: 0.6648 - Loss: 0.0024\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 02:36:31\n",
      "Accuracy: 0.9896 - Precision: 0.9303 - Recall: 0.5400 - Specificity: 0.9992 - F1: 0.6654 - Loss: 0.0023\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 02:36:38\n",
      "Accuracy: 0.9896 - Precision: 0.9303 - Recall: 0.5406 - Specificity: 0.9992 - F1: 0.6659 - Loss: 0.0023\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 02:36:46\n",
      "Accuracy: 0.9897 - Precision: 0.9300 - Recall: 0.5413 - Specificity: 0.9992 - F1: 0.6665 - Loss: 0.0023\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 02:36:55\n",
      "Accuracy: 0.9897 - Precision: 0.9298 - Recall: 0.5415 - Specificity: 0.9992 - F1: 0.6667 - Loss: 0.0023\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 02:37:03\n",
      "Accuracy: 0.9897 - Precision: 0.9302 - Recall: 0.5414 - Specificity: 0.9992 - F1: 0.6669 - Loss: 0.0023\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 02:37:11\n",
      "Accuracy: 0.9897 - Precision: 0.9305 - Recall: 0.5414 - Specificity: 0.9992 - F1: 0.6672 - Loss: 0.0023\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 02:37:19\n",
      "Accuracy: 0.9897 - Precision: 0.9309 - Recall: 0.5423 - Specificity: 0.9992 - F1: 0.6681 - Loss: 0.0023\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 02:37:27\n",
      "Accuracy: 0.9897 - Precision: 0.9309 - Recall: 0.5431 - Specificity: 0.9992 - F1: 0.6689 - Loss: 0.0023\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 02:37:35\n",
      "Accuracy: 0.9897 - Precision: 0.9309 - Recall: 0.5445 - Specificity: 0.9992 - F1: 0.6700 - Loss: 0.0023\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 02:37:42\n",
      "Accuracy: 0.9898 - Precision: 0.9305 - Recall: 0.5456 - Specificity: 0.9992 - F1: 0.6708 - Loss: 0.0023\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 02:37:50\n",
      "Accuracy: 0.9898 - Precision: 0.9304 - Recall: 0.5465 - Specificity: 0.9992 - F1: 0.6716 - Loss: 0.0023\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 02:37:58\n",
      "Accuracy: 0.9898 - Precision: 0.9306 - Recall: 0.5478 - Specificity: 0.9992 - F1: 0.6726 - Loss: 0.0023\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 02:38:06\n",
      "Accuracy: 0.9898 - Precision: 0.9305 - Recall: 0.5486 - Specificity: 0.9992 - F1: 0.6734 - Loss: 0.0023\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 02:38:14\n",
      "Accuracy: 0.9898 - Precision: 0.9306 - Recall: 0.5494 - Specificity: 0.9992 - F1: 0.6741 - Loss: 0.0023\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 02:38:22\n",
      "Accuracy: 0.9899 - Precision: 0.9306 - Recall: 0.5507 - Specificity: 0.9992 - F1: 0.6752 - Loss: 0.0023\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 02:38:30\n",
      "Accuracy: 0.9899 - Precision: 0.9308 - Recall: 0.5508 - Specificity: 0.9992 - F1: 0.6754 - Loss: 0.0023\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 02:38:38\n",
      "Accuracy: 0.9899 - Precision: 0.9309 - Recall: 0.5515 - Specificity: 0.9992 - F1: 0.6761 - Loss: 0.0023\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 02:38:46\n",
      "Accuracy: 0.9899 - Precision: 0.9313 - Recall: 0.5520 - Specificity: 0.9992 - F1: 0.6767 - Loss: 0.0023\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 02:38:54\n",
      "Accuracy: 0.9899 - Precision: 0.9313 - Recall: 0.5529 - Specificity: 0.9992 - F1: 0.6775 - Loss: 0.0023\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 02:39:02\n",
      "Accuracy: 0.9899 - Precision: 0.9316 - Recall: 0.5536 - Specificity: 0.9992 - F1: 0.6782 - Loss: 0.0023\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 02:39:10\n",
      "Accuracy: 0.9899 - Precision: 0.9317 - Recall: 0.5544 - Specificity: 0.9992 - F1: 0.6790 - Loss: 0.0023\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 02:39:18\n",
      "Accuracy: 0.9900 - Precision: 0.9319 - Recall: 0.5552 - Specificity: 0.9992 - F1: 0.6797 - Loss: 0.0023\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 02:39:26\n",
      "Accuracy: 0.9900 - Precision: 0.9321 - Recall: 0.5565 - Specificity: 0.9992 - F1: 0.6809 - Loss: 0.0023\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 02:39:34\n",
      "Accuracy: 0.9900 - Precision: 0.9322 - Recall: 0.5577 - Specificity: 0.9992 - F1: 0.6818 - Loss: 0.0023\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 02:39:42\n",
      "Accuracy: 0.9900 - Precision: 0.9322 - Recall: 0.5585 - Specificity: 0.9992 - F1: 0.6825 - Loss: 0.0023\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 02:39:50\n",
      "Accuracy: 0.9900 - Precision: 0.9322 - Recall: 0.5593 - Specificity: 0.9992 - F1: 0.6832 - Loss: 0.0023\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 02:39:57\n",
      "Accuracy: 0.9901 - Precision: 0.9320 - Recall: 0.5604 - Specificity: 0.9992 - F1: 0.6841 - Loss: 0.0023\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 02:40:05\n",
      "Accuracy: 0.9901 - Precision: 0.9321 - Recall: 0.5610 - Specificity: 0.9992 - F1: 0.6846 - Loss: 0.0023\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 02:40:13\n",
      "Accuracy: 0.9901 - Precision: 0.9321 - Recall: 0.5622 - Specificity: 0.9992 - F1: 0.6855 - Loss: 0.0023\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 02:40:21\n",
      "Accuracy: 0.9901 - Precision: 0.9323 - Recall: 0.5627 - Specificity: 0.9992 - F1: 0.6861 - Loss: 0.0023\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 02:40:29\n",
      "Accuracy: 0.9901 - Precision: 0.9323 - Recall: 0.5638 - Specificity: 0.9992 - F1: 0.6870 - Loss: 0.0023\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 02:40:37\n",
      "Accuracy: 0.9901 - Precision: 0.9322 - Recall: 0.5624 - Specificity: 0.9992 - F1: 0.6859 - Loss: 0.0023\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 02:40:45\n",
      "Accuracy: 0.9901 - Precision: 0.9325 - Recall: 0.5625 - Specificity: 0.9992 - F1: 0.6861 - Loss: 0.0023\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 02:40:52\n",
      "Accuracy: 0.9901 - Precision: 0.9325 - Recall: 0.5622 - Specificity: 0.9992 - F1: 0.6859 - Loss: 0.0023\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 02:41:00\n",
      "Accuracy: 0.9901 - Precision: 0.9327 - Recall: 0.5625 - Specificity: 0.9992 - F1: 0.6863 - Loss: 0.0023\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 02:41:08\n",
      "Accuracy: 0.9901 - Precision: 0.9329 - Recall: 0.5626 - Specificity: 0.9992 - F1: 0.6866 - Loss: 0.0023\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 02:41:16\n",
      "Accuracy: 0.9901 - Precision: 0.9332 - Recall: 0.5628 - Specificity: 0.9992 - F1: 0.6869 - Loss: 0.0023\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 02:41:24\n",
      "Accuracy: 0.9901 - Precision: 0.9334 - Recall: 0.5633 - Specificity: 0.9992 - F1: 0.6875 - Loss: 0.0023\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 02:41:32\n",
      "Accuracy: 0.9901 - Precision: 0.9336 - Recall: 0.5636 - Specificity: 0.9992 - F1: 0.6879 - Loss: 0.0023\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 02:41:40\n",
      "Accuracy: 0.9901 - Precision: 0.9337 - Recall: 0.5645 - Specificity: 0.9992 - F1: 0.6886 - Loss: 0.0023\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 02:41:48\n",
      "Accuracy: 0.9902 - Precision: 0.9338 - Recall: 0.5654 - Specificity: 0.9992 - F1: 0.6894 - Loss: 0.0023\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 02:41:56\n",
      "Accuracy: 0.9902 - Precision: 0.9339 - Recall: 0.5660 - Specificity: 0.9992 - F1: 0.6899 - Loss: 0.0023\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 02:42:04\n",
      "Accuracy: 0.9902 - Precision: 0.9339 - Recall: 0.5667 - Specificity: 0.9992 - F1: 0.6906 - Loss: 0.0023\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 02:42:12\n",
      "Accuracy: 0.9902 - Precision: 0.9339 - Recall: 0.5675 - Specificity: 0.9992 - F1: 0.6913 - Loss: 0.0023\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 02:42:20\n",
      "Accuracy: 0.9902 - Precision: 0.9340 - Recall: 0.5686 - Specificity: 0.9992 - F1: 0.6921 - Loss: 0.0023\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 02:42:28\n",
      "Accuracy: 0.9903 - Precision: 0.9340 - Recall: 0.5696 - Specificity: 0.9992 - F1: 0.6929 - Loss: 0.0023\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 02:42:36\n",
      "Accuracy: 0.9903 - Precision: 0.9341 - Recall: 0.5704 - Specificity: 0.9992 - F1: 0.6936 - Loss: 0.0022\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 02:42:44\n",
      "Accuracy: 0.9903 - Precision: 0.9343 - Recall: 0.5713 - Specificity: 0.9992 - F1: 0.6944 - Loss: 0.0022\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 02:42:52\n",
      "Accuracy: 0.9903 - Precision: 0.9343 - Recall: 0.5720 - Specificity: 0.9992 - F1: 0.6949 - Loss: 0.0022\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 02:43:00\n",
      "Accuracy: 0.9903 - Precision: 0.9345 - Recall: 0.5724 - Specificity: 0.9992 - F1: 0.6954 - Loss: 0.0022\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 02:43:08\n",
      "Accuracy: 0.9903 - Precision: 0.9347 - Recall: 0.5727 - Specificity: 0.9992 - F1: 0.6958 - Loss: 0.0022\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 02:43:16\n",
      "Accuracy: 0.9904 - Precision: 0.9349 - Recall: 0.5733 - Specificity: 0.9992 - F1: 0.6964 - Loss: 0.0022\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 02:43:24\n",
      "Accuracy: 0.9904 - Precision: 0.9352 - Recall: 0.5736 - Specificity: 0.9992 - F1: 0.6968 - Loss: 0.0022\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 02:43:31\n",
      "Accuracy: 0.9904 - Precision: 0.9355 - Recall: 0.5735 - Specificity: 0.9992 - F1: 0.6968 - Loss: 0.0022\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 02:43:40\n",
      "Accuracy: 0.9904 - Precision: 0.9357 - Recall: 0.5738 - Specificity: 0.9992 - F1: 0.6973 - Loss: 0.0022\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 02:43:48\n",
      "Accuracy: 0.9904 - Precision: 0.9358 - Recall: 0.5743 - Specificity: 0.9992 - F1: 0.6977 - Loss: 0.0022\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 02:43:55\n",
      "Accuracy: 0.9904 - Precision: 0.9359 - Recall: 0.5750 - Specificity: 0.9992 - F1: 0.6983 - Loss: 0.0022\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 02:44:03\n",
      "Accuracy: 0.9904 - Precision: 0.9358 - Recall: 0.5757 - Specificity: 0.9992 - F1: 0.6989 - Loss: 0.0022\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 02:44:11\n",
      "Accuracy: 0.9904 - Precision: 0.9358 - Recall: 0.5767 - Specificity: 0.9992 - F1: 0.6997 - Loss: 0.0022\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 02:44:19\n",
      "Accuracy: 0.9905 - Precision: 0.9358 - Recall: 0.5777 - Specificity: 0.9992 - F1: 0.7004 - Loss: 0.0022\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 02:44:27\n",
      "Accuracy: 0.9905 - Precision: 0.9359 - Recall: 0.5785 - Specificity: 0.9992 - F1: 0.7011 - Loss: 0.0022\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 02:44:35\n",
      "Accuracy: 0.9905 - Precision: 0.9354 - Recall: 0.5789 - Specificity: 0.9992 - F1: 0.7013 - Loss: 0.0022\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 02:44:43\n",
      "Accuracy: 0.9905 - Precision: 0.9356 - Recall: 0.5793 - Specificity: 0.9992 - F1: 0.7017 - Loss: 0.0022\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 02:44:51\n",
      "Accuracy: 0.9905 - Precision: 0.9357 - Recall: 0.5793 - Specificity: 0.9992 - F1: 0.7019 - Loss: 0.0022\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 02:44:59\n",
      "Accuracy: 0.9905 - Precision: 0.9360 - Recall: 0.5793 - Specificity: 0.9992 - F1: 0.7020 - Loss: 0.0022\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 02:45:07\n",
      "Accuracy: 0.9905 - Precision: 0.9362 - Recall: 0.5789 - Specificity: 0.9992 - F1: 0.7018 - Loss: 0.0022\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 02:45:15\n",
      "Accuracy: 0.9905 - Precision: 0.9365 - Recall: 0.5783 - Specificity: 0.9992 - F1: 0.7014 - Loss: 0.0022\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 02:45:23\n",
      "Accuracy: 0.9905 - Precision: 0.9367 - Recall: 0.5783 - Specificity: 0.9992 - F1: 0.7015 - Loss: 0.0022\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 02:45:31\n",
      "Accuracy: 0.9905 - Precision: 0.9369 - Recall: 0.5783 - Specificity: 0.9992 - F1: 0.7017 - Loss: 0.0022\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 02:45:39\n",
      "Accuracy: 0.9905 - Precision: 0.9370 - Recall: 0.5783 - Specificity: 0.9992 - F1: 0.7017 - Loss: 0.0022\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 02:45:47\n",
      "Accuracy: 0.9905 - Precision: 0.9370 - Recall: 0.5787 - Specificity: 0.9992 - F1: 0.7021 - Loss: 0.0022\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 02:45:55\n",
      "Accuracy: 0.9905 - Precision: 0.9372 - Recall: 0.5793 - Specificity: 0.9992 - F1: 0.7027 - Loss: 0.0022\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 02:46:03\n",
      "Accuracy: 0.9905 - Precision: 0.9372 - Recall: 0.5800 - Specificity: 0.9992 - F1: 0.7033 - Loss: 0.0022\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 02:46:11\n",
      "Accuracy: 0.9906 - Precision: 0.9373 - Recall: 0.5808 - Specificity: 0.9992 - F1: 0.7039 - Loss: 0.0022\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 02:46:19\n",
      "Accuracy: 0.9906 - Precision: 0.9373 - Recall: 0.5815 - Specificity: 0.9992 - F1: 0.7045 - Loss: 0.0022\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 02:46:27\n",
      "Accuracy: 0.9906 - Precision: 0.9368 - Recall: 0.5823 - Specificity: 0.9992 - F1: 0.7049 - Loss: 0.0022\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 02:46:35\n",
      "Accuracy: 0.9906 - Precision: 0.9369 - Recall: 0.5830 - Specificity: 0.9992 - F1: 0.7055 - Loss: 0.0022\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 02:46:43\n",
      "Accuracy: 0.9906 - Precision: 0.9371 - Recall: 0.5832 - Specificity: 0.9992 - F1: 0.7058 - Loss: 0.0022\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 02:46:51\n",
      "Accuracy: 0.9906 - Precision: 0.9372 - Recall: 0.5839 - Specificity: 0.9992 - F1: 0.7063 - Loss: 0.0022\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 02:46:58\n",
      "Accuracy: 0.9906 - Precision: 0.9374 - Recall: 0.5844 - Specificity: 0.9992 - F1: 0.7068 - Loss: 0.0022\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 02:47:07\n",
      "Accuracy: 0.9906 - Precision: 0.9376 - Recall: 0.5845 - Specificity: 0.9992 - F1: 0.7071 - Loss: 0.0022\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 02:47:14\n",
      "Accuracy: 0.9906 - Precision: 0.9378 - Recall: 0.5847 - Specificity: 0.9992 - F1: 0.7073 - Loss: 0.0022\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 02:47:22\n",
      "Accuracy: 0.9907 - Precision: 0.9379 - Recall: 0.5850 - Specificity: 0.9992 - F1: 0.7076 - Loss: 0.0022\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 02:47:30\n",
      "Accuracy: 0.9907 - Precision: 0.9380 - Recall: 0.5850 - Specificity: 0.9992 - F1: 0.7077 - Loss: 0.0022\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 02:47:38\n",
      "Accuracy: 0.9907 - Precision: 0.9382 - Recall: 0.5855 - Specificity: 0.9992 - F1: 0.7083 - Loss: 0.0022\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 02:47:46\n",
      "Accuracy: 0.9907 - Precision: 0.9383 - Recall: 0.5861 - Specificity: 0.9992 - F1: 0.7088 - Loss: 0.0022\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 02:47:54\n",
      "Accuracy: 0.9907 - Precision: 0.9381 - Recall: 0.5870 - Specificity: 0.9992 - F1: 0.7093 - Loss: 0.0022\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 02:48:02\n",
      "Accuracy: 0.9907 - Precision: 0.9380 - Recall: 0.5880 - Specificity: 0.9992 - F1: 0.7100 - Loss: 0.0022\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 02:48:10\n",
      "Accuracy: 0.9908 - Precision: 0.9378 - Recall: 0.5890 - Specificity: 0.9992 - F1: 0.7107 - Loss: 0.0022\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 02:48:18\n",
      "Accuracy: 0.9908 - Precision: 0.9374 - Recall: 0.5900 - Specificity: 0.9992 - F1: 0.7112 - Loss: 0.0022\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 02:48:26\n",
      "Accuracy: 0.9908 - Precision: 0.9372 - Recall: 0.5908 - Specificity: 0.9992 - F1: 0.7117 - Loss: 0.0021\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 02:48:34\n",
      "Accuracy: 0.9908 - Precision: 0.9373 - Recall: 0.5914 - Specificity: 0.9992 - F1: 0.7123 - Loss: 0.0021\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 02:48:42\n",
      "Accuracy: 0.9908 - Precision: 0.9375 - Recall: 0.5917 - Specificity: 0.9992 - F1: 0.7126 - Loss: 0.0021\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 02:48:50\n",
      "Accuracy: 0.9908 - Precision: 0.9377 - Recall: 0.5920 - Specificity: 0.9992 - F1: 0.7129 - Loss: 0.0021\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 02:48:58\n",
      "Accuracy: 0.9908 - Precision: 0.9379 - Recall: 0.5920 - Specificity: 0.9992 - F1: 0.7131 - Loss: 0.0021\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 02:49:05\n",
      "Accuracy: 0.9908 - Precision: 0.9380 - Recall: 0.5915 - Specificity: 0.9992 - F1: 0.7128 - Loss: 0.0021\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 02:49:13\n",
      "Accuracy: 0.9908 - Precision: 0.9382 - Recall: 0.5903 - Specificity: 0.9992 - F1: 0.7117 - Loss: 0.0021\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 02:49:21\n",
      "Accuracy: 0.9908 - Precision: 0.9381 - Recall: 0.5895 - Specificity: 0.9992 - F1: 0.7111 - Loss: 0.0022\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 02:49:29\n",
      "Accuracy: 0.9907 - Precision: 0.9380 - Recall: 0.5887 - Specificity: 0.9992 - F1: 0.7105 - Loss: 0.0022\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 02:49:37\n",
      "Accuracy: 0.9907 - Precision: 0.9381 - Recall: 0.5883 - Specificity: 0.9992 - F1: 0.7102 - Loss: 0.0022\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 02:49:46\n",
      "Accuracy: 0.9907 - Precision: 0.9381 - Recall: 0.5882 - Specificity: 0.9992 - F1: 0.7102 - Loss: 0.0022\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 02:49:54\n",
      "Accuracy: 0.9907 - Precision: 0.9380 - Recall: 0.5878 - Specificity: 0.9992 - F1: 0.7099 - Loss: 0.0022\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 02:50:02\n",
      "Accuracy: 0.9906 - Precision: 0.9380 - Recall: 0.5874 - Specificity: 0.9992 - F1: 0.7096 - Loss: 0.0022\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 02:50:10\n",
      "Accuracy: 0.9906 - Precision: 0.9379 - Recall: 0.5877 - Specificity: 0.9992 - F1: 0.7099 - Loss: 0.0022\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 02:50:18\n",
      "Accuracy: 0.9906 - Precision: 0.9377 - Recall: 0.5877 - Specificity: 0.9992 - F1: 0.7099 - Loss: 0.0022\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 02:50:26\n",
      "Accuracy: 0.9906 - Precision: 0.9371 - Recall: 0.5880 - Specificity: 0.9992 - F1: 0.7099 - Loss: 0.0022\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 02:50:34\n",
      "Accuracy: 0.9906 - Precision: 0.9369 - Recall: 0.5884 - Specificity: 0.9992 - F1: 0.7102 - Loss: 0.0022\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 02:50:42\n",
      "Accuracy: 0.9906 - Precision: 0.9367 - Recall: 0.5882 - Specificity: 0.9992 - F1: 0.7100 - Loss: 0.0022\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 02:50:50\n",
      "Accuracy: 0.9906 - Precision: 0.9367 - Recall: 0.5877 - Specificity: 0.9992 - F1: 0.7097 - Loss: 0.0022\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 02:50:58\n",
      "Accuracy: 0.9906 - Precision: 0.9368 - Recall: 0.5870 - Specificity: 0.9992 - F1: 0.7092 - Loss: 0.0022\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 02:51:06\n",
      "Accuracy: 0.9906 - Precision: 0.9370 - Recall: 0.5865 - Specificity: 0.9992 - F1: 0.7089 - Loss: 0.0022\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 02:51:14\n",
      "Accuracy: 0.9906 - Precision: 0.9372 - Recall: 0.5853 - Specificity: 0.9992 - F1: 0.7079 - Loss: 0.0022\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 02:51:22\n",
      "Accuracy: 0.9905 - Precision: 0.9373 - Recall: 0.5844 - Specificity: 0.9992 - F1: 0.7072 - Loss: 0.0022\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 02:51:29\n",
      "Accuracy: 0.9905 - Precision: 0.9375 - Recall: 0.5836 - Specificity: 0.9992 - F1: 0.7066 - Loss: 0.0022\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 02:51:37\n",
      "Accuracy: 0.9905 - Precision: 0.9375 - Recall: 0.5827 - Specificity: 0.9992 - F1: 0.7058 - Loss: 0.0022\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 02:51:45\n",
      "Accuracy: 0.9904 - Precision: 0.9375 - Recall: 0.5818 - Specificity: 0.9992 - F1: 0.7051 - Loss: 0.0022\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 02:51:53\n",
      "Accuracy: 0.9904 - Precision: 0.9374 - Recall: 0.5813 - Specificity: 0.9992 - F1: 0.7047 - Loss: 0.0022\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 02:52:01\n",
      "Accuracy: 0.9903 - Precision: 0.9373 - Recall: 0.5806 - Specificity: 0.9992 - F1: 0.7041 - Loss: 0.0022\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 02:52:09\n",
      "Accuracy: 0.9903 - Precision: 0.9372 - Recall: 0.5802 - Specificity: 0.9992 - F1: 0.7038 - Loss: 0.0023\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 02:52:17\n",
      "Accuracy: 0.9903 - Precision: 0.9372 - Recall: 0.5801 - Specificity: 0.9992 - F1: 0.7038 - Loss: 0.0023\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 02:52:25\n",
      "Accuracy: 0.9903 - Precision: 0.9369 - Recall: 0.5795 - Specificity: 0.9992 - F1: 0.7033 - Loss: 0.0023\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 02:52:33\n",
      "Accuracy: 0.9902 - Precision: 0.9368 - Recall: 0.5794 - Specificity: 0.9992 - F1: 0.7033 - Loss: 0.0023\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 02:52:41\n",
      "Accuracy: 0.9899 - Precision: 0.9368 - Recall: 0.5777 - Specificity: 0.9992 - F1: 0.7015 - Loss: 0.0024\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 02:52:49\n",
      "Accuracy: 0.9898 - Precision: 0.9368 - Recall: 0.5763 - Specificity: 0.9992 - F1: 0.7002 - Loss: 0.0024\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 02:52:57\n",
      "Accuracy: 0.9896 - Precision: 0.9369 - Recall: 0.5754 - Specificity: 0.9992 - F1: 0.6994 - Loss: 0.0024\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 02:53:05\n",
      "Accuracy: 0.9894 - Precision: 0.9369 - Recall: 0.5747 - Specificity: 0.9992 - F1: 0.6989 - Loss: 0.0025\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 02:53:13\n",
      "Accuracy: 0.9892 - Precision: 0.9367 - Recall: 0.5744 - Specificity: 0.9991 - F1: 0.6987 - Loss: 0.0025\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 02:53:21\n",
      "Accuracy: 0.9891 - Precision: 0.9359 - Recall: 0.5747 - Specificity: 0.9991 - F1: 0.6987 - Loss: 0.0026\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 02:53:29\n",
      "Accuracy: 0.9889 - Precision: 0.9354 - Recall: 0.5745 - Specificity: 0.9990 - F1: 0.6984 - Loss: 0.0026\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 02:53:37\n",
      "Accuracy: 0.9888 - Precision: 0.9343 - Recall: 0.5732 - Specificity: 0.9990 - F1: 0.6970 - Loss: 0.0027\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 02:53:45\n",
      "Accuracy: 0.9884 - Precision: 0.9344 - Recall: 0.5714 - Specificity: 0.9990 - F1: 0.6951 - Loss: 0.0027\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 02:53:53\n",
      "Accuracy: 0.9881 - Precision: 0.9344 - Recall: 0.5695 - Specificity: 0.9990 - F1: 0.6930 - Loss: 0.0028\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 02:54:01\n",
      "Accuracy: 0.9879 - Precision: 0.9346 - Recall: 0.5677 - Specificity: 0.9990 - F1: 0.6911 - Loss: 0.0028\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 02:54:09\n",
      "Accuracy: 0.9878 - Precision: 0.9343 - Recall: 0.5657 - Specificity: 0.9990 - F1: 0.6889 - Loss: 0.0028\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 02:54:17\n",
      "Accuracy: 0.9875 - Precision: 0.9342 - Recall: 0.5637 - Specificity: 0.9990 - F1: 0.6866 - Loss: 0.0029\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 02:54:25\n",
      "Accuracy: 0.9873 - Precision: 0.9339 - Recall: 0.5617 - Specificity: 0.9990 - F1: 0.6843 - Loss: 0.0029\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 02:54:34\n",
      "Accuracy: 0.9870 - Precision: 0.9338 - Recall: 0.5597 - Specificity: 0.9990 - F1: 0.6820 - Loss: 0.0030\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 02:54:43\n",
      "Accuracy: 0.9867 - Precision: 0.9337 - Recall: 0.5576 - Specificity: 0.9990 - F1: 0.6796 - Loss: 0.0030\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 02:54:51\n",
      "Accuracy: 0.9864 - Precision: 0.9337 - Recall: 0.5557 - Specificity: 0.9990 - F1: 0.6774 - Loss: 0.0030\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 02:54:59\n",
      "Accuracy: 0.9863 - Precision: 0.9326 - Recall: 0.5538 - Specificity: 0.9990 - F1: 0.6753 - Loss: 0.0031\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 02:55:07\n",
      "Accuracy: 0.9862 - Precision: 0.9306 - Recall: 0.5519 - Specificity: 0.9990 - F1: 0.6730 - Loss: 0.0031\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 02:55:15\n",
      "Accuracy: 0.9861 - Precision: 0.9290 - Recall: 0.5499 - Specificity: 0.9990 - F1: 0.6707 - Loss: 0.0032\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 02:55:23\n",
      "Accuracy: 0.9861 - Precision: 0.9279 - Recall: 0.5481 - Specificity: 0.9990 - F1: 0.6687 - Loss: 0.0032\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 02:55:31\n",
      "Accuracy: 0.9861 - Precision: 0.9277 - Recall: 0.5462 - Specificity: 0.9990 - F1: 0.6665 - Loss: 0.0032\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 02:55:39\n",
      "Accuracy: 0.9859 - Precision: 0.9280 - Recall: 0.5443 - Specificity: 0.9990 - F1: 0.6643 - Loss: 0.0032\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 02:55:47\n",
      "Accuracy: 0.9858 - Precision: 0.9280 - Recall: 0.5423 - Specificity: 0.9990 - F1: 0.6619 - Loss: 0.0033\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 02:55:55\n",
      "Accuracy: 0.9858 - Precision: 0.9281 - Recall: 0.5404 - Specificity: 0.9990 - F1: 0.6596 - Loss: 0.0033\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 02:56:03\n",
      "Accuracy: 0.9857 - Precision: 0.9277 - Recall: 0.5384 - Specificity: 0.9990 - F1: 0.6573 - Loss: 0.0033\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 02:56:11\n",
      "Accuracy: 0.9857 - Precision: 0.9280 - Recall: 0.5365 - Specificity: 0.9990 - F1: 0.6551 - Loss: 0.0033\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 02:56:19\n",
      "Accuracy: 0.9857 - Precision: 0.9282 - Recall: 0.5347 - Specificity: 0.9990 - F1: 0.6529 - Loss: 0.0034\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 02:56:27\n",
      "Accuracy: 0.9856 - Precision: 0.9285 - Recall: 0.5328 - Specificity: 0.9990 - F1: 0.6507 - Loss: 0.0034\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 02:56:35\n",
      "Accuracy: 0.9856 - Precision: 0.9270 - Recall: 0.5309 - Specificity: 0.9990 - F1: 0.6486 - Loss: 0.0034\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 02:56:43\n",
      "Accuracy: 0.9855 - Precision: 0.9272 - Recall: 0.5291 - Specificity: 0.9990 - F1: 0.6465 - Loss: 0.0034\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 02:56:51\n",
      "Accuracy: 0.9855 - Precision: 0.9273 - Recall: 0.5273 - Specificity: 0.9990 - F1: 0.6443 - Loss: 0.0034\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 02:56:59\n",
      "Accuracy: 0.9854 - Precision: 0.9271 - Recall: 0.5256 - Specificity: 0.9990 - F1: 0.6423 - Loss: 0.0034\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 02:57:07\n",
      "Accuracy: 0.9854 - Precision: 0.9269 - Recall: 0.5238 - Specificity: 0.9990 - F1: 0.6402 - Loss: 0.0034\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 02:57:15\n",
      "Accuracy: 0.9854 - Precision: 0.9266 - Recall: 0.5221 - Specificity: 0.9990 - F1: 0.6383 - Loss: 0.0034\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 02:57:23\n",
      "Accuracy: 0.9853 - Precision: 0.9248 - Recall: 0.5203 - Specificity: 0.9990 - F1: 0.6361 - Loss: 0.0034\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 02:57:31\n",
      "Accuracy: 0.9853 - Precision: 0.9250 - Recall: 0.5185 - Specificity: 0.9991 - F1: 0.6340 - Loss: 0.0035\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 02:57:39\n",
      "Accuracy: 0.9853 - Precision: 0.9223 - Recall: 0.5166 - Specificity: 0.9991 - F1: 0.6317 - Loss: 0.0035\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 02:57:47\n",
      "Accuracy: 0.9852 - Precision: 0.9221 - Recall: 0.5148 - Specificity: 0.9991 - F1: 0.6295 - Loss: 0.0035\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 02:57:55\n",
      "Accuracy: 0.9852 - Precision: 0.9223 - Recall: 0.5131 - Specificity: 0.9991 - F1: 0.6275 - Loss: 0.0035\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 02:58:03\n",
      "Accuracy: 0.9852 - Precision: 0.9211 - Recall: 0.5114 - Specificity: 0.9991 - F1: 0.6256 - Loss: 0.0035\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 02:58:10\n",
      "Accuracy: 0.9852 - Precision: 0.9186 - Recall: 0.5096 - Specificity: 0.9991 - F1: 0.6234 - Loss: 0.0035\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 02:58:18\n",
      "Accuracy: 0.9851 - Precision: 0.9179 - Recall: 0.5079 - Specificity: 0.9991 - F1: 0.6213 - Loss: 0.0035\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 02:58:26\n",
      "Accuracy: 0.9851 - Precision: 0.9155 - Recall: 0.5061 - Specificity: 0.9991 - F1: 0.6191 - Loss: 0.0035\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 02:58:34\n",
      "Accuracy: 0.9851 - Precision: 0.9153 - Recall: 0.5043 - Specificity: 0.9991 - F1: 0.6170 - Loss: 0.0035\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 02:58:42\n",
      "Accuracy: 0.9851 - Precision: 0.9147 - Recall: 0.5026 - Specificity: 0.9991 - F1: 0.6150 - Loss: 0.0035\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 02:58:50\n",
      "Accuracy: 0.9851 - Precision: 0.9148 - Recall: 0.5010 - Specificity: 0.9991 - F1: 0.6131 - Loss: 0.0035\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 02:58:58\n",
      "Accuracy: 0.9850 - Precision: 0.9150 - Recall: 0.4994 - Specificity: 0.9991 - F1: 0.6112 - Loss: 0.0035\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 02:59:05\n",
      "Accuracy: 0.9850 - Precision: 0.9151 - Recall: 0.4977 - Specificity: 0.9991 - F1: 0.6092 - Loss: 0.0035\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 02:59:13\n",
      "Accuracy: 0.9849 - Precision: 0.9153 - Recall: 0.4961 - Specificity: 0.9991 - F1: 0.6072 - Loss: 0.0035\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 02:59:22\n",
      "Accuracy: 0.9849 - Precision: 0.9149 - Recall: 0.4945 - Specificity: 0.9991 - F1: 0.6054 - Loss: 0.0035\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 02:59:30\n",
      "Accuracy: 0.9849 - Precision: 0.9147 - Recall: 0.4929 - Specificity: 0.9991 - F1: 0.6036 - Loss: 0.0035\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 02:59:38\n",
      "Accuracy: 0.9848 - Precision: 0.9142 - Recall: 0.4915 - Specificity: 0.9991 - F1: 0.6019 - Loss: 0.0036\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 02:59:46\n",
      "Accuracy: 0.9848 - Precision: 0.9141 - Recall: 0.4901 - Specificity: 0.9991 - F1: 0.6004 - Loss: 0.0036\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 02:59:54\n",
      "Accuracy: 0.9848 - Precision: 0.9144 - Recall: 0.4886 - Specificity: 0.9991 - F1: 0.5987 - Loss: 0.0036\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 03:00:02\n",
      "Accuracy: 0.9847 - Precision: 0.9142 - Recall: 0.4871 - Specificity: 0.9991 - F1: 0.5969 - Loss: 0.0036\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 03:00:09\n",
      "Accuracy: 0.9847 - Precision: 0.9143 - Recall: 0.4857 - Specificity: 0.9991 - F1: 0.5954 - Loss: 0.0036\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 03:00:17\n",
      "Accuracy: 0.9847 - Precision: 0.9145 - Recall: 0.4844 - Specificity: 0.9991 - F1: 0.5940 - Loss: 0.0036\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 03:00:25\n",
      "Accuracy: 0.9846 - Precision: 0.9146 - Recall: 0.4829 - Specificity: 0.9991 - F1: 0.5923 - Loss: 0.0036\n",
      "\n",
      "Epoch 19/20\n",
      "Validation - Accuracy: 0.9802, Precision: 0.9078, Recall: 0.0884, Specificity: 0.9998, F1: 0.1605, Loss: 0.0045\n",
      "\n",
      "\n",
      "Epoch 20/20\n",
      "Batch 1/298 ━━━━━━━━━━━━━━━━━━━━ 03:07:44\n",
      "Accuracy: 0.9760 - Precision: 0.9651 - Recall: 0.0884 - Specificity: 0.9999 - F1: 0.1619 - Loss: 0.0049\n",
      "\n",
      "Batch 2/298 ━━━━━━━━━━━━━━━━━━━━ 03:07:52\n",
      "Accuracy: 0.9745 - Precision: 0.9575 - Recall: 0.0870 - Specificity: 0.9999 - F1: 0.1594 - Loss: 0.0052\n",
      "\n",
      "Batch 3/298 ━━━━━━━━━━━━━━━━━━━━ 03:08:00\n",
      "Accuracy: 0.9742 - Precision: 0.9641 - Recall: 0.1114 - Specificity: 0.9999 - F1: 0.1981 - Loss: 0.0049\n",
      "\n",
      "Batch 4/298 ━━━━━━━━━━━━━━━━━━━━ 03:08:08\n",
      "Accuracy: 0.9771 - Precision: 0.9662 - Recall: 0.1186 - Specificity: 0.9999 - F1: 0.2098 - Loss: 0.0043\n",
      "\n",
      "Batch 5/298 ━━━━━━━━━━━━━━━━━━━━ 03:08:16\n",
      "Accuracy: 0.9788 - Precision: 0.9535 - Recall: 0.1160 - Specificity: 0.9999 - F1: 0.2057 - Loss: 0.0041\n",
      "\n",
      "Batch 6/298 ━━━━━━━━━━━━━━━━━━━━ 03:08:24\n",
      "Accuracy: 0.9789 - Precision: 0.9605 - Recall: 0.1194 - Specificity: 0.9999 - F1: 0.2113 - Loss: 0.0039\n",
      "\n",
      "Batch 7/298 ━━━━━━━━━━━━━━━━━━━━ 03:08:32\n",
      "Accuracy: 0.9802 - Precision: 0.9654 - Recall: 0.1243 - Specificity: 0.9999 - F1: 0.2193 - Loss: 0.0037\n",
      "\n",
      "Batch 8/298 ━━━━━━━━━━━━━━━━━━━━ 03:08:40\n",
      "Accuracy: 0.9807 - Precision: 0.9403 - Recall: 0.1308 - Specificity: 0.9998 - F1: 0.2276 - Loss: 0.0035\n",
      "\n",
      "Batch 9/298 ━━━━━━━━━━━━━━━━━━━━ 03:08:48\n",
      "Accuracy: 0.9815 - Precision: 0.9457 - Recall: 0.1395 - Specificity: 0.9998 - F1: 0.2407 - Loss: 0.0034\n",
      "\n",
      "Batch 10/298 ━━━━━━━━━━━━━━━━━━━━ 03:08:56\n",
      "Accuracy: 0.9819 - Precision: 0.9470 - Recall: 0.1439 - Specificity: 0.9998 - F1: 0.2474 - Loss: 0.0033\n",
      "\n",
      "Batch 11/298 ━━━━━━━━━━━━━━━━━━━━ 03:09:04\n",
      "Accuracy: 0.9822 - Precision: 0.9361 - Recall: 0.1505 - Specificity: 0.9998 - F1: 0.2561 - Loss: 0.0033\n",
      "\n",
      "Batch 12/298 ━━━━━━━━━━━━━━━━━━━━ 03:09:12\n",
      "Accuracy: 0.9825 - Precision: 0.9408 - Recall: 0.1551 - Specificity: 0.9998 - F1: 0.2632 - Loss: 0.0032\n",
      "\n",
      "Batch 13/298 ━━━━━━━━━━━━━━━━━━━━ 03:09:20\n",
      "Accuracy: 0.9828 - Precision: 0.9417 - Recall: 0.1624 - Specificity: 0.9998 - F1: 0.2734 - Loss: 0.0031\n",
      "\n",
      "Batch 14/298 ━━━━━━━━━━━━━━━━━━━━ 03:09:28\n",
      "Accuracy: 0.9829 - Precision: 0.9264 - Recall: 0.1651 - Specificity: 0.9997 - F1: 0.2763 - Loss: 0.0031\n",
      "\n",
      "Batch 15/298 ━━━━━━━━━━━━━━━━━━━━ 03:09:36\n",
      "Accuracy: 0.9832 - Precision: 0.9303 - Recall: 0.1717 - Specificity: 0.9997 - F1: 0.2857 - Loss: 0.0031\n",
      "\n",
      "Batch 16/298 ━━━━━━━━━━━━━━━━━━━━ 03:09:44\n",
      "Accuracy: 0.9829 - Precision: 0.9326 - Recall: 0.1756 - Specificity: 0.9997 - F1: 0.2913 - Loss: 0.0031\n",
      "\n",
      "Batch 17/298 ━━━━━━━━━━━━━━━━━━━━ 03:09:52\n",
      "Accuracy: 0.9833 - Precision: 0.9345 - Recall: 0.1876 - Specificity: 0.9997 - F1: 0.3063 - Loss: 0.0031\n",
      "\n",
      "Batch 18/298 ━━━━━━━━━━━━━━━━━━━━ 03:10:00\n",
      "Accuracy: 0.9835 - Precision: 0.9370 - Recall: 0.1972 - Specificity: 0.9997 - F1: 0.3185 - Loss: 0.0030\n",
      "\n",
      "Batch 19/298 ━━━━━━━━━━━━━━━━━━━━ 03:10:07\n",
      "Accuracy: 0.9837 - Precision: 0.9370 - Recall: 0.2074 - Specificity: 0.9997 - F1: 0.3308 - Loss: 0.0030\n",
      "\n",
      "Batch 20/298 ━━━━━━━━━━━━━━━━━━━━ 03:10:15\n",
      "Accuracy: 0.9840 - Precision: 0.9346 - Recall: 0.2200 - Specificity: 0.9997 - F1: 0.3446 - Loss: 0.0030\n",
      "\n",
      "Batch 21/298 ━━━━━━━━━━━━━━━━━━━━ 03:10:23\n",
      "Accuracy: 0.9841 - Precision: 0.9318 - Recall: 0.2268 - Specificity: 0.9996 - F1: 0.3525 - Loss: 0.0030\n",
      "\n",
      "Batch 22/298 ━━━━━━━━━━━━━━━━━━━━ 03:10:31\n",
      "Accuracy: 0.9839 - Precision: 0.9214 - Recall: 0.2269 - Specificity: 0.9996 - F1: 0.3523 - Loss: 0.0030\n",
      "\n",
      "Batch 23/298 ━━━━━━━━━━━━━━━━━━━━ 03:10:39\n",
      "Accuracy: 0.9840 - Precision: 0.9244 - Recall: 0.2319 - Specificity: 0.9996 - F1: 0.3590 - Loss: 0.0030\n",
      "\n",
      "Batch 24/298 ━━━━━━━━━━━━━━━━━━━━ 03:10:47\n",
      "Accuracy: 0.9840 - Precision: 0.9266 - Recall: 0.2376 - Specificity: 0.9996 - F1: 0.3664 - Loss: 0.0030\n",
      "\n",
      "Batch 25/298 ━━━━━━━━━━━━━━━━━━━━ 03:10:55\n",
      "Accuracy: 0.9841 - Precision: 0.9291 - Recall: 0.2452 - Specificity: 0.9996 - F1: 0.3756 - Loss: 0.0030\n",
      "\n",
      "Batch 26/298 ━━━━━━━━━━━━━━━━━━━━ 03:11:03\n",
      "Accuracy: 0.9844 - Precision: 0.9304 - Recall: 0.2535 - Specificity: 0.9996 - F1: 0.3852 - Loss: 0.0029\n",
      "\n",
      "Batch 27/298 ━━━━━━━━━━━━━━━━━━━━ 03:11:11\n",
      "Accuracy: 0.9845 - Precision: 0.9324 - Recall: 0.2573 - Specificity: 0.9996 - F1: 0.3902 - Loss: 0.0029\n",
      "\n",
      "Batch 28/298 ━━━━━━━━━━━━━━━━━━━━ 03:11:19\n",
      "Accuracy: 0.9845 - Precision: 0.9343 - Recall: 0.2586 - Specificity: 0.9996 - F1: 0.3925 - Loss: 0.0029\n",
      "\n",
      "Batch 29/298 ━━━━━━━━━━━━━━━━━━━━ 03:11:27\n",
      "Accuracy: 0.9843 - Precision: 0.9333 - Recall: 0.2609 - Specificity: 0.9996 - F1: 0.3955 - Loss: 0.0030\n",
      "\n",
      "Batch 30/298 ━━━━━━━━━━━━━━━━━━━━ 03:11:35\n",
      "Accuracy: 0.9845 - Precision: 0.9344 - Recall: 0.2695 - Specificity: 0.9996 - F1: 0.4048 - Loss: 0.0030\n",
      "\n",
      "Batch 31/298 ━━━━━━━━━━━━━━━━━━━━ 03:11:42\n",
      "Accuracy: 0.9847 - Precision: 0.9343 - Recall: 0.2790 - Specificity: 0.9996 - F1: 0.4144 - Loss: 0.0029\n",
      "\n",
      "Batch 32/298 ━━━━━━━━━━━━━━━━━━━━ 03:11:50\n",
      "Accuracy: 0.9848 - Precision: 0.9333 - Recall: 0.2841 - Specificity: 0.9996 - F1: 0.4200 - Loss: 0.0029\n",
      "\n",
      "Batch 33/298 ━━━━━━━━━━━━━━━━━━━━ 03:11:58\n",
      "Accuracy: 0.9850 - Precision: 0.9338 - Recall: 0.2923 - Specificity: 0.9996 - F1: 0.4285 - Loss: 0.0029\n",
      "\n",
      "Batch 34/298 ━━━━━━━━━━━━━━━━━━━━ 03:12:06\n",
      "Accuracy: 0.9850 - Precision: 0.9350 - Recall: 0.2977 - Specificity: 0.9996 - F1: 0.4347 - Loss: 0.0029\n",
      "\n",
      "Batch 35/298 ━━━━━━━━━━━━━━━━━━━━ 03:12:14\n",
      "Accuracy: 0.9851 - Precision: 0.9359 - Recall: 0.3020 - Specificity: 0.9996 - F1: 0.4398 - Loss: 0.0029\n",
      "\n",
      "Batch 36/298 ━━━━━━━━━━━━━━━━━━━━ 03:12:22\n",
      "Accuracy: 0.9852 - Precision: 0.9364 - Recall: 0.3088 - Specificity: 0.9996 - F1: 0.4468 - Loss: 0.0029\n",
      "\n",
      "Batch 37/298 ━━━━━━━━━━━━━━━━━━━━ 03:12:30\n",
      "Accuracy: 0.9854 - Precision: 0.9371 - Recall: 0.3164 - Specificity: 0.9996 - F1: 0.4546 - Loss: 0.0028\n",
      "\n",
      "Batch 38/298 ━━━━━━━━━━━━━━━━━━━━ 03:12:38\n",
      "Accuracy: 0.9854 - Precision: 0.9372 - Recall: 0.3220 - Specificity: 0.9996 - F1: 0.4604 - Loss: 0.0028\n",
      "\n",
      "Batch 39/298 ━━━━━━━━━━━━━━━━━━━━ 03:12:46\n",
      "Accuracy: 0.9855 - Precision: 0.9379 - Recall: 0.3276 - Specificity: 0.9996 - F1: 0.4664 - Loss: 0.0028\n",
      "\n",
      "Batch 40/298 ━━━━━━━━━━━━━━━━━━━━ 03:12:54\n",
      "Accuracy: 0.9857 - Precision: 0.9381 - Recall: 0.3343 - Specificity: 0.9995 - F1: 0.4730 - Loss: 0.0028\n",
      "\n",
      "Batch 41/298 ━━━━━━━━━━━━━━━━━━━━ 03:13:02\n",
      "Accuracy: 0.9856 - Precision: 0.9381 - Recall: 0.3373 - Specificity: 0.9995 - F1: 0.4764 - Loss: 0.0028\n",
      "\n",
      "Batch 42/298 ━━━━━━━━━━━━━━━━━━━━ 03:13:09\n",
      "Accuracy: 0.9857 - Precision: 0.9386 - Recall: 0.3441 - Specificity: 0.9995 - F1: 0.4831 - Loss: 0.0028\n",
      "\n",
      "Batch 43/298 ━━━━━━━━━━━━━━━━━━━━ 03:13:17\n",
      "Accuracy: 0.9859 - Precision: 0.9387 - Recall: 0.3508 - Specificity: 0.9995 - F1: 0.4895 - Loss: 0.0028\n",
      "\n",
      "Batch 44/298 ━━━━━━━━━━━━━━━━━━━━ 03:13:25\n",
      "Accuracy: 0.9860 - Precision: 0.9383 - Recall: 0.3590 - Specificity: 0.9995 - F1: 0.4966 - Loss: 0.0028\n",
      "\n",
      "Batch 45/298 ━━━━━━━━━━━━━━━━━━━━ 03:13:33\n",
      "Accuracy: 0.9862 - Precision: 0.9342 - Recall: 0.3670 - Specificity: 0.9994 - F1: 0.5019 - Loss: 0.0028\n",
      "\n",
      "Batch 46/298 ━━━━━━━━━━━━━━━━━━━━ 03:13:41\n",
      "Accuracy: 0.9863 - Precision: 0.9346 - Recall: 0.3730 - Specificity: 0.9994 - F1: 0.5077 - Loss: 0.0028\n",
      "\n",
      "Batch 47/298 ━━━━━━━━━━━━━━━━━━━━ 03:13:49\n",
      "Accuracy: 0.9863 - Precision: 0.9344 - Recall: 0.3773 - Specificity: 0.9994 - F1: 0.5119 - Loss: 0.0028\n",
      "\n",
      "Batch 48/298 ━━━━━━━━━━━━━━━━━━━━ 03:13:57\n",
      "Accuracy: 0.9864 - Precision: 0.9349 - Recall: 0.3811 - Specificity: 0.9994 - F1: 0.5160 - Loss: 0.0028\n",
      "\n",
      "Batch 49/298 ━━━━━━━━━━━━━━━━━━━━ 03:14:05\n",
      "Accuracy: 0.9864 - Precision: 0.9353 - Recall: 0.3848 - Specificity: 0.9994 - F1: 0.5199 - Loss: 0.0027\n",
      "\n",
      "Batch 50/298 ━━━━━━━━━━━━━━━━━━━━ 03:14:12\n",
      "Accuracy: 0.9865 - Precision: 0.9362 - Recall: 0.3889 - Specificity: 0.9994 - F1: 0.5243 - Loss: 0.0027\n",
      "\n",
      "Batch 51/298 ━━━━━━━━━━━━━━━━━━━━ 03:14:20\n",
      "Accuracy: 0.9866 - Precision: 0.9365 - Recall: 0.3934 - Specificity: 0.9994 - F1: 0.5287 - Loss: 0.0027\n",
      "\n",
      "Batch 52/298 ━━━━━━━━━━━━━━━━━━━━ 03:14:28\n",
      "Accuracy: 0.9867 - Precision: 0.9367 - Recall: 0.3967 - Specificity: 0.9994 - F1: 0.5321 - Loss: 0.0027\n",
      "\n",
      "Batch 53/298 ━━━━━━━━━━━━━━━━━━━━ 03:14:36\n",
      "Accuracy: 0.9868 - Precision: 0.9374 - Recall: 0.4006 - Specificity: 0.9994 - F1: 0.5362 - Loss: 0.0027\n",
      "\n",
      "Batch 54/298 ━━━━━━━━━━━━━━━━━━━━ 03:14:44\n",
      "Accuracy: 0.9869 - Precision: 0.9380 - Recall: 0.4048 - Specificity: 0.9994 - F1: 0.5403 - Loss: 0.0027\n",
      "\n",
      "Batch 55/298 ━━━━━━━━━━━━━━━━━━━━ 03:14:52\n",
      "Accuracy: 0.9869 - Precision: 0.9385 - Recall: 0.4085 - Specificity: 0.9994 - F1: 0.5440 - Loss: 0.0027\n",
      "\n",
      "Batch 56/298 ━━━━━━━━━━━━━━━━━━━━ 03:15:00\n",
      "Accuracy: 0.9870 - Precision: 0.9382 - Recall: 0.4128 - Specificity: 0.9994 - F1: 0.5480 - Loss: 0.0026\n",
      "\n",
      "Batch 57/298 ━━━━━━━━━━━━━━━━━━━━ 03:15:08\n",
      "Accuracy: 0.9871 - Precision: 0.9379 - Recall: 0.4172 - Specificity: 0.9994 - F1: 0.5519 - Loss: 0.0026\n",
      "\n",
      "Batch 58/298 ━━━━━━━━━━━━━━━━━━━━ 03:15:16\n",
      "Accuracy: 0.9873 - Precision: 0.9377 - Recall: 0.4222 - Specificity: 0.9994 - F1: 0.5562 - Loss: 0.0026\n",
      "\n",
      "Batch 59/298 ━━━━━━━━━━━━━━━━━━━━ 03:15:23\n",
      "Accuracy: 0.9874 - Precision: 0.9378 - Recall: 0.4267 - Specificity: 0.9994 - F1: 0.5603 - Loss: 0.0026\n",
      "\n",
      "Batch 60/298 ━━━━━━━━━━━━━━━━━━━━ 03:15:31\n",
      "Accuracy: 0.9874 - Precision: 0.9375 - Recall: 0.4311 - Specificity: 0.9994 - F1: 0.5641 - Loss: 0.0026\n",
      "\n",
      "Batch 61/298 ━━━━━━━━━━━━━━━━━━━━ 03:15:39\n",
      "Accuracy: 0.9875 - Precision: 0.9373 - Recall: 0.4351 - Specificity: 0.9994 - F1: 0.5676 - Loss: 0.0026\n",
      "\n",
      "Batch 62/298 ━━━━━━━━━━━━━━━━━━━━ 03:15:48\n",
      "Accuracy: 0.9876 - Precision: 0.9375 - Recall: 0.4392 - Specificity: 0.9994 - F1: 0.5713 - Loss: 0.0026\n",
      "\n",
      "Batch 63/298 ━━━━━━━━━━━━━━━━━━━━ 03:15:56\n",
      "Accuracy: 0.9877 - Precision: 0.9378 - Recall: 0.4430 - Specificity: 0.9994 - F1: 0.5749 - Loss: 0.0026\n",
      "\n",
      "Batch 64/298 ━━━━━━━━━━━━━━━━━━━━ 03:16:03\n",
      "Accuracy: 0.9878 - Precision: 0.9380 - Recall: 0.4472 - Specificity: 0.9994 - F1: 0.5786 - Loss: 0.0025\n",
      "\n",
      "Batch 65/298 ━━━━━━━━━━━━━━━━━━━━ 03:16:11\n",
      "Accuracy: 0.9878 - Precision: 0.9381 - Recall: 0.4505 - Specificity: 0.9994 - F1: 0.5817 - Loss: 0.0025\n",
      "\n",
      "Batch 66/298 ━━━━━━━━━━━━━━━━━━━━ 03:16:19\n",
      "Accuracy: 0.9878 - Precision: 0.9383 - Recall: 0.4522 - Specificity: 0.9994 - F1: 0.5836 - Loss: 0.0025\n",
      "\n",
      "Batch 67/298 ━━━━━━━━━━━━━━━━━━━━ 03:16:27\n",
      "Accuracy: 0.9879 - Precision: 0.9381 - Recall: 0.4546 - Specificity: 0.9994 - F1: 0.5859 - Loss: 0.0025\n",
      "\n",
      "Batch 68/298 ━━━━━━━━━━━━━━━━━━━━ 03:16:35\n",
      "Accuracy: 0.9879 - Precision: 0.9382 - Recall: 0.4567 - Specificity: 0.9994 - F1: 0.5881 - Loss: 0.0025\n",
      "\n",
      "Batch 69/298 ━━━━━━━━━━━━━━━━━━━━ 03:16:44\n",
      "Accuracy: 0.9880 - Precision: 0.9382 - Recall: 0.4604 - Specificity: 0.9994 - F1: 0.5912 - Loss: 0.0025\n",
      "\n",
      "Batch 70/298 ━━━━━━━━━━━━━━━━━━━━ 03:16:54\n",
      "Accuracy: 0.9881 - Precision: 0.9385 - Recall: 0.4637 - Specificity: 0.9994 - F1: 0.5943 - Loss: 0.0025\n",
      "\n",
      "Batch 71/298 ━━━━━━━━━━━━━━━━━━━━ 03:17:02\n",
      "Accuracy: 0.9881 - Precision: 0.9371 - Recall: 0.4660 - Specificity: 0.9993 - F1: 0.5960 - Loss: 0.0025\n",
      "\n",
      "Batch 72/298 ━━━━━━━━━━━━━━━━━━━━ 03:17:10\n",
      "Accuracy: 0.9881 - Precision: 0.9363 - Recall: 0.4683 - Specificity: 0.9993 - F1: 0.5979 - Loss: 0.0025\n",
      "\n",
      "Batch 73/298 ━━━━━━━━━━━━━━━━━━━━ 03:17:18\n",
      "Accuracy: 0.9881 - Precision: 0.9366 - Recall: 0.4697 - Specificity: 0.9993 - F1: 0.5996 - Loss: 0.0025\n",
      "\n",
      "Batch 74/298 ━━━━━━━━━━━━━━━━━━━━ 03:17:26\n",
      "Accuracy: 0.9881 - Precision: 0.9371 - Recall: 0.4712 - Specificity: 0.9993 - F1: 0.6012 - Loss: 0.0025\n",
      "\n",
      "Batch 75/298 ━━━━━━━━━━━━━━━━━━━━ 03:17:34\n",
      "Accuracy: 0.9882 - Precision: 0.9368 - Recall: 0.4730 - Specificity: 0.9993 - F1: 0.6030 - Loss: 0.0025\n",
      "\n",
      "Batch 76/298 ━━━━━━━━━━━━━━━━━━━━ 03:17:42\n",
      "Accuracy: 0.9882 - Precision: 0.9373 - Recall: 0.4745 - Specificity: 0.9993 - F1: 0.6047 - Loss: 0.0025\n",
      "\n",
      "Batch 77/298 ━━━━━━━━━━━━━━━━━━━━ 03:17:50\n",
      "Accuracy: 0.9882 - Precision: 0.9373 - Recall: 0.4762 - Specificity: 0.9993 - F1: 0.6064 - Loss: 0.0025\n",
      "\n",
      "Batch 78/298 ━━━━━━━━━━━━━━━━━━━━ 03:17:58\n",
      "Accuracy: 0.9883 - Precision: 0.9377 - Recall: 0.4781 - Specificity: 0.9993 - F1: 0.6084 - Loss: 0.0025\n",
      "\n",
      "Batch 79/298 ━━━━━━━━━━━━━━━━━━━━ 03:18:06\n",
      "Accuracy: 0.9883 - Precision: 0.9380 - Recall: 0.4801 - Specificity: 0.9993 - F1: 0.6103 - Loss: 0.0025\n",
      "\n",
      "Batch 80/298 ━━━━━━━━━━━━━━━━━━━━ 03:18:14\n",
      "Accuracy: 0.9883 - Precision: 0.9383 - Recall: 0.4825 - Specificity: 0.9993 - F1: 0.6126 - Loss: 0.0025\n",
      "\n",
      "Batch 81/298 ━━━━━━━━━━━━━━━━━━━━ 03:18:22\n",
      "Accuracy: 0.9884 - Precision: 0.9383 - Recall: 0.4845 - Specificity: 0.9993 - F1: 0.6145 - Loss: 0.0025\n",
      "\n",
      "Batch 82/298 ━━━━━━━━━━━━━━━━━━━━ 03:18:30\n",
      "Accuracy: 0.9884 - Precision: 0.9385 - Recall: 0.4855 - Specificity: 0.9993 - F1: 0.6156 - Loss: 0.0025\n",
      "\n",
      "Batch 83/298 ━━━━━━━━━━━━━━━━━━━━ 03:18:38\n",
      "Accuracy: 0.9885 - Precision: 0.9385 - Recall: 0.4866 - Specificity: 0.9993 - F1: 0.6168 - Loss: 0.0025\n",
      "\n",
      "Batch 84/298 ━━━━━━━━━━━━━━━━━━━━ 03:18:46\n",
      "Accuracy: 0.9885 - Precision: 0.9383 - Recall: 0.4880 - Specificity: 0.9993 - F1: 0.6182 - Loss: 0.0025\n",
      "\n",
      "Batch 85/298 ━━━━━━━━━━━━━━━━━━━━ 03:18:54\n",
      "Accuracy: 0.9886 - Precision: 0.9385 - Recall: 0.4910 - Specificity: 0.9993 - F1: 0.6207 - Loss: 0.0024\n",
      "\n",
      "Batch 86/298 ━━━━━━━━━━━━━━━━━━━━ 03:19:02\n",
      "Accuracy: 0.9886 - Precision: 0.9380 - Recall: 0.4933 - Specificity: 0.9993 - F1: 0.6226 - Loss: 0.0024\n",
      "\n",
      "Batch 87/298 ━━━━━━━━━━━━━━━━━━━━ 03:19:10\n",
      "Accuracy: 0.9887 - Precision: 0.9381 - Recall: 0.4960 - Specificity: 0.9993 - F1: 0.6249 - Loss: 0.0024\n",
      "\n",
      "Batch 88/298 ━━━━━━━━━━━━━━━━━━━━ 03:19:18\n",
      "Accuracy: 0.9887 - Precision: 0.9381 - Recall: 0.4979 - Specificity: 0.9993 - F1: 0.6266 - Loss: 0.0024\n",
      "\n",
      "Batch 89/298 ━━━━━━━━━━━━━━━━━━━━ 03:19:25\n",
      "Accuracy: 0.9887 - Precision: 0.9385 - Recall: 0.5001 - Specificity: 0.9993 - F1: 0.6287 - Loss: 0.0024\n",
      "\n",
      "Batch 90/298 ━━━━━━━━━━━━━━━━━━━━ 03:19:33\n",
      "Accuracy: 0.9887 - Precision: 0.9387 - Recall: 0.5013 - Specificity: 0.9993 - F1: 0.6300 - Loss: 0.0024\n",
      "\n",
      "Batch 91/298 ━━━━━━━━━━━━━━━━━━━━ 03:19:41\n",
      "Accuracy: 0.9888 - Precision: 0.9390 - Recall: 0.5034 - Specificity: 0.9993 - F1: 0.6319 - Loss: 0.0024\n",
      "\n",
      "Batch 92/298 ━━━━━━━━━━━━━━━━━━━━ 03:19:49\n",
      "Accuracy: 0.9888 - Precision: 0.9388 - Recall: 0.5053 - Specificity: 0.9993 - F1: 0.6335 - Loss: 0.0024\n",
      "\n",
      "Batch 93/298 ━━━━━━━━━━━━━━━━━━━━ 03:19:57\n",
      "Accuracy: 0.9889 - Precision: 0.9389 - Recall: 0.5075 - Specificity: 0.9993 - F1: 0.6354 - Loss: 0.0024\n",
      "\n",
      "Batch 94/298 ━━━━━━━━━━━━━━━━━━━━ 03:20:05\n",
      "Accuracy: 0.9889 - Precision: 0.9388 - Recall: 0.5093 - Specificity: 0.9993 - F1: 0.6370 - Loss: 0.0024\n",
      "\n",
      "Batch 95/298 ━━━━━━━━━━━━━━━━━━━━ 03:20:13\n",
      "Accuracy: 0.9890 - Precision: 0.9388 - Recall: 0.5113 - Specificity: 0.9993 - F1: 0.6387 - Loss: 0.0024\n",
      "\n",
      "Batch 96/298 ━━━━━━━━━━━━━━━━━━━━ 03:20:21\n",
      "Accuracy: 0.9890 - Precision: 0.9387 - Recall: 0.5129 - Specificity: 0.9993 - F1: 0.6402 - Loss: 0.0024\n",
      "\n",
      "Batch 97/298 ━━━━━━━━━━━━━━━━━━━━ 03:20:28\n",
      "Accuracy: 0.9890 - Precision: 0.9389 - Recall: 0.5148 - Specificity: 0.9993 - F1: 0.6419 - Loss: 0.0024\n",
      "\n",
      "Batch 98/298 ━━━━━━━━━━━━━━━━━━━━ 03:20:36\n",
      "Accuracy: 0.9891 - Precision: 0.9389 - Recall: 0.5172 - Specificity: 0.9993 - F1: 0.6438 - Loss: 0.0024\n",
      "\n",
      "Batch 99/298 ━━━━━━━━━━━━━━━━━━━━ 03:20:44\n",
      "Accuracy: 0.9891 - Precision: 0.9386 - Recall: 0.5190 - Specificity: 0.9993 - F1: 0.6453 - Loss: 0.0024\n",
      "\n",
      "Batch 100/298 ━━━━━━━━━━━━━━━━━━━━ 03:20:52\n",
      "Accuracy: 0.9892 - Precision: 0.9383 - Recall: 0.5211 - Specificity: 0.9993 - F1: 0.6469 - Loss: 0.0023\n",
      "\n",
      "Batch 101/298 ━━━━━━━━━━━━━━━━━━━━ 03:21:00\n",
      "Accuracy: 0.9892 - Precision: 0.9383 - Recall: 0.5229 - Specificity: 0.9993 - F1: 0.6485 - Loss: 0.0023\n",
      "\n",
      "Batch 102/298 ━━━━━━━━━━━━━━━━━━━━ 03:21:08\n",
      "Accuracy: 0.9893 - Precision: 0.9376 - Recall: 0.5238 - Specificity: 0.9993 - F1: 0.6492 - Loss: 0.0023\n",
      "\n",
      "Batch 103/298 ━━━━━━━━━━━━━━━━━━━━ 03:21:16\n",
      "Accuracy: 0.9893 - Precision: 0.9373 - Recall: 0.5251 - Specificity: 0.9993 - F1: 0.6503 - Loss: 0.0023\n",
      "\n",
      "Batch 104/298 ━━━━━━━━━━━━━━━━━━━━ 03:21:24\n",
      "Accuracy: 0.9893 - Precision: 0.9374 - Recall: 0.5261 - Specificity: 0.9993 - F1: 0.6513 - Loss: 0.0023\n",
      "\n",
      "Batch 105/298 ━━━━━━━━━━━━━━━━━━━━ 03:21:31\n",
      "Accuracy: 0.9894 - Precision: 0.9375 - Recall: 0.5263 - Specificity: 0.9993 - F1: 0.6517 - Loss: 0.0023\n",
      "\n",
      "Batch 106/298 ━━━━━━━━━━━━━━━━━━━━ 03:21:39\n",
      "Accuracy: 0.9894 - Precision: 0.9374 - Recall: 0.5273 - Specificity: 0.9993 - F1: 0.6526 - Loss: 0.0023\n",
      "\n",
      "Batch 107/298 ━━━━━━━━━━━━━━━━━━━━ 03:21:47\n",
      "Accuracy: 0.9894 - Precision: 0.9372 - Recall: 0.5263 - Specificity: 0.9993 - F1: 0.6519 - Loss: 0.0023\n",
      "\n",
      "Batch 108/298 ━━━━━━━━━━━━━━━━━━━━ 03:21:55\n",
      "Accuracy: 0.9894 - Precision: 0.9370 - Recall: 0.5254 - Specificity: 0.9993 - F1: 0.6513 - Loss: 0.0023\n",
      "\n",
      "Batch 109/298 ━━━━━━━━━━━━━━━━━━━━ 03:22:03\n",
      "Accuracy: 0.9894 - Precision: 0.9370 - Recall: 0.5261 - Specificity: 0.9993 - F1: 0.6520 - Loss: 0.0023\n",
      "\n",
      "Batch 110/298 ━━━━━━━━━━━━━━━━━━━━ 03:22:11\n",
      "Accuracy: 0.9895 - Precision: 0.9367 - Recall: 0.5278 - Specificity: 0.9993 - F1: 0.6534 - Loss: 0.0023\n",
      "\n",
      "Batch 111/298 ━━━━━━━━━━━━━━━━━━━━ 03:22:19\n",
      "Accuracy: 0.9895 - Precision: 0.9363 - Recall: 0.5283 - Specificity: 0.9993 - F1: 0.6539 - Loss: 0.0023\n",
      "\n",
      "Batch 112/298 ━━━━━━━━━━━━━━━━━━━━ 03:22:27\n",
      "Accuracy: 0.9895 - Precision: 0.9359 - Recall: 0.5299 - Specificity: 0.9993 - F1: 0.6550 - Loss: 0.0023\n",
      "\n",
      "Batch 113/298 ━━━━━━━━━━━━━━━━━━━━ 03:22:35\n",
      "Accuracy: 0.9895 - Precision: 0.9353 - Recall: 0.5315 - Specificity: 0.9992 - F1: 0.6562 - Loss: 0.0023\n",
      "\n",
      "Batch 114/298 ━━━━━━━━━━━━━━━━━━━━ 03:22:43\n",
      "Accuracy: 0.9896 - Precision: 0.9353 - Recall: 0.5326 - Specificity: 0.9992 - F1: 0.6572 - Loss: 0.0023\n",
      "\n",
      "Batch 115/298 ━━━━━━━━━━━━━━━━━━━━ 03:22:51\n",
      "Accuracy: 0.9896 - Precision: 0.9354 - Recall: 0.5335 - Specificity: 0.9992 - F1: 0.6581 - Loss: 0.0023\n",
      "\n",
      "Batch 116/298 ━━━━━━━━━━━━━━━━━━━━ 03:22:59\n",
      "Accuracy: 0.9896 - Precision: 0.9352 - Recall: 0.5341 - Specificity: 0.9992 - F1: 0.6587 - Loss: 0.0023\n",
      "\n",
      "Batch 117/298 ━━━━━━━━━━━━━━━━━━━━ 03:23:07\n",
      "Accuracy: 0.9896 - Precision: 0.9354 - Recall: 0.5343 - Specificity: 0.9992 - F1: 0.6591 - Loss: 0.0023\n",
      "\n",
      "Batch 118/298 ━━━━━━━━━━━━━━━━━━━━ 03:23:15\n",
      "Accuracy: 0.9896 - Precision: 0.9355 - Recall: 0.5347 - Specificity: 0.9992 - F1: 0.6596 - Loss: 0.0023\n",
      "\n",
      "Batch 119/298 ━━━━━━━━━━━━━━━━━━━━ 03:23:23\n",
      "Accuracy: 0.9896 - Precision: 0.9355 - Recall: 0.5353 - Specificity: 0.9992 - F1: 0.6603 - Loss: 0.0023\n",
      "\n",
      "Batch 120/298 ━━━━━━━━━━━━━━━━━━━━ 03:23:31\n",
      "Accuracy: 0.9896 - Precision: 0.9351 - Recall: 0.5357 - Specificity: 0.9992 - F1: 0.6606 - Loss: 0.0023\n",
      "\n",
      "Batch 121/298 ━━━━━━━━━━━━━━━━━━━━ 03:23:39\n",
      "Accuracy: 0.9897 - Precision: 0.9351 - Recall: 0.5361 - Specificity: 0.9992 - F1: 0.6611 - Loss: 0.0023\n",
      "\n",
      "Batch 122/298 ━━━━━━━━━━━━━━━━━━━━ 03:23:47\n",
      "Accuracy: 0.9897 - Precision: 0.9355 - Recall: 0.5359 - Specificity: 0.9992 - F1: 0.6612 - Loss: 0.0023\n",
      "\n",
      "Batch 123/298 ━━━━━━━━━━━━━━━━━━━━ 03:23:55\n",
      "Accuracy: 0.9896 - Precision: 0.9357 - Recall: 0.5358 - Specificity: 0.9992 - F1: 0.6613 - Loss: 0.0023\n",
      "\n",
      "Batch 124/298 ━━━━━━━━━━━━━━━━━━━━ 03:24:03\n",
      "Accuracy: 0.9897 - Precision: 0.9360 - Recall: 0.5368 - Specificity: 0.9992 - F1: 0.6623 - Loss: 0.0023\n",
      "\n",
      "Batch 125/298 ━━━━━━━━━━━━━━━━━━━━ 03:24:11\n",
      "Accuracy: 0.9897 - Precision: 0.9358 - Recall: 0.5377 - Specificity: 0.9992 - F1: 0.6631 - Loss: 0.0023\n",
      "\n",
      "Batch 126/298 ━━━━━━━━━━━━━━━━━━━━ 03:24:19\n",
      "Accuracy: 0.9897 - Precision: 0.9358 - Recall: 0.5393 - Specificity: 0.9992 - F1: 0.6644 - Loss: 0.0023\n",
      "\n",
      "Batch 127/298 ━━━━━━━━━━━━━━━━━━━━ 03:24:27\n",
      "Accuracy: 0.9897 - Precision: 0.9350 - Recall: 0.5407 - Specificity: 0.9992 - F1: 0.6653 - Loss: 0.0023\n",
      "\n",
      "Batch 128/298 ━━━━━━━━━━━━━━━━━━━━ 03:24:35\n",
      "Accuracy: 0.9898 - Precision: 0.9351 - Recall: 0.5419 - Specificity: 0.9992 - F1: 0.6663 - Loss: 0.0023\n",
      "\n",
      "Batch 129/298 ━━━━━━━━━━━━━━━━━━━━ 03:24:43\n",
      "Accuracy: 0.9898 - Precision: 0.9352 - Recall: 0.5433 - Specificity: 0.9992 - F1: 0.6675 - Loss: 0.0023\n",
      "\n",
      "Batch 130/298 ━━━━━━━━━━━━━━━━━━━━ 03:24:50\n",
      "Accuracy: 0.9898 - Precision: 0.9351 - Recall: 0.5444 - Specificity: 0.9992 - F1: 0.6684 - Loss: 0.0023\n",
      "\n",
      "Batch 131/298 ━━━━━━━━━━━━━━━━━━━━ 03:24:58\n",
      "Accuracy: 0.9898 - Precision: 0.9352 - Recall: 0.5451 - Specificity: 0.9992 - F1: 0.6691 - Loss: 0.0023\n",
      "\n",
      "Batch 132/298 ━━━━━━━━━━━━━━━━━━━━ 03:25:06\n",
      "Accuracy: 0.9898 - Precision: 0.9352 - Recall: 0.5463 - Specificity: 0.9992 - F1: 0.6702 - Loss: 0.0023\n",
      "\n",
      "Batch 133/298 ━━━━━━━━━━━━━━━━━━━━ 03:25:15\n",
      "Accuracy: 0.9898 - Precision: 0.9354 - Recall: 0.5463 - Specificity: 0.9992 - F1: 0.6704 - Loss: 0.0023\n",
      "\n",
      "Batch 134/298 ━━━━━━━━━━━━━━━━━━━━ 03:25:23\n",
      "Accuracy: 0.9899 - Precision: 0.9356 - Recall: 0.5471 - Specificity: 0.9992 - F1: 0.6711 - Loss: 0.0023\n",
      "\n",
      "Batch 135/298 ━━━━━━━━━━━━━━━━━━━━ 03:25:30\n",
      "Accuracy: 0.9899 - Precision: 0.9358 - Recall: 0.5476 - Specificity: 0.9992 - F1: 0.6717 - Loss: 0.0023\n",
      "\n",
      "Batch 136/298 ━━━━━━━━━━━━━━━━━━━━ 03:25:38\n",
      "Accuracy: 0.9899 - Precision: 0.9360 - Recall: 0.5482 - Specificity: 0.9992 - F1: 0.6724 - Loss: 0.0023\n",
      "\n",
      "Batch 137/298 ━━━━━━━━━━━━━━━━━━━━ 03:25:46\n",
      "Accuracy: 0.9899 - Precision: 0.9363 - Recall: 0.5484 - Specificity: 0.9992 - F1: 0.6728 - Loss: 0.0022\n",
      "\n",
      "Batch 138/298 ━━━━━━━━━━━━━━━━━━━━ 03:25:54\n",
      "Accuracy: 0.9899 - Precision: 0.9365 - Recall: 0.5491 - Specificity: 0.9992 - F1: 0.6735 - Loss: 0.0022\n",
      "\n",
      "Batch 139/298 ━━━━━━━━━━━━━━━━━━━━ 03:26:02\n",
      "Accuracy: 0.9899 - Precision: 0.9368 - Recall: 0.5497 - Specificity: 0.9992 - F1: 0.6742 - Loss: 0.0022\n",
      "\n",
      "Batch 140/298 ━━━━━━━━━━━━━━━━━━━━ 03:26:09\n",
      "Accuracy: 0.9899 - Precision: 0.9370 - Recall: 0.5506 - Specificity: 0.9992 - F1: 0.6750 - Loss: 0.0022\n",
      "\n",
      "Batch 141/298 ━━━━━━━━━━━━━━━━━━━━ 03:26:17\n",
      "Accuracy: 0.9900 - Precision: 0.9371 - Recall: 0.5517 - Specificity: 0.9992 - F1: 0.6760 - Loss: 0.0022\n",
      "\n",
      "Batch 142/298 ━━━━━━━━━━━━━━━━━━━━ 03:26:25\n",
      "Accuracy: 0.9900 - Precision: 0.9369 - Recall: 0.5527 - Specificity: 0.9992 - F1: 0.6768 - Loss: 0.0022\n",
      "\n",
      "Batch 143/298 ━━━━━━━━━━━━━━━━━━━━ 03:26:33\n",
      "Accuracy: 0.9900 - Precision: 0.9369 - Recall: 0.5537 - Specificity: 0.9992 - F1: 0.6776 - Loss: 0.0022\n",
      "\n",
      "Batch 144/298 ━━━━━━━━━━━━━━━━━━━━ 03:26:41\n",
      "Accuracy: 0.9900 - Precision: 0.9366 - Recall: 0.5551 - Specificity: 0.9992 - F1: 0.6786 - Loss: 0.0022\n",
      "\n",
      "Batch 145/298 ━━━━━━━━━━━━━━━━━━━━ 03:26:49\n",
      "Accuracy: 0.9900 - Precision: 0.9366 - Recall: 0.5560 - Specificity: 0.9992 - F1: 0.6794 - Loss: 0.0022\n",
      "\n",
      "Batch 146/298 ━━━━━━━━━━━━━━━━━━━━ 03:26:56\n",
      "Accuracy: 0.9901 - Precision: 0.9366 - Recall: 0.5573 - Specificity: 0.9992 - F1: 0.6804 - Loss: 0.0022\n",
      "\n",
      "Batch 147/298 ━━━━━━━━━━━━━━━━━━━━ 03:27:04\n",
      "Accuracy: 0.9901 - Precision: 0.9368 - Recall: 0.5577 - Specificity: 0.9992 - F1: 0.6809 - Loss: 0.0022\n",
      "\n",
      "Batch 148/298 ━━━━━━━━━━━━━━━━━━━━ 03:27:12\n",
      "Accuracy: 0.9901 - Precision: 0.9370 - Recall: 0.5587 - Specificity: 0.9992 - F1: 0.6818 - Loss: 0.0022\n",
      "\n",
      "Batch 149/298 ━━━━━━━━━━━━━━━━━━━━ 03:27:20\n",
      "Accuracy: 0.9901 - Precision: 0.9366 - Recall: 0.5574 - Specificity: 0.9992 - F1: 0.6807 - Loss: 0.0022\n",
      "\n",
      "Batch 150/298 ━━━━━━━━━━━━━━━━━━━━ 03:27:28\n",
      "Accuracy: 0.9901 - Precision: 0.9368 - Recall: 0.5575 - Specificity: 0.9992 - F1: 0.6810 - Loss: 0.0022\n",
      "\n",
      "Batch 151/298 ━━━━━━━━━━━━━━━━━━━━ 03:27:36\n",
      "Accuracy: 0.9901 - Precision: 0.9370 - Recall: 0.5573 - Specificity: 0.9992 - F1: 0.6809 - Loss: 0.0022\n",
      "\n",
      "Batch 152/298 ━━━━━━━━━━━━━━━━━━━━ 03:27:44\n",
      "Accuracy: 0.9901 - Precision: 0.9369 - Recall: 0.5575 - Specificity: 0.9992 - F1: 0.6812 - Loss: 0.0022\n",
      "\n",
      "Batch 153/298 ━━━━━━━━━━━━━━━━━━━━ 03:27:52\n",
      "Accuracy: 0.9901 - Precision: 0.9371 - Recall: 0.5577 - Specificity: 0.9992 - F1: 0.6815 - Loss: 0.0022\n",
      "\n",
      "Batch 154/298 ━━━━━━━━━━━━━━━━━━━━ 03:28:00\n",
      "Accuracy: 0.9901 - Precision: 0.9374 - Recall: 0.5581 - Specificity: 0.9992 - F1: 0.6820 - Loss: 0.0022\n",
      "\n",
      "Batch 155/298 ━━━━━━━━━━━━━━━━━━━━ 03:28:08\n",
      "Accuracy: 0.9901 - Precision: 0.9376 - Recall: 0.5585 - Specificity: 0.9992 - F1: 0.6825 - Loss: 0.0022\n",
      "\n",
      "Batch 156/298 ━━━━━━━━━━━━━━━━━━━━ 03:28:16\n",
      "Accuracy: 0.9901 - Precision: 0.9377 - Recall: 0.5588 - Specificity: 0.9992 - F1: 0.6829 - Loss: 0.0022\n",
      "\n",
      "Batch 157/298 ━━━━━━━━━━━━━━━━━━━━ 03:28:24\n",
      "Accuracy: 0.9901 - Precision: 0.9378 - Recall: 0.5596 - Specificity: 0.9992 - F1: 0.6836 - Loss: 0.0022\n",
      "\n",
      "Batch 158/298 ━━━━━━━━━━━━━━━━━━━━ 03:28:32\n",
      "Accuracy: 0.9901 - Precision: 0.9378 - Recall: 0.5607 - Specificity: 0.9992 - F1: 0.6845 - Loss: 0.0022\n",
      "\n",
      "Batch 159/298 ━━━━━━━━━━━━━━━━━━━━ 03:28:40\n",
      "Accuracy: 0.9902 - Precision: 0.9379 - Recall: 0.5618 - Specificity: 0.9992 - F1: 0.6854 - Loss: 0.0022\n",
      "\n",
      "Batch 160/298 ━━━━━━━━━━━━━━━━━━━━ 03:28:48\n",
      "Accuracy: 0.9902 - Precision: 0.9378 - Recall: 0.5629 - Specificity: 0.9992 - F1: 0.6862 - Loss: 0.0022\n",
      "\n",
      "Batch 161/298 ━━━━━━━━━━━━━━━━━━━━ 03:28:56\n",
      "Accuracy: 0.9902 - Precision: 0.9377 - Recall: 0.5637 - Specificity: 0.9992 - F1: 0.6869 - Loss: 0.0022\n",
      "\n",
      "Batch 162/298 ━━━━━━━━━━━━━━━━━━━━ 03:29:04\n",
      "Accuracy: 0.9902 - Precision: 0.9378 - Recall: 0.5648 - Specificity: 0.9992 - F1: 0.6878 - Loss: 0.0022\n",
      "\n",
      "Batch 163/298 ━━━━━━━━━━━━━━━━━━━━ 03:29:12\n",
      "Accuracy: 0.9902 - Precision: 0.9378 - Recall: 0.5658 - Specificity: 0.9992 - F1: 0.6886 - Loss: 0.0022\n",
      "\n",
      "Batch 164/298 ━━━━━━━━━━━━━━━━━━━━ 03:29:20\n",
      "Accuracy: 0.9903 - Precision: 0.9377 - Recall: 0.5665 - Specificity: 0.9992 - F1: 0.6892 - Loss: 0.0022\n",
      "\n",
      "Batch 165/298 ━━━━━━━━━━━━━━━━━━━━ 03:29:28\n",
      "Accuracy: 0.9903 - Precision: 0.9379 - Recall: 0.5674 - Specificity: 0.9992 - F1: 0.6900 - Loss: 0.0022\n",
      "\n",
      "Batch 166/298 ━━━━━━━━━━━━━━━━━━━━ 03:29:36\n",
      "Accuracy: 0.9903 - Precision: 0.9381 - Recall: 0.5680 - Specificity: 0.9992 - F1: 0.6906 - Loss: 0.0022\n",
      "\n",
      "Batch 167/298 ━━━━━━━━━━━━━━━━━━━━ 03:29:43\n",
      "Accuracy: 0.9903 - Precision: 0.9383 - Recall: 0.5684 - Specificity: 0.9992 - F1: 0.6910 - Loss: 0.0022\n",
      "\n",
      "Batch 168/298 ━━━━━━━━━━━━━━━━━━━━ 03:29:51\n",
      "Accuracy: 0.9903 - Precision: 0.9385 - Recall: 0.5686 - Specificity: 0.9992 - F1: 0.6914 - Loss: 0.0022\n",
      "\n",
      "Batch 169/298 ━━━━━━━━━━━━━━━━━━━━ 03:29:59\n",
      "Accuracy: 0.9903 - Precision: 0.9387 - Recall: 0.5693 - Specificity: 0.9992 - F1: 0.6921 - Loss: 0.0022\n",
      "\n",
      "Batch 170/298 ━━━━━━━━━━━━━━━━━━━━ 03:30:07\n",
      "Accuracy: 0.9904 - Precision: 0.9388 - Recall: 0.5700 - Specificity: 0.9992 - F1: 0.6927 - Loss: 0.0022\n",
      "\n",
      "Batch 171/298 ━━━━━━━━━━━━━━━━━━━━ 03:30:15\n",
      "Accuracy: 0.9904 - Precision: 0.9391 - Recall: 0.5702 - Specificity: 0.9992 - F1: 0.6930 - Loss: 0.0022\n",
      "\n",
      "Batch 172/298 ━━━━━━━━━━━━━━━━━━━━ 03:30:23\n",
      "Accuracy: 0.9904 - Precision: 0.9393 - Recall: 0.5709 - Specificity: 0.9992 - F1: 0.6937 - Loss: 0.0022\n",
      "\n",
      "Batch 173/298 ━━━━━━━━━━━━━━━━━━━━ 03:30:31\n",
      "Accuracy: 0.9904 - Precision: 0.9393 - Recall: 0.5713 - Specificity: 0.9992 - F1: 0.6941 - Loss: 0.0022\n",
      "\n",
      "Batch 174/298 ━━━━━━━━━━━━━━━━━━━━ 03:30:39\n",
      "Accuracy: 0.9904 - Precision: 0.9393 - Recall: 0.5721 - Specificity: 0.9992 - F1: 0.6948 - Loss: 0.0022\n",
      "\n",
      "Batch 175/298 ━━━━━━━━━━━━━━━━━━━━ 03:30:47\n",
      "Accuracy: 0.9904 - Precision: 0.9394 - Recall: 0.5727 - Specificity: 0.9992 - F1: 0.6953 - Loss: 0.0022\n",
      "\n",
      "Batch 176/298 ━━━━━━━━━━━━━━━━━━━━ 03:30:55\n",
      "Accuracy: 0.9904 - Precision: 0.9394 - Recall: 0.5738 - Specificity: 0.9992 - F1: 0.6962 - Loss: 0.0022\n",
      "\n",
      "Batch 177/298 ━━━━━━━━━━━━━━━━━━━━ 03:31:03\n",
      "Accuracy: 0.9905 - Precision: 0.9393 - Recall: 0.5749 - Specificity: 0.9992 - F1: 0.6970 - Loss: 0.0022\n",
      "\n",
      "Batch 178/298 ━━━━━━━━━━━━━━━━━━━━ 03:31:11\n",
      "Accuracy: 0.9905 - Precision: 0.9393 - Recall: 0.5759 - Specificity: 0.9992 - F1: 0.6978 - Loss: 0.0022\n",
      "\n",
      "Batch 179/298 ━━━━━━━━━━━━━━━━━━━━ 03:31:19\n",
      "Accuracy: 0.9905 - Precision: 0.9391 - Recall: 0.5765 - Specificity: 0.9992 - F1: 0.6982 - Loss: 0.0022\n",
      "\n",
      "Batch 180/298 ━━━━━━━━━━━━━━━━━━━━ 03:31:27\n",
      "Accuracy: 0.9905 - Precision: 0.9391 - Recall: 0.5770 - Specificity: 0.9992 - F1: 0.6987 - Loss: 0.0022\n",
      "\n",
      "Batch 181/298 ━━━━━━━━━━━━━━━━━━━━ 03:31:35\n",
      "Accuracy: 0.9905 - Precision: 0.9393 - Recall: 0.5774 - Specificity: 0.9992 - F1: 0.6991 - Loss: 0.0022\n",
      "\n",
      "Batch 182/298 ━━━━━━━━━━━━━━━━━━━━ 03:31:43\n",
      "Accuracy: 0.9905 - Precision: 0.9395 - Recall: 0.5777 - Specificity: 0.9992 - F1: 0.6995 - Loss: 0.0021\n",
      "\n",
      "Batch 183/298 ━━━━━━━━━━━━━━━━━━━━ 03:31:51\n",
      "Accuracy: 0.9905 - Precision: 0.9396 - Recall: 0.5778 - Specificity: 0.9992 - F1: 0.6996 - Loss: 0.0021\n",
      "\n",
      "Batch 184/298 ━━━━━━━━━━━━━━━━━━━━ 03:32:00\n",
      "Accuracy: 0.9905 - Precision: 0.9398 - Recall: 0.5775 - Specificity: 0.9992 - F1: 0.6996 - Loss: 0.0021\n",
      "\n",
      "Batch 185/298 ━━━━━━━━━━━━━━━━━━━━ 03:32:08\n",
      "Accuracy: 0.9905 - Precision: 0.9399 - Recall: 0.5778 - Specificity: 0.9992 - F1: 0.6999 - Loss: 0.0021\n",
      "\n",
      "Batch 186/298 ━━━━━━━━━━━━━━━━━━━━ 03:32:16\n",
      "Accuracy: 0.9905 - Precision: 0.9401 - Recall: 0.5776 - Specificity: 0.9993 - F1: 0.6999 - Loss: 0.0021\n",
      "\n",
      "Batch 187/298 ━━━━━━━━━━━━━━━━━━━━ 03:32:24\n",
      "Accuracy: 0.9905 - Precision: 0.9403 - Recall: 0.5775 - Specificity: 0.9993 - F1: 0.6999 - Loss: 0.0021\n",
      "\n",
      "Batch 188/298 ━━━━━━━━━━━━━━━━━━━━ 03:32:32\n",
      "Accuracy: 0.9905 - Precision: 0.9405 - Recall: 0.5779 - Specificity: 0.9993 - F1: 0.7003 - Loss: 0.0021\n",
      "\n",
      "Batch 189/298 ━━━━━━━━━━━━━━━━━━━━ 03:32:40\n",
      "Accuracy: 0.9906 - Precision: 0.9406 - Recall: 0.5785 - Specificity: 0.9993 - F1: 0.7009 - Loss: 0.0021\n",
      "\n",
      "Batch 190/298 ━━━━━━━━━━━━━━━━━━━━ 03:32:48\n",
      "Accuracy: 0.9906 - Precision: 0.9407 - Recall: 0.5790 - Specificity: 0.9993 - F1: 0.7014 - Loss: 0.0021\n",
      "\n",
      "Batch 191/298 ━━━━━━━━━━━━━━━━━━━━ 03:32:56\n",
      "Accuracy: 0.9906 - Precision: 0.9407 - Recall: 0.5799 - Specificity: 0.9993 - F1: 0.7021 - Loss: 0.0021\n",
      "\n",
      "Batch 192/298 ━━━━━━━━━━━━━━━━━━━━ 03:33:03\n",
      "Accuracy: 0.9906 - Precision: 0.9406 - Recall: 0.5808 - Specificity: 0.9992 - F1: 0.7027 - Loss: 0.0021\n",
      "\n",
      "Batch 193/298 ━━━━━━━━━━━━━━━━━━━━ 03:33:12\n",
      "Accuracy: 0.9906 - Precision: 0.9404 - Recall: 0.5818 - Specificity: 0.9992 - F1: 0.7034 - Loss: 0.0021\n",
      "\n",
      "Batch 194/298 ━━━━━━━━━━━━━━━━━━━━ 03:33:20\n",
      "Accuracy: 0.9906 - Precision: 0.9403 - Recall: 0.5827 - Specificity: 0.9992 - F1: 0.7041 - Loss: 0.0021\n",
      "\n",
      "Batch 195/298 ━━━━━━━━━━━━━━━━━━━━ 03:33:28\n",
      "Accuracy: 0.9907 - Precision: 0.9404 - Recall: 0.5833 - Specificity: 0.9992 - F1: 0.7046 - Loss: 0.0021\n",
      "\n",
      "Batch 196/298 ━━━━━━━━━━━━━━━━━━━━ 03:33:36\n",
      "Accuracy: 0.9907 - Precision: 0.9403 - Recall: 0.5841 - Specificity: 0.9992 - F1: 0.7052 - Loss: 0.0021\n",
      "\n",
      "Batch 197/298 ━━━━━━━━━━━━━━━━━━━━ 03:33:44\n",
      "Accuracy: 0.9907 - Precision: 0.9404 - Recall: 0.5847 - Specificity: 0.9992 - F1: 0.7058 - Loss: 0.0021\n",
      "\n",
      "Batch 198/298 ━━━━━━━━━━━━━━━━━━━━ 03:33:51\n",
      "Accuracy: 0.9907 - Precision: 0.9406 - Recall: 0.5850 - Specificity: 0.9992 - F1: 0.7061 - Loss: 0.0021\n",
      "\n",
      "Batch 199/298 ━━━━━━━━━━━━━━━━━━━━ 03:33:59\n",
      "Accuracy: 0.9907 - Precision: 0.9408 - Recall: 0.5853 - Specificity: 0.9992 - F1: 0.7065 - Loss: 0.0021\n",
      "\n",
      "Batch 200/298 ━━━━━━━━━━━━━━━━━━━━ 03:34:07\n",
      "Accuracy: 0.9907 - Precision: 0.9409 - Recall: 0.5857 - Specificity: 0.9992 - F1: 0.7069 - Loss: 0.0021\n",
      "\n",
      "Batch 201/298 ━━━━━━━━━━━━━━━━━━━━ 03:34:16\n",
      "Accuracy: 0.9907 - Precision: 0.9411 - Recall: 0.5857 - Specificity: 0.9993 - F1: 0.7070 - Loss: 0.0021\n",
      "\n",
      "Batch 202/298 ━━━━━━━━━━━━━━━━━━━━ 03:34:24\n",
      "Accuracy: 0.9907 - Precision: 0.9413 - Recall: 0.5863 - Specificity: 0.9993 - F1: 0.7076 - Loss: 0.0021\n",
      "\n",
      "Batch 203/298 ━━━━━━━━━━━━━━━━━━━━ 03:34:32\n",
      "Accuracy: 0.9907 - Precision: 0.9414 - Recall: 0.5865 - Specificity: 0.9993 - F1: 0.7079 - Loss: 0.0021\n",
      "\n",
      "Batch 204/298 ━━━━━━━━━━━━━━━━━━━━ 03:34:40\n",
      "Accuracy: 0.9908 - Precision: 0.9414 - Recall: 0.5871 - Specificity: 0.9993 - F1: 0.7083 - Loss: 0.0021\n",
      "\n",
      "Batch 205/298 ━━━━━━━━━━━━━━━━━━━━ 03:34:47\n",
      "Accuracy: 0.9908 - Precision: 0.9413 - Recall: 0.5878 - Specificity: 0.9993 - F1: 0.7089 - Loss: 0.0021\n",
      "\n",
      "Batch 206/298 ━━━━━━━━━━━━━━━━━━━━ 03:34:56\n",
      "Accuracy: 0.9908 - Precision: 0.9412 - Recall: 0.5887 - Specificity: 0.9993 - F1: 0.7095 - Loss: 0.0021\n",
      "\n",
      "Batch 207/298 ━━━━━━━━━━━━━━━━━━━━ 03:35:04\n",
      "Accuracy: 0.9908 - Precision: 0.9410 - Recall: 0.5897 - Specificity: 0.9992 - F1: 0.7102 - Loss: 0.0021\n",
      "\n",
      "Batch 208/298 ━━━━━━━━━━━━━━━━━━━━ 03:35:11\n",
      "Accuracy: 0.9908 - Precision: 0.9409 - Recall: 0.5907 - Specificity: 0.9992 - F1: 0.7109 - Loss: 0.0021\n",
      "\n",
      "Batch 209/298 ━━━━━━━━━━━━━━━━━━━━ 03:35:19\n",
      "Accuracy: 0.9909 - Precision: 0.9410 - Recall: 0.5916 - Specificity: 0.9992 - F1: 0.7115 - Loss: 0.0021\n",
      "\n",
      "Batch 210/298 ━━━━━━━━━━━━━━━━━━━━ 03:35:28\n",
      "Accuracy: 0.9909 - Precision: 0.9408 - Recall: 0.5923 - Specificity: 0.9992 - F1: 0.7121 - Loss: 0.0021\n",
      "\n",
      "Batch 211/298 ━━━━━━━━━━━━━━━━━━━━ 03:35:36\n",
      "Accuracy: 0.9909 - Precision: 0.9409 - Recall: 0.5929 - Specificity: 0.9992 - F1: 0.7126 - Loss: 0.0021\n",
      "\n",
      "Batch 212/298 ━━━━━━━━━━━━━━━━━━━━ 03:35:44\n",
      "Accuracy: 0.9909 - Precision: 0.9410 - Recall: 0.5933 - Specificity: 0.9992 - F1: 0.7130 - Loss: 0.0021\n",
      "\n",
      "Batch 213/298 ━━━━━━━━━━━━━━━━━━━━ 03:35:52\n",
      "Accuracy: 0.9909 - Precision: 0.9411 - Recall: 0.5932 - Specificity: 0.9992 - F1: 0.7130 - Loss: 0.0021\n",
      "\n",
      "Batch 214/298 ━━━━━━━━━━━━━━━━━━━━ 03:35:59\n",
      "Accuracy: 0.9909 - Precision: 0.9412 - Recall: 0.5922 - Specificity: 0.9992 - F1: 0.7122 - Loss: 0.0021\n",
      "\n",
      "Batch 215/298 ━━━━━━━━━━━━━━━━━━━━ 03:36:07\n",
      "Accuracy: 0.9908 - Precision: 0.9411 - Recall: 0.5915 - Specificity: 0.9992 - F1: 0.7116 - Loss: 0.0021\n",
      "\n",
      "Batch 216/298 ━━━━━━━━━━━━━━━━━━━━ 03:36:15\n",
      "Accuracy: 0.9908 - Precision: 0.9411 - Recall: 0.5906 - Specificity: 0.9992 - F1: 0.7109 - Loss: 0.0021\n",
      "\n",
      "Batch 217/298 ━━━━━━━━━━━━━━━━━━━━ 03:36:23\n",
      "Accuracy: 0.9908 - Precision: 0.9412 - Recall: 0.5899 - Specificity: 0.9992 - F1: 0.7104 - Loss: 0.0021\n",
      "\n",
      "Batch 218/298 ━━━━━━━━━━━━━━━━━━━━ 03:36:31\n",
      "Accuracy: 0.9908 - Precision: 0.9413 - Recall: 0.5896 - Specificity: 0.9993 - F1: 0.7103 - Loss: 0.0021\n",
      "\n",
      "Batch 219/298 ━━━━━━━━━━━━━━━━━━━━ 03:36:39\n",
      "Accuracy: 0.9907 - Precision: 0.9412 - Recall: 0.5892 - Specificity: 0.9992 - F1: 0.7100 - Loss: 0.0021\n",
      "\n",
      "Batch 220/298 ━━━━━━━━━━━━━━━━━━━━ 03:36:47\n",
      "Accuracy: 0.9907 - Precision: 0.9412 - Recall: 0.5891 - Specificity: 0.9992 - F1: 0.7100 - Loss: 0.0021\n",
      "\n",
      "Batch 221/298 ━━━━━━━━━━━━━━━━━━━━ 03:36:55\n",
      "Accuracy: 0.9907 - Precision: 0.9411 - Recall: 0.5894 - Specificity: 0.9992 - F1: 0.7103 - Loss: 0.0021\n",
      "\n",
      "Batch 222/298 ━━━━━━━━━━━━━━━━━━━━ 03:37:03\n",
      "Accuracy: 0.9907 - Precision: 0.9405 - Recall: 0.5896 - Specificity: 0.9992 - F1: 0.7103 - Loss: 0.0021\n",
      "\n",
      "Batch 223/298 ━━━━━━━━━━━━━━━━━━━━ 03:37:11\n",
      "Accuracy: 0.9907 - Precision: 0.9400 - Recall: 0.5900 - Specificity: 0.9992 - F1: 0.7104 - Loss: 0.0021\n",
      "\n",
      "Batch 224/298 ━━━━━━━━━━━━━━━━━━━━ 03:37:19\n",
      "Accuracy: 0.9907 - Precision: 0.9401 - Recall: 0.5902 - Specificity: 0.9992 - F1: 0.7107 - Loss: 0.0021\n",
      "\n",
      "Batch 225/298 ━━━━━━━━━━━━━━━━━━━━ 03:37:27\n",
      "Accuracy: 0.9907 - Precision: 0.9400 - Recall: 0.5899 - Specificity: 0.9992 - F1: 0.7105 - Loss: 0.0021\n",
      "\n",
      "Batch 226/298 ━━━━━━━━━━━━━━━━━━━━ 03:37:35\n",
      "Accuracy: 0.9907 - Precision: 0.9401 - Recall: 0.5892 - Specificity: 0.9992 - F1: 0.7100 - Loss: 0.0021\n",
      "\n",
      "Batch 227/298 ━━━━━━━━━━━━━━━━━━━━ 03:37:43\n",
      "Accuracy: 0.9907 - Precision: 0.9403 - Recall: 0.5884 - Specificity: 0.9992 - F1: 0.7094 - Loss: 0.0021\n",
      "\n",
      "Batch 228/298 ━━━━━━━━━━━━━━━━━━━━ 03:37:51\n",
      "Accuracy: 0.9906 - Precision: 0.9404 - Recall: 0.5879 - Specificity: 0.9992 - F1: 0.7091 - Loss: 0.0021\n",
      "\n",
      "Batch 229/298 ━━━━━━━━━━━━━━━━━━━━ 03:37:59\n",
      "Accuracy: 0.9906 - Precision: 0.9406 - Recall: 0.5867 - Specificity: 0.9992 - F1: 0.7080 - Loss: 0.0021\n",
      "\n",
      "Batch 230/298 ━━━━━━━━━━━━━━━━━━━━ 03:38:07\n",
      "Accuracy: 0.9906 - Precision: 0.9408 - Recall: 0.5859 - Specificity: 0.9992 - F1: 0.7074 - Loss: 0.0021\n",
      "\n",
      "Batch 231/298 ━━━━━━━━━━━━━━━━━━━━ 03:38:15\n",
      "Accuracy: 0.9906 - Precision: 0.9409 - Recall: 0.5853 - Specificity: 0.9992 - F1: 0.7071 - Loss: 0.0021\n",
      "\n",
      "Batch 232/298 ━━━━━━━━━━━━━━━━━━━━ 03:38:23\n",
      "Accuracy: 0.9906 - Precision: 0.9409 - Recall: 0.5844 - Specificity: 0.9992 - F1: 0.7063 - Loss: 0.0021\n",
      "\n",
      "Batch 233/298 ━━━━━━━━━━━━━━━━━━━━ 03:38:31\n",
      "Accuracy: 0.9905 - Precision: 0.9407 - Recall: 0.5832 - Specificity: 0.9992 - F1: 0.7052 - Loss: 0.0022\n",
      "\n",
      "Batch 234/298 ━━━━━━━━━━━━━━━━━━━━ 03:38:39\n",
      "Accuracy: 0.9905 - Precision: 0.9407 - Recall: 0.5826 - Specificity: 0.9992 - F1: 0.7047 - Loss: 0.0022\n",
      "\n",
      "Batch 235/298 ━━━━━━━━━━━━━━━━━━━━ 03:38:47\n",
      "Accuracy: 0.9904 - Precision: 0.9406 - Recall: 0.5817 - Specificity: 0.9992 - F1: 0.7040 - Loss: 0.0022\n",
      "\n",
      "Batch 236/298 ━━━━━━━━━━━━━━━━━━━━ 03:38:55\n",
      "Accuracy: 0.9904 - Precision: 0.9405 - Recall: 0.5814 - Specificity: 0.9992 - F1: 0.7038 - Loss: 0.0022\n",
      "\n",
      "Batch 237/298 ━━━━━━━━━━━━━━━━━━━━ 03:39:03\n",
      "Accuracy: 0.9903 - Precision: 0.9404 - Recall: 0.5810 - Specificity: 0.9992 - F1: 0.7035 - Loss: 0.0022\n",
      "\n",
      "Batch 238/298 ━━━━━━━━━━━━━━━━━━━━ 03:39:11\n",
      "Accuracy: 0.9903 - Precision: 0.9402 - Recall: 0.5803 - Specificity: 0.9992 - F1: 0.7030 - Loss: 0.0022\n",
      "\n",
      "Batch 239/298 ━━━━━━━━━━━━━━━━━━━━ 03:39:19\n",
      "Accuracy: 0.9903 - Precision: 0.9401 - Recall: 0.5804 - Specificity: 0.9992 - F1: 0.7031 - Loss: 0.0022\n",
      "\n",
      "Batch 240/298 ━━━━━━━━━━━━━━━━━━━━ 03:39:27\n",
      "Accuracy: 0.9900 - Precision: 0.9399 - Recall: 0.5784 - Specificity: 0.9992 - F1: 0.7009 - Loss: 0.0023\n",
      "\n",
      "Batch 241/298 ━━━━━━━━━━━━━━━━━━━━ 03:39:35\n",
      "Accuracy: 0.9898 - Precision: 0.9397 - Recall: 0.5766 - Specificity: 0.9992 - F1: 0.6990 - Loss: 0.0023\n",
      "\n",
      "Batch 242/298 ━━━━━━━━━━━━━━━━━━━━ 03:39:43\n",
      "Accuracy: 0.9895 - Precision: 0.9398 - Recall: 0.5749 - Specificity: 0.9992 - F1: 0.6973 - Loss: 0.0024\n",
      "\n",
      "Batch 243/298 ━━━━━━━━━━━━━━━━━━━━ 03:39:50\n",
      "Accuracy: 0.9892 - Precision: 0.9396 - Recall: 0.5734 - Specificity: 0.9992 - F1: 0.6958 - Loss: 0.0024\n",
      "\n",
      "Batch 244/298 ━━━━━━━━━━━━━━━━━━━━ 03:39:58\n",
      "Accuracy: 0.9890 - Precision: 0.9395 - Recall: 0.5721 - Specificity: 0.9992 - F1: 0.6946 - Loss: 0.0025\n",
      "\n",
      "Batch 245/298 ━━━━━━━━━━━━━━━━━━━━ 03:40:06\n",
      "Accuracy: 0.9888 - Precision: 0.9389 - Recall: 0.5715 - Specificity: 0.9992 - F1: 0.6940 - Loss: 0.0026\n",
      "\n",
      "Batch 246/298 ━━━━━━━━━━━━━━━━━━━━ 03:40:14\n",
      "Accuracy: 0.9886 - Precision: 0.9380 - Recall: 0.5708 - Specificity: 0.9991 - F1: 0.6933 - Loss: 0.0026\n",
      "\n",
      "Batch 247/298 ━━━━━━━━━━━━━━━━━━━━ 03:40:22\n",
      "Accuracy: 0.9885 - Precision: 0.9368 - Recall: 0.5699 - Specificity: 0.9991 - F1: 0.6923 - Loss: 0.0027\n",
      "\n",
      "Batch 248/298 ━━━━━━━━━━━━━━━━━━━━ 03:40:30\n",
      "Accuracy: 0.9882 - Precision: 0.9368 - Recall: 0.5687 - Specificity: 0.9991 - F1: 0.6912 - Loss: 0.0027\n",
      "\n",
      "Batch 249/298 ━━━━━━━━━━━━━━━━━━━━ 03:40:38\n",
      "Accuracy: 0.9879 - Precision: 0.9366 - Recall: 0.5672 - Specificity: 0.9990 - F1: 0.6897 - Loss: 0.0028\n",
      "\n",
      "Batch 250/298 ━━━━━━━━━━━━━━━━━━━━ 03:40:46\n",
      "Accuracy: 0.9877 - Precision: 0.9367 - Recall: 0.5656 - Specificity: 0.9991 - F1: 0.6881 - Loss: 0.0028\n",
      "\n",
      "Batch 251/298 ━━━━━━━━━━━━━━━━━━━━ 03:40:54\n",
      "Accuracy: 0.9876 - Precision: 0.9362 - Recall: 0.5641 - Specificity: 0.9990 - F1: 0.6866 - Loss: 0.0028\n",
      "\n",
      "Batch 252/298 ━━━━━━━━━━━━━━━━━━━━ 03:41:02\n",
      "Accuracy: 0.9873 - Precision: 0.9361 - Recall: 0.5622 - Specificity: 0.9990 - F1: 0.6846 - Loss: 0.0029\n",
      "\n",
      "Batch 253/298 ━━━━━━━━━━━━━━━━━━━━ 03:41:10\n",
      "Accuracy: 0.9872 - Precision: 0.9355 - Recall: 0.5606 - Specificity: 0.9990 - F1: 0.6828 - Loss: 0.0029\n",
      "\n",
      "Batch 254/298 ━━━━━━━━━━━━━━━━━━━━ 03:41:18\n",
      "Accuracy: 0.9869 - Precision: 0.9348 - Recall: 0.5591 - Specificity: 0.9990 - F1: 0.6812 - Loss: 0.0030\n",
      "\n",
      "Batch 255/298 ━━━━━━━━━━━━━━━━━━━━ 03:41:26\n",
      "Accuracy: 0.9866 - Precision: 0.9346 - Recall: 0.5577 - Specificity: 0.9990 - F1: 0.6799 - Loss: 0.0030\n",
      "\n",
      "Batch 256/298 ━━━━━━━━━━━━━━━━━━━━ 03:41:34\n",
      "Accuracy: 0.9864 - Precision: 0.9340 - Recall: 0.5565 - Specificity: 0.9990 - F1: 0.6787 - Loss: 0.0031\n",
      "\n",
      "Batch 257/298 ━━━━━━━━━━━━━━━━━━━━ 03:41:42\n",
      "Accuracy: 0.9863 - Precision: 0.9326 - Recall: 0.5556 - Specificity: 0.9989 - F1: 0.6777 - Loss: 0.0031\n",
      "\n",
      "Batch 258/298 ━━━━━━━━━━━━━━━━━━━━ 03:41:49\n",
      "Accuracy: 0.9861 - Precision: 0.9299 - Recall: 0.5540 - Specificity: 0.9989 - F1: 0.6758 - Loss: 0.0032\n",
      "\n",
      "Batch 259/298 ━━━━━━━━━━━━━━━━━━━━ 03:41:57\n",
      "Accuracy: 0.9861 - Precision: 0.9276 - Recall: 0.5523 - Specificity: 0.9989 - F1: 0.6739 - Loss: 0.0032\n",
      "\n",
      "Batch 260/298 ━━━━━━━━━━━━━━━━━━━━ 03:42:05\n",
      "Accuracy: 0.9861 - Precision: 0.9264 - Recall: 0.5508 - Specificity: 0.9989 - F1: 0.6722 - Loss: 0.0032\n",
      "\n",
      "Batch 261/298 ━━━━━━━━━━━━━━━━━━━━ 03:42:13\n",
      "Accuracy: 0.9860 - Precision: 0.9264 - Recall: 0.5489 - Specificity: 0.9989 - F1: 0.6701 - Loss: 0.0032\n",
      "\n",
      "Batch 262/298 ━━━━━━━━━━━━━━━━━━━━ 03:42:21\n",
      "Accuracy: 0.9859 - Precision: 0.9267 - Recall: 0.5469 - Specificity: 0.9989 - F1: 0.6676 - Loss: 0.0033\n",
      "\n",
      "Batch 263/298 ━━━━━━━━━━━━━━━━━━━━ 03:42:29\n",
      "Accuracy: 0.9858 - Precision: 0.9263 - Recall: 0.5449 - Specificity: 0.9989 - F1: 0.6652 - Loss: 0.0033\n",
      "\n",
      "Batch 264/298 ━━━━━━━━━━━━━━━━━━━━ 03:42:37\n",
      "Accuracy: 0.9857 - Precision: 0.9266 - Recall: 0.5429 - Specificity: 0.9989 - F1: 0.6629 - Loss: 0.0033\n",
      "\n",
      "Batch 265/298 ━━━━━━━━━━━━━━━━━━━━ 03:42:45\n",
      "Accuracy: 0.9857 - Precision: 0.9262 - Recall: 0.5409 - Specificity: 0.9989 - F1: 0.6605 - Loss: 0.0034\n",
      "\n",
      "Batch 266/298 ━━━━━━━━━━━━━━━━━━━━ 03:42:52\n",
      "Accuracy: 0.9856 - Precision: 0.9264 - Recall: 0.5390 - Specificity: 0.9989 - F1: 0.6582 - Loss: 0.0034\n",
      "\n",
      "Batch 267/298 ━━━━━━━━━━━━━━━━━━━━ 03:43:00\n",
      "Accuracy: 0.9856 - Precision: 0.9267 - Recall: 0.5370 - Specificity: 0.9989 - F1: 0.6558 - Loss: 0.0034\n",
      "\n",
      "Batch 268/298 ━━━━━━━━━━━━━━━━━━━━ 03:43:08\n",
      "Accuracy: 0.9855 - Precision: 0.9269 - Recall: 0.5350 - Specificity: 0.9989 - F1: 0.6534 - Loss: 0.0034\n",
      "\n",
      "Batch 269/298 ━━━━━━━━━━━━━━━━━━━━ 03:43:16\n",
      "Accuracy: 0.9855 - Precision: 0.9251 - Recall: 0.5330 - Specificity: 0.9989 - F1: 0.6510 - Loss: 0.0034\n",
      "\n",
      "Batch 270/298 ━━━━━━━━━━━━━━━━━━━━ 03:43:23\n",
      "Accuracy: 0.9855 - Precision: 0.9254 - Recall: 0.5311 - Specificity: 0.9989 - F1: 0.6486 - Loss: 0.0035\n",
      "\n",
      "Batch 271/298 ━━━━━━━━━━━━━━━━━━━━ 03:43:32\n",
      "Accuracy: 0.9854 - Precision: 0.9257 - Recall: 0.5291 - Specificity: 0.9989 - F1: 0.6462 - Loss: 0.0035\n",
      "\n",
      "Batch 272/298 ━━━━━━━━━━━━━━━━━━━━ 03:43:39\n",
      "Accuracy: 0.9854 - Precision: 0.9259 - Recall: 0.5272 - Specificity: 0.9989 - F1: 0.6439 - Loss: 0.0035\n",
      "\n",
      "Batch 273/298 ━━━━━━━━━━━━━━━━━━━━ 03:43:48\n",
      "Accuracy: 0.9853 - Precision: 0.9262 - Recall: 0.5253 - Specificity: 0.9989 - F1: 0.6416 - Loss: 0.0035\n",
      "\n",
      "Batch 274/298 ━━━━━━━━━━━━━━━━━━━━ 03:43:56\n",
      "Accuracy: 0.9853 - Precision: 0.9255 - Recall: 0.5234 - Specificity: 0.9989 - F1: 0.6393 - Loss: 0.0035\n",
      "\n",
      "Batch 275/298 ━━━━━━━━━━━━━━━━━━━━ 03:44:04\n",
      "Accuracy: 0.9852 - Precision: 0.9258 - Recall: 0.5215 - Specificity: 0.9989 - F1: 0.6370 - Loss: 0.0035\n",
      "\n",
      "Batch 276/298 ━━━━━━━━━━━━━━━━━━━━ 03:44:11\n",
      "Accuracy: 0.9852 - Precision: 0.9253 - Recall: 0.5196 - Specificity: 0.9989 - F1: 0.6347 - Loss: 0.0035\n",
      "\n",
      "Batch 277/298 ━━━━━━━━━━━━━━━━━━━━ 03:44:19\n",
      "Accuracy: 0.9852 - Precision: 0.9220 - Recall: 0.5177 - Specificity: 0.9989 - F1: 0.6324 - Loss: 0.0035\n",
      "\n",
      "Batch 278/298 ━━━━━━━━━━━━━━━━━━━━ 03:44:27\n",
      "Accuracy: 0.9851 - Precision: 0.9223 - Recall: 0.5159 - Specificity: 0.9989 - F1: 0.6301 - Loss: 0.0036\n",
      "\n",
      "Batch 279/298 ━━━━━━━━━━━━━━━━━━━━ 03:44:35\n",
      "Accuracy: 0.9851 - Precision: 0.9225 - Recall: 0.5140 - Specificity: 0.9989 - F1: 0.6279 - Loss: 0.0036\n",
      "\n",
      "Batch 280/298 ━━━━━━━━━━━━━━━━━━━━ 03:44:43\n",
      "Accuracy: 0.9851 - Precision: 0.9210 - Recall: 0.5122 - Specificity: 0.9989 - F1: 0.6256 - Loss: 0.0036\n",
      "\n",
      "Batch 281/298 ━━━━━━━━━━━━━━━━━━━━ 03:44:51\n",
      "Accuracy: 0.9851 - Precision: 0.9177 - Recall: 0.5104 - Specificity: 0.9989 - F1: 0.6234 - Loss: 0.0036\n",
      "\n",
      "Batch 282/298 ━━━━━━━━━━━━━━━━━━━━ 03:44:59\n",
      "Accuracy: 0.9850 - Precision: 0.9180 - Recall: 0.5086 - Specificity: 0.9989 - F1: 0.6212 - Loss: 0.0036\n",
      "\n",
      "Batch 283/298 ━━━━━━━━━━━━━━━━━━━━ 03:45:07\n",
      "Accuracy: 0.9851 - Precision: 0.9148 - Recall: 0.5068 - Specificity: 0.9989 - F1: 0.6190 - Loss: 0.0036\n",
      "\n",
      "Batch 284/298 ━━━━━━━━━━━━━━━━━━━━ 03:45:14\n",
      "Accuracy: 0.9850 - Precision: 0.9151 - Recall: 0.5050 - Specificity: 0.9989 - F1: 0.6168 - Loss: 0.0036\n",
      "\n",
      "Batch 285/298 ━━━━━━━━━━━━━━━━━━━━ 03:45:22\n",
      "Accuracy: 0.9850 - Precision: 0.9150 - Recall: 0.5033 - Specificity: 0.9990 - F1: 0.6148 - Loss: 0.0036\n",
      "\n",
      "Batch 286/298 ━━━━━━━━━━━━━━━━━━━━ 03:45:31\n",
      "Accuracy: 0.9850 - Precision: 0.9153 - Recall: 0.5015 - Specificity: 0.9990 - F1: 0.6127 - Loss: 0.0036\n",
      "\n",
      "Batch 287/298 ━━━━━━━━━━━━━━━━━━━━ 03:45:39\n",
      "Accuracy: 0.9849 - Precision: 0.9156 - Recall: 0.4998 - Specificity: 0.9990 - F1: 0.6106 - Loss: 0.0036\n",
      "\n",
      "Batch 288/298 ━━━━━━━━━━━━━━━━━━━━ 03:45:47\n",
      "Accuracy: 0.9849 - Precision: 0.9159 - Recall: 0.4981 - Specificity: 0.9990 - F1: 0.6085 - Loss: 0.0036\n",
      "\n",
      "Batch 289/298 ━━━━━━━━━━━━━━━━━━━━ 03:45:55\n",
      "Accuracy: 0.9848 - Precision: 0.9160 - Recall: 0.4964 - Specificity: 0.9990 - F1: 0.6064 - Loss: 0.0036\n",
      "\n",
      "Batch 290/298 ━━━━━━━━━━━━━━━━━━━━ 03:46:03\n",
      "Accuracy: 0.9848 - Precision: 0.9155 - Recall: 0.4947 - Specificity: 0.9990 - F1: 0.6044 - Loss: 0.0036\n",
      "\n",
      "Batch 291/298 ━━━━━━━━━━━━━━━━━━━━ 03:46:10\n",
      "Accuracy: 0.9848 - Precision: 0.9157 - Recall: 0.4931 - Specificity: 0.9990 - F1: 0.6024 - Loss: 0.0036\n",
      "\n",
      "Batch 292/298 ━━━━━━━━━━━━━━━━━━━━ 03:46:18\n",
      "Accuracy: 0.9847 - Precision: 0.9152 - Recall: 0.4915 - Specificity: 0.9990 - F1: 0.6006 - Loss: 0.0036\n",
      "\n",
      "Batch 293/298 ━━━━━━━━━━━━━━━━━━━━ 03:46:26\n",
      "Accuracy: 0.9847 - Precision: 0.9152 - Recall: 0.4900 - Specificity: 0.9990 - F1: 0.5988 - Loss: 0.0037\n",
      "\n",
      "Batch 294/298 ━━━━━━━━━━━━━━━━━━━━ 03:46:34\n",
      "Accuracy: 0.9847 - Precision: 0.9155 - Recall: 0.4884 - Specificity: 0.9990 - F1: 0.5969 - Loss: 0.0037\n",
      "\n",
      "Batch 295/298 ━━━━━━━━━━━━━━━━━━━━ 03:46:42\n",
      "Accuracy: 0.9846 - Precision: 0.9154 - Recall: 0.4868 - Specificity: 0.9990 - F1: 0.5950 - Loss: 0.0037\n",
      "\n",
      "Batch 296/298 ━━━━━━━━━━━━━━━━━━━━ 03:46:50\n",
      "Accuracy: 0.9846 - Precision: 0.9155 - Recall: 0.4853 - Specificity: 0.9990 - F1: 0.5934 - Loss: 0.0037\n",
      "\n",
      "Batch 297/298 ━━━━━━━━━━━━━━━━━━━━ 03:46:58\n",
      "Accuracy: 0.9846 - Precision: 0.9157 - Recall: 0.4839 - Specificity: 0.9990 - F1: 0.5917 - Loss: 0.0037\n",
      "\n",
      "Batch 298/298 ━━━━━━━━━━━━━━━━━━━━ 03:47:06\n",
      "Accuracy: 0.9845 - Precision: 0.9159 - Recall: 0.4823 - Specificity: 0.9990 - F1: 0.5899 - Loss: 0.0037\n",
      "\n",
      "Epoch 20/20\n",
      "Validation - Accuracy: 0.9800, Precision: 0.9426, Recall: 0.0741, Specificity: 0.9999, F1: 0.1368, Loss: 0.0044\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 3s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import plotly.figure_factory as ff  # For confusion matrix plot\n",
    "\n",
    "# Directory paths\n",
    "train_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\train\"\n",
    "train_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\train\\train_mask\"\n",
    "test_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\test\"\n",
    "test_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\test\\test_mask\"\n",
    "valid_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\valid\"\n",
    "valid_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\valid\\valid_mask\"\n",
    "\n",
    "# Image generator to load data in batches\n",
    "def image_generator(img_dir, mask_dir, batch_size, img_size=(256, 256)):\n",
    "    img_files = os.listdir(img_dir)\n",
    "    while True:\n",
    "        images = []\n",
    "        masks = []\n",
    "        for img_file in img_files:\n",
    "            img_path = os.path.join(img_dir, img_file)\n",
    "            mask_file = img_file + \"_mask.png\"\n",
    "            mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "            if os.path.exists(mask_path):\n",
    "                # Load image and mask\n",
    "                img = load_img(img_path, color_mode='rgb', target_size=img_size)\n",
    "                img = img_to_array(img) / 255.0\n",
    "                mask = load_img(mask_path, color_mode='grayscale', target_size=img_size)\n",
    "                mask = img_to_array(mask) / 255.0\n",
    "\n",
    "                images.append(img)\n",
    "                masks.append(mask)\n",
    "\n",
    "            if len(images) == batch_size:\n",
    "                yield np.array(images), np.array(masks)\n",
    "                images = []\n",
    "                masks = []\n",
    "\n",
    "# VGG16-based model replacing U-Net\n",
    "def vgg16_unet_model(input_size=(256, 256, 3)):\n",
    "    # Load VGG16 as the encoder with pre-trained ImageNet weights\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=input_size)\n",
    "    \n",
    "    # Freeze VGG16 layers to prevent them from being trained\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Extract layers for skip connections\n",
    "    block1 = vgg16.get_layer('block1_pool').output   # 128x128\n",
    "    block2 = vgg16.get_layer('block2_pool').output   # 64x64\n",
    "    block3 = vgg16.get_layer('block3_pool').output   # 32x32\n",
    "    block4 = vgg16.get_layer('block4_pool').output   # 16x16\n",
    "    block5 = vgg16.get_layer('block5_pool').output   # 8x8\n",
    "    \n",
    "    # Decoder\n",
    "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(block5)  # 16x16\n",
    "    u6 = layers.concatenate([u6, block4])\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "    \n",
    "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)  # 32x32\n",
    "    u7 = layers.concatenate([u7, block3])\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "    \n",
    "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)  # 64x64\n",
    "    u8 = layers.concatenate([u8, block2])\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "    \n",
    "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)    # 128x128\n",
    "    u9 = layers.concatenate([u9, block1])\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "    \n",
    "    # Final upsampling to reach original image size\n",
    "    u10 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c9)  # 256x256\n",
    "    c10 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u10)\n",
    "    c10 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c10)\n",
    "    \n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c10)\n",
    "    \n",
    "    model = models.Model(inputs=vgg16.input, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define custom metrics\n",
    "def custom_precision(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_positives = K.sum(K.round(y_true * y_pred_bin))\n",
    "    predicted_positives = K.sum(y_pred_bin)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def custom_recall(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_positives = K.sum(K.round(y_true * y_pred_bin))\n",
    "    possible_positives = K.sum(y_true)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def custom_specificity(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_negatives = K.sum(K.round((1 - y_true) * (1 - y_pred_bin)))\n",
    "    possible_negatives = K.sum(1 - y_true)\n",
    "    specificity = true_negatives / (possible_negatives + K.epsilon())\n",
    "    return specificity\n",
    "\n",
    "def custom_f1(y_true, y_pred):\n",
    "    precision = custom_precision(y_true, y_pred)\n",
    "    recall = custom_recall(y_true, y_pred)\n",
    "    return 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "\n",
    "# Define Focal Loss\n",
    "def focal_loss_fixed(y_true, y_pred):\n",
    "    gamma = 2.0\n",
    "    alpha = 0.25\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    cross_entropy = -y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred)\n",
    "    weight = alpha * y_true * K.pow((1 - y_pred), gamma) + (1 - alpha) * (1 - y_true) * K.pow(y_pred, gamma)\n",
    "    loss = weight * cross_entropy\n",
    "    return K.mean(loss)\n",
    "\n",
    "# Compile the model\n",
    "model = vgg16_unet_model()\n",
    "model.compile(optimizer='adam', loss=focal_loss_fixed, metrics=['accuracy', custom_precision, custom_recall, custom_specificity, custom_f1])\n",
    "\n",
    "# Batch size for training\n",
    "batch_size = 16\n",
    "\n",
    "# Create data generators\n",
    "train_gen = image_generator(train_img_dir, train_mask_dir, batch_size)\n",
    "valid_gen = image_generator(valid_img_dir, valid_mask_dir, batch_size)\n",
    "test_gen = image_generator(test_img_dir, test_mask_dir, batch_size)\n",
    "\n",
    "# Number of steps per epoch\n",
    "steps_per_epoch = len(os.listdir(train_img_dir)) // batch_size\n",
    "validation_steps = len(os.listdir(valid_img_dir)) // batch_size\n",
    "test_steps = len(os.listdir(test_img_dir)) // batch_size\n",
    "\n",
    "# Custom callback to print more metrics at each batch and epoch for training, validation, and test sets\n",
    "class MetricsCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, total_batches, X_valid, X_test):\n",
    "        super().__init__()\n",
    "        self.batch_counter = 1\n",
    "        self.total_batches = total_batches\n",
    "        self.current_epoch = 1\n",
    "        self.X_valid = X_valid\n",
    "        self.X_test = X_test\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.current_epoch = epoch + 1\n",
    "        print(f\"\\nEpoch {self.current_epoch}/{self.params['epochs']}\")\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        accuracy = logs.get('accuracy', 0)\n",
    "        loss = logs.get('loss', 0)\n",
    "        precision = logs.get('custom_precision', 0)\n",
    "        recall = logs.get('custom_recall', 0)\n",
    "        f1 = logs.get('custom_f1', 0)\n",
    "        specificity = logs.get('custom_specificity', 0)\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print(f\"Batch {self.batch_counter}/{self.total_batches} ━━━━━━━━━━━━━━━━━━━━ {current_time}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f} - Precision: {precision:.4f} - Recall: {recall:.4f} - Specificity: {specificity:.4f} - F1: {f1:.4f} - Loss: {loss:.4f}\\n\")\n",
    "        self.batch_counter += 1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        accuracy = logs.get('accuracy', 0)\n",
    "        val_accuracy = logs.get('val_accuracy', 0)\n",
    "        loss = logs.get('loss', 0)\n",
    "        val_loss = logs.get('val_loss', 0)\n",
    "        precision = logs.get('custom_precision', 0)\n",
    "        val_precision = logs.get('val_custom_precision', 0)\n",
    "        recall = logs.get('custom_recall', 0)\n",
    "        val_recall = logs.get('val_custom_recall', 0)\n",
    "        f1 = logs.get('custom_f1', 0)\n",
    "        val_f1 = logs.get('val_custom_f1', 0)\n",
    "        specificity = logs.get('custom_specificity', 0)\n",
    "        val_specificity = logs.get('val_custom_specificity', 0)\n",
    "        print(f\"Epoch {epoch+1}/{self.params['epochs']}\")\n",
    "        #print(f\"Train - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Specificity: {specificity:.4f}, F1: {f1:.4f}, Loss: {loss:.4f}\")\n",
    "        print(f\"Validation - Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, Specificity: {val_specificity:.4f}, F1: {val_f1:.4f}, Loss: {val_loss:.4f}\\n\")\n",
    "\n",
    "        self.batch_counter = 1\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Initialize the custom callback with validation and test data\n",
    "metrics_callback = MetricsCallback(total_batches=steps_per_epoch, X_valid=valid_gen, X_test=test_gen)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=20,\n",
    "    validation_data=valid_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[metrics_callback, early_stopping],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('dental_xray_vgg16_unet_model.h5')\n",
    "\n",
    "# Evaluate on the test set **only after training is fully completed**\n",
    "y_test_pred = model.predict(test_gen, steps=test_steps)\n",
    "y_test_pred_bin = (y_test_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "# Visualization: Show input image, true mask, and predicted mask for TEST set only\n",
    "def visualize_predictions(images, true_masks, pred_masks, title):\n",
    "    for i in range(3):  # Visualize first 3 predictions\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # Original image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "        \n",
    "        # Ground truth mask\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(true_masks[i].squeeze(), cmap='gray')\n",
    "        plt.title('Ground Truth Mask')\n",
    "        \n",
    "        # Predicted mask\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(pred_masks[i].squeeze(), cmap='gray')\n",
    "        plt.title('Predicted Mask')\n",
    "        \n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "\n",
    "# Visualize predictions for test set only\n",
    "X_test, y_test = next(test_gen)\n",
    "visualize_predictions(X_test, y_test, y_test_pred_bin, \"Test Set Predictions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d67d36-759e-40b5-89dd-17ac7b0bf1ac",
   "metadata": {},
   "source": [
    "* Runtime: 31884 seconds (8.85 hours)!\n",
    "* Recall is too low!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542910ce-327d-47b9-9fe1-94b065ff9591",
   "metadata": {},
   "outputs": [],
   "source": []
=======
>>>>>>> 09cd13ea (add)
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
