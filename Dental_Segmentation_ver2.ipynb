{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db7f5694-0010-4ae4-b431-d39f5e058626",
   "metadata": {},
   "source": [
    "## U-Net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f7601e-b8b2-4d72-b3eb-6ac538958c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask not found for train_mask, skipping this image.\n",
      "Mask not found for valid_mask, skipping this image.\n",
      "\n",
      "Epoch 1/20\n",
      "Batch 1/299 ━━━━━━━━━━━━━━━━━━━━ 12:41:20\n",
      "Accuracy: 0.1233 - Precision: 0.0415 - Recall: 0.9663 - Specificity: 0.0888 - F1: 0.0796 - Loss: 0.1293\n",
      "\n",
      "Batch 2/299 ━━━━━━━━━━━━━━━━━━━━ 12:42:09\n",
      "Accuracy: 0.5499 - Precision: 0.0208 - Recall: 0.4831 - Specificity: 0.5444 - F1: 0.0398 - Loss: 0.1185\n",
      "\n",
      "Batch 3/299 ━━━━━━━━━━━━━━━━━━━━ 12:42:47\n",
      "Accuracy: 0.6912 - Precision: 0.0138 - Recall: 0.3221 - Specificity: 0.6963 - F1: 0.0265 - Loss: 0.1015\n",
      "\n",
      "Batch 4/299 ━━━━━━━━━━━━━━━━━━━━ 12:43:25\n",
      "Accuracy: 0.7590 - Precision: 0.0104 - Recall: 0.2416 - Specificity: 0.7722 - F1: 0.0199 - Loss: 0.0846\n",
      "\n",
      "Batch 5/299 ━━━━━━━━━━━━━━━━━━━━ 12:44:08\n",
      "Accuracy: 0.8026 - Precision: 0.0083 - Recall: 0.1933 - Specificity: 0.8178 - F1: 0.0159 - Loss: 0.0728\n",
      "\n",
      "Batch 6/299 ━━━━━━━━━━━━━━━━━━━━ 12:45:01\n",
      "Accuracy: 0.8313 - Precision: 0.0069 - Recall: 0.1610 - Specificity: 0.8481 - F1: 0.0133 - Loss: 0.0651\n",
      "\n",
      "Batch 7/299 ━━━━━━━━━━━━━━━━━━━━ 12:45:51\n",
      "Accuracy: 0.8505 - Precision: 0.0059 - Recall: 0.1380 - Specificity: 0.8698 - F1: 0.0114 - Loss: 0.0602\n",
      "\n",
      "Batch 8/299 ━━━━━━━━━━━━━━━━━━━━ 12:46:55\n",
      "Accuracy: 0.8644 - Precision: 0.0052 - Recall: 0.1208 - Specificity: 0.8861 - F1: 0.0099 - Loss: 0.0565\n",
      "\n",
      "Batch 9/299 ━━━━━━━━━━━━━━━━━━━━ 12:47:41\n",
      "Accuracy: 0.8771 - Precision: 0.0046 - Recall: 0.1074 - Specificity: 0.8988 - F1: 0.0088 - Loss: 0.0526\n",
      "\n",
      "Batch 10/299 ━━━━━━━━━━━━━━━━━━━━ 12:48:28\n",
      "Accuracy: 0.8875 - Precision: 0.0042 - Recall: 0.0966 - Specificity: 0.9089 - F1: 0.0080 - Loss: 0.0493\n",
      "\n",
      "Batch 11/299 ━━━━━━━━━━━━━━━━━━━━ 12:49:13\n",
      "Accuracy: 0.8960 - Precision: 0.0038 - Recall: 0.0878 - Specificity: 0.9172 - F1: 0.0072 - Loss: 0.0464\n",
      "\n",
      "Batch 12/299 ━━━━━━━━━━━━━━━━━━━━ 12:49:53\n",
      "Accuracy: 0.9028 - Precision: 0.0035 - Recall: 0.0805 - Specificity: 0.9241 - F1: 0.0066 - Loss: 0.0440\n",
      "\n",
      "Batch 13/299 ━━━━━━━━━━━━━━━━━━━━ 12:50:46\n",
      "Accuracy: 0.9082 - Precision: 0.0032 - Recall: 0.0743 - Specificity: 0.9299 - F1: 0.0061 - Loss: 0.0424\n",
      "\n",
      "Batch 14/299 ━━━━━━━━━━━━━━━━━━━━ 12:51:35\n",
      "Accuracy: 0.9132 - Precision: 0.0030 - Recall: 0.0690 - Specificity: 0.9349 - F1: 0.0057 - Loss: 0.0405\n",
      "\n",
      "Batch 15/299 ━━━━━━━━━━━━━━━━━━━━ 12:52:21\n",
      "Accuracy: 0.9172 - Precision: 0.0028 - Recall: 0.0644 - Specificity: 0.9393 - F1: 0.0053 - Loss: 0.0390\n",
      "\n",
      "Batch 16/299 ━━━━━━━━━━━━━━━━━━━━ 12:53:16\n",
      "Accuracy: 0.9203 - Precision: 0.0026 - Recall: 0.0604 - Specificity: 0.9431 - F1: 0.0050 - Loss: 0.0376\n",
      "\n",
      "Batch 17/299 ━━━━━━━━━━━━━━━━━━━━ 12:53:57\n",
      "Accuracy: 0.9239 - Precision: 0.0024 - Recall: 0.0568 - Specificity: 0.9464 - F1: 0.0047 - Loss: 0.0362\n",
      "\n",
      "Batch 18/299 ━━━━━━━━━━━━━━━━━━━━ 12:54:57\n",
      "Accuracy: 0.9261 - Precision: 0.0023 - Recall: 0.0537 - Specificity: 0.9494 - F1: 0.0044 - Loss: 0.0351\n",
      "\n",
      "Batch 19/299 ━━━━━━━━━━━━━━━━━━━━ 12:55:52\n",
      "Accuracy: 0.9289 - Precision: 0.0022 - Recall: 0.0509 - Specificity: 0.9520 - F1: 0.0042 - Loss: 0.0339\n",
      "\n",
      "Batch 20/299 ━━━━━━━━━━━━━━━━━━━━ 12:56:39\n",
      "Accuracy: 0.9314 - Precision: 0.0021 - Recall: 0.0483 - Specificity: 0.9544 - F1: 0.0040 - Loss: 0.0327\n",
      "\n",
      "Batch 21/299 ━━━━━━━━━━━━━━━━━━━━ 12:57:37\n",
      "Accuracy: 0.9338 - Precision: 0.0020 - Recall: 0.0460 - Specificity: 0.9566 - F1: 0.0038 - Loss: 0.0316\n",
      "\n",
      "Batch 22/299 ━━━━━━━━━━━━━━━━━━━━ 12:58:39\n",
      "Accuracy: 0.9357 - Precision: 0.0019 - Recall: 0.0439 - Specificity: 0.9586 - F1: 0.0036 - Loss: 0.0307\n",
      "\n",
      "Batch 23/299 ━━━━━━━━━━━━━━━━━━━━ 12:59:47\n",
      "Accuracy: 0.9378 - Precision: 0.0018 - Recall: 0.0420 - Specificity: 0.9604 - F1: 0.0035 - Loss: 0.0297\n",
      "\n",
      "Batch 24/299 ━━━━━━━━━━━━━━━━━━━━ 13:01:11\n",
      "Accuracy: 0.9392 - Precision: 0.0017 - Recall: 0.0403 - Specificity: 0.9620 - F1: 0.0033 - Loss: 0.0290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import backend as K\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime  # Import datetime for the custom callback\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.callbacks import EarlyStopping  # Import EarlyStopping\n",
    "\n",
    "# Directory paths\n",
    "train_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\train\"\n",
    "train_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\train\\train_mask\"\n",
    "test_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\test\"\n",
    "test_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\test\\test_mask\"\n",
    "valid_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\valid\"\n",
    "valid_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\valid\\valid_mask\"\n",
    "\n",
    "# U-Net model\n",
    "def unet_model(input_size=(256, 256, 1)):\n",
    "    inputs = layers.Input(input_size)\n",
    "    \n",
    "    # Downsample\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    # Upsample\n",
    "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = layers.concatenate([u6, c4])\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = layers.concatenate([u7, c3])\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = layers.concatenate([u8, c2])\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = layers.concatenate([u9, c1], axis=3)\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Load images and masks\n",
    "def load_images_and_masks(img_dir, mask_dir, img_size=(256, 256)):\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    img_files = os.listdir(img_dir)\n",
    "    for img_file in img_files:\n",
    "        img_path = os.path.join(img_dir, img_file)\n",
    "        # Adjust mask filename to include \"_mask.png\"\n",
    "        mask_file = img_file + \"_mask.png\"\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "        if os.path.exists(mask_path):\n",
    "            # Load image and mask\n",
    "            img = load_img(img_path, color_mode='grayscale', target_size=img_size)\n",
    "            img = img_to_array(img) / 255.0\n",
    "            mask = load_img(mask_path, color_mode='grayscale', target_size=img_size)\n",
    "            mask = img_to_array(mask) / 255.0\n",
    "\n",
    "            images.append(img)\n",
    "            masks.append(mask)\n",
    "        else:\n",
    "            print(f\"Mask not found for {img_file}, skipping this image.\")\n",
    "    \n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Load training and validation data\n",
    "X_train, y_train = load_images_and_masks(train_img_dir, train_mask_dir)\n",
    "X_valid, y_valid = load_images_and_masks(valid_img_dir, valid_mask_dir)\n",
    "\n",
    "# Define custom metrics\n",
    "def custom_precision(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_positives = K.sum(K.round(y_true * y_pred_bin))\n",
    "    predicted_positives = K.sum(y_pred_bin)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def custom_recall(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_positives = K.sum(K.round(y_true * y_pred_bin))\n",
    "    possible_positives = K.sum(y_true)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def custom_specificity(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_negatives = K.sum(K.round((1 - y_true) * (1 - y_pred_bin)))\n",
    "    possible_negatives = K.sum(1 - y_true)\n",
    "    specificity = true_negatives / (possible_negatives + K.epsilon())\n",
    "    return specificity\n",
    "\n",
    "def custom_f1(y_true, y_pred):\n",
    "    precision = custom_precision(y_true, y_pred)\n",
    "    recall = custom_recall(y_true, y_pred)\n",
    "    return 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "\n",
    "# Define Focal Loss\n",
    "def focal_loss_fixed(y_true, y_pred):\n",
    "    gamma = 2.0\n",
    "    alpha = 0.25\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    cross_entropy = -y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred)\n",
    "    weight = alpha * y_true * K.pow((1 - y_pred), gamma) + (1 - alpha) * (1 - y_true) * K.pow(y_pred, gamma)\n",
    "    loss = weight * cross_entropy\n",
    "    return K.mean(loss)\n",
    "\n",
    "# Compile the model\n",
    "model = unet_model()\n",
    "model.compile(optimizer='adam', loss=focal_loss_fixed, metrics=['accuracy', custom_precision, custom_recall, custom_specificity, custom_f1])\n",
    "\n",
    "# Batch size for training\n",
    "batch_size = 16\n",
    "\n",
    "# Calculate total batches for training\n",
    "total_batches = int(np.ceil(len(X_train) / batch_size))\n",
    "\n",
    "# Custom callback to print more metrics at each batch\n",
    "class MetricsCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, total_batches):\n",
    "        super().__init__()\n",
    "        self.batch_counter = 1  # Initialize the batch counter\n",
    "        self.total_batches = total_batches  # Total number of batches per epoch\n",
    "        self.current_epoch = 1  # Initialize current epoch\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.current_epoch = epoch + 1  # Epochs are zero-indexed\n",
    "        print(f\"\\nEpoch {self.current_epoch}/{self.params['epochs']}\")\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        accuracy = logs.get('accuracy', 0)\n",
    "        loss = logs.get('loss', 0)\n",
    "        precision = logs.get('custom_precision', 0)\n",
    "        recall = logs.get('custom_recall', 0)\n",
    "        f1 = logs.get('custom_f1', 0)\n",
    "        specificity = logs.get('custom_specificity', 0)\n",
    "        \n",
    "        # Time formatting for current step\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        # Print the metrics with proper formatting\n",
    "        print(f\"Batch {self.batch_counter}/{self.total_batches} ━━━━━━━━━━━━━━━━━━━━ {current_time}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f} - Precision: {precision:.4f} - Recall: {recall:.4f} - Specificity: {specificity:.4f} - F1: {f1:.4f} - Loss: {loss:.4f}\\n\")\n",
    "        \n",
    "        # Increment batch counter\n",
    "        self.batch_counter += 1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Reset batch counter at the end of each epoch\n",
    "        self.batch_counter = 1\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',        # Metric to monitor\n",
    "    patience=5,                # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored metric\n",
    ")\n",
    "\n",
    "# Initialize the custom callback\n",
    "metrics_callback = MetricsCallback(total_batches=total_batches)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,               # Number of epochs\n",
    "    batch_size=batch_size,   # Batch size of 16\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[metrics_callback, early_stopping],  # Add early_stopping to the callbacks list\n",
    "    verbose=0                # Suppress default Keras logging\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('dental_xray_unet_model.h5')\n",
    "\n",
    "# Load test data\n",
    "X_test, y_test = load_images_and_masks(test_img_dir, test_mask_dir)\n",
    "\n",
    "# Evaluate on the training set\n",
    "y_train_pred = model.predict(X_train, batch_size=batch_size)\n",
    "y_train_pred_bin = (y_train_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "# Confusion Matrix for training\n",
    "conf_matrix_train = confusion_matrix(y_train.flatten(), y_train_pred_bin.flatten())\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_train, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix for Train\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_valid_pred = model.predict(X_valid, batch_size=batch_size)\n",
    "y_valid_pred_bin = (y_valid_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "# Confusion Matrix for validation\n",
    "conf_matrix_valid = confusion_matrix(y_valid.flatten(), y_valid_pred_bin.flatten())\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_valid, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix for Validation\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred = model.predict(X_test, batch_size=batch_size)\n",
    "y_test_pred_bin = (y_test_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "# Confusion Matrix for testing\n",
    "conf_matrix_test = confusion_matrix(y_test.flatten(), y_test_pred_bin.flatten())\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_test, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix for Test\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Performance report for training set\n",
    "train_accuracy = accuracy_score(y_train.flatten(), y_train_pred_bin.flatten())\n",
    "train_recall = recall_score(y_train.flatten(), y_train_pred_bin.flatten())\n",
    "train_precision = precision_score(y_train.flatten(), y_train_pred_bin.flatten())\n",
    "train_f1 = f1_score(y_train.flatten(), y_train_pred_bin.flatten())\n",
    "train_tn, train_fp, train_fn, train_tp = confusion_matrix(y_train.flatten(), y_train_pred_bin.flatten()).ravel()\n",
    "train_specificity = train_tn / (train_tn + train_fp)\n",
    "\n",
    "print(f'Training Set Results:')\n",
    "print(f'Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Recall (Sensitivity): {train_recall:.4f}')\n",
    "print(f'Precision: {train_precision:.4f}')\n",
    "print(f'F1 Score: {train_f1:.4f}')\n",
    "print(f'Specificity: {train_specificity:.4f}')\n",
    "\n",
    "# Performance report for validation set\n",
    "valid_accuracy = accuracy_score(y_valid.flatten(), y_valid_pred_bin.flatten())\n",
    "valid_recall = recall_score(y_valid.flatten(), y_valid_pred_bin.flatten())\n",
    "valid_precision = precision_score(y_valid.flatten(), y_valid_pred_bin.flatten())\n",
    "valid_f1 = f1_score(y_valid.flatten(), y_valid_pred_bin.flatten())\n",
    "valid_tn, valid_fp, valid_fn, valid_tp = confusion_matrix(y_valid.flatten(), y_valid_pred_bin.flatten()).ravel()\n",
    "valid_specificity = valid_tn / (valid_tn + valid_fp)\n",
    "\n",
    "print(f'Validation Set Results:')\n",
    "print(f'Accuracy: {valid_accuracy:.4f}')\n",
    "print(f'Recall (Sensitivity): {valid_recall:.4f}')\n",
    "print(f'Precision: {valid_precision:.4f}')\n",
    "print(f'F1 Score: {valid_f1:.4f}')\n",
    "print(f'Specificity: {valid_specificity:.4f}')\n",
    "\n",
    "# Performance report for testing set\n",
    "test_accuracy = accuracy_score(y_test.flatten(), y_test_pred_bin.flatten())\n",
    "test_recall = recall_score(y_test.flatten(), y_test_pred_bin.flatten())\n",
    "test_precision = precision_score(y_test.flatten(), y_test_pred_bin.flatten())\n",
    "test_f1 = f1_score(y_test.flatten(), y_test_pred_bin.flatten())\n",
    "test_tn, test_fp, test_fn, test_tp = confusion_matrix(y_test.flatten(), y_test_pred_bin.flatten()).ravel()\n",
    "test_specificity = test_tn / (test_tn + test_fp)\n",
    "\n",
    "print(f'Testing Set Results:')\n",
    "print(f'Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Recall (Sensitivity): {test_recall:.4f}')\n",
    "print(f'Precision: {test_precision:.4f}')\n",
    "print(f'F1 Score: {test_f1:.4f}')\n",
    "print(f'Specificity: {test_specificity:.4f}')\n",
    "\n",
    "# Visualization: Show input image, true mask, and predicted mask for a few samples\n",
    "def visualize_predictions(images, true_masks, pred_masks, title):\n",
    "    for i in range(3):  # Visualize first 3 predictions\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # Original image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "        \n",
    "        # Ground truth mask\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(true_masks[i].squeeze(), cmap='gray')\n",
    "        plt.title('Ground Truth Mask')\n",
    "        \n",
    "        # Predicted mask\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(pred_masks[i].squeeze(), cmap='gray')\n",
    "        plt.title('Predicted Mask')\n",
    "        \n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "\n",
    "# Visualize predictions for training set\n",
    "visualize_predictions(X_train, y_train, y_train_pred_bin, \"Train Set Predictions\")\n",
    "\n",
    "# Visualize predictions for validation set\n",
    "visualize_predictions(X_valid, y_valid, y_valid_pred_bin, \"Validation Set Predictions\")\n",
    "\n",
    "# Visualize predictions for testing set\n",
    "visualize_predictions(X_test, y_test, y_test_pred_bin, \"Test Set Predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38478de5-3f19-480b-bd58-772706f6eda2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4acdd3-a082-4a66-bb4a-798527bbdb66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b04868de-2443-4254-a327-45a5d2c84fcf",
   "metadata": {},
   "source": [
    "## VGG16 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819c473b-2c57-40de-981a-293ca839c79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask not found for train_mask, skipping this image.\n",
      "Mask not found for valid_mask, skipping this image.\n",
      "\n",
      "Epoch 1/20\n",
      "Batch 1/299 ━━━━━━━━━━━━━━━━━━━━ 13:13:53\n",
      "Accuracy: 0.9514 - Precision: 0.0494 - Recall: 0.0375 - Specificity: 0.9785 - F1: 0.0426 - Loss: 0.0644\n",
      "\n",
      "Batch 2/299 ━━━━━━━━━━━━━━━━━━━━ 13:14:03\n",
      "Accuracy: 0.9619 - Precision: 0.0247 - Recall: 0.0187 - Specificity: 0.9893 - F1: 0.0213 - Loss: 0.0469\n",
      "\n",
      "Batch 3/299 ━━━━━━━━━━━━━━━━━━━━ 13:14:12\n",
      "Accuracy: 0.9667 - Precision: 0.0165 - Recall: 0.0125 - Specificity: 0.9928 - F1: 0.0142 - Loss: 0.0390\n",
      "\n",
      "Batch 4/299 ━━━━━━━━━━━━━━━━━━━━ 13:14:21\n",
      "Accuracy: 0.9690 - Precision: 0.0123 - Recall: 0.0094 - Specificity: 0.9946 - F1: 0.0107 - Loss: 0.0338\n",
      "\n",
      "Batch 5/299 ━━━━━━━━━━━━━━━━━━━━ 13:14:29\n",
      "Accuracy: 0.9693 - Precision: 0.0099 - Recall: 0.0075 - Specificity: 0.9957 - F1: 0.0085 - Loss: 0.0303\n",
      "\n",
      "Batch 6/299 ━━━━━━━━━━━━━━━━━━━━ 13:14:38\n",
      "Accuracy: 0.9714 - Precision: 0.0082 - Recall: 0.0062 - Specificity: 0.9964 - F1: 0.0071 - Loss: 0.0272\n",
      "\n",
      "Batch 7/299 ━━━━━━━━━━━━━━━━━━━━ 13:14:48\n",
      "Accuracy: 0.9716 - Precision: 0.0071 - Recall: 0.0054 - Specificity: 0.9969 - F1: 0.0061 - Loss: 0.0253\n",
      "\n",
      "Batch 8/299 ━━━━━━━━━━━━━━━━━━━━ 13:14:58\n",
      "Accuracy: 0.9719 - Precision: 0.0062 - Recall: 0.0047 - Specificity: 0.9973 - F1: 0.0053 - Loss: 0.0237\n",
      "\n",
      "Batch 9/299 ━━━━━━━━━━━━━━━━━━━━ 13:15:08\n",
      "Accuracy: 0.9725 - Precision: 0.0055 - Recall: 0.0042 - Specificity: 0.9976 - F1: 0.0047 - Loss: 0.0224\n",
      "\n",
      "Batch 10/299 ━━━━━━━━━━━━━━━━━━━━ 13:15:21\n",
      "Accuracy: 0.9725 - Precision: 0.0049 - Recall: 0.0037 - Specificity: 0.9978 - F1: 0.0043 - Loss: 0.0216\n",
      "\n",
      "Batch 11/299 ━━━━━━━━━━━━━━━━━━━━ 13:15:31\n",
      "Accuracy: 0.9719 - Precision: 0.0045 - Recall: 0.0034 - Specificity: 0.9980 - F1: 0.0039 - Loss: 0.0210\n",
      "\n",
      "Batch 12/299 ━━━━━━━━━━━━━━━━━━━━ 13:15:39\n",
      "Accuracy: 0.9726 - Precision: 0.0041 - Recall: 0.0031 - Specificity: 0.9982 - F1: 0.0036 - Loss: 0.0202\n",
      "\n",
      "Batch 13/299 ━━━━━━━━━━━━━━━━━━━━ 13:15:48\n",
      "Accuracy: 0.9731 - Precision: 0.0038 - Recall: 0.0029 - Specificity: 0.9983 - F1: 0.0033 - Loss: 0.0195\n",
      "\n",
      "Batch 14/299 ━━━━━━━━━━━━━━━━━━━━ 13:15:56\n",
      "Accuracy: 0.9732 - Precision: 0.0035 - Recall: 0.0027 - Specificity: 0.9985 - F1: 0.0030 - Loss: 0.0191\n",
      "\n",
      "Batch 15/299 ━━━━━━━━━━━━━━━━━━━━ 13:16:06\n",
      "Accuracy: 0.9726 - Precision: 0.0033 - Recall: 0.0025 - Specificity: 0.9986 - F1: 0.0028 - Loss: 0.0188\n",
      "\n",
      "Batch 16/299 ━━━━━━━━━━━━━━━━━━━━ 13:16:16\n",
      "Accuracy: 0.9729 - Precision: 0.0031 - Recall: 0.0023 - Specificity: 0.9987 - F1: 0.0027 - Loss: 0.0184\n",
      "\n",
      "Batch 17/299 ━━━━━━━━━━━━━━━━━━━━ 13:16:26\n",
      "Accuracy: 0.9724 - Precision: 0.0029 - Recall: 0.0022 - Specificity: 0.9987 - F1: 0.0025 - Loss: 0.0182\n",
      "\n",
      "Batch 18/299 ━━━━━━━━━━━━━━━━━━━━ 13:16:34\n",
      "Accuracy: 0.9726 - Precision: 0.0027 - Recall: 0.0021 - Specificity: 0.9988 - F1: 0.0024 - Loss: 0.0178\n",
      "\n",
      "Batch 19/299 ━━━━━━━━━━━━━━━━━━━━ 13:16:43\n",
      "Accuracy: 0.9730 - Precision: 0.0026 - Recall: 0.0020 - Specificity: 0.9989 - F1: 0.0022 - Loss: 0.0174\n",
      "\n",
      "Batch 20/299 ━━━━━━━━━━━━━━━━━━━━ 13:16:53\n",
      "Accuracy: 0.9732 - Precision: 0.0025 - Recall: 0.0019 - Specificity: 0.9989 - F1: 0.0021 - Loss: 0.0170\n",
      "\n",
      "Batch 21/299 ━━━━━━━━━━━━━━━━━━━━ 13:17:04\n",
      "Accuracy: 0.9733 - Precision: 0.0024 - Recall: 0.0018 - Specificity: 0.9990 - F1: 0.0020 - Loss: 0.0167\n",
      "\n",
      "Batch 22/299 ━━━━━━━━━━━━━━━━━━━━ 13:17:14\n",
      "Accuracy: 0.9734 - Precision: 0.0022 - Recall: 0.0017 - Specificity: 0.9990 - F1: 0.0019 - Loss: 0.0165\n",
      "\n",
      "Batch 23/299 ━━━━━━━━━━━━━━━━━━━━ 13:17:26\n",
      "Accuracy: 0.9734 - Precision: 0.0021 - Recall: 0.0016 - Specificity: 0.9991 - F1: 0.0019 - Loss: 0.0162\n",
      "\n",
      "Batch 24/299 ━━━━━━━━━━━━━━━━━━━━ 13:17:37\n",
      "Accuracy: 0.9735 - Precision: 0.0021 - Recall: 0.0016 - Specificity: 0.9991 - F1: 0.0018 - Loss: 0.0160\n",
      "\n",
      "Batch 25/299 ━━━━━━━━━━━━━━━━━━━━ 13:17:48\n",
      "Accuracy: 0.9730 - Precision: 0.0020 - Recall: 0.0015 - Specificity: 0.9991 - F1: 0.0017 - Loss: 0.0160\n",
      "\n",
      "Batch 26/299 ━━━━━━━━━━━━━━━━━━━━ 13:17:59\n",
      "Accuracy: 0.9730 - Precision: 0.0019 - Recall: 0.0014 - Specificity: 0.9992 - F1: 0.0016 - Loss: 0.0158\n",
      "\n",
      "Batch 27/299 ━━━━━━━━━━━━━━━━━━━━ 13:18:09\n",
      "Accuracy: 0.9733 - Precision: 0.0018 - Recall: 0.0014 - Specificity: 0.9992 - F1: 0.0016 - Loss: 0.0156\n",
      "\n",
      "Batch 28/299 ━━━━━━━━━━━━━━━━━━━━ 13:18:17\n",
      "Accuracy: 0.9733 - Precision: 0.0018 - Recall: 0.0013 - Specificity: 0.9992 - F1: 0.0015 - Loss: 0.0154\n",
      "\n",
      "Batch 29/299 ━━━━━━━━━━━━━━━━━━━━ 13:18:30\n",
      "Accuracy: 0.9735 - Precision: 0.0017 - Recall: 0.0013 - Specificity: 0.9993 - F1: 0.0015 - Loss: 0.0152\n",
      "\n",
      "Batch 30/299 ━━━━━━━━━━━━━━━━━━━━ 13:18:42\n",
      "Accuracy: 0.9735 - Precision: 0.0016 - Recall: 0.0012 - Specificity: 0.9993 - F1: 0.0014 - Loss: 0.0151\n",
      "\n",
      "Batch 31/299 ━━━━━━━━━━━━━━━━━━━━ 13:18:52\n",
      "Accuracy: 0.9735 - Precision: 0.0016 - Recall: 0.0012 - Specificity: 0.9993 - F1: 0.0014 - Loss: 0.0149\n",
      "\n",
      "Batch 32/299 ━━━━━━━━━━━━━━━━━━━━ 13:19:02\n",
      "Accuracy: 0.9734 - Precision: 0.0015 - Recall: 0.0012 - Specificity: 0.9993 - F1: 0.0013 - Loss: 0.0148\n",
      "\n",
      "Batch 33/299 ━━━━━━━━━━━━━━━━━━━━ 13:19:13\n",
      "Accuracy: 0.9734 - Precision: 0.0015 - Recall: 0.0011 - Specificity: 0.9993 - F1: 0.0013 - Loss: 0.0146\n",
      "\n",
      "Batch 34/299 ━━━━━━━━━━━━━━━━━━━━ 13:19:25\n",
      "Accuracy: 0.9736 - Precision: 0.0015 - Recall: 0.0011 - Specificity: 0.9994 - F1: 0.0013 - Loss: 0.0144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import backend as K\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime  # Import datetime for the custom callback\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.callbacks import EarlyStopping  # Import EarlyStopping\n",
    "from tensorflow.keras.applications import VGG16  # Import VGG16 for the new model\n",
    "\n",
    "# Directory paths\n",
    "train_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\train\"\n",
    "train_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\train\\train_mask\"\n",
    "test_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\test\"\n",
    "test_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\test\\test_mask\"\n",
    "valid_img_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\valid\"\n",
    "valid_mask_dir = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\ImageSegmentation\\Datasets\\Dental_XRay_Computacional_Vision_Segmentation\\Dental X_Ray\\valid\\valid_mask\"\n",
    "\n",
    "# U-Net model replaced with VGG16-based model\n",
    "def vgg16_unet_model(input_size=(256, 256, 3)):\n",
    "    # Load VGG16 as the encoder with pre-trained ImageNet weights\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=input_size)\n",
    "    \n",
    "    # Freeze VGG16 layers to prevent them from being trained\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Extract layers for skip connections\n",
    "    block1 = vgg16.get_layer('block1_pool').output   # 128x128\n",
    "    block2 = vgg16.get_layer('block2_pool').output   # 64x64\n",
    "    block3 = vgg16.get_layer('block3_pool').output   # 32x32\n",
    "    block4 = vgg16.get_layer('block4_pool').output   # 16x16\n",
    "    block5 = vgg16.get_layer('block5_pool').output   # 8x8\n",
    "    \n",
    "    # Decoder\n",
    "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(block5)  # 16x16\n",
    "    u6 = layers.concatenate([u6, block4])\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "    \n",
    "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)  # 32x32\n",
    "    u7 = layers.concatenate([u7, block3])\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "    \n",
    "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)  # 64x64\n",
    "    u8 = layers.concatenate([u8, block2])\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "    \n",
    "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)    # 128x128\n",
    "    u9 = layers.concatenate([u9, block1])\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "    \n",
    "    # Final upsampling to reach original image size\n",
    "    u10 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c9)  # 256x256\n",
    "    c10 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u10)\n",
    "    c10 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c10)\n",
    "    \n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c10)\n",
    "    \n",
    "    model = models.Model(inputs=vgg16.input, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Load images and masks\n",
    "def load_images_and_masks(img_dir, mask_dir, img_size=(256, 256)):\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    img_files = os.listdir(img_dir)\n",
    "    for img_file in img_files:\n",
    "        img_path = os.path.join(img_dir, img_file)\n",
    "        # Adjust mask filename to include \"_mask.png\"\n",
    "        mask_file = img_file + \"_mask.png\"\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "        if os.path.exists(mask_path):\n",
    "            # Load image as RGB\n",
    "            img = load_img(img_path, color_mode='rgb', target_size=img_size)\n",
    "            img = img_to_array(img) / 255.0\n",
    "            # Load mask as grayscale\n",
    "            mask = load_img(mask_path, color_mode='grayscale', target_size=img_size)\n",
    "            mask = img_to_array(mask) / 255.0\n",
    "\n",
    "            images.append(img)\n",
    "            masks.append(mask)\n",
    "        else:\n",
    "            print(f\"Mask not found for {img_file}, skipping this image.\")\n",
    "    \n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Load training and validation data\n",
    "X_train, y_train = load_images_and_masks(train_img_dir, train_mask_dir)\n",
    "X_valid, y_valid = load_images_and_masks(valid_img_dir, valid_mask_dir)\n",
    "\n",
    "# Define custom metrics\n",
    "def custom_precision(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_positives = K.sum(K.round(y_true * y_pred_bin))\n",
    "    predicted_positives = K.sum(y_pred_bin)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def custom_recall(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_positives = K.sum(K.round(y_true * y_pred_bin))\n",
    "    possible_positives = K.sum(y_true)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def custom_specificity(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)\n",
    "    true_negatives = K.sum(K.round((1 - y_true) * (1 - y_pred_bin)))\n",
    "    possible_negatives = K.sum(1 - y_true)\n",
    "    specificity = true_negatives / (possible_negatives + K.epsilon())\n",
    "    return specificity\n",
    "\n",
    "def custom_f1(y_true, y_pred):\n",
    "    precision = custom_precision(y_true, y_pred)\n",
    "    recall = custom_recall(y_true, y_pred)\n",
    "    return 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "\n",
    "# Define Focal Loss\n",
    "def focal_loss_fixed(y_true, y_pred):\n",
    "    gamma = 2.0\n",
    "    alpha = 0.25\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    cross_entropy = -y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred)\n",
    "    weight = alpha * y_true * K.pow((1 - y_pred), gamma) + (1 - alpha) * (1 - y_true) * K.pow(y_pred, gamma)\n",
    "    loss = weight * cross_entropy\n",
    "    return K.mean(loss)\n",
    "\n",
    "# Compile the model\n",
    "model = vgg16_unet_model()\n",
    "model.compile(optimizer='adam', loss=focal_loss_fixed, metrics=['accuracy', custom_precision, custom_recall, custom_specificity, custom_f1])\n",
    "\n",
    "# Batch size for training\n",
    "batch_size = 16\n",
    "\n",
    "# Calculate total batches for training\n",
    "total_batches = int(np.ceil(len(X_train) / batch_size))\n",
    "\n",
    "# Custom callback to print more metrics at each batch with epoch tracking\n",
    "class MetricsCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, total_batches):\n",
    "        super().__init__()\n",
    "        self.batch_counter = 1  # Initialize the batch counter\n",
    "        self.total_batches = total_batches  # Total number of batches per epoch\n",
    "        self.current_epoch = 1  # Initialize current epoch\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.current_epoch = epoch + 1  # Epochs are zero-indexed\n",
    "        print(f\"\\nEpoch {self.current_epoch}/{self.params['epochs']}\")\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        accuracy = logs.get('accuracy', 0)\n",
    "        loss = logs.get('loss', 0)\n",
    "        precision = logs.get('custom_precision', 0)\n",
    "        recall = logs.get('custom_recall', 0)\n",
    "        f1 = logs.get('custom_f1', 0)\n",
    "        specificity = logs.get('custom_specificity', 0)\n",
    "        \n",
    "        # Time formatting for current step\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        # Print the metrics with proper formatting\n",
    "        print(f\"Batch {self.batch_counter}/{self.total_batches} ━━━━━━━━━━━━━━━━━━━━ {current_time}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f} - Precision: {precision:.4f} - Recall: {recall:.4f} - Specificity: {specificity:.4f} - F1: {f1:.4f} - Loss: {loss:.4f}\\n\")\n",
    "        \n",
    "        # Increment batch counter\n",
    "        self.batch_counter += 1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Reset batch counter at the end of each epoch\n",
    "        self.batch_counter = 1\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',        # Metric to monitor\n",
    "    patience=5,                # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored metric\n",
    ")\n",
    "\n",
    "# Initialize the custom callback\n",
    "metrics_callback = MetricsCallback(total_batches=total_batches)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,               # Number of epochs\n",
    "    batch_size=batch_size,   # Batch size of 16\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[metrics_callback, early_stopping],  # Add early_stopping to the callbacks list\n",
    "    verbose=0                # Suppress default Keras logging\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('dental_xray_vgg16_unet_model.h5')\n",
    "\n",
    "# Load test data\n",
    "X_test, y_test = load_images_and_masks(test_img_dir, test_mask_dir)\n",
    "\n",
    "# Evaluate on the training set\n",
    "y_train_pred = model.predict(X_train, batch_size=batch_size)\n",
    "y_train_pred_bin = (y_train_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "# Confusion Matrix for training\n",
    "conf_matrix_train = confusion_matrix(y_train.flatten(), y_train_pred_bin.flatten())\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_train, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix for Train\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_valid_pred = model.predict(X_valid, batch_size=batch_size)\n",
    "y_valid_pred_bin = (y_valid_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "# Confusion Matrix for validation\n",
    "conf_matrix_valid = confusion_matrix(y_valid.flatten(), y_valid_pred_bin.flatten())\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_valid, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix for Validation\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred = model.predict(X_test, batch_size=batch_size)\n",
    "y_test_pred_bin = (y_test_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "# Confusion Matrix for testing\n",
    "conf_matrix_test = confusion_matrix(y_test.flatten(), y_test_pred_bin.flatten())\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_test, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix for Test\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Performance report for training set\n",
    "train_accuracy = accuracy_score(y_train.flatten(), y_train_pred_bin.flatten())\n",
    "train_recall = recall_score(y_train.flatten(), y_train_pred_bin.flatten())\n",
    "train_precision = precision_score(y_train.flatten(), y_train_pred_bin.flatten())\n",
    "train_f1 = f1_score(y_train.flatten(), y_train_pred_bin.flatten())\n",
    "train_tn, train_fp, train_fn, train_tp = confusion_matrix(y_train.flatten(), y_train_pred_bin.flatten()).ravel()\n",
    "train_specificity = train_tn / (train_tn + train_fp)\n",
    "\n",
    "print(f'Training Set Results:')\n",
    "print(f'Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Recall (Sensitivity): {train_recall:.4f}')\n",
    "print(f'Precision: {train_precision:.4f}')\n",
    "print(f'F1 Score: {train_f1:.4f}')\n",
    "print(f'Specificity: {train_specificity:.4f}')\n",
    "\n",
    "# Performance report for validation set\n",
    "valid_accuracy = accuracy_score(y_valid.flatten(), y_valid_pred_bin.flatten())\n",
    "valid_recall = recall_score(y_valid.flatten(), y_valid_pred_bin.flatten())\n",
    "valid_precision = precision_score(y_valid.flatten(), y_valid_pred_bin.flatten())\n",
    "valid_f1 = f1_score(y_valid.flatten(), y_valid_pred_bin.flatten())\n",
    "valid_tn, valid_fp, valid_fn, valid_tp = confusion_matrix(y_valid.flatten(), y_valid_pred_bin.flatten()).ravel()\n",
    "valid_specificity = valid_tn / (valid_tn + valid_fp)\n",
    "\n",
    "print(f'Validation Set Results:')\n",
    "print(f'Accuracy: {valid_accuracy:.4f}')\n",
    "print(f'Recall (Sensitivity): {valid_recall:.4f}')\n",
    "print(f'Precision: {valid_precision:.4f}')\n",
    "print(f'F1 Score: {valid_f1:.4f}')\n",
    "print(f'Specificity: {valid_specificity:.4f}')\n",
    "\n",
    "# Performance report for testing set\n",
    "test_accuracy = accuracy_score(y_test.flatten(), y_test_pred_bin.flatten())\n",
    "test_recall = recall_score(y_test.flatten(), y_test_pred_bin.flatten())\n",
    "test_precision = precision_score(y_test.flatten(), y_test_pred_bin.flatten())\n",
    "test_f1 = f1_score(y_test.flatten(), y_test_pred_bin.flatten())\n",
    "test_tn, test_fp, test_fn, test_tp = confusion_matrix(y_test.flatten(), y_test_pred_bin.flatten()).ravel()\n",
    "test_specificity = test_tn / (test_tn + test_fp)\n",
    "\n",
    "print(f'Testing Set Results:')\n",
    "print(f'Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Recall (Sensitivity): {test_recall:.4f}')\n",
    "print(f'Precision: {test_precision:.4f}')\n",
    "print(f'F1 Score: {test_f1:.4f}')\n",
    "print(f'Specificity: {test_specificity:.4f}')\n",
    "\n",
    "# Visualization: Show input image, true mask, and predicted mask for a few samples\n",
    "def visualize_predictions(images, true_masks, pred_masks, title):\n",
    "    for i in range(3):  # Visualize first 3 predictions\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # Original image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "        \n",
    "        # Ground truth mask\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(true_masks[i].squeeze(), cmap='gray')\n",
    "        plt.title('Ground Truth Mask')\n",
    "        \n",
    "        # Predicted mask\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(pred_masks[i].squeeze(), cmap='gray')\n",
    "        plt.title('Predicted Mask')\n",
    "        \n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "\n",
    "# Visualize predictions for training set\n",
    "visualize_predictions(X_train, y_train, y_train_pred_bin, \"Train Set Predictions\")\n",
    "\n",
    "# Visualize predictions for validation set\n",
    "visualize_predictions(X_valid, y_valid, y_valid_pred_bin, \"Validation Set Predictions\")\n",
    "\n",
    "# Visualize predictions for testing set\n",
    "visualize_predictions(X_test, y_test, y_test_pred_bin, \"Test Set Predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea259b0c-ffec-4429-8b43-54bf1821226c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
